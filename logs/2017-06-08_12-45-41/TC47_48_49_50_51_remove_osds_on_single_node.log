2017-06-08 12:45:42,037 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. remove the osd one by one on the first node
4. check the status
5. create osd on the node

2017-06-08 12:45:42,954 INFO monitors.py [line:126]    "quorum_leader_name": "CW113",
stdin: is not a tty

2017-06-08 12:45:42,954 INFO monitors.py [line:129]    "quorum_leader_name": "CW113",
2017-06-08 12:45:44,959 INFO node.py [line:97] init osd on node CW113
2017-06-08 12:45:45,188 INFO node.py [line:112] osd.0  ---> processId 
2017-06-08 12:45:45,189 INFO node.py [line:112] osd.1  ---> processId 
2017-06-08 12:45:45,189 INFO node.py [line:112] osd.2  ---> processId 
2017-06-08 12:45:45,189 INFO node.py [line:112] osd.3  ---> processId 
2017-06-08 12:45:45,189 INFO node.py [line:112] osd.4  ---> processId 
2017-06-08 12:45:45,189 INFO osd.py [line:28] node is  CW113
2017-06-08 12:45:45,189 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=0 & sleep 3
2017-06-08 12:45:48,363 ERROR osd.py [line:34] Error when shutdown osdosd.0
2017-06-08 12:45:48,363 ERROR osd.py [line:35] sudo -i stop ceph-osd id=0 & sleep 3
2017-06-08 12:45:48,363 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/0

2017-06-08 12:45:53,369 INFO osd.py [line:102] node is  CW113
2017-06-08 12:45:53,369 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-08 12:46:23,587 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-08 12:46:23,587 INFO osd.py [line:28] node is  CW113
2017-06-08 12:46:23,587 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=1 & sleep 3
2017-06-08 12:46:26,793 ERROR osd.py [line:34] Error when shutdown osdosd.1
2017-06-08 12:46:26,793 ERROR osd.py [line:35] sudo -i stop ceph-osd id=1 & sleep 3
2017-06-08 12:46:26,794 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/1

2017-06-08 12:46:31,799 INFO osd.py [line:102] node is  CW113
2017-06-08 12:46:31,799 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-08 12:47:02,005 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-08 12:47:02,005 INFO osd.py [line:28] node is  CW113
2017-06-08 12:47:02,005 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=2 & sleep 3
2017-06-08 12:47:05,174 ERROR osd.py [line:34] Error when shutdown osdosd.2
2017-06-08 12:47:05,174 ERROR osd.py [line:35] sudo -i stop ceph-osd id=2 & sleep 3
2017-06-08 12:47:05,175 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/2

2017-06-08 12:47:10,180 INFO osd.py [line:102] node is  CW113
2017-06-08 12:47:10,180 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-08 12:47:40,368 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-08 12:47:40,368 INFO osd.py [line:28] node is  CW113
2017-06-08 12:47:40,368 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=3 & sleep 3
2017-06-08 12:47:43,586 ERROR osd.py [line:34] Error when shutdown osdosd.3
2017-06-08 12:47:43,586 ERROR osd.py [line:35] sudo -i stop ceph-osd id=3 & sleep 3
2017-06-08 12:47:43,587 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/3

2017-06-08 12:47:48,592 INFO osd.py [line:102] node is  CW113
2017-06-08 12:47:48,592 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 3 & sleep 30
2017-06-08 12:48:18,746 INFO osd.py [line:107] osd osd.3 is start successfully
2017-06-08 12:48:18,746 INFO osd.py [line:28] node is  CW113
2017-06-08 12:48:18,746 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=4 & sleep 3
2017-06-08 12:48:21,931 ERROR osd.py [line:34] Error when shutdown osdosd.4
2017-06-08 12:48:21,932 ERROR osd.py [line:35] sudo -i stop ceph-osd id=4 & sleep 3
2017-06-08 12:48:21,932 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/4

2017-06-08 12:48:26,937 INFO osd.py [line:102] node is  CW113
2017-06-08 12:48:26,937 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 4 & sleep 30
2017-06-08 12:48:57,123 INFO osd.py [line:107] osd osd.4 is start successfully
2017-06-08 12:48:57,366 INFO node.py [line:133] osd.0  ---> processId 7179
2017-06-08 12:48:57,366 INFO node.py [line:133] osd.1  ---> processId 16470
2017-06-08 12:48:57,366 INFO node.py [line:133] osd.2  ---> processId 27281
2017-06-08 12:48:57,366 INFO node.py [line:133] osd.3  ---> processId 38312
2017-06-08 12:48:57,366 INFO node.py [line:133] osd.4  ---> processId 48478
2017-06-08 12:48:57,366 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 12:48:57,778 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e140: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v19301: 3072 pgs, 11 pools, 51699 MB data, 12966 objects
            213 GB used, 8876 GB / 9089 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 12:48:57,779 INFO cluster.py [line:238] PG number is 3072
2017-06-08 12:48:57,779 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 12:48:57,779 INFO cluster.py [line:302] osd on node CW113 were init successfully
2017-06-08 12:48:57,780 INFO node.py [line:97] init osd on node CW114
2017-06-08 12:48:58,059 INFO node.py [line:112] osd.5  ---> processId 
2017-06-08 12:48:58,059 INFO node.py [line:112] osd.6  ---> processId 
2017-06-08 12:48:58,060 INFO node.py [line:112] osd.7  ---> processId 
2017-06-08 12:48:58,060 INFO osd.py [line:28] node is  CW114
2017-06-08 12:48:58,060 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=5 & sleep 3
2017-06-08 12:49:01,245 ERROR osd.py [line:34] Error when shutdown osdosd.5
2017-06-08 12:49:01,245 ERROR osd.py [line:35] sudo -i stop ceph-osd id=5 & sleep 3
2017-06-08 12:49:01,245 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/5

2017-06-08 12:49:06,251 INFO osd.py [line:102] node is  CW114
2017-06-08 12:49:06,251 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 5 & sleep 30
2017-06-08 12:49:36,404 INFO osd.py [line:107] osd osd.5 is start successfully
2017-06-08 12:49:36,404 INFO osd.py [line:28] node is  CW114
2017-06-08 12:49:36,404 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=6 & sleep 3
2017-06-08 12:49:39,620 ERROR osd.py [line:34] Error when shutdown osdosd.6
2017-06-08 12:49:39,620 ERROR osd.py [line:35] sudo -i stop ceph-osd id=6 & sleep 3
2017-06-08 12:49:39,621 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/6

2017-06-08 12:49:44,626 INFO osd.py [line:102] node is  CW114
2017-06-08 12:49:44,626 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 6 & sleep 30
2017-06-08 12:50:15,002 INFO osd.py [line:107] osd osd.6 is start successfully
2017-06-08 12:50:15,002 INFO osd.py [line:28] node is  CW114
2017-06-08 12:50:15,002 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=7 & sleep 3
2017-06-08 12:50:18,186 ERROR osd.py [line:34] Error when shutdown osdosd.7
2017-06-08 12:50:18,187 ERROR osd.py [line:35] sudo -i stop ceph-osd id=7 & sleep 3
2017-06-08 12:50:18,187 ERROR osd.py [line:36] tdin: is not a tty
stop: Unknown instance: ceph/7

2017-06-08 12:50:23,192 INFO osd.py [line:102] node is  CW114
2017-06-08 12:50:23,193 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 7 & sleep 30
2017-06-08 12:50:53,377 INFO osd.py [line:107] osd osd.7 is start successfully
2017-06-08 12:50:53,621 INFO node.py [line:133] osd.5  ---> processId 53644
2017-06-08 12:50:53,622 INFO node.py [line:133] osd.6  ---> processId 55633
2017-06-08 12:50:53,622 INFO node.py [line:133] osd.7  ---> processId 56245
2017-06-08 12:50:53,622 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 12:50:54,003 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e140: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v19301: 3072 pgs, 11 pools, 51699 MB data, 12966 objects
            213 GB used, 8876 GB / 9089 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 12:50:54,003 INFO cluster.py [line:238] PG number is 3072
2017-06-08 12:50:54,003 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 12:50:54,004 INFO cluster.py [line:302] osd on node CW114 were init successfully
2017-06-08 12:50:54,004 INFO node.py [line:97] init osd on node CW115
2017-06-08 12:50:54,273 INFO node.py [line:112] osd.8  ---> processId 23402
2017-06-08 12:50:54,274 INFO node.py [line:112] osd.9  ---> processId 24327
2017-06-08 12:50:54,285 INFO node.py [line:112] osd.10  ---> processId 25500
2017-06-08 12:50:54,285 INFO node.py [line:112] osd.11  ---> processId 26427
2017-06-08 12:50:54,285 INFO node.py [line:112] osd.12  ---> processId 27359
2017-06-08 12:50:54,285 INFO osd.py [line:28] node is  CW115
2017-06-08 12:50:54,285 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=8 & sleep 3
2017-06-08 12:50:59,417 INFO osd.py [line:32] osd osd.8 is shutdown successfully
2017-06-08 12:51:04,422 INFO osd.py [line:102] node is  CW115
2017-06-08 12:51:04,422 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 8 & sleep 30
2017-06-08 12:51:34,608 INFO osd.py [line:107] osd osd.8 is start successfully
2017-06-08 12:51:34,608 INFO osd.py [line:28] node is  CW115
2017-06-08 12:51:34,609 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=9 & sleep 3
2017-06-08 12:51:39,198 INFO osd.py [line:32] osd osd.9 is shutdown successfully
2017-06-08 12:51:44,203 INFO osd.py [line:102] node is  CW115
2017-06-08 12:51:44,204 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 9 & sleep 30
2017-06-08 12:52:14,389 INFO osd.py [line:107] osd osd.9 is start successfully
2017-06-08 12:52:14,389 INFO osd.py [line:28] node is  CW115
2017-06-08 12:52:14,390 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=10 & sleep 3
2017-06-08 12:52:18,939 INFO osd.py [line:32] osd osd.10 is shutdown successfully
2017-06-08 12:52:23,944 INFO osd.py [line:102] node is  CW115
2017-06-08 12:52:23,944 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 10 & sleep 30
2017-06-08 12:52:54,130 INFO osd.py [line:107] osd osd.10 is start successfully
2017-06-08 12:52:54,130 INFO osd.py [line:28] node is  CW115
2017-06-08 12:52:54,130 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=11 & sleep 3
2017-06-08 12:52:59,042 INFO osd.py [line:32] osd osd.11 is shutdown successfully
2017-06-08 12:53:04,047 INFO osd.py [line:102] node is  CW115
2017-06-08 12:53:04,047 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 11 & sleep 30
2017-06-08 12:53:34,233 INFO osd.py [line:107] osd osd.11 is start successfully
2017-06-08 12:53:34,233 INFO osd.py [line:28] node is  CW115
2017-06-08 12:53:34,233 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=12 & sleep 3
2017-06-08 12:53:39,074 INFO osd.py [line:32] osd osd.12 is shutdown successfully
2017-06-08 12:53:44,080 INFO osd.py [line:102] node is  CW115
2017-06-08 12:53:44,080 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 12 & sleep 30
2017-06-08 12:54:14,233 INFO osd.py [line:107] osd osd.12 is start successfully
2017-06-08 12:54:14,441 INFO node.py [line:133] osd.8  ---> processId 22260
2017-06-08 12:54:14,441 INFO node.py [line:133] osd.9  ---> processId 25379
2017-06-08 12:54:14,441 INFO node.py [line:133] osd.10  ---> processId 28935
2017-06-08 12:54:14,441 INFO node.py [line:133] osd.11  ---> processId 31826
2017-06-08 12:54:14,441 INFO node.py [line:133] osd.12  ---> processId 35028
2017-06-08 12:54:14,441 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 12:54:14,825 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e167: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v19410: 3072 pgs, 11 pools, 51699 MB data, 12966 objects
            213 GB used, 8876 GB / 9089 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 12:54:14,825 INFO cluster.py [line:238] PG number is 3072
2017-06-08 12:54:14,825 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 12:54:14,825 INFO cluster.py [line:302] osd on node CW115 were init successfully
2017-06-08 12:54:14,826 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:30] start to check cluster status before case running
2017-06-08 12:54:16,831 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 12:54:17,263 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e167: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v19410: 3072 pgs, 11 pools, 51699 MB data, 12966 objects
            213 GB used, 8876 GB / 9089 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 12:54:17,263 INFO cluster.py [line:238] PG number is 3072
2017-06-08 12:54:17,263 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 12:54:17,263 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:33] health status is OK
2017-06-08 12:54:17,264 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:38] 
Step1: Check IO from clients
2017-06-08 12:54:17,735 INFO client.py [line:172] ['enali   142667 142646  0 04:54 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   142669 142667  0 04:54 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-08 12:54:17,735 INFO client.py [line:177] IO stopped
2017-06-08 12:54:17,735 INFO client.py [line:178] start IO again
2017-06-08 12:54:17,735 INFO base.py [line:37] 
Now start IO on  client103rbdImg0
2017-06-08 12:54:18,062 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg0 -rw=randwrite -bs=8K -size=100G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg0
2017-06-08 12:54:18,307 INFO base.py [line:37] 
Now start IO on  client103rbdImg1
2017-06-08 12:54:18,528 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg1 -rw=randwrite -bs=8K -size=200G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg1
2017-06-08 12:54:18,756 INFO base.py [line:37] 
Now start IO on  client103rbdImg2
2017-06-08 12:54:18,981 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg2 -rw=randwrite -bs=8K -size=300G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg2
2017-06-08 12:54:19,222 INFO base.py [line:37] 
Now start IO on  client103rbdImg3
2017-06-08 12:54:19,573 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg3 -rw=randwrite -bs=8K -size=400G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg3
2017-06-08 12:54:19,815 INFO base.py [line:37] 
Now start IO on  client103rbdImg4
2017-06-08 12:54:20,040 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg4
2017-06-08 12:54:20,464 INFO node.py [line:159] /var/lib/jenkins/workspace/AutoRun/config/changeCommon.sh
2017-06-08 12:54:20,464 INFO node.py [line:161] /var/lib/jenkins/workspace/AutoRun/config/updateCephConfig.sh
2017-06-08 12:54:21,496 INFO osd.py [line:40] execute command is sudo -i kill -9 7179 & sleep 3
2017-06-08 12:54:25,534 INFO osd.py [line:89] node is  CW113
2017-06-08 12:54:25,534 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=0 & sleep 30
2017-06-08 12:54:55,756 ERROR osd.py [line:96] Error when start osdosd.0
2017-06-08 12:54:55,756 ERROR osd.py [line:97] sudo -i start ceph-osd id=0 & sleep 30
2017-06-08 12:54:55,757 ERROR osd.py [line:98] eph-osd (ceph/0) start/running, process 21016
stdin: is not a tty

2017-06-08 12:54:55,757 INFO osd.py [line:40] execute command is sudo -i kill -9 16470 & sleep 3
2017-06-08 12:54:58,978 INFO osd.py [line:89] node is  CW113
2017-06-08 12:54:58,978 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=1 & sleep 30
2017-06-08 12:55:29,163 ERROR osd.py [line:96] Error when start osdosd.1
2017-06-08 12:55:29,163 ERROR osd.py [line:97] sudo -i start ceph-osd id=1 & sleep 30
2017-06-08 12:55:29,163 ERROR osd.py [line:98] eph-osd (ceph/1) start/running, process 23561
stdin: is not a tty

2017-06-08 12:55:29,163 INFO osd.py [line:40] execute command is sudo -i kill -9 27281 & sleep 3
2017-06-08 12:55:32,385 INFO osd.py [line:89] node is  CW113
2017-06-08 12:55:32,386 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=2 & sleep 30
2017-06-08 12:56:02,537 ERROR osd.py [line:96] Error when start osdosd.2
2017-06-08 12:56:02,537 ERROR osd.py [line:97] sudo -i start ceph-osd id=2 & sleep 30
2017-06-08 12:56:02,537 ERROR osd.py [line:98] eph-osd (ceph/2) start/running, process 26247
stdin: is not a tty

2017-06-08 12:56:02,538 INFO osd.py [line:40] execute command is sudo -i kill -9 38312 & sleep 3
2017-06-08 12:56:05,788 INFO osd.py [line:89] node is  CW113
2017-06-08 12:56:05,789 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=3 & sleep 30
2017-06-08 12:56:35,975 ERROR osd.py [line:96] Error when start osdosd.3
2017-06-08 12:56:35,975 ERROR osd.py [line:97] sudo -i start ceph-osd id=3 & sleep 30
2017-06-08 12:56:35,975 ERROR osd.py [line:98] eph-osd (ceph/3) start/running, process 28984
stdin: is not a tty

2017-06-08 12:56:35,975 INFO osd.py [line:40] execute command is sudo -i kill -9 48478 & sleep 3
2017-06-08 12:56:39,197 INFO osd.py [line:89] node is  CW113
2017-06-08 12:56:39,197 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=4 & sleep 30
2017-06-08 12:57:09,351 ERROR osd.py [line:96] Error when start osdosd.4
2017-06-08 12:57:09,351 ERROR osd.py [line:97] sudo -i start ceph-osd id=4 & sleep 30
2017-06-08 12:57:09,351 ERROR osd.py [line:98] eph-osd (ceph/4) start/running, process 31811
stdin: is not a tty

2017-06-08 12:58:09,374 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:52] 
Step2: remove osd and create them 10 times
2017-06-08 12:58:09,595 INFO node.py [line:185] 0
2017-06-08 12:58:09,595 INFO node.py [line:192] nvme2n1
2017-06-08 12:58:09,595 INFO node.py [line:185] 0
2017-06-08 12:58:09,596 INFO node.py [line:192] nvme2n1
2017-06-08 12:58:09,596 INFO node.py [line:185] 0
2017-06-08 12:58:09,596 INFO node.py [line:192] nvme2n1
2017-06-08 12:58:09,596 INFO node.py [line:185] 1
2017-06-08 12:58:09,596 INFO node.py [line:192] nvme1n1
2017-06-08 12:58:09,596 INFO node.py [line:185] 1
2017-06-08 12:58:09,596 INFO node.py [line:192] nvme1n1
2017-06-08 12:58:09,596 INFO node.py [line:185] 1
2017-06-08 12:58:09,597 INFO node.py [line:192] nvme1n1
2017-06-08 12:58:09,597 INFO node.py [line:185] 2
2017-06-08 12:58:09,597 INFO node.py [line:192] nvme4n1
2017-06-08 12:58:09,597 INFO node.py [line:185] 2
2017-06-08 12:58:09,597 INFO node.py [line:192] nvme4n1
2017-06-08 12:58:09,597 INFO node.py [line:185] 2
2017-06-08 12:58:09,597 INFO node.py [line:192] nvme4n1
2017-06-08 12:58:09,597 INFO node.py [line:185] 3
2017-06-08 12:58:09,598 INFO node.py [line:192] nvme0n1
2017-06-08 12:58:09,598 INFO node.py [line:185] 3
2017-06-08 12:58:09,598 INFO node.py [line:192] nvme0n1
2017-06-08 12:58:09,598 INFO node.py [line:185] 3
2017-06-08 12:58:09,598 INFO node.py [line:192] nvme0n1
2017-06-08 12:58:09,598 INFO node.py [line:185] 4
2017-06-08 12:58:09,598 INFO node.py [line:192] nvme3n1
2017-06-08 12:58:09,598 INFO node.py [line:185] 4
2017-06-08 12:58:09,598 INFO node.py [line:192] nvme3n1
2017-06-08 12:58:09,599 INFO node.py [line:185] 4
2017-06-08 12:58:09,599 INFO node.py [line:192] nvme3n1
2017-06-08 12:58:09,599 INFO node.py [line:185] 
2017-06-08 12:58:09,599 INFO node.py [line:192] nvme3n1
2017-06-08 12:58:09,599 INFO node.py [line:200] osd.0  ---> disk nvme2n1
2017-06-08 12:58:09,599 INFO node.py [line:200] osd.1  ---> disk nvme1n1
2017-06-08 12:58:09,599 INFO node.py [line:200] osd.2  ---> disk nvme4n1
2017-06-08 12:58:09,599 INFO node.py [line:200] osd.3  ---> disk nvme0n1
2017-06-08 12:58:09,600 INFO node.py [line:200] osd.4  ---> disk nvme3n1
2017-06-08 12:58:09,600 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node CW113 
2017-06-08 12:58:09,600 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-08 13:23:37,747 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 13:23:38,116 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e475: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v20850: 3072 pgs, 11 pools, 1538 GB data, 387 kobjects
            901 GB used, 7488 GB / 8390 GB avail
                3072 active+clean
  client io 49680 kB/s wr, 0 op/s rd, 6210 op/s wr
stdin: is not a tty

2017-06-08 13:23:38,117 INFO cluster.py [line:238] PG number is 3072
2017-06-08 13:23:38,117 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 13:23:38,117 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-08 13:23:38,117 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-08 14:28:38,521 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 14:28:38,853 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e864: 11 osds: 11 up, 11 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v24375: 3072 pgs, 11 pools, 1548 GB data, 388 kobjects
            1605 GB used, 6085 GB / 7691 GB avail
                3072 active+clean
  client io 13572 kB/s rd, 113 MB/s wr, 1817 op/s rd, 14587 op/s wr
stdin: is not a tty

2017-06-08 14:28:38,853 INFO cluster.py [line:238] PG number is 3072
2017-06-08 14:28:38,853 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 14:28:38,853 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-08 14:28:38,854 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-08 15:33:14,999 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 15:33:15,378 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e1353: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28000: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            1872 GB used, 5120 GB / 6992 GB avail
                3072 active+clean
  client io 106 kB/s rd, 88347 kB/s wr, 160 op/s rd, 11043 op/s wr
stdin: is not a tty

2017-06-08 15:33:15,379 INFO cluster.py [line:238] PG number is 3072
2017-06-08 15:33:15,379 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 15:33:15,379 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-08 15:33:15,379 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme0n1
2017-06-08 17:22:47,055 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 17:22:47,473 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e1889: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33800: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2076 GB used, 4216 GB / 6293 GB avail
                3072 active+clean
  client io 68410 kB/s rd, 8551 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 17:22:47,473 INFO cluster.py [line:238] PG number is 3072
2017-06-08 17:22:47,473 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 17:22:47,473 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-08 17:22:47,473 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-08 18:10:04,601 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:10:05,032 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2357: 8 osds: 8 up, 8 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36329: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2066 GB used, 3526 GB / 5593 GB avail
                3072 active+clean
  client io 50489 kB/s rd, 6512 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:10:05,032 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:10:05,032 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 18:10:05,032 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-08 18:10:07,069 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node CW113 delete succesfully
2017-06-08 18:10:07,069 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node CW113 
2017-06-08 18:10:07,070 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-08 18:10:18,947 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-08 18:10:18,947 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-08 18:10:18,948 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:10:19,319 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/9 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2359: 9 osds: 8 up, 9 in; 989 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36341: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2066 GB used, 3526 GB / 5593 GB avail
                3072 active+clean
  client io 31906 kB/s rd, 4038 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:10:19,319 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:10:19,319 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 18:10:19,319 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-08 18:10:19,320 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-08 18:10:30,901 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-08 18:10:30,902 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-08 18:10:30,902 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:10:31,376 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            257 pgs backfill_wait
            2 pgs backfilling
            30 pgs degraded
            30 pgs recovery_wait
            79 pgs stuck unclean
            Difference in osd space utilization 49.5161% greater than 40%
            recovery 69/987482 objects degraded (0.007%)
            recovery 343822/987482 objects misplaced (34.818%)
            1/10 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2367: 10 osds: 9 up, 10 in; 939 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36353: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2076 GB used, 4216 GB / 6293 GB avail
            69/987482 objects degraded (0.007%)
            343822/987482 objects misplaced (34.818%)
                2783 active+clean
                 257 active+remapped+backfill_wait
                  30 active+recovery_wait+degraded
                   2 active+remapped+backfilling
  client io 74436 B/s rd, 72 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:10:31,377 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:10:31,377 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-08 18:11:31,401 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-08 18:11:31,401 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:11:31,791 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            399 pgs backfill_wait
            2 pgs backfilling
            35 pgs degraded
            35 pgs recovery_wait
            149 pgs stuck unclean
            Difference in osd space utilization 49.7606% greater than 40%
            recovery 92/1073606 objects degraded (0.009%)
            recovery 514962/1073606 objects misplaced (47.966%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2374: 10 osds: 10 up, 10 in; 401 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36407: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            92/1073606 objects degraded (0.009%)
            514962/1073606 objects misplaced (47.966%)
                2635 active+clean
                 399 active+remapped+backfill_wait
                  35 active+recovery_wait+degraded
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing
  client io 11892 kB/s rd, 1529 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:11:31,792 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:11:31,792 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 18:12:31,809 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-08 18:12:31,809 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:12:32,225 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            395 pgs backfill_wait
            2 pgs backfilling
            4 pgs degraded
            4 pgs recovery_wait
            149 pgs stuck unclean
            Difference in osd space utilization 50.2137% greater than 40%
            recovery 10/1069739 objects degraded (0.001%)
            recovery 507364/1069739 objects misplaced (47.429%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2382: 10 osds: 10 up, 10 in; 397 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36466: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            10/1069739 objects degraded (0.001%)
            507364/1069739 objects misplaced (47.429%)
                2671 active+clean
                 395 active+remapped+backfill_wait
                   4 active+recovery_wait+degraded
                   2 active+remapped+backfilling
  client io 16727 kB/s rd, 2090 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:12:32,226 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:12:32,226 INFO cluster.py [line:239] usefull PG number is 2671
2017-06-08 18:13:32,286 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-08 18:13:32,286 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:13:32,723 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            388 pgs backfill_wait
            2 pgs backfilling
            163 pgs stuck unclean
            Difference in osd space utilization 50.5374% greater than 40%
            recovery 501597/1066405 objects misplaced (47.036%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2391: 10 osds: 10 up, 10 in; 390 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36524: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            501597/1066405 objects misplaced (47.036%)
                2682 active+clean
                 388 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 527 MB/s, 162 objects/s
  client io 17874 kB/s rd, 2234 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:13:32,723 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:13:32,723 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-08 18:14:32,727 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-08 18:14:32,727 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:14:33,112 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            382 pgs backfill_wait
            1 pgs backfilling
            163 pgs stuck unclean
            Difference in osd space utilization 50.8354% greater than 40%
            recovery 494942/1063146 objects misplaced (46.554%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2400: 10 osds: 10 up, 10 in; 383 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36580: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            494942/1063146 objects misplaced (46.554%)
                2689 active+clean
                 382 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 26178 kB/s rd, 3272 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:14:33,113 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:14:33,113 INFO cluster.py [line:239] usefull PG number is 2689
2017-06-08 18:15:33,130 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-08 18:15:33,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:15:33,555 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            380 pgs backfill_wait
            1 pgs backfilling
            381 pgs stuck unclean
            Difference in osd space utilization 51.0429% greater than 40%
            recovery 490619/1060789 objects misplaced (46.250%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2404: 10 osds: 10 up, 10 in; 381 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36636: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            490619/1060789 objects misplaced (46.250%)
                2691 active+clean
                 380 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 221 MB/s, 69 objects/s
  client io 18331 kB/s rd, 2291 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:15:33,555 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:15:33,555 INFO cluster.py [line:239] usefull PG number is 2691
2017-06-08 18:16:33,616 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-08 18:16:33,616 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:16:34,010 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            379 pgs backfill_wait
            1 pgs backfilling
            380 pgs stuck unclean
            Difference in osd space utilization 50.7779% greater than 40%
            recovery 488843/1060018 objects misplaced (46.116%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2406: 10 osds: 10 up, 10 in; 380 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36690: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            488843/1060018 objects misplaced (46.116%)
                2692 active+clean
                 379 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 28222 kB/s rd, 3527 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:16:34,010 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:16:34,010 INFO cluster.py [line:239] usefull PG number is 2692
2017-06-08 18:17:34,023 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-08 18:17:34,023 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:17:34,429 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            378 pgs backfill_wait
            1 pgs backfilling
            379 pgs stuck unclean
            Difference in osd space utilization 50.5137% greater than 40%
            recovery 487040/1059244 objects misplaced (45.980%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2408: 10 osds: 10 up, 10 in; 379 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36743: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            487040/1059244 objects misplaced (45.980%)
                2693 active+clean
                 378 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 21835 kB/s rd, 2729 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:17:34,429 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:17:34,429 INFO cluster.py [line:239] usefull PG number is 2693
2017-06-08 18:18:34,485 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-08 18:18:34,486 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:18:34,866 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            373 pgs backfill_wait
            374 pgs stuck unclean
            Difference in osd space utilization 50.2128% greater than 40%
            recovery 484133/1057499 objects misplaced (45.781%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2418: 10 osds: 10 up, 10 in; 373 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36802: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            484133/1057499 objects misplaced (45.781%)
                2698 active+clean
                 373 active+remapped+backfill_wait
                   1 active+remapped
recovery io 381 MB/s, 95 objects/s
  client io 20130 kB/s rd, 2516 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:18:34,867 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:18:34,867 INFO cluster.py [line:239] usefull PG number is 2698
2017-06-08 18:19:34,905 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-08 18:19:34,905 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:19:35,335 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            371 pgs backfill_wait
            1 pgs backfilling
            372 pgs stuck unclean
            Difference in osd space utilization 49.951% greater than 40%
            recovery 481584/1056669 objects misplaced (45.576%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2421: 10 osds: 10 up, 10 in; 372 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36855: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            481584/1056669 objects misplaced (45.576%)
                2700 active+clean
                 371 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 62369 kB/s rd, 7821 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:19:35,336 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:19:35,336 INFO cluster.py [line:239] usefull PG number is 2700
2017-06-08 18:20:35,369 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-08 18:20:35,369 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:20:35,759 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            369 pgs backfill_wait
            1 pgs backfilling
            370 pgs stuck unclean
            Difference in osd space utilization 49.6787% greater than 40%
            recovery 477048/1054338 objects misplaced (45.246%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2425: 10 osds: 10 up, 10 in; 370 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36911: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            477048/1054338 objects misplaced (45.246%)
                2702 active+clean
                 369 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 9780 kB/s rd, 1268 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:20:35,759 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:20:35,759 INFO cluster.py [line:239] usefull PG number is 2702
2017-06-08 18:21:35,785 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-08 18:21:35,785 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:21:36,169 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            365 pgs backfill_wait
            2 pgs backfilling
            367 pgs stuck unclean
            Difference in osd space utilization 49.1478% greater than 40%
            recovery 470439/1051219 objects misplaced (44.752%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2430: 10 osds: 10 up, 10 in; 367 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36966: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            470439/1051219 objects misplaced (44.752%)
                2705 active+clean
                 365 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 16168 kB/s rd, 2062 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:21:36,169 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:21:36,169 INFO cluster.py [line:239] usefull PG number is 2705
2017-06-08 18:22:36,199 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-08 18:22:36,200 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:22:36,598 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            363 pgs backfill_wait
            1 pgs backfilling
            364 pgs stuck unclean
            Difference in osd space utilization 48.8889% greater than 40%
            recovery 464272/1048215 objects misplaced (44.292%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2437: 10 osds: 10 up, 10 in; 363 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37024: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            464272/1048215 objects misplaced (44.292%)
                2708 active+clean
                 363 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 62900 B/s rd, 61 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:22:36,598 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:22:36,598 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-08 18:23:36,658 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-08 18:23:36,658 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:23:37,076 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            360 pgs backfill_wait
            1 pgs backfilling
            361 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 460554/1045793 objects misplaced (44.039%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2442: 10 osds: 10 up, 10 in; 361 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37079: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            460554/1045793 objects misplaced (44.039%)
                2711 active+clean
                 360 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 23808 kB/s rd, 3054 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:23:37,076 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:23:37,076 INFO cluster.py [line:239] usefull PG number is 2711
2017-06-08 18:24:37,088 INFO cluster.py [line:247] cost 61 seconds, left 5153 seconds when check the ceph status
2017-06-08 18:24:37,089 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:24:37,511 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            359 pgs backfill_wait
            1 pgs backfilling
            360 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 458554/1045026 objects misplaced (43.880%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2444: 10 osds: 10 up, 10 in; 360 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37133: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            458554/1045026 objects misplaced (43.880%)
                2712 active+clean
                 359 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 245 MB/s, 76 objects/s
  client io 43141 kB/s rd, 5484 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:24:37,512 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:24:37,512 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-08 18:25:37,536 INFO cluster.py [line:247] cost 60 seconds, left 5093 seconds when check the ceph status
2017-06-08 18:25:37,537 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:25:37,940 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            357 pgs backfill_wait
            1 pgs backfilling
            358 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 456015/1043514 objects misplaced (43.700%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2448: 10 osds: 10 up, 10 in; 358 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37190: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            456015/1043514 objects misplaced (43.700%)
                2714 active+clean
                 357 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 31899 kB/s rd, 4006 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:25:37,940 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:25:37,940 INFO cluster.py [line:239] usefull PG number is 2714
2017-06-08 18:26:37,967 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-08 18:26:37,967 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:26:38,372 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            356 pgs backfill_wait
            1 pgs backfilling
            357 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 453436/1042752 objects misplaced (43.485%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2450: 10 osds: 10 up, 10 in; 357 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37245: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            453436/1042752 objects misplaced (43.485%)
                2715 active+clean
                 356 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 10823 B/s rd, 15 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:26:38,373 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:26:38,373 INFO cluster.py [line:239] usefull PG number is 2715
2017-06-08 18:27:38,433 INFO cluster.py [line:247] cost 61 seconds, left 4972 seconds when check the ceph status
2017-06-08 18:27:38,433 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:27:38,863 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            354 pgs backfill_wait
            1 pgs backfilling
            355 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 447841/1039670 objects misplaced (43.075%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2454: 10 osds: 10 up, 10 in; 355 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37300: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            447841/1039670 objects misplaced (43.075%)
                2717 active+clean
                 354 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 237 MB/s, 73 objects/s
  client io 10640 B/s rd, 15 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:27:38,863 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:27:38,863 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-08 18:28:38,881 INFO cluster.py [line:247] cost 60 seconds, left 4912 seconds when check the ceph status
2017-06-08 18:28:38,881 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:28:39,277 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            351 pgs backfill_wait
            1 pgs backfilling
            352 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 445106/1038093 objects misplaced (42.877%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2459: 10 osds: 10 up, 10 in; 352 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37354: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            445106/1038093 objects misplaced (42.877%)
                2720 active+clean
                 351 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 234 MB/s, 72 objects/s
  client io 15340 B/s rd, 22 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:28:39,278 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:28:39,278 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-08 18:29:39,290 INFO cluster.py [line:247] cost 61 seconds, left 4851 seconds when check the ceph status
2017-06-08 18:29:39,290 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:29:39,657 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            350 pgs backfill_wait
            1 pgs backfilling
            351 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 443213/1037334 objects misplaced (42.726%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2461: 10 osds: 10 up, 10 in; 351 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37408: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            443213/1037334 objects misplaced (42.726%)
                2721 active+clean
                 350 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 297 MB/s, 93 objects/s
  client io 5341 B/s rd, 7 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 18:29:39,657 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:29:39,657 INFO cluster.py [line:239] usefull PG number is 2721
2017-06-08 18:30:39,701 INFO cluster.py [line:247] cost 60 seconds, left 4791 seconds when check the ceph status
2017-06-08 18:30:39,701 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:30:40,099 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            348 pgs backfill_wait
            1 pgs backfilling
            349 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 440605/1035764 objects misplaced (42.539%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2465: 10 osds: 10 up, 10 in; 349 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37455: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            440605/1035764 objects misplaced (42.539%)
                2723 active+clean
                 348 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:30:40,100 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:30:40,100 INFO cluster.py [line:239] usefull PG number is 2723
2017-06-08 18:31:40,160 INFO cluster.py [line:247] cost 61 seconds, left 4730 seconds when check the ceph status
2017-06-08 18:31:40,160 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:31:40,562 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            347 pgs backfill_wait
            1 pgs backfilling
            348 pgs stuck unclean
            Difference in osd space utilization 48.8571% greater than 40%
            recovery 438574/1034973 objects misplaced (42.375%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2467: 10 osds: 10 up, 10 in; 348 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37496: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            438574/1034973 objects misplaced (42.375%)
                2724 active+clean
                 347 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 251 MB/s, 76 objects/s
stdin: is not a tty

2017-06-08 18:31:40,562 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:31:40,562 INFO cluster.py [line:239] usefull PG number is 2724
2017-06-08 18:32:40,623 INFO cluster.py [line:247] cost 60 seconds, left 4670 seconds when check the ceph status
2017-06-08 18:32:40,623 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:32:41,029 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            344 pgs backfill_wait
            1 pgs backfilling
            345 pgs stuck unclean
            Difference in osd space utilization 48.5689% greater than 40%
            recovery 435761/1033361 objects misplaced (42.169%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2472: 10 osds: 10 up, 10 in; 345 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37547: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            435761/1033361 objects misplaced (42.169%)
                2727 active+clean
                 344 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:32:41,030 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:32:41,030 INFO cluster.py [line:239] usefull PG number is 2727
2017-06-08 18:33:41,083 INFO cluster.py [line:247] cost 61 seconds, left 4609 seconds when check the ceph status
2017-06-08 18:33:41,083 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:33:41,490 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            342 pgs backfill_wait
            1 pgs backfilling
            343 pgs stuck unclean
            Difference in osd space utilization 48.5387% greater than 40%
            recovery 433789/1032537 objects misplaced (42.012%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2475: 10 osds: 10 up, 10 in; 343 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37589: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            433789/1032537 objects misplaced (42.012%)
                2729 active+clean
                 342 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:33:41,491 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:33:41,491 INFO cluster.py [line:239] usefull PG number is 2729
2017-06-08 18:34:41,551 INFO cluster.py [line:247] cost 60 seconds, left 4549 seconds when check the ceph status
2017-06-08 18:34:41,551 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:34:41,940 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            339 pgs backfill_wait
            340 pgs stuck unclean
            Difference in osd space utilization 48.5387% greater than 40%
            recovery 431058/1030954 objects misplaced (41.812%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2482: 10 osds: 10 up, 10 in; 339 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37631: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            431058/1030954 objects misplaced (41.812%)
                2732 active+clean
                 339 active+remapped+backfill_wait
                   1 active+remapped
stdin: is not a tty

2017-06-08 18:34:41,941 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:34:41,941 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-08 18:35:41,971 INFO cluster.py [line:247] cost 60 seconds, left 4489 seconds when check the ceph status
2017-06-08 18:35:41,971 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:35:42,391 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            337 pgs backfill_wait
            1 pgs backfilling
            338 pgs stuck unclean
            Difference in osd space utilization 48.5387% greater than 40%
            recovery 429100/1030155 objects misplaced (41.654%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2484: 10 osds: 10 up, 10 in; 338 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37675: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            429100/1030155 objects misplaced (41.654%)
                2734 active+clean
                 337 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 275 MB/s, 86 objects/s
stdin: is not a tty

2017-06-08 18:35:42,391 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:35:42,391 INFO cluster.py [line:239] usefull PG number is 2734
2017-06-08 18:36:42,429 INFO cluster.py [line:247] cost 61 seconds, left 4428 seconds when check the ceph status
2017-06-08 18:36:42,429 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:36:42,846 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            335 pgs backfill_wait
            1 pgs backfilling
            336 pgs stuck unclean
            Difference in osd space utilization 48.5164% greater than 40%
            recovery 427181/1029351 objects misplaced (41.500%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2488: 10 osds: 10 up, 10 in; 336 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37720: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            427181/1029351 objects misplaced (41.500%)
                2736 active+clean
                 335 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 298 MB/s, 92 objects/s
stdin: is not a tty

2017-06-08 18:36:42,846 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:36:42,846 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-08 18:37:42,907 INFO cluster.py [line:247] cost 60 seconds, left 4368 seconds when check the ceph status
2017-06-08 18:37:42,907 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:37:43,359 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            332 pgs backfill_wait
            1 pgs backfilling
            333 pgs stuck unclean
            Difference in osd space utilization 48.2864% greater than 40%
            recovery 424273/1027678 objects misplaced (41.285%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2494: 10 osds: 10 up, 10 in; 333 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37765: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            424273/1027678 objects misplaced (41.285%)
                2739 active+clean
                 332 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:37:43,359 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:37:43,359 INFO cluster.py [line:239] usefull PG number is 2739
2017-06-08 18:38:43,375 INFO cluster.py [line:247] cost 61 seconds, left 4307 seconds when check the ceph status
2017-06-08 18:38:43,375 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:38:43,765 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            330 pgs backfill_wait
            1 pgs backfilling
            331 pgs stuck unclean
            Difference in osd space utilization 48.2864% greater than 40%
            recovery 422306/1026857 objects misplaced (41.126%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2498: 10 osds: 10 up, 10 in; 331 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37810: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            422306/1026857 objects misplaced (41.126%)
                2741 active+clean
                 330 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 174 MB/s, 53 objects/s
stdin: is not a tty

2017-06-08 18:38:43,765 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:38:43,766 INFO cluster.py [line:239] usefull PG number is 2741
2017-06-08 18:39:43,815 INFO cluster.py [line:247] cost 60 seconds, left 4247 seconds when check the ceph status
2017-06-08 18:39:43,816 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:39:44,214 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            326 pgs backfill_wait
            1 pgs backfilling
            327 pgs stuck unclean
            Difference in osd space utilization 48.2864% greater than 40%
            recovery 419476/1025194 objects misplaced (40.917%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2503: 10 osds: 10 up, 10 in; 327 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37855: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            419476/1025194 objects misplaced (40.917%)
                2745 active+clean
                 326 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 280 MB/s, 84 objects/s
stdin: is not a tty

2017-06-08 18:39:44,214 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:39:44,214 INFO cluster.py [line:239] usefull PG number is 2745
2017-06-08 18:40:44,230 INFO cluster.py [line:247] cost 61 seconds, left 4186 seconds when check the ceph status
2017-06-08 18:40:44,230 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:40:44,621 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            325 pgs backfill_wait
            1 pgs backfilling
            326 pgs stuck unclean
            Difference in osd space utilization 48.014% greater than 40%
            recovery 417501/1024461 objects misplaced (40.753%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2507: 10 osds: 10 up, 10 in; 325 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37894: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            417501/1024461 objects misplaced (40.753%)
                2746 active+clean
                 325 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:40:44,621 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:40:44,621 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-08 18:41:44,646 INFO cluster.py [line:247] cost 60 seconds, left 4126 seconds when check the ceph status
2017-06-08 18:41:44,646 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:41:45,065 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            323 pgs backfill_wait
            1 pgs backfilling
            324 pgs stuck unclean
            Difference in osd space utilization 48.014% greater than 40%
            recovery 414748/1022927 objects misplaced (40.545%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2509: 10 osds: 10 up, 10 in; 324 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37939: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            414748/1022927 objects misplaced (40.545%)
                2748 active+clean
                 323 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 169 MB/s, 53 objects/s
stdin: is not a tty

2017-06-08 18:41:45,065 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:41:45,065 INFO cluster.py [line:239] usefull PG number is 2748
2017-06-08 18:42:45,107 INFO cluster.py [line:247] cost 61 seconds, left 4065 seconds when check the ceph status
2017-06-08 18:42:45,108 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:42:45,467 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            321 pgs backfill_wait
            1 pgs backfilling
            322 pgs stuck unclean
            Difference in osd space utilization 47.7464% greater than 40%
            recovery 412813/1022084 objects misplaced (40.389%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2513: 10 osds: 10 up, 10 in; 322 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37985: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            412813/1022084 objects misplaced (40.389%)
                2750 active+clean
                 321 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 184 MB/s, 58 objects/s
stdin: is not a tty

2017-06-08 18:42:45,468 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:42:45,468 INFO cluster.py [line:239] usefull PG number is 2750
2017-06-08 18:43:45,528 INFO cluster.py [line:247] cost 60 seconds, left 4005 seconds when check the ceph status
2017-06-08 18:43:45,528 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:43:45,965 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            319 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            320 pgs stuck unclean
            Difference in osd space utilization 47.7464% greater than 40%
            recovery 410311/1020578 objects misplaced (40.204%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2517: 10 osds: 10 up, 10 in; 320 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38028: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            410311/1020578 objects misplaced (40.204%)
                2751 active+clean
                 319 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:43:45,965 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:43:45,966 INFO cluster.py [line:239] usefull PG number is 2751
2017-06-08 18:44:46,026 INFO cluster.py [line:247] cost 61 seconds, left 3944 seconds when check the ceph status
2017-06-08 18:44:46,026 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:44:46,403 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            318 pgs backfill_wait
            1 pgs backfilling
            319 pgs stuck unclean
            Difference in osd space utilization 47.7464% greater than 40%
            recovery 408089/1019752 objects misplaced (40.018%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2519: 10 osds: 10 up, 10 in; 319 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38071: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            408089/1019752 objects misplaced (40.018%)
                2753 active+clean
                 318 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 434 MB/s, 134 objects/s
stdin: is not a tty

2017-06-08 18:44:46,404 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:44:46,404 INFO cluster.py [line:239] usefull PG number is 2753
2017-06-08 18:45:46,433 INFO cluster.py [line:247] cost 60 seconds, left 3884 seconds when check the ceph status
2017-06-08 18:45:46,433 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:45:46,862 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            313 pgs backfill_wait
            1 pgs backfilling
            314 pgs stuck unclean
            Difference in osd space utilization 47.4643% greater than 40%
            recovery 405234/1018048 objects misplaced (39.805%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2528: 10 osds: 10 up, 10 in; 314 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38121: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            405234/1018048 objects misplaced (39.805%)
                2758 active+clean
                 313 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 167 MB/s, 52 objects/s
stdin: is not a tty

2017-06-08 18:45:46,862 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:45:46,862 INFO cluster.py [line:239] usefull PG number is 2758
2017-06-08 18:46:46,922 INFO cluster.py [line:247] cost 60 seconds, left 3824 seconds when check the ceph status
2017-06-08 18:46:46,923 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:46:47,276 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            312 pgs backfill_wait
            1 pgs backfilling
            313 pgs stuck unclean
            Difference in osd space utilization 47.4643% greater than 40%
            recovery 403395/1017255 objects misplaced (39.655%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2530: 10 osds: 10 up, 10 in; 313 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38165: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            403395/1017255 objects misplaced (39.655%)
                2759 active+clean
                 312 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 198 MB/s, 61 objects/s
stdin: is not a tty

2017-06-08 18:46:47,276 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:46:47,276 INFO cluster.py [line:239] usefull PG number is 2759
2017-06-08 18:47:47,336 INFO cluster.py [line:247] cost 61 seconds, left 3763 seconds when check the ceph status
2017-06-08 18:47:47,337 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:47:47,753 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            308 pgs backfill_wait
            1 pgs backfilling
            309 pgs stuck unclean
            Difference in osd space utilization 47.4643% greater than 40%
            recovery 398816/1014832 objects misplaced (39.299%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2537: 10 osds: 10 up, 10 in; 309 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38211: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4905 GB / 6992 GB avail
            398816/1014832 objects misplaced (39.299%)
                2763 active+clean
                 308 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 430 MB/s, 145 objects/s
stdin: is not a tty

2017-06-08 18:47:47,754 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:47:47,754 INFO cluster.py [line:239] usefull PG number is 2763
2017-06-08 18:48:47,808 INFO cluster.py [line:247] cost 60 seconds, left 3703 seconds when check the ceph status
2017-06-08 18:48:47,808 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:48:48,203 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            306 pgs backfill_wait
            1 pgs backfilling
            307 pgs stuck unclean
            Difference in osd space utilization 47.1887% greater than 40%
            recovery 396278/1013925 objects misplaced (39.084%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2540: 10 osds: 10 up, 10 in; 307 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38255: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            396278/1013925 objects misplaced (39.084%)
                2765 active+clean
                 306 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 258 MB/s, 86 objects/s
stdin: is not a tty

2017-06-08 18:48:48,204 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:48:48,204 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-08 18:49:48,237 INFO cluster.py [line:247] cost 61 seconds, left 3642 seconds when check the ceph status
2017-06-08 18:49:48,237 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:49:48,651 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            304 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            305 pgs stuck unclean
            Difference in osd space utilization 46.9281% greater than 40%
            recovery 392463/1011658 objects misplaced (38.794%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2544: 10 osds: 10 up, 10 in; 305 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38300: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            392463/1011658 objects misplaced (38.794%)
                2766 active+clean
                 304 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 392 MB/s, 121 objects/s
stdin: is not a tty

2017-06-08 18:49:48,651 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:49:48,651 INFO cluster.py [line:239] usefull PG number is 2766
2017-06-08 18:50:48,697 INFO cluster.py [line:247] cost 60 seconds, left 3582 seconds when check the ceph status
2017-06-08 18:50:48,697 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:50:49,093 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            303 pgs backfill_wait
            1 pgs backfilling
            304 pgs stuck unclean
            Difference in osd space utilization 46.6645% greater than 40%
            recovery 390292/1010879 objects misplaced (38.609%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2546: 10 osds: 10 up, 10 in; 304 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38345: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            390292/1010879 objects misplaced (38.609%)
                2768 active+clean
                 303 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 385 MB/s, 129 objects/s
stdin: is not a tty

2017-06-08 18:50:49,093 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:50:49,093 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-08 18:51:49,123 INFO cluster.py [line:247] cost 61 seconds, left 3521 seconds when check the ceph status
2017-06-08 18:51:49,124 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:51:49,626 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            301 pgs backfill_wait
            1 pgs backfilling
            302 pgs stuck unclean
            Difference in osd space utilization 46.6645% greater than 40%
            recovery 386096/1008597 objects misplaced (38.281%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2550: 10 osds: 10 up, 10 in; 302 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38391: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            386096/1008597 objects misplaced (38.281%)
                2770 active+clean
                 301 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 127 MB/s, 39 objects/s
stdin: is not a tty

2017-06-08 18:51:49,626 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:51:49,627 INFO cluster.py [line:239] usefull PG number is 2770
2017-06-08 18:52:49,682 INFO cluster.py [line:247] cost 60 seconds, left 3461 seconds when check the ceph status
2017-06-08 18:52:49,682 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:52:50,086 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            300 pgs backfill_wait
            1 pgs backfilling
            301 pgs stuck unclean
            Difference in osd space utilization 46.6645% greater than 40%
            recovery 384205/1007842 objects misplaced (38.122%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2552: 10 osds: 10 up, 10 in; 301 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38431: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            384205/1007842 objects misplaced (38.122%)
                2771 active+clean
                 300 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 241 MB/s, 74 objects/s
stdin: is not a tty

2017-06-08 18:52:50,086 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:52:50,086 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-08 18:53:50,130 INFO cluster.py [line:247] cost 61 seconds, left 3400 seconds when check the ceph status
2017-06-08 18:53:50,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:53:50,558 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            297 pgs backfill_wait
            1 pgs backfilling
            298 pgs stuck unclean
            Difference in osd space utilization 46.1086% greater than 40%
            recovery 378426/1004687 objects misplaced (37.666%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2558: 10 osds: 10 up, 10 in; 298 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38485: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            378426/1004687 objects misplaced (37.666%)
                2774 active+clean
                 297 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:53:50,558 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:53:50,559 INFO cluster.py [line:239] usefull PG number is 2774
2017-06-08 18:54:50,608 INFO cluster.py [line:247] cost 60 seconds, left 3340 seconds when check the ceph status
2017-06-08 18:54:50,608 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:54:50,985 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            296 pgs backfill_wait
            1 pgs backfilling
            297 pgs stuck unclean
            Difference in osd space utilization 46.1086% greater than 40%
            recovery 376555/1003938 objects misplaced (37.508%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2560: 10 osds: 10 up, 10 in; 297 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38528: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            376555/1003938 objects misplaced (37.508%)
                2775 active+clean
                 296 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 261 MB/s, 79 objects/s
stdin: is not a tty

2017-06-08 18:54:50,986 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:54:50,986 INFO cluster.py [line:239] usefull PG number is 2775
2017-06-08 18:55:51,025 INFO cluster.py [line:247] cost 61 seconds, left 3279 seconds when check the ceph status
2017-06-08 18:55:51,025 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:55:51,423 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            294 pgs backfill_wait
            1 pgs backfilling
            295 pgs stuck unclean
            Difference in osd space utilization 46.1086% greater than 40%
            recovery 371882/1001569 objects misplaced (37.130%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2564: 10 osds: 10 up, 10 in; 295 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38579: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            371882/1001569 objects misplaced (37.130%)
                2777 active+clean
                 294 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:55:51,424 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:55:51,424 INFO cluster.py [line:239] usefull PG number is 2777
2017-06-08 18:56:51,442 INFO cluster.py [line:247] cost 60 seconds, left 3219 seconds when check the ceph status
2017-06-08 18:56:51,443 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:56:51,850 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            290 pgs backfill_wait
            1 pgs backfilling
            291 pgs stuck unclean
            Difference in osd space utilization 46.1315% greater than 40%
            recovery 369658/1000564 objects misplaced (36.945%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2572: 10 osds: 10 up, 10 in; 291 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38628: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            369658/1000564 objects misplaced (36.945%)
                2781 active+clean
                 290 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 252 MB/s, 78 objects/s
stdin: is not a tty

2017-06-08 18:56:51,850 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:56:51,851 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-08 18:57:51,910 INFO cluster.py [line:247] cost 60 seconds, left 3159 seconds when check the ceph status
2017-06-08 18:57:51,910 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:57:52,302 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            287 pgs backfill_wait
            1 pgs backfilling
            288 pgs stuck unclean
            Difference in osd space utilization 45.844% greater than 40%
            recovery 366674/998938 objects misplaced (36.706%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2577: 10 osds: 10 up, 10 in; 288 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38669: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            366674/998938 objects misplaced (36.706%)
                2784 active+clean
                 287 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 125 MB/s, 38 objects/s
stdin: is not a tty

2017-06-08 18:57:52,302 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:57:52,302 INFO cluster.py [line:239] usefull PG number is 2784
2017-06-08 18:58:52,345 INFO cluster.py [line:247] cost 61 seconds, left 3098 seconds when check the ceph status
2017-06-08 18:58:52,346 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:58:52,759 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            286 pgs backfill_wait
            1 pgs backfilling
            287 pgs stuck unclean
            Difference in osd space utilization 45.844% greater than 40%
            recovery 364881/998189 objects misplaced (36.554%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2580: 10 osds: 10 up, 10 in; 286 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38702: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            364881/998189 objects misplaced (36.554%)
                2785 active+clean
                 286 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 18:58:52,760 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:58:52,760 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-08 18:59:52,816 INFO cluster.py [line:247] cost 60 seconds, left 3038 seconds when check the ceph status
2017-06-08 18:59:52,817 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 18:59:53,239 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            283 pgs backfill_wait
            2 pgs backfilling
            285 pgs stuck unclean
            Difference in osd space utilization 45.844% greater than 40%
            recovery 361548/996645 objects misplaced (36.277%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2583: 10 osds: 10 up, 10 in; 285 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38745: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            361548/996645 objects misplaced (36.277%)
                2787 active+clean
                 283 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 173 MB/s, 54 objects/s
stdin: is not a tty

2017-06-08 18:59:53,240 INFO cluster.py [line:238] PG number is 3072
2017-06-08 18:59:53,240 INFO cluster.py [line:239] usefull PG number is 2787
2017-06-08 19:00:53,300 INFO cluster.py [line:247] cost 61 seconds, left 2977 seconds when check the ceph status
2017-06-08 19:00:53,300 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:00:53,689 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            279 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            281 pgs stuck unclean
            Difference in osd space utilization 45.5809% greater than 40%
            recovery 357751/994297 objects misplaced (35.980%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2593: 10 osds: 10 up, 10 in; 280 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38791: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            357751/994297 objects misplaced (35.980%)
                2790 active+clean
                 279 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 63755 kB/s, 19 objects/s
stdin: is not a tty

2017-06-08 19:00:53,689 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:00:53,690 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-08 19:01:53,743 INFO cluster.py [line:247] cost 60 seconds, left 2917 seconds when check the ceph status
2017-06-08 19:01:53,744 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:01:54,166 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            278 pgs backfill_wait
            1 pgs backfilling
            279 pgs stuck unclean
            Difference in osd space utilization 45.3023% greater than 40%
            recovery 355781/993431 objects misplaced (35.813%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2595: 10 osds: 10 up, 10 in; 279 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38828: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            355781/993431 objects misplaced (35.813%)
                2793 active+clean
                 278 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 269 MB/s, 82 objects/s
stdin: is not a tty

2017-06-08 19:01:54,166 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:01:54,166 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-08 19:02:54,205 INFO cluster.py [line:247] cost 61 seconds, left 2856 seconds when check the ceph status
2017-06-08 19:02:54,206 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:02:54,647 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            2 pgs backfilling
            276 pgs stuck unclean
            Difference in osd space utilization 45.0172% greater than 40%
            recovery 350905/991120 objects misplaced (35.405%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2601: 10 osds: 10 up, 10 in; 276 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38874: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            350905/991120 objects misplaced (35.405%)
                2796 active+clean
                 274 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 753 MB/s, 242 objects/s
stdin: is not a tty

2017-06-08 19:02:54,647 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:02:54,648 INFO cluster.py [line:239] usefull PG number is 2796
2017-06-08 19:03:54,708 INFO cluster.py [line:247] cost 60 seconds, left 2796 seconds when check the ceph status
2017-06-08 19:03:54,708 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:03:55,113 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            271 pgs backfill_wait
            1 pgs backfilling
            272 pgs stuck unclean
            Difference in osd space utilization 44.769% greater than 40%
            recovery 345874/988643 objects misplaced (34.985%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2607: 10 osds: 10 up, 10 in; 272 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38923: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            345874/988643 objects misplaced (34.985%)
                2800 active+clean
                 271 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 106 MB/s, 32 objects/s
stdin: is not a tty

2017-06-08 19:03:55,114 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:03:55,114 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-08 19:04:55,144 INFO cluster.py [line:247] cost 61 seconds, left 2735 seconds when check the ceph status
2017-06-08 19:04:55,144 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:04:55,579 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            266 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            267 pgs stuck unclean
            Difference in osd space utilization 44.7433% greater than 40%
            recovery 339653/985493 objects misplaced (34.465%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2615: 10 osds: 10 up, 10 in; 267 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38971: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            339653/985493 objects misplaced (34.465%)
                2804 active+clean
                 266 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:04:55,580 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:04:55,580 INFO cluster.py [line:239] usefull PG number is 2804
2017-06-08 19:05:55,610 INFO cluster.py [line:247] cost 60 seconds, left 2675 seconds when check the ceph status
2017-06-08 19:05:55,611 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:05:56,008 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            262 pgs backfill_wait
            1 pgs backfilling
            263 pgs stuck unclean
            Difference in osd space utilization 44.4123% greater than 40%
            recovery 336710/983807 objects misplaced (34.225%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2621: 10 osds: 10 up, 10 in; 263 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39015: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            336710/983807 objects misplaced (34.225%)
                2809 active+clean
                 262 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:05:56,008 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:05:56,009 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-08 19:06:56,069 INFO cluster.py [line:247] cost 61 seconds, left 2614 seconds when check the ceph status
2017-06-08 19:06:56,069 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:06:56,447 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            261 pgs backfill_wait
            1 pgs backfilling
            262 pgs stuck unclean
            Difference in osd space utilization 44.4123% greater than 40%
            recovery 334725/982964 objects misplaced (34.053%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2623: 10 osds: 10 up, 10 in; 262 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39053: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            334725/982964 objects misplaced (34.053%)
                2810 active+clean
                 261 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 135 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 19:06:56,447 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:06:56,447 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-08 19:07:56,486 INFO cluster.py [line:247] cost 60 seconds, left 2554 seconds when check the ceph status
2017-06-08 19:07:56,487 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:07:56,916 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            260 pgs backfill_wait
            1 pgs backfilling
            261 pgs stuck unclean
            Difference in osd space utilization 44.4123% greater than 40%
            recovery 332905/982212 objects misplaced (33.893%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2625: 10 osds: 10 up, 10 in; 261 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39091: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            332905/982212 objects misplaced (33.893%)
                2811 active+clean
                 260 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 101 MB/s, 31 objects/s
stdin: is not a tty

2017-06-08 19:07:56,916 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:07:56,916 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-08 19:08:56,977 INFO cluster.py [line:247] cost 60 seconds, left 2494 seconds when check the ceph status
2017-06-08 19:08:56,977 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:08:57,409 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            257 pgs backfill_wait
            1 pgs backfilling
            258 pgs stuck unclean
            Difference in osd space utilization 44.6963% greater than 40%
            recovery 327201/979051 objects misplaced (33.420%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2631: 10 osds: 10 up, 10 in; 258 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39140: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            327201/979051 objects misplaced (33.420%)
                2814 active+clean
                 257 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 739 MB/s, 243 objects/s
stdin: is not a tty

2017-06-08 19:08:57,409 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:08:57,410 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-08 19:09:57,470 INFO cluster.py [line:247] cost 61 seconds, left 2433 seconds when check the ceph status
2017-06-08 19:09:57,470 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:09:57,847 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            255 pgs backfill_wait
            1 pgs backfilling
            257 pgs stuck unclean
            Difference in osd space utilization 44.6963% greater than 40%
            recovery 324956/978288 objects misplaced (33.217%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2636: 10 osds: 10 up, 10 in; 255 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39179: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            324956/978288 objects misplaced (33.217%)
                2815 active+clean
                 255 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
recovery io 411 MB/s, 102 objects/s
stdin: is not a tty

2017-06-08 19:09:57,847 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:09:57,848 INFO cluster.py [line:239] usefull PG number is 2815
2017-06-08 19:10:57,881 INFO cluster.py [line:247] cost 60 seconds, left 2373 seconds when check the ceph status
2017-06-08 19:10:57,881 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:10:58,267 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            252 pgs backfill_wait
            1 pgs backfilling
            253 pgs stuck unclean
            Difference in osd space utilization 44.6963% greater than 40%
            recovery 319520/975223 objects misplaced (32.764%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2641: 10 osds: 10 up, 10 in; 253 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39224: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            319520/975223 objects misplaced (32.764%)
                2819 active+clean
                 252 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 339 MB/s, 106 objects/s
stdin: is not a tty

2017-06-08 19:10:58,267 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:10:58,267 INFO cluster.py [line:239] usefull PG number is 2819
2017-06-08 19:11:58,328 INFO cluster.py [line:247] cost 61 seconds, left 2312 seconds when check the ceph status
2017-06-08 19:11:58,328 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:11:58,720 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            250 pgs backfill_wait
            1 pgs backfilling
            251 pgs stuck unclean
            Difference in osd space utilization 44.6963% greater than 40%
            recovery 314254/972901 objects misplaced (32.301%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2645: 10 osds: 10 up, 10 in; 251 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39271: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            314254/972901 objects misplaced (32.301%)
                2821 active+clean
                 250 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 372 MB/s, 121 objects/s
stdin: is not a tty

2017-06-08 19:11:58,720 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:11:58,720 INFO cluster.py [line:239] usefull PG number is 2821
2017-06-08 19:12:58,758 INFO cluster.py [line:247] cost 60 seconds, left 2252 seconds when check the ceph status
2017-06-08 19:12:58,759 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:12:59,170 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            249 pgs backfill_wait
            1 pgs backfilling
            250 pgs stuck unclean
            Difference in osd space utilization 44.6963% greater than 40%
            recovery 311151/971339 objects misplaced (32.033%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2648: 10 osds: 10 up, 10 in; 249 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39308: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            311151/971339 objects misplaced (32.033%)
                2822 active+clean
                 249 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:12:59,170 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:12:59,170 INFO cluster.py [line:239] usefull PG number is 2822
2017-06-08 19:13:59,230 INFO cluster.py [line:247] cost 61 seconds, left 2191 seconds when check the ceph status
2017-06-08 19:13:59,231 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:13:59,647 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            245 pgs backfill_wait
            1 pgs backfilling
            246 pgs stuck unclean
            Difference in osd space utilization 44.7481% greater than 40%
            recovery 308250/969690 objects misplaced (31.789%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2655: 10 osds: 10 up, 10 in; 246 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39350: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            308250/969690 objects misplaced (31.789%)
                2826 active+clean
                 245 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:13:59,647 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:13:59,647 INFO cluster.py [line:239] usefull PG number is 2826
2017-06-08 19:14:59,690 INFO cluster.py [line:247] cost 60 seconds, left 2131 seconds when check the ceph status
2017-06-08 19:14:59,690 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:15:00,104 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            243 pgs backfill_wait
            2 pgs backfilling
            245 pgs stuck unclean
            Difference in osd space utilization 44.9559% greater than 40%
            recovery 304782/968188 objects misplaced (31.480%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2660: 10 osds: 10 up, 10 in; 243 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39392: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            304782/968188 objects misplaced (31.480%)
                2827 active+clean
                 243 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:15:00,104 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:15:00,104 INFO cluster.py [line:239] usefull PG number is 2827
2017-06-08 19:16:00,162 INFO cluster.py [line:247] cost 61 seconds, left 2070 seconds when check the ceph status
2017-06-08 19:16:00,162 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:16:00,638 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            236 pgs backfill_wait
            2 pgs backfilling
            238 pgs stuck unclean
            Difference in osd space utilization 44.6327% greater than 40%
            recovery 301690/966375 objects misplaced (31.219%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2672: 10 osds: 10 up, 10 in; 237 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39434: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            301690/966375 objects misplaced (31.219%)
                2834 active+clean
                 236 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:16:00,638 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:16:00,638 INFO cluster.py [line:239] usefull PG number is 2834
2017-06-08 19:17:00,690 INFO cluster.py [line:247] cost 60 seconds, left 2010 seconds when check the ceph status
2017-06-08 19:17:00,690 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:17:01,085 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            231 pgs backfill_wait
            2 pgs backfilling
            233 pgs stuck unclean
            Difference in osd space utilization 44.392% greater than 40%
            recovery 294673/963161 objects misplaced (30.594%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2681: 10 osds: 10 up, 10 in; 233 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39484: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            294673/963161 objects misplaced (30.594%)
                2839 active+clean
                 231 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 783 MB/s, 257 objects/s
stdin: is not a tty

2017-06-08 19:17:01,085 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:17:01,086 INFO cluster.py [line:239] usefull PG number is 2839
2017-06-08 19:18:01,146 INFO cluster.py [line:247] cost 61 seconds, left 1949 seconds when check the ceph status
2017-06-08 19:18:01,146 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:18:01,534 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            225 pgs backfill_wait
            2 pgs backfilling
            227 pgs stuck unclean
            Difference in osd space utilization 43.9916% greater than 40%
            recovery 287618/959326 objects misplaced (29.981%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2689: 10 osds: 10 up, 10 in; 227 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39532: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            287618/959326 objects misplaced (29.981%)
                2845 active+clean
                 225 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 234 MB/s, 73 objects/s
stdin: is not a tty

2017-06-08 19:18:01,534 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:18:01,534 INFO cluster.py [line:239] usefull PG number is 2845
2017-06-08 19:19:01,590 INFO cluster.py [line:247] cost 60 seconds, left 1889 seconds when check the ceph status
2017-06-08 19:19:01,590 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:19:01,979 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_ERR
            1 pgs are stuck inactive for more than 300 seconds
            222 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            1 pgs stuck inactive
            223 pgs stuck unclean
            Difference in osd space utilization 43.0244% greater than 40%
            recovery 277154/954673 objects misplaced (29.031%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2698: 10 osds: 10 up, 10 in; 221 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39584: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2090 GB used, 4901 GB / 6992 GB avail
            277154/954673 objects misplaced (29.031%)
                2848 active+clean
                 222 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:19:01,980 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-08 19:20:02,038 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:20:02,461 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            216 pgs backfill_wait
            2 pgs backfilling
            218 pgs stuck unclean
            Difference in osd space utilization 42.2337% greater than 40%
            recovery 271014/951540 objects misplaced (28.482%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2705: 10 osds: 10 up, 10 in; 218 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39626: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            271014/951540 objects misplaced (28.482%)
                2854 active+clean
                 216 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 408 MB/s, 135 objects/s
stdin: is not a tty

2017-06-08 19:20:02,462 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:20:02,462 INFO cluster.py [line:239] usefull PG number is 2854
2017-06-08 19:21:02,522 INFO cluster.py [line:247] cost 60 seconds, left 1829 seconds when check the ceph status
2017-06-08 19:21:02,522 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:21:03,022 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            209 pgs backfill_wait
            2 pgs backfilling
            211 pgs stuck unclean
            Difference in osd space utilization 41.4559% greater than 40%
            recovery 260094/945821 objects misplaced (27.499%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2717: 10 osds: 10 up, 10 in; 211 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39675: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            260094/945821 objects misplaced (27.499%)
                2861 active+clean
                 209 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 172 MB/s, 53 objects/s
stdin: is not a tty

2017-06-08 19:21:03,023 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:21:03,023 INFO cluster.py [line:239] usefull PG number is 2861
2017-06-08 19:22:03,052 INFO cluster.py [line:247] cost 61 seconds, left 1768 seconds when check the ceph status
2017-06-08 19:22:03,053 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:22:03,468 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            203 pgs backfill_wait
            2 pgs backfilling
            205 pgs stuck unclean
            Difference in osd space utilization 41.0013% greater than 40%
            recovery 256028/944006 objects misplaced (27.121%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2729: 10 osds: 10 up, 10 in; 205 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39727: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            256028/944006 objects misplaced (27.121%)
                2867 active+clean
                 203 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 131 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 19:22:03,469 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:22:03,469 INFO cluster.py [line:239] usefull PG number is 2867
2017-06-08 19:23:03,510 INFO cluster.py [line:247] cost 60 seconds, left 1708 seconds when check the ceph status
2017-06-08 19:23:03,510 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:23:03,931 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            196 pgs backfill_wait
            2 pgs backfilling
            198 pgs stuck unclean
            Difference in osd space utilization 40.3098% greater than 40%
            recovery 250237/940684 objects misplaced (26.602%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2741: 10 osds: 10 up, 10 in; 198 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39782: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            250237/940684 objects misplaced (26.602%)
                2874 active+clean
                 196 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 242 MB/s, 74 objects/s
stdin: is not a tty

2017-06-08 19:23:03,931 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:23:03,931 INFO cluster.py [line:239] usefull PG number is 2874
2017-06-08 19:24:03,991 INFO cluster.py [line:247] cost 60 seconds, left 1648 seconds when check the ceph status
2017-06-08 19:24:03,991 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:24:04,434 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            193 pgs backfill_wait
            2 pgs backfilling
            195 pgs stuck unclean
            recovery 243323/937809 objects misplaced (25.946%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2747: 10 osds: 10 up, 10 in; 195 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39831: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            243323/937809 objects misplaced (25.946%)
                2877 active+clean
                 193 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 346 MB/s, 115 objects/s
stdin: is not a tty

2017-06-08 19:24:04,434 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:24:04,434 INFO cluster.py [line:239] usefull PG number is 2877
2017-06-08 19:25:04,488 INFO cluster.py [line:247] cost 61 seconds, left 1587 seconds when check the ceph status
2017-06-08 19:25:04,488 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:25:04,874 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            190 pgs backfill_wait
            2 pgs backfilling
            192 pgs stuck unclean
            recovery 237462/934646 objects misplaced (25.407%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2754: 10 osds: 10 up, 10 in; 191 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39879: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            237462/934646 objects misplaced (25.407%)
                2880 active+clean
                 190 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:25:04,875 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:25:04,875 INFO cluster.py [line:239] usefull PG number is 2880
2017-06-08 19:26:04,935 INFO cluster.py [line:247] cost 60 seconds, left 1527 seconds when check the ceph status
2017-06-08 19:26:04,935 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:26:05,335 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            184 pgs backfill_wait
            2 pgs backfilling
            186 pgs stuck unclean
            recovery 229786/930682 objects misplaced (24.690%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2765: 10 osds: 10 up, 10 in; 186 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39932: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            229786/930682 objects misplaced (24.690%)
                2886 active+clean
                 184 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:26:05,336 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:26:05,336 INFO cluster.py [line:239] usefull PG number is 2886
2017-06-08 19:27:05,396 INFO cluster.py [line:247] cost 61 seconds, left 1466 seconds when check the ceph status
2017-06-08 19:27:05,396 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:27:05,788 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            182 pgs backfill_wait
            2 pgs backfilling
            184 pgs stuck unclean
            recovery 222987/927526 objects misplaced (24.041%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2767: 10 osds: 10 up, 10 in; 184 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39974: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4904 GB / 6992 GB avail
            222987/927526 objects misplaced (24.041%)
                2888 active+clean
                 182 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 294 MB/s, 90 objects/s
stdin: is not a tty

2017-06-08 19:27:05,788 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:27:05,788 INFO cluster.py [line:239] usefull PG number is 2888
2017-06-08 19:28:05,809 INFO cluster.py [line:247] cost 60 seconds, left 1406 seconds when check the ceph status
2017-06-08 19:28:05,809 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:28:06,218 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            175 pgs backfill_wait
            2 pgs backfilling
            177 pgs stuck unclean
            recovery 216801/924377 objects misplaced (23.454%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2780: 10 osds: 10 up, 10 in; 177 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40024: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            216801/924377 objects misplaced (23.454%)
                2895 active+clean
                 175 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 881 MB/s, 294 objects/s
stdin: is not a tty

2017-06-08 19:28:06,218 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:28:06,218 INFO cluster.py [line:239] usefull PG number is 2895
2017-06-08 19:29:06,220 INFO cluster.py [line:247] cost 61 seconds, left 1345 seconds when check the ceph status
2017-06-08 19:29:06,221 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:29:06,579 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            168 pgs backfill_wait
            2 pgs backfilling
            170 pgs stuck unclean
            recovery 210785/921008 objects misplaced (22.886%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2793: 10 osds: 10 up, 10 in; 170 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40075: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            210785/921008 objects misplaced (22.886%)
                2902 active+clean
                 168 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 277 MB/s, 88 objects/s
stdin: is not a tty

2017-06-08 19:29:06,580 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:29:06,580 INFO cluster.py [line:239] usefull PG number is 2902
2017-06-08 19:30:06,582 INFO cluster.py [line:247] cost 60 seconds, left 1285 seconds when check the ceph status
2017-06-08 19:30:06,582 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:30:06,969 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            165 pgs backfill_wait
            2 pgs backfilling
            167 pgs stuck unclean
            recovery 206907/919466 objects misplaced (22.503%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2799: 10 osds: 10 up, 10 in; 166 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40117: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4905 GB / 6992 GB avail
            206907/919466 objects misplaced (22.503%)
                2905 active+clean
                 165 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:30:06,970 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:30:06,970 INFO cluster.py [line:239] usefull PG number is 2905
2017-06-08 19:31:06,996 INFO cluster.py [line:247] cost 60 seconds, left 1225 seconds when check the ceph status
2017-06-08 19:31:06,996 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:31:07,451 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            159 pgs backfill_wait
            1 pgs backfilling
            2 pgs peering
            160 pgs stuck unclean
            recovery 199718/915416 objects misplaced (21.817%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2811: 10 osds: 10 up, 10 in; 159 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40169: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            199718/915416 objects misplaced (21.817%)
                2910 active+clean
                 159 active+remapped+backfill_wait
                   2 peering
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:31:07,451 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:31:07,452 INFO cluster.py [line:239] usefull PG number is 2910
2017-06-08 19:32:07,512 INFO cluster.py [line:247] cost 61 seconds, left 1164 seconds when check the ceph status
2017-06-08 19:32:07,512 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:32:07,904 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            154 pgs backfill_wait
            1 pgs backfilling
            155 pgs stuck unclean
            recovery 195746/913614 objects misplaced (21.425%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2819: 10 osds: 10 up, 10 in; 155 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40217: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            195746/913614 objects misplaced (21.425%)
                2917 active+clean
                 154 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 602 MB/s, 206 objects/s
stdin: is not a tty

2017-06-08 19:32:07,904 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:32:07,905 INFO cluster.py [line:239] usefull PG number is 2917
2017-06-08 19:33:07,914 INFO cluster.py [line:247] cost 60 seconds, left 1104 seconds when check the ceph status
2017-06-08 19:33:07,914 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:33:08,314 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            148 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            149 pgs stuck unclean
            recovery 189618/910218 objects misplaced (20.832%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2829: 10 osds: 10 up, 10 in; 149 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40268: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            189618/910218 objects misplaced (20.832%)
                2921 active+clean
                 148 active+remapped+backfill_wait
                   1 peering
                   1 active+clean+scrubbing+deep
                   1 active+remapped+backfilling
recovery io 219 MB/s, 57 objects/s
stdin: is not a tty

2017-06-08 19:33:08,314 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:33:08,314 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 19:34:08,370 INFO cluster.py [line:247] cost 61 seconds, left 1043 seconds when check the ceph status
2017-06-08 19:34:08,370 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:34:08,756 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            147 pgs backfill_wait
            1 pgs backfilling
            148 pgs stuck unclean
            recovery 187745/909394 objects misplaced (20.645%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2831: 10 osds: 10 up, 10 in; 148 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40304: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            187745/909394 objects misplaced (20.645%)
                2924 active+clean
                 147 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 115 MB/s, 35 objects/s
stdin: is not a tty

2017-06-08 19:34:08,756 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:34:08,756 INFO cluster.py [line:239] usefull PG number is 2924
2017-06-08 19:35:08,783 INFO cluster.py [line:247] cost 60 seconds, left 983 seconds when check the ceph status
2017-06-08 19:35:08,783 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:35:09,198 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            143 pgs backfill_wait
            1 pgs backfilling
            144 pgs stuck unclean
            recovery 182772/906904 objects misplaced (20.153%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2838: 10 osds: 10 up, 10 in; 144 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40342: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            182772/906904 objects misplaced (20.153%)
                2928 active+clean
                 143 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 130 MB/s, 40 objects/s
stdin: is not a tty

2017-06-08 19:35:09,199 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:35:09,199 INFO cluster.py [line:239] usefull PG number is 2928
2017-06-08 19:36:09,256 INFO cluster.py [line:247] cost 61 seconds, left 922 seconds when check the ceph status
2017-06-08 19:36:09,257 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:36:09,658 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            142 pgs backfill_wait
            1 pgs backfilling
            143 pgs stuck unclean
            recovery 180873/906142 objects misplaced (19.961%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2840: 10 osds: 10 up, 10 in; 143 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40380: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            180873/906142 objects misplaced (19.961%)
                2929 active+clean
                 142 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 252 MB/s, 78 objects/s
stdin: is not a tty

2017-06-08 19:36:09,659 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:36:09,659 INFO cluster.py [line:239] usefull PG number is 2929
2017-06-08 19:37:09,688 INFO cluster.py [line:247] cost 60 seconds, left 862 seconds when check the ceph status
2017-06-08 19:37:09,688 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:37:10,072 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            140 pgs backfill_wait
            1 pgs backfilling
            141 pgs stuck unclean
            recovery 176406/903889 objects misplaced (19.516%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2844: 10 osds: 10 up, 10 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40416: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            176406/903889 objects misplaced (19.516%)
                2931 active+clean
                 140 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 118 MB/s, 36 objects/s
stdin: is not a tty

2017-06-08 19:37:10,072 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:37:10,072 INFO cluster.py [line:239] usefull PG number is 2931
2017-06-08 19:38:10,132 INFO cluster.py [line:247] cost 61 seconds, left 801 seconds when check the ceph status
2017-06-08 19:38:10,133 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:38:10,520 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            137 pgs backfill_wait
            1 pgs backfilling
            138 pgs stuck unclean
            recovery 173436/902278 objects misplaced (19.222%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2850: 10 osds: 10 up, 10 in; 138 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40461: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            173436/902278 objects misplaced (19.222%)
                2933 active+clean
                 137 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 398 MB/s, 133 objects/s
stdin: is not a tty

2017-06-08 19:38:10,520 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:38:10,520 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 19:39:10,534 INFO cluster.py [line:247] cost 60 seconds, left 741 seconds when check the ceph status
2017-06-08 19:39:10,535 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:39:10,952 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            133 pgs backfill_wait
            1 pgs backfilling
            134 pgs stuck unclean
            recovery 168366/899809 objects misplaced (18.711%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2858: 10 osds: 10 up, 10 in; 134 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40510: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            168366/899809 objects misplaced (18.711%)
                2938 active+clean
                 133 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 464 MB/s, 156 objects/s
stdin: is not a tty

2017-06-08 19:39:10,952 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:39:10,952 INFO cluster.py [line:239] usefull PG number is 2938
2017-06-08 19:40:11,008 INFO cluster.py [line:247] cost 61 seconds, left 680 seconds when check the ceph status
2017-06-08 19:40:11,008 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:40:11,461 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            131 pgs backfill_wait
            1 pgs backfilling
            132 pgs stuck unclean
            recovery 163658/897412 objects misplaced (18.237%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2862: 10 osds: 10 up, 10 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40550: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            163658/897412 objects misplaced (18.237%)
                2940 active+clean
                 131 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 117 MB/s, 36 objects/s
stdin: is not a tty

2017-06-08 19:40:11,461 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:40:11,461 INFO cluster.py [line:239] usefull PG number is 2940
2017-06-08 19:41:11,470 INFO cluster.py [line:247] cost 60 seconds, left 620 seconds when check the ceph status
2017-06-08 19:41:11,470 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:41:11,861 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            128 pgs backfill_wait
            1 pgs backfilling
            129 pgs stuck unclean
            recovery 161660/896503 objects misplaced (18.032%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2866: 10 osds: 10 up, 10 in; 129 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40585: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            161660/896503 objects misplaced (18.032%)
                2943 active+clean
                 128 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 269 MB/s, 83 objects/s
stdin: is not a tty

2017-06-08 19:41:11,861 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:41:11,861 INFO cluster.py [line:239] usefull PG number is 2943
2017-06-08 19:42:11,882 INFO cluster.py [line:247] cost 60 seconds, left 560 seconds when check the ceph status
2017-06-08 19:42:11,882 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:42:12,306 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            124 pgs backfill_wait
            1 pgs backfilling
            125 pgs stuck unclean
            recovery 158899/894889 objects misplaced (17.756%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2874: 10 osds: 10 up, 10 in; 125 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40626: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            158899/894889 objects misplaced (17.756%)
                2947 active+clean
                 124 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 203 MB/s, 62 objects/s
stdin: is not a tty

2017-06-08 19:42:12,306 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:42:12,306 INFO cluster.py [line:239] usefull PG number is 2947
2017-06-08 19:43:12,341 INFO cluster.py [line:247] cost 61 seconds, left 499 seconds when check the ceph status
2017-06-08 19:43:12,341 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:43:12,717 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            123 pgs backfill_wait
            1 pgs backfilling
            124 pgs stuck unclean
            recovery 156979/894112 objects misplaced (17.557%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2876: 10 osds: 10 up, 10 in; 124 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40661: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            156979/894112 objects misplaced (17.557%)
                2948 active+clean
                 123 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 126 MB/s, 39 objects/s
stdin: is not a tty

2017-06-08 19:43:12,717 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:43:12,717 INFO cluster.py [line:239] usefull PG number is 2948
2017-06-08 19:44:12,718 INFO cluster.py [line:247] cost 60 seconds, left 439 seconds when check the ceph status
2017-06-08 19:44:12,718 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:44:13,129 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            121 pgs backfill_wait
            1 pgs backfilling
            122 pgs stuck unclean
            recovery 155094/893274 objects misplaced (17.362%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2881: 10 osds: 10 up, 10 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40698: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            155094/893274 objects misplaced (17.362%)
                2950 active+clean
                 121 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:44:13,129 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:44:13,129 INFO cluster.py [line:239] usefull PG number is 2950
2017-06-08 19:45:13,154 INFO cluster.py [line:247] cost 61 seconds, left 378 seconds when check the ceph status
2017-06-08 19:45:13,154 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:45:13,539 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            118 pgs backfill_wait
            1 pgs backfilling
            119 pgs stuck unclean
            recovery 150519/890966 objects misplaced (16.894%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2885: 10 osds: 10 up, 10 in; 119 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40738: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            150519/890966 objects misplaced (16.894%)
                2953 active+clean
                 118 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 107 MB/s, 33 objects/s
stdin: is not a tty

2017-06-08 19:45:13,539 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:45:13,539 INFO cluster.py [line:239] usefull PG number is 2953
2017-06-08 19:46:13,573 INFO cluster.py [line:247] cost 60 seconds, left 318 seconds when check the ceph status
2017-06-08 19:46:13,573 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:46:14,104 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            116 pgs backfill_wait
            1 pgs backfilling
            117 pgs stuck unclean
            recovery 146790/889431 objects misplaced (16.504%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2889: 10 osds: 10 up, 10 in; 117 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40778: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2087 GB used, 4905 GB / 6992 GB avail
            146790/889431 objects misplaced (16.504%)
                2955 active+clean
                 116 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 582 MB/s, 197 objects/s
stdin: is not a tty

2017-06-08 19:46:14,104 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:46:14,105 INFO cluster.py [line:239] usefull PG number is 2955
2017-06-08 19:47:14,154 INFO cluster.py [line:247] cost 61 seconds, left 257 seconds when check the ceph status
2017-06-08 19:47:14,154 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:47:14,577 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            114 pgs backfill_wait
            1 pgs backfilling
            115 pgs stuck unclean
            recovery 143076/887077 objects misplaced (16.129%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2893: 10 osds: 10 up, 10 in; 115 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40818: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            143076/887077 objects misplaced (16.129%)
                2957 active+clean
                 114 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 128 MB/s, 40 objects/s
stdin: is not a tty

2017-06-08 19:47:14,577 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:47:14,577 INFO cluster.py [line:239] usefull PG number is 2957
2017-06-08 19:48:14,596 INFO cluster.py [line:247] cost 60 seconds, left 197 seconds when check the ceph status
2017-06-08 19:48:14,597 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:48:15,020 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            112 pgs backfill_wait
            1 pgs backfilling
            113 pgs stuck unclean
            recovery 141204/886262 objects misplaced (15.933%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2897: 10 osds: 10 up, 10 in; 113 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40852: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            141204/886262 objects misplaced (15.933%)
                2959 active+clean
                 112 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 124 MB/s, 39 objects/s
stdin: is not a tty

2017-06-08 19:48:15,020 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:48:15,020 INFO cluster.py [line:239] usefull PG number is 2959
2017-06-08 19:49:15,059 INFO cluster.py [line:247] cost 61 seconds, left 136 seconds when check the ceph status
2017-06-08 19:49:15,059 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:49:15,448 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            110 pgs backfill_wait
            1 pgs backfilling
            111 pgs stuck unclean
            recovery 138481/884680 objects misplaced (15.653%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2901: 10 osds: 10 up, 10 in; 111 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40891: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            138481/884680 objects misplaced (15.653%)
                2961 active+clean
                 110 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 66 objects/s
stdin: is not a tty

2017-06-08 19:49:15,448 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:49:15,448 INFO cluster.py [line:239] usefull PG number is 2961
2017-06-08 19:50:15,508 INFO cluster.py [line:247] cost 60 seconds, left 76 seconds when check the ceph status
2017-06-08 19:50:15,509 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:50:15,928 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            109 pgs backfill_wait
            1 pgs backfilling
            110 pgs stuck unclean
            recovery 136543/883948 objects misplaced (15.447%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2903: 10 osds: 10 up, 10 in; 110 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40926: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            136543/883948 objects misplaced (15.447%)
                2962 active+clean
                 109 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 132 MB/s, 40 objects/s
stdin: is not a tty

2017-06-08 19:50:15,929 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:50:15,929 INFO cluster.py [line:239] usefull PG number is 2962
2017-06-08 19:51:15,988 INFO cluster.py [line:247] cost 60 seconds, left 16 seconds when check the ceph status
2017-06-08 19:51:15,988 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:51:16,431 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            107 pgs backfill_wait
            1 pgs backfilling
            108 pgs stuck unclean
            recovery 133883/882373 objects misplaced (15.173%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2907: 10 osds: 10 up, 10 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40963: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            133883/882373 objects misplaced (15.173%)
                2964 active+clean
                 107 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:51:16,432 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:51:16,432 INFO cluster.py [line:239] usefull PG number is 2964
2017-06-08 19:52:16,451 INFO cluster.py [line:247] cost 61 seconds, left -45 seconds when check the ceph status
2017-06-08 19:52:16,451 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:85] status is HEALTH_ERROR
2017-06-08 19:52:16,451 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:86] TC47_48_49_50_51_remove_osds_on_single_node  runs failed
2017-06-08 19:52:16,452 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:52:16,841 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            106 pgs backfill_wait
            1 pgs backfilling
            107 pgs stuck unclean
            recovery 132044/881581 objects misplaced (14.978%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2909: 10 osds: 10 up, 10 in; 107 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41000: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            132044/881581 objects misplaced (14.978%)
                2965 active+clean
                 106 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 142 MB/s, 44 objects/s
stdin: is not a tty

2017-06-08 19:52:16,842 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:52:16,842 INFO cluster.py [line:239] usefull PG number is 2965
2017-06-08 19:53:16,902 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-08 19:53:16,902 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:53:17,306 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            104 pgs backfill_wait
            1 pgs backfilling
            105 pgs stuck unclean
            recovery 130095/880747 objects misplaced (14.771%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2913: 10 osds: 10 up, 10 in; 105 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41038: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            130095/880747 objects misplaced (14.771%)
                2967 active+clean
                 104 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 19:53:17,306 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:53:17,306 INFO cluster.py [line:239] usefull PG number is 2967
2017-06-08 19:54:17,319 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-08 19:54:17,320 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:54:17,740 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            102 pgs backfill_wait
            1 pgs backfilling
            103 pgs stuck unclean
            recovery 126706/879194 objects misplaced (14.412%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2917: 10 osds: 10 up, 10 in; 103 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41077: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            126706/879194 objects misplaced (14.412%)
                2969 active+clean
                 102 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:54:17,740 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:54:17,740 INFO cluster.py [line:239] usefull PG number is 2969
2017-06-08 19:55:17,800 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-08 19:55:17,801 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:55:18,231 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            99 pgs backfill_wait
            1 pgs backfilling
            100 pgs stuck unclean
            recovery 122702/876840 objects misplaced (13.994%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2923: 10 osds: 10 up, 10 in; 100 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41120: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            122702/876840 objects misplaced (13.994%)
                2972 active+clean
                  99 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 263 MB/s, 81 objects/s
stdin: is not a tty

2017-06-08 19:55:18,231 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:55:18,231 INFO cluster.py [line:239] usefull PG number is 2972
2017-06-08 19:56:18,233 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-08 19:56:18,233 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:56:18,597 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            98 pgs backfill_wait
            1 pgs backfilling
            99 pgs stuck unclean
            recovery 120909/876091 objects misplaced (13.801%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2925: 10 osds: 10 up, 10 in; 99 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41155: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            120909/876091 objects misplaced (13.801%)
                2973 active+clean
                  98 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 124 MB/s, 38 objects/s
stdin: is not a tty

2017-06-08 19:56:18,597 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:56:18,597 INFO cluster.py [line:239] usefull PG number is 2973
2017-06-08 19:57:18,604 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-08 19:57:18,604 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:57:19,010 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            97 pgs stuck unclean
            recovery 116248/873758 objects misplaced (13.304%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2929: 10 osds: 10 up, 10 in; 97 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41198: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            116248/873758 objects misplaced (13.304%)
                2975 active+clean
                  96 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 419 MB/s, 136 objects/s
stdin: is not a tty

2017-06-08 19:57:19,010 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:57:19,011 INFO cluster.py [line:239] usefull PG number is 2975
2017-06-08 19:58:19,064 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-08 19:58:19,064 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:58:19,495 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            94 pgs backfill_wait
            1 pgs backfilling
            95 pgs stuck unclean
            recovery 112237/871523 objects misplaced (12.878%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2933: 10 osds: 10 up, 10 in; 95 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41237: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            112237/871523 objects misplaced (12.878%)
                2977 active+clean
                  94 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 113 MB/s, 35 objects/s
stdin: is not a tty

2017-06-08 19:58:19,495 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:58:19,496 INFO cluster.py [line:239] usefull PG number is 2977
2017-06-08 19:59:19,514 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-08 19:59:19,515 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 19:59:19,953 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            91 pgs backfill_wait
            1 pgs backfilling
            92 pgs stuck unclean
            recovery 110122/870665 objects misplaced (12.648%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2939: 10 osds: 10 up, 10 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41277: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            110122/870665 objects misplaced (12.648%)
                2980 active+clean
                  91 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 19:59:19,954 INFO cluster.py [line:238] PG number is 3072
2017-06-08 19:59:19,954 INFO cluster.py [line:239] usefull PG number is 2980
2017-06-08 20:00:20,001 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-08 20:00:20,001 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:00:20,418 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            89 pgs backfill_wait
            1 pgs backfilling
            90 pgs stuck unclean
            recovery 106755/869078 objects misplaced (12.284%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2943: 10 osds: 10 up, 10 in; 90 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41316: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            106755/869078 objects misplaced (12.284%)
                2982 active+clean
                  89 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 121 MB/s, 37 objects/s
stdin: is not a tty

2017-06-08 20:00:20,418 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:00:20,418 INFO cluster.py [line:239] usefull PG number is 2982
2017-06-08 20:01:20,475 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-08 20:01:20,475 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:01:20,976 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            85 pgs backfill_wait
            1 pgs backfilling
            86 pgs stuck unclean
            recovery 103555/867384 objects misplaced (11.939%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2951: 10 osds: 10 up, 10 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41364: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            103555/867384 objects misplaced (11.939%)
                2986 active+clean
                  85 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 170 MB/s, 52 objects/s
stdin: is not a tty

2017-06-08 20:01:20,976 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:01:20,976 INFO cluster.py [line:239] usefull PG number is 2986
2017-06-08 20:02:21,037 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-08 20:02:21,037 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:02:21,399 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            84 pgs backfill_wait
            85 pgs stuck unclean
            recovery 101650/866601 objects misplaced (11.730%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2954: 10 osds: 10 up, 10 in; 84 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41399: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            101650/866601 objects misplaced (11.730%)
                2987 active+clean
                  84 active+remapped+backfill_wait
                   1 active+remapped
recovery io 393 MB/s, 120 objects/s
stdin: is not a tty

2017-06-08 20:02:21,399 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:02:21,399 INFO cluster.py [line:239] usefull PG number is 2987
2017-06-08 20:03:21,444 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-08 20:03:21,445 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:03:21,834 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            81 pgs backfill_wait
            1 pgs backfilling
            82 pgs stuck unclean
            recovery 98226/865013 objects misplaced (11.355%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2959: 10 osds: 10 up, 10 in; 82 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41439: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            98226/865013 objects misplaced (11.355%)
                2990 active+clean
                  81 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:03:21,835 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:03:21,835 INFO cluster.py [line:239] usefull PG number is 2990
2017-06-08 20:04:21,892 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-08 20:04:21,893 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:04:22,320 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            78 pgs backfill_wait
            1 pgs backfilling
            79 pgs stuck unclean
            recovery 94564/862747 objects misplaced (10.961%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2965: 10 osds: 10 up, 10 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41480: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            94564/862747 objects misplaced (10.961%)
                2993 active+clean
                  78 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:04:22,320 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:04:22,320 INFO cluster.py [line:239] usefull PG number is 2993
2017-06-08 20:05:22,381 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-08 20:05:22,381 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:05:22,769 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            76 pgs backfill_wait
            1 pgs backfilling
            77 pgs stuck unclean
            recovery 92576/861936 objects misplaced (10.740%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2969: 10 osds: 10 up, 10 in; 77 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41517: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            92576/861936 objects misplaced (10.740%)
                2995 active+clean
                  76 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 120 MB/s, 37 objects/s
stdin: is not a tty

2017-06-08 20:05:22,769 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:05:22,770 INFO cluster.py [line:239] usefull PG number is 2995
2017-06-08 20:06:22,823 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-08 20:06:22,824 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:06:23,223 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            75 pgs backfill_wait
            1 pgs backfilling
            76 pgs stuck unclean
            recovery 90714/861126 objects misplaced (10.534%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2973: 10 osds: 10 up, 10 in; 75 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41550: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            90714/861126 objects misplaced (10.534%)
                2996 active+clean
                  75 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:06:23,224 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:06:23,224 INFO cluster.py [line:239] usefull PG number is 2996
2017-06-08 20:07:23,280 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-08 20:07:23,280 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:07:23,664 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            69 pgs backfill_wait
            1 pgs backfilling
            70 pgs stuck unclean
            recovery 83377/857254 objects misplaced (9.726%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2982: 10 osds: 10 up, 10 in; 70 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41601: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            83377/857254 objects misplaced (9.726%)
                3002 active+clean
                  69 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 132 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 20:07:23,664 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:07:23,664 INFO cluster.py [line:239] usefull PG number is 3002
2017-06-08 20:08:23,724 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-08 20:08:23,725 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:08:24,146 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            67 pgs backfill_wait
            1 pgs backfilling
            68 pgs stuck unclean
            recovery 81476/856453 objects misplaced (9.513%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2986: 10 osds: 10 up, 10 in; 68 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41638: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            81476/856453 objects misplaced (9.513%)
                3004 active+clean
                  67 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 160 MB/s, 49 objects/s
stdin: is not a tty

2017-06-08 20:08:24,147 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:08:24,147 INFO cluster.py [line:239] usefull PG number is 3004
2017-06-08 20:09:24,206 INFO cluster.py [line:247] cost 61 seconds, left 4972 seconds when check the ceph status
2017-06-08 20:09:24,207 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:09:24,623 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            63 pgs backfill_wait
            1 pgs backfilling
            64 pgs stuck unclean
            recovery 78666/854735 objects misplaced (9.204%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2993: 10 osds: 10 up, 10 in; 64 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41680: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            78666/854735 objects misplaced (9.204%)
                3008 active+clean
                  63 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 103 MB/s, 25 objects/s
stdin: is not a tty

2017-06-08 20:09:24,623 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:09:24,623 INFO cluster.py [line:239] usefull PG number is 3008
2017-06-08 20:10:24,670 INFO cluster.py [line:247] cost 60 seconds, left 4912 seconds when check the ceph status
2017-06-08 20:10:24,670 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:10:25,064 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            62 pgs backfill_wait
            1 pgs backfilling
            63 pgs stuck unclean
            recovery 76658/853906 objects misplaced (8.977%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2995: 10 osds: 10 up, 10 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41716: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            76658/853906 objects misplaced (8.977%)
                3009 active+clean
                  62 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 168 MB/s, 53 objects/s
stdin: is not a tty

2017-06-08 20:10:25,064 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:10:25,065 INFO cluster.py [line:239] usefull PG number is 3009
2017-06-08 20:11:25,067 INFO cluster.py [line:247] cost 61 seconds, left 4851 seconds when check the ceph status
2017-06-08 20:11:25,067 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:11:25,454 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            60 pgs backfill_wait
            1 pgs backfilling
            61 pgs stuck unclean
            recovery 74793/853128 objects misplaced (8.767%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e2999: 10 osds: 10 up, 10 in; 61 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41748: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            74793/853128 objects misplaced (8.767%)
                3011 active+clean
                  60 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 124 MB/s, 38 objects/s
stdin: is not a tty

2017-06-08 20:11:25,455 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:11:25,455 INFO cluster.py [line:239] usefull PG number is 3011
2017-06-08 20:12:25,470 INFO cluster.py [line:247] cost 60 seconds, left 4791 seconds when check the ceph status
2017-06-08 20:12:25,470 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:12:25,918 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            58 pgs backfill_wait
            1 pgs backfilling
            59 pgs stuck unclean
            recovery 72212/851614 objects misplaced (8.479%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3003: 10 osds: 10 up, 10 in; 59 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41789: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            72212/851614 objects misplaced (8.479%)
                3013 active+clean
                  58 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 247 MB/s, 76 objects/s
stdin: is not a tty

2017-06-08 20:12:25,918 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:12:25,918 INFO cluster.py [line:239] usefull PG number is 3013
2017-06-08 20:13:25,946 INFO cluster.py [line:247] cost 60 seconds, left 4731 seconds when check the ceph status
2017-06-08 20:13:25,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:13:26,331 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            57 pgs backfill_wait
            1 pgs backfilling
            58 pgs stuck unclean
            recovery 70358/850892 objects misplaced (8.269%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3005: 10 osds: 10 up, 10 in; 58 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41820: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            70358/850892 objects misplaced (8.269%)
                3014 active+clean
                  57 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 112 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 20:13:26,331 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:13:26,331 INFO cluster.py [line:239] usefull PG number is 3014
2017-06-08 20:14:26,390 INFO cluster.py [line:247] cost 61 seconds, left 4670 seconds when check the ceph status
2017-06-08 20:14:26,390 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:14:26,737 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            55 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 67748/849363 objects misplaced (7.976%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3009: 10 osds: 10 up, 10 in; 56 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41860: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            67748/849363 objects misplaced (7.976%)
                3016 active+clean
                  55 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:14:26,738 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:14:26,738 INFO cluster.py [line:239] usefull PG number is 3016
2017-06-08 20:15:26,798 INFO cluster.py [line:247] cost 60 seconds, left 4610 seconds when check the ceph status
2017-06-08 20:15:26,798 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:15:27,216 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            53 pgs backfill_wait
            1 pgs backfilling
            54 pgs stuck unclean
            recovery 65869/848500 objects misplaced (7.763%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3013: 10 osds: 10 up, 10 in; 54 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41894: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            65869/848500 objects misplaced (7.763%)
                3018 active+clean
                  53 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 107 MB/s, 33 objects/s
stdin: is not a tty

2017-06-08 20:15:27,216 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:15:27,217 INFO cluster.py [line:239] usefull PG number is 3018
2017-06-08 20:16:27,231 INFO cluster.py [line:247] cost 61 seconds, left 4549 seconds when check the ceph status
2017-06-08 20:16:27,231 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:16:27,650 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            49 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 63833/847575 objects misplaced (7.531%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3020: 10 osds: 10 up, 10 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41932: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            63833/847575 objects misplaced (7.531%)
                3022 active+clean
                  49 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 109 MB/s, 33 objects/s
stdin: is not a tty

2017-06-08 20:16:27,650 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:16:27,650 INFO cluster.py [line:239] usefull PG number is 3022
2017-06-08 20:17:27,690 INFO cluster.py [line:247] cost 60 seconds, left 4489 seconds when check the ceph status
2017-06-08 20:17:27,690 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:17:28,114 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            47 pgs backfill_wait
            1 pgs backfilling
            48 pgs stuck unclean
            recovery 61271/846084 objects misplaced (7.242%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3024: 10 osds: 10 up, 10 in; 48 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41968: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            61271/846084 objects misplaced (7.242%)
                3024 active+clean
                  47 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:17:28,115 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:17:28,115 INFO cluster.py [line:239] usefull PG number is 3024
2017-06-08 20:18:28,170 INFO cluster.py [line:247] cost 61 seconds, left 4428 seconds when check the ceph status
2017-06-08 20:18:28,170 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:18:28,560 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            45 pgs backfill_wait
            1 pgs backfilling
            46 pgs stuck unclean
            recovery 59354/845243 objects misplaced (7.022%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3028: 10 osds: 10 up, 10 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42009: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            59354/845243 objects misplaced (7.022%)
                3026 active+clean
                  45 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 121 MB/s, 37 objects/s
stdin: is not a tty

2017-06-08 20:18:28,561 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:18:28,561 INFO cluster.py [line:239] usefull PG number is 3026
2017-06-08 20:19:28,571 INFO cluster.py [line:247] cost 60 seconds, left 4368 seconds when check the ceph status
2017-06-08 20:19:28,571 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:19:28,978 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            44 pgs backfill_wait
            1 pgs backfilling
            45 pgs stuck unclean
            recovery 57366/844413 objects misplaced (6.794%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3030: 10 osds: 10 up, 10 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42042: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            57366/844413 objects misplaced (6.794%)
                3027 active+clean
                  44 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 131 MB/s, 40 objects/s
stdin: is not a tty

2017-06-08 20:19:28,978 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:19:28,978 INFO cluster.py [line:239] usefull PG number is 3027
2017-06-08 20:20:29,039 INFO cluster.py [line:247] cost 61 seconds, left 4307 seconds when check the ceph status
2017-06-08 20:20:29,039 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:20:29,443 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            42 pgs backfill_wait
            1 pgs backfilling
            43 pgs stuck unclean
            recovery 54782/842860 objects misplaced (6.500%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3034: 10 osds: 10 up, 10 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42082: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            54782/842860 objects misplaced (6.500%)
                3029 active+clean
                  42 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:20:29,443 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:20:29,443 INFO cluster.py [line:239] usefull PG number is 3029
2017-06-08 20:21:29,444 INFO cluster.py [line:247] cost 60 seconds, left 4247 seconds when check the ceph status
2017-06-08 20:21:29,444 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:21:29,850 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            41 pgs backfill_wait
            1 pgs backfilling
            42 pgs stuck unclean
            recovery 52948/842134 objects misplaced (6.287%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3036: 10 osds: 10 up, 10 in; 42 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42112: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            52948/842134 objects misplaced (6.287%)
                3030 active+clean
                  41 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 109 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 20:21:29,851 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:21:29,851 INFO cluster.py [line:239] usefull PG number is 3030
2017-06-08 20:22:29,853 INFO cluster.py [line:247] cost 60 seconds, left 4187 seconds when check the ceph status
2017-06-08 20:22:29,854 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:22:30,239 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            39 pgs backfill_wait
            1 pgs backfilling
            40 pgs stuck unclean
            recovery 50359/840633 objects misplaced (5.991%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3040: 10 osds: 10 up, 10 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42147: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            50359/840633 objects misplaced (5.991%)
                3032 active+clean
                  39 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:22:30,239 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:22:30,239 INFO cluster.py [line:239] usefull PG number is 3032
2017-06-08 20:23:30,299 INFO cluster.py [line:247] cost 61 seconds, left 4126 seconds when check the ceph status
2017-06-08 20:23:30,300 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:23:30,691 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            38 pgs backfill_wait
            1 pgs backfilling
            39 pgs stuck unclean
            recovery 48428/839847 objects misplaced (5.766%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3042: 10 osds: 10 up, 10 in; 39 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42183: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            48428/839847 objects misplaced (5.766%)
                3033 active+clean
                  38 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 190 MB/s, 58 objects/s
stdin: is not a tty

2017-06-08 20:23:30,692 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:23:30,692 INFO cluster.py [line:239] usefull PG number is 3033
2017-06-08 20:24:30,724 INFO cluster.py [line:247] cost 60 seconds, left 4066 seconds when check the ceph status
2017-06-08 20:24:30,725 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:24:31,121 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            36 pgs backfill_wait
            1 pgs backfilling
            37 pgs stuck unclean
            recovery 46519/839035 objects misplaced (5.544%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3048: 10 osds: 10 up, 10 in; 36 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42220: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            46519/839035 objects misplaced (5.544%)
                3035 active+clean
                  36 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:24:31,121 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:24:31,121 INFO cluster.py [line:239] usefull PG number is 3035
2017-06-08 20:25:31,179 INFO cluster.py [line:247] cost 61 seconds, left 4005 seconds when check the ceph status
2017-06-08 20:25:31,180 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:25:31,592 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            34 pgs backfill_wait
            1 pgs backfilling
            35 pgs stuck unclean
            recovery 43914/837518 objects misplaced (5.243%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3050: 10 osds: 10 up, 10 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42259: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            43914/837518 objects misplaced (5.243%)
                3037 active+clean
                  34 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 104 MB/s, 32 objects/s
stdin: is not a tty

2017-06-08 20:25:31,593 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:25:31,593 INFO cluster.py [line:239] usefull PG number is 3037
2017-06-08 20:26:31,596 INFO cluster.py [line:247] cost 60 seconds, left 3945 seconds when check the ceph status
2017-06-08 20:26:31,597 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:26:32,013 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            33 pgs backfill_wait
            1 pgs backfilling
            34 pgs stuck unclean
            recovery 41959/836713 objects misplaced (5.015%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3052: 10 osds: 10 up, 10 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42292: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            41959/836713 objects misplaced (5.015%)
                3038 active+clean
                  33 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 134 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 20:26:32,013 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:26:32,013 INFO cluster.py [line:239] usefull PG number is 3038
2017-06-08 20:27:32,067 INFO cluster.py [line:247] cost 61 seconds, left 3884 seconds when check the ceph status
2017-06-08 20:27:32,068 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:27:32,496 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 37268/834345 objects misplaced (4.467%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3058: 10 osds: 10 up, 10 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42331: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            37268/834345 objects misplaced (4.467%)
                3041 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:27:32,496 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:27:32,496 INFO cluster.py [line:239] usefull PG number is 3041
2017-06-08 20:28:32,556 INFO cluster.py [line:247] cost 60 seconds, left 3824 seconds when check the ceph status
2017-06-08 20:28:32,557 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:28:33,050 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            28 pgs backfill_wait
            1 pgs backfilling
            29 pgs stuck unclean
            recovery 34288/832829 objects misplaced (4.117%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3062: 10 osds: 10 up, 10 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42371: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            34288/832829 objects misplaced (4.117%)
                3043 active+clean
                  28 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:28:33,050 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:28:33,050 INFO cluster.py [line:239] usefull PG number is 3043
2017-06-08 20:29:33,083 INFO cluster.py [line:247] cost 61 seconds, left 3763 seconds when check the ceph status
2017-06-08 20:29:33,083 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:29:33,490 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            27 pgs stuck unclean
            recovery 30923/831240 objects misplaced (3.720%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3068: 10 osds: 10 up, 10 in; 26 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42413: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            30923/831240 objects misplaced (3.720%)
                3045 active+clean
                  26 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:29:33,490 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:29:33,490 INFO cluster.py [line:239] usefull PG number is 3045
2017-06-08 20:30:33,496 INFO cluster.py [line:247] cost 60 seconds, left 3703 seconds when check the ceph status
2017-06-08 20:30:33,496 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:30:33,873 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            24 pgs backfill_wait
            1 pgs backfilling
            25 pgs stuck unclean
            recovery 28218/829700 objects misplaced (3.401%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3070: 10 osds: 10 up, 10 in; 25 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42449: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            28218/829700 objects misplaced (3.401%)
                3047 active+clean
                  24 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 133 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 20:30:33,873 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:30:33,873 INFO cluster.py [line:239] usefull PG number is 3047
2017-06-08 20:31:33,907 INFO cluster.py [line:247] cost 60 seconds, left 3643 seconds when check the ceph status
2017-06-08 20:31:33,907 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:31:34,313 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            21 pgs backfill_wait
            1 pgs backfilling
            22 pgs stuck unclean
            recovery 26299/828860 objects misplaced (3.173%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3076: 10 osds: 10 up, 10 in; 22 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42487: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            26299/828860 objects misplaced (3.173%)
                3050 active+clean
                  21 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 135 MB/s, 43 objects/s
stdin: is not a tty

2017-06-08 20:31:34,314 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:31:34,314 INFO cluster.py [line:239] usefull PG number is 3050
2017-06-08 20:32:34,370 INFO cluster.py [line:247] cost 61 seconds, left 3582 seconds when check the ceph status
2017-06-08 20:32:34,370 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:32:34,760 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            19 pgs backfill_wait
            1 pgs backfilling
            20 pgs stuck unclean
            recovery 21650/826569 objects misplaced (2.619%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3080: 10 osds: 10 up, 10 in; 20 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42527: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4905 GB / 6992 GB avail
            21650/826569 objects misplaced (2.619%)
                3052 active+clean
                  19 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 120 MB/s, 37 objects/s
stdin: is not a tty

2017-06-08 20:32:34,760 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:32:34,760 INFO cluster.py [line:239] usefull PG number is 3052
2017-06-08 20:33:34,775 INFO cluster.py [line:247] cost 60 seconds, left 3522 seconds when check the ceph status
2017-06-08 20:33:34,775 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:33:35,172 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs backfilling
            18 pgs stuck unclean
            recovery 18921/824981 objects misplaced (2.294%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3084: 10 osds: 10 up, 10 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42567: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            18921/824981 objects misplaced (2.294%)
                3054 active+clean
                  17 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 168 MB/s, 52 objects/s
stdin: is not a tty

2017-06-08 20:33:35,172 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:33:35,172 INFO cluster.py [line:239] usefull PG number is 3054
2017-06-08 20:34:35,200 INFO cluster.py [line:247] cost 61 seconds, left 3461 seconds when check the ceph status
2017-06-08 20:34:35,200 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:34:35,618 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 16975/824120 objects misplaced (2.060%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3088: 10 osds: 10 up, 10 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42601: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4907 GB / 6992 GB avail
            16975/824120 objects misplaced (2.060%)
                3056 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 119 MB/s, 36 objects/s
stdin: is not a tty

2017-06-08 20:34:35,618 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:34:35,618 INFO cluster.py [line:239] usefull PG number is 3056
2017-06-08 20:35:35,678 INFO cluster.py [line:247] cost 60 seconds, left 3401 seconds when check the ceph status
2017-06-08 20:35:35,679 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:35:36,094 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 13590/822598 objects misplaced (1.652%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3092: 10 osds: 10 up, 10 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42642: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            13590/822598 objects misplaced (1.652%)
                3057 active+clean
                  13 active+remapped+backfill_wait
                   1 active+clean+scrubbing+deep
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:35:36,094 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:35:36,095 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 20:36:36,127 INFO cluster.py [line:247] cost 61 seconds, left 3340 seconds when check the ceph status
2017-06-08 20:36:36,127 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:36:36,512 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            11 pgs backfill_wait
            1 pgs backfilling
            12 pgs stuck unclean
            recovery 9863/820394 objects misplaced (1.202%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3096: 10 osds: 10 up, 10 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42679: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            9863/820394 objects misplaced (1.202%)
                3060 active+clean
                  11 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 283 MB/s, 89 objects/s
stdin: is not a tty

2017-06-08 20:36:36,513 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:36:36,513 INFO cluster.py [line:239] usefull PG number is 3060
2017-06-08 20:37:36,573 INFO cluster.py [line:247] cost 60 seconds, left 3280 seconds when check the ceph status
2017-06-08 20:37:36,573 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:37:36,959 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            10 pgs backfill_wait
            1 pgs backfilling
            11 pgs stuck unclean
            recovery 7950/819651 objects misplaced (0.970%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3098: 10 osds: 10 up, 10 in; 11 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42710: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2085 GB used, 4906 GB / 6992 GB avail
            7950/819651 objects misplaced (0.970%)
                3061 active+clean
                  10 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 134 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 20:37:36,960 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:37:36,960 INFO cluster.py [line:239] usefull PG number is 3061
2017-06-08 20:38:37,020 INFO cluster.py [line:247] cost 61 seconds, left 3219 seconds when check the ceph status
2017-06-08 20:38:37,020 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:38:37,361 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            9 pgs stuck unclean
            recovery 6021/818784 objects misplaced (0.735%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3102: 10 osds: 10 up, 10 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42747: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2086 GB used, 4906 GB / 6992 GB avail
            6021/818784 objects misplaced (0.735%)
                3063 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 114 MB/s, 35 objects/s
stdin: is not a tty

2017-06-08 20:38:37,362 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:38:37,362 INFO cluster.py [line:239] usefull PG number is 3063
2017-06-08 20:39:37,422 INFO cluster.py [line:247] cost 60 seconds, left 3159 seconds when check the ceph status
2017-06-08 20:39:37,422 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:39:37,799 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            4 pgs backfill_wait
            1 pgs backfilling
            5 pgs stuck unclean
            recovery 3388/817113 objects misplaced (0.415%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3112: 10 osds: 10 up, 10 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42789: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4908 GB / 6992 GB avail
            3388/817113 objects misplaced (0.415%)
                3067 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 216 MB/s, 59 objects/s
stdin: is not a tty

2017-06-08 20:39:37,799 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:39:37,799 INFO cluster.py [line:239] usefull PG number is 3067
2017-06-08 20:40:37,859 INFO cluster.py [line:247] cost 60 seconds, left 3099 seconds when check the ceph status
2017-06-08 20:40:37,860 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:40:38,242 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 1345/816201 objects misplaced (0.165%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3117: 10 osds: 10 up, 10 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42829: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
            1345/816201 objects misplaced (0.165%)
                3071 active+clean
                   1 active+remapped+backfilling
recovery io 160 MB/s, 49 objects/s
stdin: is not a tty

2017-06-08 20:40:38,242 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:40:38,242 INFO cluster.py [line:239] usefull PG number is 3071
2017-06-08 20:41:38,261 INFO cluster.py [line:247] cost 61 seconds, left 3038 seconds when check the ceph status
2017-06-08 20:41:38,261 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:41:38,643 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3119: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42860: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
                3071 active+clean
                   1 active+clean+scrubbing+deep
stdin: is not a tty

2017-06-08 20:41:38,643 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:41:38,643 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 20:42:38,698 INFO cluster.py [line:247] cost 60 seconds, left 2978 seconds when check the ceph status
2017-06-08 20:42:38,698 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:42:39,040 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3119: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42872: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 20:42:39,040 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:42:39,040 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 20:42:39,040 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:89] stop in cluster successfully
2017-06-08 20:42:39,041 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-08 20:42:51,028 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-08 20:42:51,028 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-08 20:42:51,028 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:42:51,423 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/11 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3121: 11 osds: 10 up, 11 in; 1040 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42882: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2084 GB used, 4907 GB / 6992 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 20:42:51,423 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:42:51,423 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 20:42:51,423 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-08 20:42:51,423 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme0n1
2017-06-08 20:43:03,624 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-08 20:43:03,624 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-08 20:43:03,625 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:43:04,004 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            275 pgs backfill_wait
            4 pgs backfilling
            25 pgs degraded
            25 pgs recovery_wait
            168 pgs stuck unclean
            recovery 63/980527 objects degraded (0.006%)
            recovery 329116/980527 objects misplaced (33.565%)
            1/12 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3129: 12 osds: 11 up, 12 in; 1081 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42897: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2095 GB used, 5596 GB / 7691 GB avail
            63/980527 objects degraded (0.006%)
            329116/980527 objects misplaced (33.565%)
                2768 active+clean
                 275 active+remapped+backfill_wait
                  25 active+recovery_wait+degraded
                   4 active+remapped+backfilling
recovery io 906 MB/s, 289 objects/s
  client io 21754 B/s rd, 31 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 20:43:04,005 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:43:04,005 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-08 20:44:04,038 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-08 20:44:04,038 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:44:04,471 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            406 pgs backfill_wait
            5 pgs backfilling
            9 pgs degraded
            9 pgs recovery_wait
            250 pgs stuck unclean
            recovery 26/1066907 objects degraded (0.002%)
            recovery 500652/1066907 objects misplaced (46.926%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3148: 12 osds: 12 up, 12 in; 411 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42961: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2108 GB used, 6282 GB / 8390 GB avail
            26/1066907 objects degraded (0.002%)
            500652/1066907 objects misplaced (46.926%)
                2652 active+clean
                 406 active+remapped+backfill_wait
                   9 active+recovery_wait+degraded
                   5 active+remapped+backfilling
recovery io 1114 MB/s, 345 objects/s
stdin: is not a tty

2017-06-08 20:44:04,471 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:44:04,471 INFO cluster.py [line:239] usefull PG number is 2652
2017-06-08 20:45:04,495 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-08 20:45:04,495 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:45:04,876 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            392 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            241 pgs stuck unclean
            recovery 481713/1056716 objects misplaced (45.586%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3173: 12 osds: 12 up, 12 in; 396 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43025: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2109 GB used, 6280 GB / 8390 GB avail
            481713/1056716 objects misplaced (45.586%)
                2675 active+clean
                 392 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 982 MB/s, 327 objects/s
stdin: is not a tty

2017-06-08 20:45:04,877 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:45:04,877 INFO cluster.py [line:239] usefull PG number is 2675
2017-06-08 20:46:04,905 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-08 20:46:04,905 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:46:05,301 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            378 pgs backfill_wait
            2 pgs backfilling
            325 pgs stuck unclean
            recovery 464721/1048452 objects misplaced (44.324%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3193: 12 osds: 12 up, 12 in; 380 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43087: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            464721/1048452 objects misplaced (44.324%)
                2692 active+clean
                 378 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 421 MB/s, 137 objects/s
stdin: is not a tty

2017-06-08 20:46:05,301 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:46:05,301 INFO cluster.py [line:239] usefull PG number is 2692
2017-06-08 20:47:05,304 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-08 20:47:05,305 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:47:05,712 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            367 pgs backfill_wait
            5 pgs backfilling
            1 pgs peering
            347 pgs stuck unclean
            recovery 449464/1041340 objects misplaced (43.162%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3208: 12 osds: 12 up, 12 in; 371 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43147: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2108 GB used, 6282 GB / 8390 GB avail
            449464/1041340 objects misplaced (43.162%)
                2699 active+clean
                 367 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 peering
recovery io 1761 MB/s, 574 objects/s
stdin: is not a tty

2017-06-08 20:47:05,713 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:47:05,713 INFO cluster.py [line:239] usefull PG number is 2699
2017-06-08 20:48:05,769 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-08 20:48:05,769 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:48:06,144 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            361 pgs backfill_wait
            3 pgs backfilling
            364 pgs stuck unclean
            recovery 439392/1035682 objects misplaced (42.425%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3220: 12 osds: 12 up, 12 in; 364 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43205: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            439392/1035682 objects misplaced (42.425%)
                2708 active+clean
                 361 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 487 MB/s, 150 objects/s
stdin: is not a tty

2017-06-08 20:48:06,144 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:48:06,144 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-08 20:49:06,198 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-08 20:49:06,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:49:06,628 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            356 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            358 pgs stuck unclean
            recovery 433007/1032460 objects misplaced (41.939%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3232: 12 osds: 12 up, 12 in; 358 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43266: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6284 GB / 8390 GB avail
            433007/1032460 objects misplaced (41.939%)
                2713 active+clean
                 356 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 472 MB/s, 146 objects/s
stdin: is not a tty

2017-06-08 20:49:06,628 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:49:06,628 INFO cluster.py [line:239] usefull PG number is 2713
2017-06-08 20:50:06,669 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-08 20:50:06,670 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:50:07,049 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            349 pgs backfill_wait
            3 pgs backfilling
            352 pgs stuck unclean
            recovery 425885/1028605 objects misplaced (41.404%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3241: 12 osds: 12 up, 12 in; 352 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43324: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            425885/1028605 objects misplaced (41.404%)
                2720 active+clean
                 349 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 538 MB/s, 166 objects/s
stdin: is not a tty

2017-06-08 20:50:07,049 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:50:07,050 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-08 20:51:07,110 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-08 20:51:07,110 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:51:07,569 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            345 pgs backfill_wait
            3 pgs backfilling
            348 pgs stuck unclean
            recovery 420114/1026310 objects misplaced (40.934%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3248: 12 osds: 12 up, 12 in; 348 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43381: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            420114/1026310 objects misplaced (40.934%)
                2724 active+clean
                 345 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 267 MB/s, 83 objects/s
stdin: is not a tty

2017-06-08 20:51:07,569 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:51:07,569 INFO cluster.py [line:239] usefull PG number is 2724
2017-06-08 20:52:07,603 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-08 20:52:07,603 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:52:08,131 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            336 pgs backfill_wait
            3 pgs backfilling
            339 pgs stuck unclean
            recovery 410752/1021510 objects misplaced (40.210%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3263: 12 osds: 12 up, 12 in; 338 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43441: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            410752/1021510 objects misplaced (40.210%)
                2733 active+clean
                 336 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 24596 B/s rd, 36 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 20:52:08,132 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:52:08,132 INFO cluster.py [line:239] usefull PG number is 2733
2017-06-08 20:53:08,166 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-08 20:53:08,166 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:53:08,572 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            329 pgs backfill_wait
            2 pgs backfilling
            331 pgs stuck unclean
            recovery 400484/1015868 objects misplaced (39.423%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3276: 12 osds: 12 up, 12 in; 331 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43499: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            400484/1015868 objects misplaced (39.423%)
                2741 active+clean
                 329 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 378 MB/s, 117 objects/s
  client io 23660 B/s rd, 34 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 20:53:08,573 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:53:08,573 INFO cluster.py [line:239] usefull PG number is 2741
2017-06-08 20:54:08,605 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-08 20:54:08,606 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:54:09,019 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            324 pgs backfill_wait
            2 pgs backfilling
            326 pgs stuck unclean
            recovery 395005/1013399 objects misplaced (38.978%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3285: 12 osds: 12 up, 12 in; 326 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43557: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            395005/1013399 objects misplaced (38.978%)
                2746 active+clean
                 324 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 757 MB/s, 248 objects/s
  client io 27388 B/s rd, 40 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 20:54:09,019 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:54:09,020 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-08 20:55:09,048 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-08 20:55:09,048 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:55:09,459 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            318 pgs backfill_wait
            2 pgs backfilling
            320 pgs stuck unclean
            recovery 388869/1010240 objects misplaced (38.493%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3297: 12 osds: 12 up, 12 in; 320 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43617: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            388869/1010240 objects misplaced (38.493%)
                2751 active+clean
                 318 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 241 MB/s, 75 objects/s
stdin: is not a tty

2017-06-08 20:55:09,459 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:55:09,459 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 20:56:09,519 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-08 20:56:09,520 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:56:10,063 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            313 pgs backfill_wait
            1 pgs backfilling
            314 pgs stuck unclean
            recovery 383119/1007069 objects misplaced (38.043%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3309: 12 osds: 12 up, 12 in; 314 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43675: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            383119/1007069 objects misplaced (38.043%)
                2758 active+clean
                 313 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:56:10,063 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:56:10,063 INFO cluster.py [line:239] usefull PG number is 2758
2017-06-08 20:57:10,102 INFO cluster.py [line:247] cost 61 seconds, left 5153 seconds when check the ceph status
2017-06-08 20:57:10,102 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:57:10,483 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            311 pgs backfill_wait
            1 pgs backfilling
            312 pgs stuck unclean
            recovery 378984/1005554 objects misplaced (37.689%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3313: 12 osds: 12 up, 12 in; 312 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43730: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6285 GB / 8390 GB avail
            378984/1005554 objects misplaced (37.689%)
                2760 active+clean
                 311 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:57:10,483 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:57:10,483 INFO cluster.py [line:239] usefull PG number is 2760
2017-06-08 20:58:10,543 INFO cluster.py [line:247] cost 60 seconds, left 5093 seconds when check the ceph status
2017-06-08 20:58:10,544 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:58:10,948 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            309 pgs backfill_wait
            1 pgs backfilling
            310 pgs stuck unclean
            recovery 375256/1003144 objects misplaced (37.408%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3317: 12 osds: 12 up, 12 in; 310 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43783: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            375256/1003144 objects misplaced (37.408%)
                2762 active+clean
                 309 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:58:10,948 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:58:10,948 INFO cluster.py [line:239] usefull PG number is 2762
2017-06-08 20:59:10,971 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-08 20:59:10,971 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 20:59:11,343 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            308 pgs backfill_wait
            1 pgs backfilling
            309 pgs stuck unclean
            recovery 372638/1002338 objects misplaced (37.177%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3319: 12 osds: 12 up, 12 in; 309 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43834: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6285 GB / 8390 GB avail
            372638/1002338 objects misplaced (37.177%)
                2763 active+clean
                 308 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 20:59:11,343 INFO cluster.py [line:238] PG number is 3072
2017-06-08 20:59:11,343 INFO cluster.py [line:239] usefull PG number is 2763
2017-06-08 21:00:11,402 INFO cluster.py [line:247] cost 61 seconds, left 4972 seconds when check the ceph status
2017-06-08 21:00:11,402 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:00:11,803 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            306 pgs backfill_wait
            1 pgs backfilling
            307 pgs stuck unclean
            recovery 368760/999872 objects misplaced (36.881%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3323: 12 osds: 12 up, 12 in; 307 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43888: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            368760/999872 objects misplaced (36.881%)
                2765 active+clean
                 306 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 334 MB/s, 109 objects/s
stdin: is not a tty

2017-06-08 21:00:11,804 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:00:11,804 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-08 21:01:11,864 INFO cluster.py [line:247] cost 60 seconds, left 4912 seconds when check the ceph status
2017-06-08 21:01:11,864 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:01:12,266 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            305 pgs backfill_wait
            1 pgs backfilling
            306 pgs stuck unclean
            recovery 365504/998344 objects misplaced (36.611%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3325: 12 osds: 12 up, 12 in; 306 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43939: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            365504/998344 objects misplaced (36.611%)
                2766 active+clean
                 305 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 236 MB/s, 74 objects/s
stdin: is not a tty

2017-06-08 21:01:12,266 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:01:12,267 INFO cluster.py [line:239] usefull PG number is 2766
2017-06-08 21:02:12,299 INFO cluster.py [line:247] cost 61 seconds, left 4851 seconds when check the ceph status
2017-06-08 21:02:12,299 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:02:12,665 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            303 pgs backfill_wait
            1 pgs backfilling
            304 pgs stuck unclean
            recovery 363510/997485 objects misplaced (36.443%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3329: 12 osds: 12 up, 12 in; 304 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43989: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            363510/997485 objects misplaced (36.443%)
                2768 active+clean
                 303 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 252 MB/s, 76 objects/s
  client io 122 kB/s rd, 154 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:02:12,666 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:02:12,666 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-08 21:03:12,726 INFO cluster.py [line:247] cost 60 seconds, left 4791 seconds when check the ceph status
2017-06-08 21:03:12,726 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:03:13,115 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            301 pgs backfill_wait
            1 pgs backfilling
            302 pgs stuck unclean
            recovery 360881/995916 objects misplaced (36.236%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3333: 12 osds: 12 up, 12 in; 302 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44042: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            360881/995916 objects misplaced (36.236%)
                2770 active+clean
                 301 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 268 MB/s, 83 objects/s
stdin: is not a tty

2017-06-08 21:03:13,115 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:03:13,116 INFO cluster.py [line:239] usefull PG number is 2770
2017-06-08 21:04:13,127 INFO cluster.py [line:247] cost 61 seconds, left 4730 seconds when check the ceph status
2017-06-08 21:04:13,128 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:04:13,527 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            300 pgs backfill_wait
            1 pgs backfilling
            301 pgs stuck unclean
            recovery 359061/995139 objects misplaced (36.081%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3335: 12 osds: 12 up, 12 in; 301 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44092: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            359061/995139 objects misplaced (36.081%)
                2771 active+clean
                 300 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:04:13,527 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:04:13,527 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-08 21:05:13,588 INFO cluster.py [line:247] cost 60 seconds, left 4670 seconds when check the ceph status
2017-06-08 21:05:13,588 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:05:13,994 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            298 pgs backfill_wait
            1 pgs backfilling
            299 pgs stuck unclean
            recovery 356189/993578 objects misplaced (35.849%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3339: 12 osds: 12 up, 12 in; 299 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44147: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            356189/993578 objects misplaced (35.849%)
                2773 active+clean
                 298 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 21336 B/s rd, 31 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:05:13,994 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:05:13,994 INFO cluster.py [line:239] usefull PG number is 2773
2017-06-08 21:06:13,998 INFO cluster.py [line:247] cost 60 seconds, left 4610 seconds when check the ceph status
2017-06-08 21:06:13,999 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:06:14,403 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            295 pgs backfill_wait
            1 pgs backfilling
            296 pgs stuck unclean
            recovery 354049/992696 objects misplaced (35.665%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3345: 12 osds: 12 up, 12 in; 296 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44196: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            354049/992696 objects misplaced (35.665%)
                2776 active+clean
                 295 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 262 MB/s, 81 objects/s
  client io 23665 B/s rd, 34 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:06:14,404 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:06:14,404 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-08 21:07:14,430 INFO cluster.py [line:247] cost 61 seconds, left 4549 seconds when check the ceph status
2017-06-08 21:07:14,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:07:14,847 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            293 pgs backfill_wait
            1 pgs backfilling
            294 pgs stuck unclean
            recovery 349775/990353 objects misplaced (35.318%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3349: 12 osds: 12 up, 12 in; 294 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44246: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            349775/990353 objects misplaced (35.318%)
                2778 active+clean
                 293 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 18942 B/s rd, 27 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:07:14,847 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:07:14,847 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-08 21:08:14,903 INFO cluster.py [line:247] cost 60 seconds, left 4489 seconds when check the ceph status
2017-06-08 21:08:14,903 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:08:15,286 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            292 pgs backfill_wait
            1 pgs backfilling
            293 pgs stuck unclean
            recovery 347915/989550 objects misplaced (35.159%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3351: 12 osds: 12 up, 12 in; 293 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44296: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            347915/989550 objects misplaced (35.159%)
                2779 active+clean
                 292 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24188 B/s rd, 35 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:08:15,287 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:08:15,287 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-08 21:09:15,296 INFO cluster.py [line:247] cost 61 seconds, left 4428 seconds when check the ceph status
2017-06-08 21:09:15,296 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:09:15,681 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            290 pgs backfill_wait
            1 pgs backfilling
            291 pgs stuck unclean
            recovery 344872/987920 objects misplaced (34.909%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3355: 12 osds: 12 up, 12 in; 291 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44346: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            344872/987920 objects misplaced (34.909%)
                2781 active+clean
                 290 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 312 MB/s, 96 objects/s
  client io 98662 B/s rd, 121 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:09:15,681 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:09:15,681 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-08 21:10:15,729 INFO cluster.py [line:247] cost 60 seconds, left 4368 seconds when check the ceph status
2017-06-08 21:10:15,729 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:10:16,162 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            289 pgs backfill_wait
            1 pgs backfilling
            290 pgs stuck unclean
            recovery 342944/987118 objects misplaced (34.742%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3357: 12 osds: 12 up, 12 in; 290 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44398: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            342944/987118 objects misplaced (34.742%)
                2782 active+clean
                 289 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 232 MB/s, 71 objects/s
  client io 100 kB/s rd, 126 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:10:16,162 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:10:16,162 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-08 21:11:16,201 INFO cluster.py [line:247] cost 61 seconds, left 4307 seconds when check the ceph status
2017-06-08 21:11:16,202 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:11:16,680 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            286 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            288 pgs stuck unclean
            recovery 338641/984790 objects misplaced (34.387%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3363: 12 osds: 12 up, 12 in; 287 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44455: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2106 GB used, 6284 GB / 8390 GB avail
            338641/984790 objects misplaced (34.387%)
                2783 active+clean
                 286 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 416 MB/s, 129 objects/s
stdin: is not a tty

2017-06-08 21:11:16,680 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:11:16,680 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-08 21:12:16,714 INFO cluster.py [line:247] cost 60 seconds, left 4247 seconds when check the ceph status
2017-06-08 21:12:16,714 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:12:17,139 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            281 pgs backfill_wait
            2 pgs backfilling
            283 pgs stuck unclean
            recovery 334733/983053 objects misplaced (34.050%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3370: 12 osds: 12 up, 12 in; 283 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44512: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            334733/983053 objects misplaced (34.050%)
                2789 active+clean
                 281 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 284 MB/s, 87 objects/s
  client io 85415 B/s rd, 104 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:12:17,139 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:12:17,139 INFO cluster.py [line:239] usefull PG number is 2789
2017-06-08 21:13:17,198 INFO cluster.py [line:247] cost 61 seconds, left 4186 seconds when check the ceph status
2017-06-08 21:13:17,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:13:17,610 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            275 pgs backfill_wait
            2 pgs backfilling
            277 pgs stuck unclean
            recovery 329703/980516 objects misplaced (33.625%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3382: 12 osds: 12 up, 12 in; 277 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44570: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            329703/980516 objects misplaced (33.625%)
                2795 active+clean
                 275 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 240 MB/s, 75 objects/s
stdin: is not a tty

2017-06-08 21:13:17,610 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:13:17,611 INFO cluster.py [line:239] usefull PG number is 2795
2017-06-08 21:14:17,671 INFO cluster.py [line:247] cost 60 seconds, left 4126 seconds when check the ceph status
2017-06-08 21:14:17,671 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:14:18,074 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            271 pgs backfill_wait
            2 pgs backfilling
            273 pgs stuck unclean
            recovery 325877/978890 objects misplaced (33.290%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3390: 12 osds: 12 up, 12 in; 273 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44627: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            325877/978890 objects misplaced (33.290%)
                2799 active+clean
                 271 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 539 MB/s, 167 objects/s
  client io 82307 B/s rd, 101 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:14:18,074 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:14:18,074 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-08 21:15:18,130 INFO cluster.py [line:247] cost 61 seconds, left 4065 seconds when check the ceph status
2017-06-08 21:15:18,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:15:18,522 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            265 pgs backfill_wait
            2 pgs backfilling
            267 pgs stuck unclean
            recovery 320705/975856 objects misplaced (32.864%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3401: 12 osds: 12 up, 12 in; 267 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44683: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            320705/975856 objects misplaced (32.864%)
                2805 active+clean
                 265 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:15:18,522 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:15:18,522 INFO cluster.py [line:239] usefull PG number is 2805
2017-06-08 21:16:18,583 INFO cluster.py [line:247] cost 60 seconds, left 4005 seconds when check the ceph status
2017-06-08 21:16:18,583 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:16:18,928 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            263 pgs backfill_wait
            2 pgs backfilling
            265 pgs stuck unclean
            recovery 316863/974289 objects misplaced (32.522%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3405: 12 osds: 12 up, 12 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44738: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            316863/974289 objects misplaced (32.522%)
                2807 active+clean
                 263 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 22149 B/s rd, 32 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:16:18,928 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:16:18,929 INFO cluster.py [line:239] usefull PG number is 2807
2017-06-08 21:17:18,983 INFO cluster.py [line:247] cost 60 seconds, left 3945 seconds when check the ceph status
2017-06-08 21:17:18,983 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:17:19,392 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            259 pgs backfill_wait
            2 pgs backfilling
            261 pgs stuck unclean
            recovery 310758/971157 objects misplaced (31.999%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3413: 12 osds: 12 up, 12 in; 261 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44793: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            310758/971157 objects misplaced (31.999%)
                2811 active+clean
                 259 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 253 MB/s, 78 objects/s
  client io 16614 B/s rd, 24 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:17:19,392 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:17:19,393 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-08 21:18:19,430 INFO cluster.py [line:247] cost 61 seconds, left 3884 seconds when check the ceph status
2017-06-08 21:18:19,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:18:19,837 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            255 pgs backfill_wait
            2 pgs backfilling
            257 pgs stuck unclean
            recovery 306332/968803 objects misplaced (31.620%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3421: 12 osds: 12 up, 12 in; 257 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44847: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            306332/968803 objects misplaced (31.620%)
                2815 active+clean
                 255 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 23746 B/s rd, 34 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:18:19,837 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:18:19,837 INFO cluster.py [line:239] usefull PG number is 2815
2017-06-08 21:19:19,854 INFO cluster.py [line:247] cost 60 seconds, left 3824 seconds when check the ceph status
2017-06-08 21:19:19,855 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:19:20,257 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            250 pgs backfill_wait
            2 pgs backfilling
            252 pgs stuck unclean
            recovery 301351/966540 objects misplaced (31.178%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3429: 12 osds: 12 up, 12 in; 252 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44902: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            301351/966540 objects misplaced (31.178%)
                2820 active+clean
                 250 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 21034 B/s rd, 30 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:19:20,257 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:19:20,257 INFO cluster.py [line:239] usefull PG number is 2820
2017-06-08 21:20:20,318 INFO cluster.py [line:247] cost 61 seconds, left 3763 seconds when check the ceph status
2017-06-08 21:20:20,318 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:20:20,673 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            245 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            248 pgs stuck unclean
            recovery 295133/963363 objects misplaced (30.636%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3436: 12 osds: 12 up, 12 in; 246 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44957: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            295133/963363 objects misplaced (30.636%)
                2823 active+clean
                 245 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
                   1 active+remapped
recovery io 554 MB/s, 162 objects/s
stdin: is not a tty

2017-06-08 21:20:20,674 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:20:20,674 INFO cluster.py [line:239] usefull PG number is 2823
2017-06-08 21:21:20,722 INFO cluster.py [line:247] cost 60 seconds, left 3703 seconds when check the ceph status
2017-06-08 21:21:20,722 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:21:21,112 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            242 pgs backfill_wait
            1 pgs backfilling
            243 pgs stuck unclean
            recovery 289214/960160 objects misplaced (30.121%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3442: 12 osds: 12 up, 12 in; 243 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45010: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            289214/960160 objects misplaced (30.121%)
                2829 active+clean
                 242 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 182 MB/s, 57 objects/s
  client io 13015 B/s rd, 19 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:21:21,113 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:21:21,113 INFO cluster.py [line:239] usefull PG number is 2829
2017-06-08 21:22:21,150 INFO cluster.py [line:247] cost 61 seconds, left 3642 seconds when check the ceph status
2017-06-08 21:22:21,150 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:22:21,535 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            240 pgs backfill_wait
            1 pgs backfilling
            241 pgs stuck unclean
            recovery 287216/959325 objects misplaced (29.939%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3446: 12 osds: 12 up, 12 in; 241 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45061: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            287216/959325 objects misplaced (29.939%)
                2831 active+clean
                 240 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:22:21,536 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:22:21,536 INFO cluster.py [line:239] usefull PG number is 2831
2017-06-08 21:23:21,548 INFO cluster.py [line:247] cost 60 seconds, left 3582 seconds when check the ceph status
2017-06-08 21:23:21,549 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:23:21,931 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            236 pgs backfill_wait
            1 pgs backfilling
            237 pgs stuck unclean
            recovery 284142/957623 objects misplaced (29.672%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3454: 12 osds: 12 up, 12 in; 237 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45118: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            284142/957623 objects misplaced (29.672%)
                2835 active+clean
                 236 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 243 MB/s, 5 keys/s, 74 objects/s
stdin: is not a tty

2017-06-08 21:23:21,932 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:23:21,932 INFO cluster.py [line:239] usefull PG number is 2835
2017-06-08 21:24:21,965 INFO cluster.py [line:247] cost 60 seconds, left 3522 seconds when check the ceph status
2017-06-08 21:24:21,966 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:24:22,389 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            235 pgs backfill_wait
            1 pgs backfilling
            236 pgs stuck unclean
            recovery 282318/956840 objects misplaced (29.505%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3456: 12 osds: 12 up, 12 in; 236 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45166: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            282318/956840 objects misplaced (29.505%)
                2836 active+clean
                 235 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:24:22,389 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:24:22,389 INFO cluster.py [line:239] usefull PG number is 2836
2017-06-08 21:25:22,430 INFO cluster.py [line:247] cost 61 seconds, left 3461 seconds when check the ceph status
2017-06-08 21:25:22,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:25:22,841 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            233 pgs backfill_wait
            1 pgs backfilling
            234 pgs stuck unclean
            recovery 279654/955323 objects misplaced (29.273%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3460: 12 osds: 12 up, 12 in; 234 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45216: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            279654/955323 objects misplaced (29.273%)
                2838 active+clean
                 233 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 270 MB/s, 83 objects/s
stdin: is not a tty

2017-06-08 21:25:22,841 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:25:22,842 INFO cluster.py [line:239] usefull PG number is 2838
2017-06-08 21:26:22,880 INFO cluster.py [line:247] cost 60 seconds, left 3401 seconds when check the ceph status
2017-06-08 21:26:22,880 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:26:23,304 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            232 pgs backfill_wait
            1 pgs backfilling
            233 pgs stuck unclean
            recovery 277852/954546 objects misplaced (29.108%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3462: 12 osds: 12 up, 12 in; 233 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45266: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            277852/954546 objects misplaced (29.108%)
                2838 active+clean
                 232 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
stdin: is not a tty

2017-06-08 21:26:23,304 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:26:23,304 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 21:27:23,310 INFO cluster.py [line:247] cost 61 seconds, left 3340 seconds when check the ceph status
2017-06-08 21:27:23,311 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:27:23,775 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            230 pgs backfill_wait
            1 pgs backfilling
            231 pgs stuck unclean
            recovery 275168/952990 objects misplaced (28.874%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3466: 12 osds: 12 up, 12 in; 231 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45322: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            275168/952990 objects misplaced (28.874%)
                2840 active+clean
                 230 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 164 MB/s, 49 objects/s
stdin: is not a tty

2017-06-08 21:27:23,776 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:27:23,776 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 21:28:23,826 INFO cluster.py [line:247] cost 60 seconds, left 3280 seconds when check the ceph status
2017-06-08 21:28:23,826 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:28:24,250 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            227 pgs backfill_wait
            1 pgs backfilling
            228 pgs stuck unclean
            recovery 273341/952113 objects misplaced (28.709%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3472: 12 osds: 12 up, 12 in; 228 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45375: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            273341/952113 objects misplaced (28.709%)
                2844 active+clean
                 227 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:28:24,251 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:28:24,251 INFO cluster.py [line:239] usefull PG number is 2844
2017-06-08 21:29:24,267 INFO cluster.py [line:247] cost 61 seconds, left 3219 seconds when check the ceph status
2017-06-08 21:29:24,268 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:29:24,673 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            223 pgs backfill_wait
            2 pgs backfilling
            225 pgs stuck unclean
            recovery 270716/951203 objects misplaced (28.460%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3477: 12 osds: 12 up, 12 in; 225 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45428: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            270716/951203 objects misplaced (28.460%)
                2847 active+clean
                 223 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 229 MB/s, 71 objects/s
stdin: is not a tty

2017-06-08 21:29:24,673 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:29:24,673 INFO cluster.py [line:239] usefull PG number is 2847
2017-06-08 21:30:24,733 INFO cluster.py [line:247] cost 60 seconds, left 3159 seconds when check the ceph status
2017-06-08 21:30:24,734 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:30:25,081 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            219 pgs backfill_wait
            2 pgs backfilling
            221 pgs stuck unclean
            recovery 265528/948192 objects misplaced (28.004%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3485: 12 osds: 12 up, 12 in; 220 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45485: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            265528/948192 objects misplaced (28.004%)
                2851 active+clean
                 219 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 41825 kB/s, 13 objects/s
  client io 16042 B/s rd, 23 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:30:25,082 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:30:25,082 INFO cluster.py [line:239] usefull PG number is 2851
2017-06-08 21:31:25,142 INFO cluster.py [line:247] cost 61 seconds, left 3098 seconds when check the ceph status
2017-06-08 21:31:25,142 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:31:25,568 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            216 pgs backfill_wait
            1 pgs backfilling
            217 pgs stuck unclean
            recovery 261900/946464 objects misplaced (27.671%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3490: 12 osds: 12 up, 12 in; 217 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45537: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            261900/946464 objects misplaced (27.671%)
                2855 active+clean
                 216 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 87773 B/s rd, 110 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:31:25,568 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:31:25,569 INFO cluster.py [line:239] usefull PG number is 2855
2017-06-08 21:32:25,599 INFO cluster.py [line:247] cost 60 seconds, left 3038 seconds when check the ceph status
2017-06-08 21:32:25,600 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:32:25,996 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            215 pgs backfill_wait
            1 pgs backfilling
            216 pgs stuck unclean
            recovery 260009/945687 objects misplaced (27.494%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3492: 12 osds: 12 up, 12 in; 216 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45586: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            260009/945687 objects misplaced (27.494%)
                2856 active+clean
                 215 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 91024 B/s rd, 115 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:32:25,996 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:32:25,996 INFO cluster.py [line:239] usefull PG number is 2856
2017-06-08 21:33:26,056 INFO cluster.py [line:247] cost 61 seconds, left 2977 seconds when check the ceph status
2017-06-08 21:33:26,056 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:33:26,411 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            212 pgs backfill_wait
            1 pgs backfilling
            213 pgs stuck unclean
            recovery 257364/944138 objects misplaced (27.259%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3498: 12 osds: 12 up, 12 in; 213 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45637: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2101 GB used, 6288 GB / 8390 GB avail
            257364/944138 objects misplaced (27.259%)
                2859 active+clean
                 212 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 88666 B/s rd, 108 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:33:26,411 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:33:26,411 INFO cluster.py [line:239] usefull PG number is 2859
2017-06-08 21:34:26,451 INFO cluster.py [line:247] cost 60 seconds, left 2917 seconds when check the ceph status
2017-06-08 21:34:26,451 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:34:26,852 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            211 pgs backfill_wait
            1 pgs backfilling
            212 pgs stuck unclean
            recovery 255531/943367 objects misplaced (27.087%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3500: 12 osds: 12 up, 12 in; 212 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45690: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            255531/943367 objects misplaced (27.087%)
                2860 active+clean
                 211 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 295 MB/s, 91 objects/s
  client io 108 kB/s rd, 136 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:34:26,852 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:34:26,852 INFO cluster.py [line:239] usefull PG number is 2860
2017-06-08 21:35:26,853 INFO cluster.py [line:247] cost 60 seconds, left 2857 seconds when check the ceph status
2017-06-08 21:35:26,854 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:35:27,284 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            204 pgs backfill_wait
            2 pgs backfilling
            206 pgs stuck unclean
            recovery 251381/941599 objects misplaced (26.697%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3511: 12 osds: 12 up, 12 in; 206 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45747: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            251381/941599 objects misplaced (26.697%)
                2866 active+clean
                 204 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 325 MB/s, 110 objects/s
  client io 81461 B/s rd, 100 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:35:27,284 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:35:27,284 INFO cluster.py [line:239] usefull PG number is 2866
2017-06-08 21:36:27,336 INFO cluster.py [line:247] cost 61 seconds, left 2796 seconds when check the ceph status
2017-06-08 21:36:27,336 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:36:27,718 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            201 pgs backfill_wait
            2 pgs backfilling
            203 pgs stuck unclean
            recovery 245516/938487 objects misplaced (26.161%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3517: 12 osds: 12 up, 12 in; 203 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45803: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            245516/938487 objects misplaced (26.161%)
                2869 active+clean
                 201 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 227 MB/s, 70 objects/s
  client io 73892 B/s rd, 90 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:36:27,719 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:36:27,719 INFO cluster.py [line:239] usefull PG number is 2869
2017-06-08 21:37:27,779 INFO cluster.py [line:247] cost 60 seconds, left 2736 seconds when check the ceph status
2017-06-08 21:37:27,779 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:37:28,154 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            196 pgs backfill_wait
            2 pgs backfilling
            198 pgs stuck unclean
            recovery 240979/936788 objects misplaced (25.724%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3524: 12 osds: 12 up, 12 in; 198 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45857: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6284 GB / 8390 GB avail
            240979/936788 objects misplaced (25.724%)
                2874 active+clean
                 196 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 429 MB/s, 140 objects/s
  client io 89199 B/s rd, 109 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:37:28,154 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:37:28,154 INFO cluster.py [line:239] usefull PG number is 2874
2017-06-08 21:38:28,195 INFO cluster.py [line:247] cost 61 seconds, left 2675 seconds when check the ceph status
2017-06-08 21:38:28,195 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:38:28,618 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            188 pgs backfill_wait
            2 pgs backfilling
            190 pgs stuck unclean
            recovery 235444/933509 objects misplaced (25.221%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3539: 12 osds: 12 up, 12 in; 190 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45918: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            235444/933509 objects misplaced (25.221%)
                2882 active+clean
                 188 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 253 MB/s, 79 objects/s
stdin: is not a tty

2017-06-08 21:38:28,619 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:38:28,619 INFO cluster.py [line:239] usefull PG number is 2882
2017-06-08 21:39:28,668 INFO cluster.py [line:247] cost 60 seconds, left 2615 seconds when check the ceph status
2017-06-08 21:39:28,668 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:39:29,055 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            181 pgs backfill_wait
            3 pgs backfilling
            184 pgs stuck unclean
            recovery 230580/931037 objects misplaced (24.766%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3550: 12 osds: 12 up, 12 in; 184 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45977: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            230580/931037 objects misplaced (24.766%)
                2888 active+clean
                 181 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 254 MB/s, 78 objects/s
  client io 24454 B/s rd, 35 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:39:29,056 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:39:29,056 INFO cluster.py [line:239] usefull PG number is 2888
2017-06-08 21:40:29,080 INFO cluster.py [line:247] cost 61 seconds, left 2554 seconds when check the ceph status
2017-06-08 21:40:29,081 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:40:29,459 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            178 pgs backfill_wait
            2 pgs backfilling
            180 pgs stuck unclean
            recovery 225440/928648 objects misplaced (24.276%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3557: 12 osds: 12 up, 12 in; 180 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46030: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            225440/928648 objects misplaced (24.276%)
                2892 active+clean
                 178 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 289 MB/s, 89 objects/s
  client io 22166 B/s rd, 32 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:40:29,459 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:40:29,459 INFO cluster.py [line:239] usefull PG number is 2892
2017-06-08 21:41:29,519 INFO cluster.py [line:247] cost 60 seconds, left 2494 seconds when check the ceph status
2017-06-08 21:41:29,520 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:41:29,912 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            176 pgs backfill_wait
            1 pgs backfilling
            177 pgs stuck unclean
            recovery 221745/926321 objects misplaced (23.938%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3563: 12 osds: 12 up, 12 in; 177 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46081: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            221745/926321 objects misplaced (23.938%)
                2895 active+clean
                 176 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 338 MB/s, 106 objects/s
  client io 18455 B/s rd, 27 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:41:29,912 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:41:29,912 INFO cluster.py [line:239] usefull PG number is 2895
2017-06-08 21:42:29,958 INFO cluster.py [line:247] cost 60 seconds, left 2434 seconds when check the ceph status
2017-06-08 21:42:29,958 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:42:30,373 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            174 pgs backfill_wait
            2 pgs backfilling
            176 pgs stuck unclean
            recovery 219142/925540 objects misplaced (23.677%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3565: 12 osds: 12 up, 12 in; 176 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46135: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            219142/925540 objects misplaced (23.677%)
                2896 active+clean
                 174 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 576 MB/s, 189 objects/s
  client io 19086 B/s rd, 27 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:42:30,374 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:42:30,374 INFO cluster.py [line:239] usefull PG number is 2896
2017-06-08 21:43:30,434 INFO cluster.py [line:247] cost 61 seconds, left 2373 seconds when check the ceph status
2017-06-08 21:43:30,434 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:43:30,828 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            172 pgs backfill_wait
            1 pgs backfilling
            173 pgs stuck unclean
            recovery 211969/921733 objects misplaced (22.997%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3572: 12 osds: 12 up, 12 in; 172 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46193: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2107 GB used, 6283 GB / 8390 GB avail
            211969/921733 objects misplaced (22.997%)
                2899 active+clean
                 172 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 386 MB/s, 131 objects/s
  client io 135 kB/s rd, 170 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:43:30,828 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:43:30,828 INFO cluster.py [line:239] usefull PG number is 2899
2017-06-08 21:44:30,836 INFO cluster.py [line:247] cost 60 seconds, left 2313 seconds when check the ceph status
2017-06-08 21:44:30,836 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:44:31,253 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            170 pgs backfill_wait
            1 pgs backfilling
            171 pgs stuck unclean
            recovery 209166/920144 objects misplaced (22.732%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3575: 12 osds: 12 up, 12 in; 171 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46242: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            209166/920144 objects misplaced (22.732%)
                2901 active+clean
                 170 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 47173 B/s rd, 69 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-08 21:44:31,253 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:44:31,253 INFO cluster.py [line:239] usefull PG number is 2901
2017-06-08 21:45:31,312 INFO cluster.py [line:247] cost 61 seconds, left 2252 seconds when check the ceph status
2017-06-08 21:45:31,312 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:45:31,744 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            162 pgs backfill_wait
            3 pgs backfilling
            165 pgs stuck unclean
            recovery 204958/918267 objects misplaced (22.320%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3584: 12 osds: 12 up, 12 in; 165 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46295: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            204958/918267 objects misplaced (22.320%)
                2907 active+clean
                 162 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 333 MB/s, 110 objects/s
stdin: is not a tty

2017-06-08 21:45:31,744 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:45:31,744 INFO cluster.py [line:239] usefull PG number is 2907
2017-06-08 21:46:31,804 INFO cluster.py [line:247] cost 60 seconds, left 2192 seconds when check the ceph status
2017-06-08 21:46:31,805 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:46:32,203 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            158 pgs backfill_wait
            1 pgs backfilling
            159 pgs stuck unclean
            recovery 199096/915110 objects misplaced (21.757%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3596: 12 osds: 12 up, 12 in; 159 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46352: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            199096/915110 objects misplaced (21.757%)
                2913 active+clean
                 158 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 124 MB/s, 38 objects/s
stdin: is not a tty

2017-06-08 21:46:32,203 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:46:32,204 INFO cluster.py [line:239] usefull PG number is 2913
2017-06-08 21:47:32,222 INFO cluster.py [line:247] cost 61 seconds, left 2131 seconds when check the ceph status
2017-06-08 21:47:32,222 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:47:32,607 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            156 pgs backfill_wait
            2 pgs backfilling
            158 pgs stuck unclean
            recovery 196117/914307 objects misplaced (21.450%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3598: 12 osds: 12 up, 12 in; 158 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46391: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6284 GB / 8390 GB avail
            196117/914307 objects misplaced (21.450%)
                2914 active+clean
                 156 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 573 MB/s, 185 objects/s
stdin: is not a tty

2017-06-08 21:47:32,607 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:47:32,607 INFO cluster.py [line:239] usefull PG number is 2914
2017-06-08 21:48:32,668 INFO cluster.py [line:247] cost 60 seconds, left 2071 seconds when check the ceph status
2017-06-08 21:48:32,668 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:48:33,062 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            151 pgs backfill_wait
            2 pgs backfilling
            153 pgs stuck unclean
            recovery 189078/910392 objects misplaced (20.769%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3608: 12 osds: 12 up, 12 in; 153 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46449: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            189078/910392 objects misplaced (20.769%)
                2918 active+clean
                 151 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing
recovery io 241 MB/s, 74 objects/s
stdin: is not a tty

2017-06-08 21:48:33,062 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:48:33,062 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 21:49:33,097 INFO cluster.py [line:247] cost 61 seconds, left 2010 seconds when check the ceph status
2017-06-08 21:49:33,097 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:49:33,521 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            144 pgs backfill_wait
            2 pgs backfilling
            146 pgs stuck unclean
            recovery 182018/907033 objects misplaced (20.067%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3620: 12 osds: 12 up, 12 in; 146 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46506: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            182018/907033 objects misplaced (20.067%)
                2925 active+clean
                 144 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 273 MB/s, 85 objects/s
stdin: is not a tty

2017-06-08 21:49:33,521 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:49:33,521 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 21:50:33,557 INFO cluster.py [line:247] cost 60 seconds, left 1950 seconds when check the ceph status
2017-06-08 21:50:33,558 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:50:33,966 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            139 pgs backfill_wait
            2 pgs backfilling
            141 pgs stuck unclean
            recovery 176245/904571 objects misplaced (19.484%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3629: 12 osds: 12 up, 12 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46556: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2106 GB used, 6283 GB / 8390 GB avail
            176245/904571 objects misplaced (19.484%)
                2931 active+clean
                 139 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:50:33,966 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:50:33,966 INFO cluster.py [line:239] usefull PG number is 2931
2017-06-08 21:51:33,968 INFO cluster.py [line:247] cost 60 seconds, left 1890 seconds when check the ceph status
2017-06-08 21:51:33,968 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:51:34,357 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            129 pgs backfill_wait
            4 pgs backfilling
            133 pgs stuck unclean
            recovery 167638/899710 objects misplaced (18.632%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3644: 12 osds: 12 up, 12 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46618: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            167638/899710 objects misplaced (18.632%)
                2939 active+clean
                 129 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 269 MB/s, 83 objects/s
stdin: is not a tty

2017-06-08 21:51:34,358 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:51:34,358 INFO cluster.py [line:239] usefull PG number is 2939
2017-06-08 21:52:34,418 INFO cluster.py [line:247] cost 61 seconds, left 1829 seconds when check the ceph status
2017-06-08 21:52:34,418 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:52:34,845 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            121 pgs backfill_wait
            4 pgs backfilling
            125 pgs stuck unclean
            recovery 157198/895069 objects misplaced (17.563%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3660: 12 osds: 12 up, 12 in; 123 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46680: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2107 GB used, 6283 GB / 8390 GB avail
            157198/895069 objects misplaced (17.563%)
                2947 active+clean
                 121 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 1184 MB/s, 367 objects/s
stdin: is not a tty

2017-06-08 21:52:34,846 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:52:34,846 INFO cluster.py [line:239] usefull PG number is 2947
2017-06-08 21:53:34,869 INFO cluster.py [line:247] cost 60 seconds, left 1769 seconds when check the ceph status
2017-06-08 21:53:34,870 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:53:35,353 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            115 pgs backfill_wait
            3 pgs backfilling
            118 pgs stuck unclean
            recovery 146291/888998 objects misplaced (16.456%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3669: 12 osds: 12 up, 12 in; 118 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46737: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            146291/888998 objects misplaced (16.456%)
                2954 active+clean
                 115 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 252 MB/s, 77 objects/s
stdin: is not a tty

2017-06-08 21:53:35,354 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:53:35,354 INFO cluster.py [line:239] usefull PG number is 2954
2017-06-08 21:54:35,361 INFO cluster.py [line:247] cost 61 seconds, left 1708 seconds when check the ceph status
2017-06-08 21:54:35,362 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:54:35,757 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            113 pgs backfill_wait
            2 pgs backfilling
            115 pgs stuck unclean
            recovery 141361/886664 objects misplaced (15.943%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3674: 12 osds: 12 up, 12 in; 115 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46787: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6285 GB / 8390 GB avail
            141361/886664 objects misplaced (15.943%)
                2956 active+clean
                 113 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 292 MB/s, 89 objects/s
stdin: is not a tty

2017-06-08 21:54:35,758 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:54:35,758 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 21:55:35,772 INFO cluster.py [line:247] cost 60 seconds, left 1648 seconds when check the ceph status
2017-06-08 21:55:35,772 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:55:36,242 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            105 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            108 pgs stuck unclean
            recovery 135036/883280 objects misplaced (15.288%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3688: 12 osds: 12 up, 12 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46845: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6284 GB / 8390 GB avail
            135036/883280 objects misplaced (15.288%)
                2963 active+clean
                 105 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 393 MB/s, 119 objects/s
stdin: is not a tty

2017-06-08 21:55:36,243 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:55:36,243 INFO cluster.py [line:239] usefull PG number is 2963
2017-06-08 21:56:36,253 INFO cluster.py [line:247] cost 61 seconds, left 1587 seconds when check the ceph status
2017-06-08 21:56:36,253 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:56:36,615 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            99 pgs backfill_wait
            3 pgs backfilling
            102 pgs stuck unclean
            recovery 128465/880096 objects misplaced (14.597%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3700: 12 osds: 12 up, 12 in; 102 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46903: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6285 GB / 8390 GB avail
            128465/880096 objects misplaced (14.597%)
                2970 active+clean
                  99 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 304 MB/s, 94 objects/s
stdin: is not a tty

2017-06-08 21:56:36,615 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:56:36,615 INFO cluster.py [line:239] usefull PG number is 2970
2017-06-08 21:57:36,676 INFO cluster.py [line:247] cost 60 seconds, left 1527 seconds when check the ceph status
2017-06-08 21:57:36,676 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:57:37,067 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            90 pgs backfill_wait
            2 pgs backfilling
            92 pgs stuck unclean
            recovery 119998/875846 objects misplaced (13.701%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3717: 12 osds: 12 up, 12 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46963: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            119998/875846 objects misplaced (13.701%)
                2980 active+clean
                  90 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-08 21:57:37,067 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:57:37,067 INFO cluster.py [line:239] usefull PG number is 2980
2017-06-08 21:58:37,087 INFO cluster.py [line:247] cost 61 seconds, left 1466 seconds when check the ceph status
2017-06-08 21:58:37,087 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:58:37,493 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            87 pgs backfill_wait
            2 pgs backfilling
            89 pgs stuck unclean
            recovery 113220/872764 objects misplaced (12.973%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3723: 12 osds: 12 up, 12 in; 89 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47019: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2107 GB used, 6282 GB / 8390 GB avail
            113220/872764 objects misplaced (12.973%)
                2983 active+clean
                  87 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 352 MB/s, 118 objects/s
stdin: is not a tty

2017-06-08 21:58:37,493 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:58:37,494 INFO cluster.py [line:239] usefull PG number is 2983
2017-06-08 21:59:37,521 INFO cluster.py [line:247] cost 60 seconds, left 1406 seconds when check the ceph status
2017-06-08 21:59:37,522 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 21:59:38,001 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            84 pgs backfill_wait
            2 pgs backfilling
            86 pgs stuck unclean
            recovery 105272/868939 objects misplaced (12.115%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3729: 12 osds: 12 up, 12 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47077: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2106 GB used, 6284 GB / 8390 GB avail
            105272/868939 objects misplaced (12.115%)
                2985 active+clean
                  84 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+clean+scrubbing+deep
recovery io 339 MB/s, 114 objects/s
stdin: is not a tty

2017-06-08 21:59:38,001 INFO cluster.py [line:238] PG number is 3072
2017-06-08 21:59:38,001 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 22:00:38,062 INFO cluster.py [line:247] cost 61 seconds, left 1345 seconds when check the ceph status
2017-06-08 22:00:38,062 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:00:38,450 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            81 pgs backfill_wait
            1 pgs backfilling
            82 pgs stuck unclean
            recovery 99417/865178 objects misplaced (11.491%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3737: 12 osds: 12 up, 12 in; 82 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47130: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            99417/865178 objects misplaced (11.491%)
                2989 active+clean
                  81 active+remapped+backfill_wait
                   1 active+clean+scrubbing+deep
                   1 active+remapped+backfilling
recovery io 274 MB/s, 86 objects/s
stdin: is not a tty

2017-06-08 22:00:38,451 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:00:38,451 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 22:01:38,511 INFO cluster.py [line:247] cost 60 seconds, left 1285 seconds when check the ceph status
2017-06-08 22:01:38,511 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:01:39,039 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            80 pgs backfill_wait
            81 pgs stuck unclean
            recovery 96632/864452 objects misplaced (11.178%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3741: 12 osds: 12 up, 12 in; 80 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47177: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            96632/864452 objects misplaced (11.178%)
                2990 active+clean
                  80 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+clean+scrubbing+deep
stdin: is not a tty

2017-06-08 22:01:39,039 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:01:39,039 INFO cluster.py [line:239] usefull PG number is 1
2017-06-08 22:02:39,089 INFO cluster.py [line:247] cost 61 seconds, left 1224 seconds when check the ceph status
2017-06-08 22:02:39,089 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:02:39,486 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            76 pgs backfill_wait
            1 pgs backfilling
            77 pgs stuck unclean
            recovery 93290/862144 objects misplaced (10.821%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3747: 12 osds: 12 up, 12 in; 77 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47227: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            93290/862144 objects misplaced (10.821%)
                2995 active+clean
                  76 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 256 MB/s, 79 objects/s
stdin: is not a tty

2017-06-08 22:02:39,487 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:02:39,487 INFO cluster.py [line:239] usefull PG number is 2995
2017-06-08 22:03:39,501 INFO cluster.py [line:247] cost 60 seconds, left 1164 seconds when check the ceph status
2017-06-08 22:03:39,501 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:03:39,896 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            75 pgs backfill_wait
            1 pgs backfilling
            76 pgs stuck unclean
            recovery 91493/861391 objects misplaced (10.622%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3749: 12 osds: 12 up, 12 in; 76 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47268: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            91493/861391 objects misplaced (10.622%)
                2996 active+clean
                  75 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 276 MB/s, 86 objects/s
stdin: is not a tty

2017-06-08 22:03:39,896 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:03:39,897 INFO cluster.py [line:239] usefull PG number is 2996
2017-06-08 22:04:39,920 INFO cluster.py [line:247] cost 60 seconds, left 1104 seconds when check the ceph status
2017-06-08 22:04:39,921 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:04:40,320 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            73 pgs backfill_wait
            1 pgs backfilling
            74 pgs stuck unclean
            recovery 88720/860501 objects misplaced (10.310%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3754: 12 osds: 12 up, 12 in; 73 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47308: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2105 GB used, 6285 GB / 8390 GB avail
            88720/860501 objects misplaced (10.310%)
                2998 active+clean
                  73 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:04:40,321 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:04:40,321 INFO cluster.py [line:239] usefull PG number is 2998
2017-06-08 22:05:40,381 INFO cluster.py [line:247] cost 61 seconds, left 1043 seconds when check the ceph status
2017-06-08 22:05:40,381 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:05:40,767 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            70 pgs backfill_wait
            1 pgs backfilling
            71 pgs stuck unclean
            recovery 85027/858081 objects misplaced (9.909%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3759: 12 osds: 12 up, 12 in; 71 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47352: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            85027/858081 objects misplaced (9.909%)
                3001 active+clean
                  70 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 128 MB/s, 40 objects/s
stdin: is not a tty

2017-06-08 22:05:40,768 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:05:40,768 INFO cluster.py [line:239] usefull PG number is 3001
2017-06-08 22:06:40,803 INFO cluster.py [line:247] cost 60 seconds, left 983 seconds when check the ceph status
2017-06-08 22:06:40,803 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:06:41,197 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            69 pgs backfill_wait
            1 pgs backfilling
            70 pgs stuck unclean
            recovery 83082/857314 objects misplaced (9.691%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3761: 12 osds: 12 up, 12 in; 70 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47386: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            83082/857314 objects misplaced (9.691%)
                3002 active+clean
                  69 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 145 MB/s, 45 objects/s
stdin: is not a tty

2017-06-08 22:06:41,198 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:06:41,198 INFO cluster.py [line:239] usefull PG number is 3002
2017-06-08 22:07:41,234 INFO cluster.py [line:247] cost 61 seconds, left 922 seconds when check the ceph status
2017-06-08 22:07:41,234 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:07:41,626 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            66 pgs backfill_wait
            1 pgs backfilling
            67 pgs stuck unclean
            recovery 80474/855716 objects misplaced (9.404%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3767: 12 osds: 12 up, 12 in; 67 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47429: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            80474/855716 objects misplaced (9.404%)
                3005 active+clean
                  66 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:07:41,627 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:07:41,627 INFO cluster.py [line:239] usefull PG number is 3005
2017-06-08 22:08:41,637 INFO cluster.py [line:247] cost 60 seconds, left 862 seconds when check the ceph status
2017-06-08 22:08:41,637 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:08:42,053 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            62 pgs backfill_wait
            1 pgs backfilling
            63 pgs stuck unclean
            recovery 78488/854802 objects misplaced (9.182%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3774: 12 osds: 12 up, 12 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47470: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            78488/854802 objects misplaced (9.182%)
                3009 active+clean
                  62 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 133 MB/s, 41 objects/s
stdin: is not a tty

2017-06-08 22:08:42,053 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:08:42,053 INFO cluster.py [line:239] usefull PG number is 3009
2017-06-08 22:09:42,100 INFO cluster.py [line:247] cost 61 seconds, left 801 seconds when check the ceph status
2017-06-08 22:09:42,100 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:09:42,457 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            61 pgs backfill_wait
            1 pgs backfilling
            62 pgs stuck unclean
            recovery 76046/853987 objects misplaced (8.905%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3776: 12 osds: 12 up, 12 in; 62 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47508: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6285 GB / 8390 GB avail
            76046/853987 objects misplaced (8.905%)
                3010 active+clean
                  61 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:09:42,457 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:09:42,457 INFO cluster.py [line:239] usefull PG number is 3010
2017-06-08 22:10:42,468 INFO cluster.py [line:247] cost 60 seconds, left 741 seconds when check the ceph status
2017-06-08 22:10:42,469 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:10:42,849 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            58 pgs backfill_wait
            2 pgs backfilling
            60 pgs stuck unclean
            recovery 72284/851587 objects misplaced (8.488%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3783: 12 osds: 12 up, 12 in; 58 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47557: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            72284/851587 objects misplaced (8.488%)
                3012 active+clean
                  58 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 267 MB/s, 66 objects/s
stdin: is not a tty

2017-06-08 22:10:42,849 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:10:42,849 INFO cluster.py [line:239] usefull PG number is 3012
2017-06-08 22:11:42,887 INFO cluster.py [line:247] cost 60 seconds, left 681 seconds when check the ceph status
2017-06-08 22:11:42,888 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:11:43,305 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            56 pgs backfill_wait
            1 pgs backfilling
            57 pgs stuck unclean
            recovery 70273/850726 objects misplaced (8.260%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3786: 12 osds: 12 up, 12 in; 57 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47595: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            70273/850726 objects misplaced (8.260%)
                3015 active+clean
                  56 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 113 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 22:11:43,306 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:11:43,306 INFO cluster.py [line:239] usefull PG number is 3015
2017-06-08 22:12:43,366 INFO cluster.py [line:247] cost 61 seconds, left 620 seconds when check the ceph status
2017-06-08 22:12:43,366 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:12:43,749 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            54 pgs backfill_wait
            1 pgs backfilling
            55 pgs stuck unclean
            recovery 68450/849942 objects misplaced (8.053%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3790: 12 osds: 12 up, 12 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47628: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            68450/849942 objects misplaced (8.053%)
                3017 active+clean
                  54 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 117 MB/s, 36 objects/s
stdin: is not a tty

2017-06-08 22:12:43,749 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:12:43,749 INFO cluster.py [line:239] usefull PG number is 3017
2017-06-08 22:13:43,767 INFO cluster.py [line:247] cost 60 seconds, left 560 seconds when check the ceph status
2017-06-08 22:13:43,767 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:13:44,195 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            52 pgs backfill_wait
            1 pgs backfilling
            53 pgs stuck unclean
            recovery 65880/848392 objects misplaced (7.765%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3794: 12 osds: 12 up, 12 in; 53 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47669: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            65880/848392 objects misplaced (7.765%)
                3019 active+clean
                  52 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:13:44,195 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:13:44,195 INFO cluster.py [line:239] usefull PG number is 3019
2017-06-08 22:14:44,234 INFO cluster.py [line:247] cost 61 seconds, left 499 seconds when check the ceph status
2017-06-08 22:14:44,235 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:14:44,626 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            50 pgs backfill_wait
            1 pgs backfilling
            51 pgs stuck unclean
            recovery 63911/847601 objects misplaced (7.540%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3798: 12 osds: 12 up, 12 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47709: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            63911/847601 objects misplaced (7.540%)
                3021 active+clean
                  50 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 117 MB/s, 36 objects/s
stdin: is not a tty

2017-06-08 22:14:44,627 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:14:44,627 INFO cluster.py [line:239] usefull PG number is 3021
2017-06-08 22:15:44,652 INFO cluster.py [line:247] cost 60 seconds, left 439 seconds when check the ceph status
2017-06-08 22:15:44,652 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:15:45,017 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            47 pgs backfill_wait
            1 pgs backfilling
            48 pgs stuck unclean
            recovery 61073/846024 objects misplaced (7.219%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3804: 12 osds: 12 up, 12 in; 48 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47755: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            61073/846024 objects misplaced (7.219%)
                3024 active+clean
                  47 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 276 MB/s, 86 objects/s
stdin: is not a tty

2017-06-08 22:15:45,018 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:15:45,018 INFO cluster.py [line:239] usefull PG number is 3024
2017-06-08 22:16:45,022 INFO cluster.py [line:247] cost 61 seconds, left 378 seconds when check the ceph status
2017-06-08 22:16:45,022 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:16:45,411 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            46 pgs backfill_wait
            1 pgs backfilling
            47 pgs stuck unclean
            recovery 59264/845277 objects misplaced (7.011%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3806: 12 osds: 12 up, 12 in; 47 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47786: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            59264/845277 objects misplaced (7.011%)
                3025 active+clean
                  46 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 112 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 22:16:45,411 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:16:45,411 INFO cluster.py [line:239] usefull PG number is 3025
2017-06-08 22:17:45,439 INFO cluster.py [line:247] cost 60 seconds, left 318 seconds when check the ceph status
2017-06-08 22:17:45,439 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:17:45,838 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            44 pgs backfill_wait
            1 pgs backfilling
            45 pgs stuck unclean
            recovery 57425/844472 objects misplaced (6.800%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3811: 12 osds: 12 up, 12 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47823: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            57425/844472 objects misplaced (6.800%)
                3027 active+clean
                  44 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 122 MB/s, 38 objects/s
stdin: is not a tty

2017-06-08 22:17:45,838 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:17:45,838 INFO cluster.py [line:239] usefull PG number is 3027
2017-06-08 22:18:45,860 INFO cluster.py [line:247] cost 60 seconds, left 258 seconds when check the ceph status
2017-06-08 22:18:45,860 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:18:46,235 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            41 pgs backfill_wait
            1 pgs backfilling
            42 pgs stuck unclean
            recovery 52861/842054 objects misplaced (6.278%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3816: 12 osds: 12 up, 12 in; 42 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47869: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6287 GB / 8390 GB avail
            52861/842054 objects misplaced (6.278%)
                3030 active+clean
                  41 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 180 MB/s, 56 objects/s
stdin: is not a tty

2017-06-08 22:18:46,235 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:18:46,235 INFO cluster.py [line:239] usefull PG number is 3030
2017-06-08 22:19:46,285 INFO cluster.py [line:247] cost 61 seconds, left 197 seconds when check the ceph status
2017-06-08 22:19:46,285 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:19:46,698 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            39 pgs backfill_wait
            2 pgs backfilling
            41 pgs stuck unclean
            recovery 50948/841265 objects misplaced (6.056%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3820: 12 osds: 12 up, 12 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47913: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            50948/841265 objects misplaced (6.056%)
                3031 active+clean
                  39 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 146 MB/s, 45 objects/s
stdin: is not a tty

2017-06-08 22:19:46,698 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:19:46,698 INFO cluster.py [line:239] usefull PG number is 3031
2017-06-08 22:20:46,750 INFO cluster.py [line:247] cost 60 seconds, left 137 seconds when check the ceph status
2017-06-08 22:20:46,750 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:20:47,167 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            38 pgs backfill_wait
            1 pgs backfilling
            39 pgs stuck unclean
            recovery 48371/839715 objects misplaced (5.760%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3822: 12 osds: 12 up, 12 in; 39 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47953: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            48371/839715 objects misplaced (5.760%)
                3033 active+clean
                  38 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 161 MB/s, 50 objects/s
stdin: is not a tty

2017-06-08 22:20:47,168 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:20:47,168 INFO cluster.py [line:239] usefull PG number is 3033
2017-06-08 22:21:47,198 INFO cluster.py [line:247] cost 61 seconds, left 76 seconds when check the ceph status
2017-06-08 22:21:47,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:21:47,588 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            37 pgs backfill_wait
            1 pgs backfilling
            38 pgs stuck unclean
            recovery 46444/838906 objects misplaced (5.536%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3824: 12 osds: 12 up, 12 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47988: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            46444/838906 objects misplaced (5.536%)
                3034 active+clean
                  37 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:21:47,588 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:21:47,589 INFO cluster.py [line:239] usefull PG number is 3034
2017-06-08 22:22:47,594 INFO cluster.py [line:247] cost 60 seconds, left 16 seconds when check the ceph status
2017-06-08 22:22:47,594 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:22:47,992 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            35 pgs backfill_wait
            1 pgs backfilling
            36 pgs stuck unclean
            recovery 42158/836490 objects misplaced (5.040%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3830: 12 osds: 12 up, 12 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48033: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2106 GB used, 6284 GB / 8390 GB avail
            42158/836490 objects misplaced (5.040%)
                3036 active+clean
                  35 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:22:47,992 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:22:47,992 INFO cluster.py [line:239] usefull PG number is 3036
2017-06-08 22:23:48,052 INFO cluster.py [line:247] cost 61 seconds, left -45 seconds when check the ceph status
2017-06-08 22:23:48,053 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:85] status is HEALTH_ERROR
2017-06-08 22:23:48,053 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:86] TC47_48_49_50_51_remove_osds_on_single_node  runs failed
2017-06-08 22:23:48,053 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:23:48,435 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            33 pgs backfill_wait
            1 pgs backfilling
            34 pgs stuck unclean
            recovery 39432/835691 objects misplaced (4.718%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3832: 12 osds: 12 up, 12 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48073: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            39432/835691 objects misplaced (4.718%)
                3038 active+clean
                  33 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 506 MB/s, 170 objects/s
stdin: is not a tty

2017-06-08 22:23:48,436 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:23:48,436 INFO cluster.py [line:239] usefull PG number is 3038
2017-06-08 22:24:48,468 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-08 22:24:48,468 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:24:48,886 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            31 pgs stuck unclean
            recovery 35901/833399 objects misplaced (4.308%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3838: 12 osds: 12 up, 12 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48118: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            35901/833399 objects misplaced (4.308%)
                3040 active+clean
                  30 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 250 MB/s, 76 objects/s
stdin: is not a tty

2017-06-08 22:24:48,887 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:24:48,887 INFO cluster.py [line:239] usefull PG number is 3040
2017-06-08 22:25:48,947 INFO cluster.py [line:247] cost 60 seconds, left 5880 seconds when check the ceph status
2017-06-08 22:25:48,947 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:25:49,370 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            29 pgs backfill_wait
            1 pgs backfilling
            30 pgs stuck unclean
            recovery 34049/832657 objects misplaced (4.089%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3840: 12 osds: 12 up, 12 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48152: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            34049/832657 objects misplaced (4.089%)
                3042 active+clean
                  29 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 143 MB/s, 44 objects/s
stdin: is not a tty

2017-06-08 22:25:49,370 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:25:49,370 INFO cluster.py [line:239] usefull PG number is 3042
2017-06-08 22:26:49,394 INFO cluster.py [line:247] cost 61 seconds, left 5819 seconds when check the ceph status
2017-06-08 22:26:49,394 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:26:49,787 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            27 pgs stuck unclean
            recovery 31365/831136 objects misplaced (3.774%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3846: 12 osds: 12 up, 12 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48193: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2104 GB used, 6286 GB / 8390 GB avail
            31365/831136 objects misplaced (3.774%)
                3044 active+clean
                  26 active+remapped+backfill_wait
                   1 activating
                   1 active+remapped+backfilling
recovery io 295 MB/s, 92 objects/s
stdin: is not a tty

2017-06-08 22:26:49,788 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:26:49,788 INFO cluster.py [line:239] usefull PG number is 3044
2017-06-08 22:27:49,835 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-08 22:27:49,835 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:27:50,260 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            25 pgs backfill_wait
            1 pgs backfilling
            26 pgs stuck unclean
            recovery 29322/830355 objects misplaced (3.531%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3848: 12 osds: 12 up, 12 in; 26 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48227: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            29322/830355 objects misplaced (3.531%)
                3046 active+clean
                  25 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 22:27:50,260 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:27:50,260 INFO cluster.py [line:239] usefull PG number is 3046
2017-06-08 22:28:50,318 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-08 22:28:50,318 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:28:50,710 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            22 pgs backfill_wait
            1 pgs backfilling
            23 pgs stuck unclean
            recovery 26513/828735 objects misplaced (3.199%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3854: 12 osds: 12 up, 12 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48264: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            26513/828735 objects misplaced (3.199%)
                3049 active+clean
                  22 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 257 MB/s, 81 objects/s
stdin: is not a tty

2017-06-08 22:28:50,710 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:28:50,710 INFO cluster.py [line:239] usefull PG number is 3049
2017-06-08 22:29:50,722 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-08 22:29:50,722 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:29:51,118 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            21 pgs backfill_wait
            1 pgs backfilling
            22 pgs stuck unclean
            recovery 24552/827968 objects misplaced (2.965%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3856: 12 osds: 12 up, 12 in; 22 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48298: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            24552/827968 objects misplaced (2.965%)
                3050 active+clean
                  21 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 142 MB/s, 43 objects/s
stdin: is not a tty

2017-06-08 22:29:51,118 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:29:51,118 INFO cluster.py [line:239] usefull PG number is 3050
2017-06-08 22:30:51,135 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-08 22:30:51,135 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:30:51,661 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            19 pgs backfill_wait
            1 pgs backfilling
            20 pgs stuck unclean
            recovery 21918/826441 objects misplaced (2.652%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3860: 12 osds: 12 up, 12 in; 20 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48338: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            21918/826441 objects misplaced (2.652%)
                3052 active+clean
                  19 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 236 MB/s, 73 objects/s
stdin: is not a tty

2017-06-08 22:30:51,661 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:30:51,661 INFO cluster.py [line:239] usefull PG number is 3052
2017-06-08 22:31:51,722 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-08 22:31:51,722 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:31:52,075 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 20149/825717 objects misplaced (2.440%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3862: 12 osds: 12 up, 12 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48370: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            20149/825717 objects misplaced (2.440%)
                3053 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 115 MB/s, 35 objects/s
stdin: is not a tty

2017-06-08 22:31:52,075 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:31:52,075 INFO cluster.py [line:239] usefull PG number is 3053
2017-06-08 22:32:52,104 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-08 22:32:52,104 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:32:52,522 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 18267/824863 objects misplaced (2.215%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3866: 12 osds: 12 up, 12 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48405: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            18267/824863 objects misplaced (2.215%)
                3056 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 105 MB/s, 32 objects/s
stdin: is not a tty

2017-06-08 22:32:52,523 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:32:52,523 INFO cluster.py [line:239] usefull PG number is 3056
2017-06-08 22:33:52,531 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-08 22:33:52,531 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:33:53,021 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 15604/823291 objects misplaced (1.895%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3870: 12 osds: 12 up, 12 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48448: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            15604/823291 objects misplaced (1.895%)
                3058 active+clean
                  13 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-08 22:33:53,022 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:33:53,022 INFO cluster.py [line:239] usefull PG number is 3058
2017-06-08 22:34:53,066 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-08 22:34:53,066 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:34:53,455 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            11 pgs backfill_wait
            1 pgs backfilling
            12 pgs stuck unclean
            recovery 13660/822515 objects misplaced (1.661%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3872: 12 osds: 12 up, 12 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48481: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            13660/822515 objects misplaced (1.661%)
                3060 active+clean
                  11 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 100 MB/s, 31 objects/s
stdin: is not a tty

2017-06-08 22:34:53,455 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:34:53,455 INFO cluster.py [line:239] usefull PG number is 3060
2017-06-08 22:35:53,479 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-08 22:35:53,480 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:35:53,879 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs peering
            10 pgs stuck unclean
            recovery 11027/820937 objects misplaced (1.343%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3877: 12 osds: 12 up, 12 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48515: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6286 GB / 8390 GB avail
            11027/820937 objects misplaced (1.343%)
                3061 active+clean
                   9 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped
recovery io 193 MB/s, 48 objects/s
stdin: is not a tty

2017-06-08 22:35:53,879 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:35:53,879 INFO cluster.py [line:239] usefull PG number is 3061
2017-06-08 22:36:53,940 INFO cluster.py [line:247] cost 60 seconds, left 5215 seconds when check the ceph status
2017-06-08 22:36:53,940 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:36:54,363 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 7398/819364 objects misplaced (0.903%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3882: 12 osds: 12 up, 12 in; 7 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48554: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            7398/819364 objects misplaced (0.903%)
                3065 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 107 MB/s, 32 objects/s
stdin: is not a tty

2017-06-08 22:36:54,363 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:36:54,363 INFO cluster.py [line:239] usefull PG number is 3065
2017-06-08 22:37:54,401 INFO cluster.py [line:247] cost 61 seconds, left 5154 seconds when check the ceph status
2017-06-08 22:37:54,401 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:37:54,814 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            4 pgs backfill_wait
            1 pgs backfilling
            5 pgs stuck unclean
            recovery 2950/817033 objects misplaced (0.361%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3886: 12 osds: 12 up, 12 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48595: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
            2950/817033 objects misplaced (0.361%)
                3067 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 34 objects/s
stdin: is not a tty

2017-06-08 22:37:54,814 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:37:54,815 INFO cluster.py [line:239] usefull PG number is 3067
2017-06-08 22:38:54,863 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-08 22:38:54,863 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:38:55,402 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            3 pgs backfill_wait
            1 pgs backfilling
            4 pgs stuck unclean
            recovery 1099/816305 objects misplaced (0.135%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3888: 12 osds: 12 up, 12 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48630: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2103 GB used, 6287 GB / 8390 GB avail
            1099/816305 objects misplaced (0.135%)
                3068 active+clean
                   3 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 135 MB/s, 42 objects/s
stdin: is not a tty

2017-06-08 22:38:55,403 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:38:55,403 INFO cluster.py [line:239] usefull PG number is 3068
2017-06-08 22:39:55,438 INFO cluster.py [line:247] cost 61 seconds, left 5033 seconds when check the ceph status
2017-06-08 22:39:55,438 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:39:55,849 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3896: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48665: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 22:39:55,849 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:39:55,849 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 22:39:55,849 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:89] stop in cluster successfully
2017-06-08 22:39:55,850 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-08 22:40:08,646 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-08 22:40:08,646 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-08 22:40:08,646 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-08 22:40:09,060 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/13 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e3898: 13 osds: 12 up, 13 in; 779 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48677: 3072 pgs, 11 pools, 1588 GB data, 398 kobjects
            2102 GB used, 6288 GB / 8390 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-08 22:40:09,060 INFO cluster.py [line:238] PG number is 3072
2017-06-08 22:40:09,060 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-08 22:40:09,061 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-08 22:40:10,780 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node CW113 create succesfully
2017-06-08 22:40:11,041 INFO client.py [line:172] ['enali   135346 135345  0 14:40 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   135348 135346  0 14:40 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-08 22:40:11,041 INFO client.py [line:177] IO stopped
2017-06-08 22:40:11,042 INFO client.py [line:178] start IO again
2017-06-08 22:40:11,042 INFO base.py [line:37] 
Now start IO on  client103rbdImg0
2017-06-08 22:40:11,251 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg0 -rw=randwrite -bs=8K -size=100G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg0
2017-06-08 22:40:11,473 INFO base.py [line:37] 
Now start IO on  client103rbdImg1
2017-06-08 22:40:11,810 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg1 -rw=randwrite -bs=8K -size=200G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg1
2017-06-08 22:40:12,071 INFO base.py [line:37] 
Now start IO on  client103rbdImg2
2017-06-08 22:40:12,261 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg2 -rw=randwrite -bs=8K -size=300G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg2
2017-06-08 22:40:12,505 INFO base.py [line:37] 
Now start IO on  client103rbdImg3
2017-06-08 22:40:12,725 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg3 -rw=randwrite -bs=8K -size=400G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg3
2017-06-08 22:40:12,976 INFO base.py [line:37] 
Now start IO on  client103rbdImg4
2017-06-08 22:40:13,187 INFO client.py [line:141] nohup sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg4
2017-06-08 22:40:13,641 INFO node.py [line:185] 0
2017-06-08 22:40:13,641 INFO node.py [line:192] nvme2n1
2017-06-08 22:40:13,641 INFO node.py [line:185] 0
2017-06-08 22:40:13,641 INFO node.py [line:192] nvme2n1
2017-06-08 22:40:13,641 INFO node.py [line:185] 0
2017-06-08 22:40:13,653 INFO node.py [line:192] nvme2n1
2017-06-08 22:40:13,653 INFO node.py [line:185] 1
2017-06-08 22:40:13,653 INFO node.py [line:192] nvme1n1
2017-06-08 22:40:13,653 INFO node.py [line:185] 1
2017-06-08 22:40:13,653 INFO node.py [line:192] nvme1n1
2017-06-08 22:40:13,653 INFO node.py [line:185] 1
2017-06-08 22:40:13,653 INFO node.py [line:192] nvme1n1
2017-06-08 22:40:13,653 INFO node.py [line:185] 2
2017-06-08 22:40:13,654 INFO node.py [line:192] nvme4n1
2017-06-08 22:40:13,654 INFO node.py [line:185] 2
2017-06-08 22:40:13,654 INFO node.py [line:192] nvme4n1
2017-06-08 22:40:13,654 INFO node.py [line:185] 2
2017-06-08 22:40:13,654 INFO node.py [line:192] nvme4n1
2017-06-08 22:40:13,654 INFO node.py [line:185] 3
2017-06-08 22:40:13,654 INFO node.py [line:192] nvme0n1
2017-06-08 22:40:13,654 INFO node.py [line:185] 3
2017-06-08 22:40:13,655 INFO node.py [line:192] nvme0n1
2017-06-08 22:40:13,655 INFO node.py [line:185] 3
2017-06-08 22:40:13,655 INFO node.py [line:192] nvme0n1
2017-06-08 22:40:13,655 INFO node.py [line:185] 4
2017-06-08 22:40:13,655 INFO node.py [line:192] nvme3n1
2017-06-08 22:40:13,655 INFO node.py [line:185] 4
2017-06-08 22:40:13,655 INFO node.py [line:192] nvme3n1
2017-06-08 22:40:13,655 INFO node.py [line:185] 4
2017-06-08 22:40:13,655 INFO node.py [line:192] nvme3n1
2017-06-08 22:40:13,656 INFO node.py [line:185] 
2017-06-08 22:40:13,656 INFO node.py [line:192] nvme3n1
2017-06-08 22:40:13,656 INFO node.py [line:200] osd.0  ---> disk nvme2n1
2017-06-08 22:40:13,656 INFO node.py [line:200] osd.1  ---> disk nvme1n1
2017-06-08 22:40:13,656 INFO node.py [line:200] osd.2  ---> disk nvme4n1
2017-06-08 22:40:13,656 INFO node.py [line:200] osd.3  ---> disk nvme0n1
2017-06-08 22:40:13,656 INFO node.py [line:200] osd.4  ---> disk nvme3n1
2017-06-08 22:40:13,656 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node CW113 
2017-06-08 22:40:13,656 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-09 02:15:33,812 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 02:15:34,170 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e4318: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60214: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2832 GB used, 5557 GB / 8390 GB avail
                3072 active+clean
  client io 42542 kB/s rd, 172 MB/s wr, 5491 op/s rd, 22141 op/s wr
stdin: is not a tty

2017-06-09 02:15:34,170 INFO cluster.py [line:238] PG number is 3072
2017-06-09 02:15:34,170 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 02:15:34,171 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-09 02:15:34,171 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-09 02:58:32,095 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 02:58:32,512 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e4688: 11 osds: 11 up, 11 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62542: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2844 GB used, 4846 GB / 7691 GB avail
                3072 active+clean
  client io 208 MB/s rd, 26673 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 02:58:32,513 INFO cluster.py [line:238] PG number is 3072
2017-06-09 02:58:32,513 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 02:58:32,513 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-09 02:58:32,513 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-09 04:07:41,231 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 04:07:41,609 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e5152: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66179: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4156 GB / 6992 GB avail
                3072 active+clean
  client io 87553 kB/s rd, 10944 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 04:07:41,609 INFO cluster.py [line:238] PG number is 3072
2017-06-09 04:07:41,609 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 04:07:41,609 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-09 04:07:41,609 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme0n1
2017-06-09 05:32:12,098 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 05:32:12,454 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e5671: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v70398: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2828 GB used, 3464 GB / 6293 GB avail
                3072 active+clean
  client io 83964 B/s rd, 81 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 05:32:12,454 INFO cluster.py [line:238] PG number is 3072
2017-06-09 05:32:12,454 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 05:32:12,454 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-09 05:32:12,454 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-09 06:25:18,433 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:25:18,839 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6131: 8 osds: 8 up, 8 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73152: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2819 GB used, 2774 GB / 5593 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-09 06:25:18,840 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:25:18,840 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 06:25:18,840 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-09 06:25:21,478 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node CW113 delete succesfully
2017-06-09 06:25:21,478 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node CW113 
2017-06-09 06:25:21,478 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-09 06:25:34,257 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 06:25:34,257 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-09 06:25:34,257 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:25:34,665 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/9 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6133: 9 osds: 8 up, 9 in; 989 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73167: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2819 GB used, 2774 GB / 5593 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-09 06:25:34,666 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:25:34,666 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 06:25:34,666 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-09 06:25:34,666 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-09 06:25:46,902 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 06:25:46,902 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-09 06:25:46,902 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:25:47,317 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            258 pgs backfill_wait
            2 pgs backfilling
            30 pgs degraded
            30 pgs recovery_wait
            99 pgs stuck unclean
            Difference in osd space utilization 68.2091% greater than 40%
            recovery 69/987536 objects degraded (0.007%)
            recovery 344074/987536 objects misplaced (34.842%)
            1/10 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6140: 10 osds: 9 up, 10 in; 950 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73182: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2828 GB used, 3464 GB / 6293 GB avail
            69/987536 objects degraded (0.007%)
            344074/987536 objects misplaced (34.842%)
                2782 active+clean
                 258 active+remapped+backfill_wait
                  30 active+recovery_wait+degraded
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:25:47,317 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:25:47,317 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-09 06:26:47,377 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-09 06:26:47,378 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:26:47,801 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            398 pgs backfill_wait
            1 pgs backfilling
            38 pgs degraded
            38 pgs recovery_wait
            223 pgs stuck unclean
            Difference in osd space utilization 68.3858% greater than 40%
            recovery 93/1074376 objects degraded (0.009%)
            recovery 517216/1074376 objects misplaced (48.141%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6150: 10 osds: 10 up, 10 in; 399 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73236: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            93/1074376 objects degraded (0.009%)
            517216/1074376 objects misplaced (48.141%)
                2635 active+clean
                 398 active+remapped+backfill_wait
                  38 active+recovery_wait+degraded
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:26:47,802 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:26:47,802 INFO cluster.py [line:239] usefull PG number is 2635
2017-06-09 06:27:47,813 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-09 06:27:47,813 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:27:48,187 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            397 pgs backfill_wait
            1 pgs backfilling
            23 pgs degraded
            23 pgs recovery_wait
            267 pgs stuck unclean
            Difference in osd space utilization 68.8608% greater than 40%
            recovery 65/1072740 objects degraded (0.006%)
            recovery 514047/1072740 objects misplaced (47.919%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6152: 10 osds: 10 up, 10 in; 398 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73285: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            65/1072740 objects degraded (0.006%)
            514047/1072740 objects misplaced (47.919%)
                2651 active+clean
                 397 active+remapped+backfill_wait
                  23 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 227 MB/s, 61 objects/s
stdin: is not a tty

2017-06-09 06:27:48,188 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:27:48,188 INFO cluster.py [line:239] usefull PG number is 2651
2017-06-09 06:28:48,246 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-09 06:28:48,246 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:28:48,665 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            393 pgs backfill_wait
            2 pgs backfilling
            7 pgs degraded
            7 pgs recovery_wait
            295 pgs stuck unclean
            Difference in osd space utilization 69.693% greater than 40%
            recovery 20/1068886 objects degraded (0.002%)
            recovery 506338/1068886 objects misplaced (47.371%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6158: 10 osds: 10 up, 10 in; 395 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73335: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            20/1068886 objects degraded (0.002%)
            506338/1068886 objects misplaced (47.371%)
                2670 active+clean
                 393 active+remapped+backfill_wait
                   7 active+recovery_wait+degraded
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:28:48,665 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:28:48,665 INFO cluster.py [line:239] usefull PG number is 2670
2017-06-09 06:29:48,714 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-09 06:29:48,714 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:29:49,152 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            389 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            331 pgs stuck unclean
            Difference in osd space utilization 69.4902% greater than 40%
            recovery 502029/1066612 objects misplaced (47.068%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6166: 10 osds: 10 up, 10 in; 391 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73388: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2840 GB used, 4151 GB / 6992 GB avail
            502029/1066612 objects misplaced (47.068%)
                2679 active+clean
                 389 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 12698 kB/s, 3 objects/s
stdin: is not a tty

2017-06-09 06:29:49,152 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:29:49,152 INFO cluster.py [line:239] usefull PG number is 2679
2017-06-09 06:30:49,212 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-09 06:30:49,213 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:30:49,608 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            387 pgs backfill_wait
            2 pgs backfilling
            389 pgs stuck unclean
            Difference in osd space utilization 69.9851% greater than 40%
            recovery 497025/1064357 objects misplaced (46.697%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6170: 10 osds: 10 up, 10 in; 389 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73438: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            497025/1064357 objects misplaced (46.697%)
                2683 active+clean
                 387 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 146 MB/s, 39 objects/s
stdin: is not a tty

2017-06-09 06:30:49,609 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:30:49,609 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-09 06:31:49,661 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-09 06:31:49,661 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:31:50,065 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            384 pgs backfill_wait
            1 pgs backfilling
            385 pgs stuck unclean
            Difference in osd space utilization 69.6824% greater than 40%
            recovery 493990/1062655 objects misplaced (46.486%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6177: 10 osds: 10 up, 10 in; 385 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73488: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            493990/1062655 objects misplaced (46.486%)
                2687 active+clean
                 384 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:31:50,065 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:31:50,065 INFO cluster.py [line:239] usefull PG number is 2687
2017-06-09 06:32:50,070 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-09 06:32:50,070 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:32:50,472 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            382 pgs backfill_wait
            1 pgs backfilling
            383 pgs stuck unclean
            Difference in osd space utilization 69.6824% greater than 40%
            recovery 490950/1061041 objects misplaced (46.271%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6181: 10 osds: 10 up, 10 in; 383 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73538: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            490950/1061041 objects misplaced (46.271%)
                2689 active+clean
                 382 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:32:50,472 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:32:50,472 INFO cluster.py [line:239] usefull PG number is 2689
2017-06-09 06:33:50,533 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-09 06:33:50,533 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:33:50,948 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            381 pgs backfill_wait
            1 pgs backfilling
            382 pgs stuck unclean
            Difference in osd space utilization 69.3127% greater than 40%
            recovery 489345/1060270 objects misplaced (46.153%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6183: 10 osds: 10 up, 10 in; 382 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73586: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            489345/1060270 objects misplaced (46.153%)
                2690 active+clean
                 381 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 144 MB/s, 39 objects/s
stdin: is not a tty

2017-06-09 06:33:50,948 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:33:50,949 INFO cluster.py [line:239] usefull PG number is 2690
2017-06-09 06:34:51,007 INFO cluster.py [line:247] cost 61 seconds, left 5455 seconds when check the ceph status
2017-06-09 06:34:51,008 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:34:51,432 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            380 pgs backfill_wait
            1 pgs backfilling
            381 pgs stuck unclean
            Difference in osd space utilization 69.3127% greater than 40%
            recovery 487811/1059523 objects misplaced (46.041%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6185: 10 osds: 10 up, 10 in; 381 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73635: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            487811/1059523 objects misplaced (46.041%)
                2691 active+clean
                 380 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 207 MB/s, 55 objects/s
stdin: is not a tty

2017-06-09 06:34:51,432 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:34:51,432 INFO cluster.py [line:239] usefull PG number is 2691
2017-06-09 06:35:51,472 INFO cluster.py [line:247] cost 60 seconds, left 5395 seconds when check the ceph status
2017-06-09 06:35:51,473 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:35:51,861 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            376 pgs backfill_wait
            1 pgs backfilling
            377 pgs stuck unclean
            Difference in osd space utilization 68.9137% greater than 40%
            recovery 482406/1057055 objects misplaced (45.637%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6192: 10 osds: 10 up, 10 in; 377 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73689: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            482406/1057055 objects misplaced (45.637%)
                2695 active+clean
                 376 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 895 MB/s, 246 objects/s
  client io 52942 B/s rd, 51 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:35:51,861 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:35:51,862 INFO cluster.py [line:239] usefull PG number is 2695
2017-06-09 06:36:51,922 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-09 06:36:51,922 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:36:52,345 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            374 pgs backfill_wait
            1 pgs backfilling
            375 pgs stuck unclean
            Difference in osd space utilization 68.5466% greater than 40%
            recovery 479506/1055460 objects misplaced (45.431%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6196: 10 osds: 10 up, 10 in; 375 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73738: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            479506/1055460 objects misplaced (45.431%)
                2697 active+clean
                 374 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 199 MB/s, 53 objects/s
  client io 66480 B/s rd, 64 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:36:52,345 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:36:52,345 INFO cluster.py [line:239] usefull PG number is 2697
2017-06-09 06:37:52,377 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-09 06:37:52,377 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:37:52,805 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            373 pgs backfill_wait
            1 pgs backfilling
            374 pgs stuck unclean
            Difference in osd space utilization 68.1789% greater than 40%
            recovery 477944/1054691 objects misplaced (45.316%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6198: 10 osds: 10 up, 10 in; 374 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73789: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            477944/1054691 objects misplaced (45.316%)
                2698 active+clean
                 373 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 41531 B/s rd, 40 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:37:52,805 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:37:52,805 INFO cluster.py [line:239] usefull PG number is 2698
2017-06-09 06:38:52,865 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-09 06:38:52,866 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:38:53,256 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            372 pgs backfill_wait
            1 pgs backfilling
            373 pgs stuck unclean
            Difference in osd space utilization 68.1789% greater than 40%
            recovery 476424/1053946 objects misplaced (45.204%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6200: 10 osds: 10 up, 10 in; 373 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73838: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            476424/1053946 objects misplaced (45.204%)
                2699 active+clean
                 372 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 56827 B/s rd, 55 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:38:53,256 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:38:53,256 INFO cluster.py [line:239] usefull PG number is 2699
2017-06-09 06:39:53,296 INFO cluster.py [line:247] cost 61 seconds, left 5153 seconds when check the ceph status
2017-06-09 06:39:53,296 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:39:53,719 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            369 pgs backfill_wait
            1 pgs backfilling
            370 pgs stuck unclean
            Difference in osd space utilization 68.1488% greater than 40%
            recovery 471812/1051532 objects misplaced (44.869%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6205: 10 osds: 10 up, 10 in; 370 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73890: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            471812/1051532 objects misplaced (44.869%)
                2702 active+clean
                 369 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 45170 B/s rd, 44 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:39:53,719 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:39:53,719 INFO cluster.py [line:239] usefull PG number is 2702
2017-06-09 06:40:53,761 INFO cluster.py [line:247] cost 60 seconds, left 5093 seconds when check the ceph status
2017-06-09 06:40:53,761 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:40:54,192 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            366 pgs backfill_wait
            1 pgs backfilling
            367 pgs stuck unclean
            Difference in osd space utilization 68.1488% greater than 40%
            recovery 469508/1050574 objects misplaced (44.691%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6210: 10 osds: 10 up, 10 in; 367 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73943: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            469508/1050574 objects misplaced (44.691%)
                2705 active+clean
                 366 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 06:40:54,192 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:40:54,193 INFO cluster.py [line:239] usefull PG number is 2705
2017-06-09 06:41:54,237 INFO cluster.py [line:247] cost 61 seconds, left 5032 seconds when check the ceph status
2017-06-09 06:41:54,237 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:41:54,689 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            365 pgs backfill_wait
            1 pgs backfilling
            366 pgs stuck unclean
            Difference in osd space utilization 68.1488% greater than 40%
            recovery 466683/1048984 objects misplaced (44.489%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6212: 10 osds: 10 up, 10 in; 366 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73995: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            466683/1048984 objects misplaced (44.489%)
                2706 active+clean
                 365 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24456 B/s rd, 35 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:41:54,689 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:41:54,689 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-09 06:42:54,750 INFO cluster.py [line:247] cost 60 seconds, left 4972 seconds when check the ceph status
2017-06-09 06:42:54,750 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:42:55,168 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            363 pgs backfill_wait
            1 pgs backfilling
            364 pgs stuck unclean
            Difference in osd space utilization 68.1488% greater than 40%
            recovery 463705/1047397 objects misplaced (44.272%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6216: 10 osds: 10 up, 10 in; 364 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74046: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            463705/1047397 objects misplaced (44.272%)
                2708 active+clean
                 363 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 222 MB/s, 60 objects/s
  client io 26862 B/s rd, 39 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:42:55,169 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:42:55,169 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-09 06:43:55,219 INFO cluster.py [line:247] cost 61 seconds, left 4911 seconds when check the ceph status
2017-06-09 06:43:55,219 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:43:55,633 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            362 pgs backfill_wait
            1 pgs backfilling
            363 pgs stuck unclean
            Difference in osd space utilization 67.7595% greater than 40%
            recovery 462052/1046587 objects misplaced (44.148%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6218: 10 osds: 10 up, 10 in; 363 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74097: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            462052/1046587 objects misplaced (44.148%)
                2709 active+clean
                 362 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 218 MB/s, 58 objects/s
  client io 87776 B/s rd, 128 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:43:55,634 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:43:55,634 INFO cluster.py [line:239] usefull PG number is 2709
2017-06-09 06:44:55,685 INFO cluster.py [line:247] cost 60 seconds, left 4851 seconds when check the ceph status
2017-06-09 06:44:55,686 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:44:56,105 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            361 pgs backfill_wait
            1 pgs backfilling
            362 pgs stuck unclean
            Difference in osd space utilization 67.7595% greater than 40%
            recovery 460088/1045817 objects misplaced (43.993%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6221: 10 osds: 10 up, 10 in; 361 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74146: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            460088/1045817 objects misplaced (43.993%)
                2710 active+clean
                 361 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 479 MB/s, 128 objects/s
  client io 126 kB/s rd, 189 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:44:56,106 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:44:56,106 INFO cluster.py [line:239] usefull PG number is 2710
2017-06-09 06:45:56,126 INFO cluster.py [line:247] cost 61 seconds, left 4790 seconds when check the ceph status
2017-06-09 06:45:56,126 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:45:56,565 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            359 pgs backfill_wait
            1 pgs backfilling
            360 pgs stuck unclean
            Difference in osd space utilization 67.7595% greater than 40%
            recovery 457209/1044278 objects misplaced (43.782%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6224: 10 osds: 10 up, 10 in; 360 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74197: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            457209/1044278 objects misplaced (43.782%)
                2712 active+clean
                 359 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 149 kB/s rd, 187 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:45:56,565 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:45:56,565 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-09 06:46:56,626 INFO cluster.py [line:247] cost 60 seconds, left 4730 seconds when check the ceph status
2017-06-09 06:46:56,626 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:46:57,021 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            356 pgs backfill_wait
            1 pgs backfilling
            357 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 452540/1041823 objects misplaced (43.437%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6230: 10 osds: 10 up, 10 in; 357 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74250: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            452540/1041823 objects misplaced (43.437%)
                2715 active+clean
                 356 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 120 kB/s rd, 148 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:46:57,021 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:46:57,022 INFO cluster.py [line:239] usefull PG number is 2715
2017-06-09 06:47:57,072 INFO cluster.py [line:247] cost 61 seconds, left 4669 seconds when check the ceph status
2017-06-09 06:47:57,072 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:47:57,467 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            355 pgs backfill_wait
            1 pgs backfilling
            356 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 450928/1041001 objects misplaced (43.317%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6232: 10 osds: 10 up, 10 in; 356 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74298: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            450928/1041001 objects misplaced (43.317%)
                2716 active+clean
                 355 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 131 kB/s rd, 167 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:47:57,468 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:47:57,468 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-09 06:48:57,478 INFO cluster.py [line:247] cost 60 seconds, left 4609 seconds when check the ceph status
2017-06-09 06:48:57,478 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:48:57,899 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            354 pgs backfill_wait
            1 pgs backfilling
            355 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 449184/1040175 objects misplaced (43.184%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6234: 10 osds: 10 up, 10 in; 355 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74348: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            449184/1040175 objects misplaced (43.184%)
                2717 active+clean
                 354 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 130 kB/s rd, 161 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:48:57,900 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:48:57,900 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-09 06:49:57,946 INFO cluster.py [line:247] cost 60 seconds, left 4549 seconds when check the ceph status
2017-06-09 06:49:57,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:49:58,307 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            353 pgs backfill_wait
            1 pgs backfilling
            354 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 447518/1039408 objects misplaced (43.055%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6236: 10 osds: 10 up, 10 in; 354 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74398: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            447518/1039408 objects misplaced (43.055%)
                2718 active+clean
                 353 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 53512 B/s rd, 52 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:49:58,308 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:49:58,308 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-09 06:50:58,364 INFO cluster.py [line:247] cost 61 seconds, left 4488 seconds when check the ceph status
2017-06-09 06:50:58,365 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:50:58,771 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            352 pgs backfill_wait
            1 pgs backfilling
            353 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 445914/1038655 objects misplaced (42.932%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6238: 10 osds: 10 up, 10 in; 353 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74447: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            445914/1038655 objects misplaced (42.932%)
                2719 active+clean
                 352 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 150 MB/s, 40 objects/s
  client io 46708 B/s rd, 45 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:50:58,771 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:50:58,771 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-09 06:51:58,777 INFO cluster.py [line:247] cost 60 seconds, left 4428 seconds when check the ceph status
2017-06-09 06:51:58,778 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:51:59,178 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            351 pgs backfill_wait
            1 pgs backfilling
            352 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 444376/1037915 objects misplaced (42.814%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6240: 10 osds: 10 up, 10 in; 352 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74496: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            444376/1037915 objects misplaced (42.814%)
                2720 active+clean
                 351 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 67163 B/s rd, 65 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:51:59,178 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:51:59,178 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-09 06:52:59,198 INFO cluster.py [line:247] cost 61 seconds, left 4367 seconds when check the ceph status
2017-06-09 06:52:59,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:52:59,623 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            348 pgs backfill_wait
            1 pgs backfilling
            349 pgs stuck unclean
            Difference in osd space utilization 67.7276% greater than 40%
            recovery 442506/1037017 objects misplaced (42.671%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6246: 10 osds: 10 up, 10 in; 349 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74548: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            442506/1037017 objects misplaced (42.671%)
                2723 active+clean
                 348 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 228 MB/s, 62 objects/s
  client io 19493 B/s rd, 28 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:52:59,623 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:52:59,624 INFO cluster.py [line:239] usefull PG number is 2723
2017-06-09 06:53:59,684 INFO cluster.py [line:247] cost 60 seconds, left 4307 seconds when check the ceph status
2017-06-09 06:53:59,684 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:54:00,113 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            346 pgs backfill_wait
            1 pgs backfilling
            347 pgs stuck unclean
            Difference in osd space utilization 67.3708% greater than 40%
            recovery 438243/1034796 objects misplaced (42.351%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6250: 10 osds: 10 up, 10 in; 347 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74600: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            438243/1034796 objects misplaced (42.351%)
                2725 active+clean
                 346 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 220 MB/s, 60 objects/s
  client io 23405 B/s rd, 34 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:54:00,113 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:54:00,113 INFO cluster.py [line:239] usefull PG number is 2725
2017-06-09 06:55:00,174 INFO cluster.py [line:247] cost 61 seconds, left 4246 seconds when check the ceph status
2017-06-09 06:55:00,174 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:55:00,671 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            344 pgs backfill_wait
            1 pgs backfilling
            345 pgs stuck unclean
            Difference in osd space utilization 67.3445% greater than 40%
            recovery 436584/1033941 objects misplaced (42.225%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6253: 10 osds: 10 up, 10 in; 345 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74650: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            436584/1033941 objects misplaced (42.225%)
                2727 active+clean
                 344 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 84576 B/s rd, 123 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:55:00,672 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:55:00,672 INFO cluster.py [line:239] usefull PG number is 2727
2017-06-09 06:56:00,732 INFO cluster.py [line:247] cost 60 seconds, left 4186 seconds when check the ceph status
2017-06-09 06:56:00,732 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:56:01,133 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            341 pgs backfill_wait
            1 pgs backfilling
            342 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 434616/1032947 objects misplaced (42.075%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6259: 10 osds: 10 up, 10 in; 342 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74702: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            434616/1032947 objects misplaced (42.075%)
                2730 active+clean
                 341 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 216 MB/s, 58 objects/s
  client io 101 kB/s rd, 152 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:56:01,134 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:56:01,134 INFO cluster.py [line:239] usefull PG number is 2730
2017-06-09 06:57:01,193 INFO cluster.py [line:247] cost 61 seconds, left 4125 seconds when check the ceph status
2017-06-09 06:57:01,193 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:57:01,597 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            340 pgs backfill_wait
            1 pgs backfilling
            341 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 433021/1032143 objects misplaced (41.954%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6261: 10 osds: 10 up, 10 in; 341 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74751: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            433021/1032143 objects misplaced (41.954%)
                2731 active+clean
                 340 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 224 MB/s, 60 objects/s
  client io 97612 B/s rd, 142 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:57:01,597 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:57:01,597 INFO cluster.py [line:239] usefull PG number is 2731
2017-06-09 06:58:01,658 INFO cluster.py [line:247] cost 60 seconds, left 4065 seconds when check the ceph status
2017-06-09 06:58:01,658 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:58:02,081 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            339 pgs backfill_wait
            1 pgs backfilling
            340 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 430782/1031415 objects misplaced (41.766%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6263: 10 osds: 10 up, 10 in; 340 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74801: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4150 GB / 6992 GB avail
            430782/1031415 objects misplaced (41.766%)
                2732 active+clean
                 339 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 137 kB/s rd, 172 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:58:02,081 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:58:02,081 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-09 06:59:02,130 INFO cluster.py [line:247] cost 61 seconds, left 4004 seconds when check the ceph status
2017-06-09 06:59:02,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 06:59:02,511 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            338 pgs backfill_wait
            1 pgs backfilling
            339 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 428267/1029875 objects misplaced (41.584%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6265: 10 osds: 10 up, 10 in; 339 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74851: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            428267/1029875 objects misplaced (41.584%)
                2733 active+clean
                 338 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 218 MB/s, 58 objects/s
  client io 121 kB/s rd, 150 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 06:59:02,511 INFO cluster.py [line:238] PG number is 3072
2017-06-09 06:59:02,511 INFO cluster.py [line:239] usefull PG number is 2733
2017-06-09 07:00:02,572 INFO cluster.py [line:247] cost 60 seconds, left 3944 seconds when check the ceph status
2017-06-09 07:00:02,572 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:00:02,981 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            335 pgs backfill_wait
            1 pgs backfilling
            336 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 426435/1028905 objects misplaced (41.446%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6271: 10 osds: 10 up, 10 in; 336 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74903: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            426435/1028905 objects misplaced (41.446%)
                2736 active+clean
                 335 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 138 kB/s rd, 174 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:00:02,981 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:00:02,981 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-09 07:01:03,028 INFO cluster.py [line:247] cost 61 seconds, left 3883 seconds when check the ceph status
2017-06-09 07:01:03,028 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:01:03,400 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            333 pgs backfill_wait
            1 pgs backfilling
            334 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 424814/1028129 objects misplaced (41.319%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6275: 10 osds: 10 up, 10 in; 334 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74953: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            424814/1028129 objects misplaced (41.319%)
                2738 active+clean
                 333 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 43122 B/s rd, 42 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:01:03,400 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:01:03,401 INFO cluster.py [line:239] usefull PG number is 2738
2017-06-09 07:02:03,439 INFO cluster.py [line:247] cost 60 seconds, left 3823 seconds when check the ceph status
2017-06-09 07:02:03,439 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:02:03,844 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            331 pgs backfill_wait
            1 pgs backfilling
            332 pgs stuck unclean
            Difference in osd space utilization 66.996% greater than 40%
            recovery 422229/1026622 objects misplaced (41.128%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6279: 10 osds: 10 up, 10 in; 332 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75004: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            422229/1026622 objects misplaced (41.128%)
                2740 active+clean
                 331 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 154 MB/s, 41 objects/s
  client io 62148 B/s rd, 68 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:02:03,844 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:02:03,844 INFO cluster.py [line:239] usefull PG number is 2740
2017-06-09 07:03:03,866 INFO cluster.py [line:247] cost 60 seconds, left 3763 seconds when check the ceph status
2017-06-09 07:03:03,866 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:03:04,273 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            330 pgs backfill_wait
            1 pgs backfilling
            331 pgs stuck unclean
            Difference in osd space utilization 66.9959% greater than 40%
            recovery 420703/1025863 objects misplaced (41.010%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6281: 10 osds: 10 up, 10 in; 331 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75055: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            420703/1025863 objects misplaced (41.010%)
                2741 active+clean
                 330 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 25681 B/s rd, 37 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:03:04,273 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:03:04,273 INFO cluster.py [line:239] usefull PG number is 2741
2017-06-09 07:04:04,333 INFO cluster.py [line:247] cost 61 seconds, left 3702 seconds when check the ceph status
2017-06-09 07:04:04,334 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:04:04,734 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            329 pgs backfill_wait
            1 pgs backfilling
            330 pgs stuck unclean
            Difference in osd space utilization 66.6202% greater than 40%
            recovery 418050/1025080 objects misplaced (40.782%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6285: 10 osds: 10 up, 10 in; 329 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75105: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4151 GB / 6992 GB avail
            418050/1025080 objects misplaced (40.782%)
                2742 active+clean
                 329 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 31659 B/s rd, 46 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:04:04,734 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:04:04,734 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-09 07:05:04,793 INFO cluster.py [line:247] cost 60 seconds, left 3642 seconds when check the ceph status
2017-06-09 07:05:04,793 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:05:05,130 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            327 pgs backfill_wait
            2 pgs backfilling
            329 pgs stuck unclean
            Difference in osd space utilization 66.2561% greater than 40%
            recovery 415481/1023560 objects misplaced (40.592%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6287: 10 osds: 10 up, 10 in; 328 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75155: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            415481/1023560 objects misplaced (40.592%)
                2743 active+clean
                 327 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 35093 B/s rd, 51 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:05:05,130 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:05:05,130 INFO cluster.py [line:239] usefull PG number is 2743
2017-06-09 07:06:05,189 INFO cluster.py [line:247] cost 61 seconds, left 3581 seconds when check the ceph status
2017-06-09 07:06:05,189 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:06:05,589 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            326 pgs backfill_wait
            1 pgs backfilling
            327 pgs stuck unclean
            Difference in osd space utilization 65.8626% greater than 40%
            recovery 412920/1022021 objects misplaced (40.402%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6289: 10 osds: 10 up, 10 in; 327 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75204: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            412920/1022021 objects misplaced (40.402%)
                2745 active+clean
                 326 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 14514 B/s rd, 21 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:06:05,589 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:06:05,589 INFO cluster.py [line:239] usefull PG number is 2745
2017-06-09 07:07:05,608 INFO cluster.py [line:247] cost 60 seconds, left 3521 seconds when check the ceph status
2017-06-09 07:07:05,609 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:07:05,985 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            320 pgs backfill_wait
            1 pgs backfilling
            321 pgs stuck unclean
            Difference in osd space utilization 65.1226% greater than 40%
            recovery 408153/1019538 objects misplaced (40.033%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6297: 10 osds: 10 up, 10 in; 321 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75257: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            408153/1019538 objects misplaced (40.033%)
                2751 active+clean
                 320 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 57 objects/s
  client io 88356 B/s rd, 129 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:07:05,985 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:07:05,985 INFO cluster.py [line:239] usefull PG number is 2751
2017-06-09 07:08:06,018 INFO cluster.py [line:247] cost 61 seconds, left 3460 seconds when check the ceph status
2017-06-09 07:08:06,019 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:08:06,423 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            319 pgs backfill_wait
            1 pgs backfilling
            320 pgs stuck unclean
            Difference in osd space utilization 65.1226% greater than 40%
            recovery 406655/1018806 objects misplaced (39.915%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6299: 10 osds: 10 up, 10 in; 320 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75299: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            406655/1018806 objects misplaced (39.915%)
                2752 active+clean
                 319 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 36979 B/s rd, 54 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:08:06,424 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:08:06,424 INFO cluster.py [line:239] usefull PG number is 2752
2017-06-09 07:09:06,472 INFO cluster.py [line:247] cost 60 seconds, left 3400 seconds when check the ceph status
2017-06-09 07:09:06,473 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:09:06,892 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            316 pgs backfill_wait
            1 pgs backfilling
            317 pgs stuck unclean
            Difference in osd space utilization 65.1226% greater than 40%
            recovery 404858/1017939 objects misplaced (39.772%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6303: 10 osds: 10 up, 10 in; 317 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75342: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            404858/1017939 objects misplaced (39.772%)
                2755 active+clean
                 316 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 224 MB/s, 60 objects/s
  client io 73856 B/s rd, 108 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:09:06,892 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:09:06,892 INFO cluster.py [line:239] usefull PG number is 2755
2017-06-09 07:10:06,950 INFO cluster.py [line:247] cost 60 seconds, left 3340 seconds when check the ceph status
2017-06-09 07:10:06,950 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:10:07,303 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            315 pgs backfill_wait
            1 pgs backfilling
            316 pgs stuck unclean
            Difference in osd space utilization 65.1226% greater than 40%
            recovery 403322/1017185 objects misplaced (39.651%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6305: 10 osds: 10 up, 10 in; 316 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75384: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            403322/1017185 objects misplaced (39.651%)
                2756 active+clean
                 315 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 52108 B/s rd, 76 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:10:07,303 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:10:07,304 INFO cluster.py [line:239] usefull PG number is 2756
2017-06-09 07:11:07,349 INFO cluster.py [line:247] cost 61 seconds, left 3279 seconds when check the ceph status
2017-06-09 07:11:07,349 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:11:07,758 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            313 pgs backfill_wait
            1 pgs backfilling
            314 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 398925/1014886 objects misplaced (39.307%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6309: 10 osds: 10 up, 10 in; 314 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75434: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4150 GB / 6992 GB avail
            398925/1014886 objects misplaced (39.307%)
                2758 active+clean
                 313 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 525 MB/s, 145 objects/s
  client io 59293 B/s rd, 86 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:11:07,759 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:11:07,759 INFO cluster.py [line:239] usefull PG number is 2758
2017-06-09 07:12:07,819 INFO cluster.py [line:247] cost 60 seconds, left 3219 seconds when check the ceph status
2017-06-09 07:12:07,819 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:12:08,166 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            312 pgs backfill_wait
            1 pgs backfilling
            313 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 397182/1014108 objects misplaced (39.166%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6311: 10 osds: 10 up, 10 in; 313 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75475: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            397182/1014108 objects misplaced (39.166%)
                2759 active+clean
                 312 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 225 MB/s, 60 objects/s
  client io 45779 B/s rd, 67 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:12:08,166 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:12:08,166 INFO cluster.py [line:239] usefull PG number is 2759
2017-06-09 07:13:08,181 INFO cluster.py [line:247] cost 61 seconds, left 3158 seconds when check the ceph status
2017-06-09 07:13:08,181 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:13:08,567 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            309 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            310 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 394289/1012561 objects misplaced (38.940%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6318: 10 osds: 10 up, 10 in; 309 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75520: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            394289/1012561 objects misplaced (38.940%)
                2761 active+clean
                 309 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 84752 kB/s, 20 objects/s
stdin: is not a tty

2017-06-09 07:13:08,567 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:13:08,567 INFO cluster.py [line:239] usefull PG number is 2761
2017-06-09 07:14:08,628 INFO cluster.py [line:247] cost 60 seconds, left 3098 seconds when check the ceph status
2017-06-09 07:14:08,628 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:14:09,020 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            307 pgs backfill_wait
            1 pgs backfilling
            308 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 392630/1011757 objects misplaced (38.807%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6321: 10 osds: 10 up, 10 in; 308 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75560: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            392630/1011757 objects misplaced (38.807%)
                2764 active+clean
                 307 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 217 MB/s, 58 objects/s
stdin: is not a tty

2017-06-09 07:14:09,020 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:14:09,020 INFO cluster.py [line:239] usefull PG number is 2764
2017-06-09 07:15:09,081 INFO cluster.py [line:247] cost 61 seconds, left 3037 seconds when check the ceph status
2017-06-09 07:15:09,081 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:15:09,480 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            306 pgs backfill_wait
            1 pgs backfilling
            307 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 390628/1011010 objects misplaced (38.637%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6323: 10 osds: 10 up, 10 in; 307 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75605: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            390628/1011010 objects misplaced (38.637%)
                2765 active+clean
                 306 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 486 MB/s, 130 objects/s
stdin: is not a tty

2017-06-09 07:15:09,480 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:15:09,480 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-09 07:16:09,496 INFO cluster.py [line:247] cost 60 seconds, left 2977 seconds when check the ceph status
2017-06-09 07:16:09,496 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:16:09,881 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            304 pgs backfill_wait
            1 pgs backfilling
            305 pgs stuck unclean
            Difference in osd space utilization 64.7495% greater than 40%
            recovery 388882/1010148 objects misplaced (38.498%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6327: 10 osds: 10 up, 10 in; 305 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75646: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            388882/1010148 objects misplaced (38.498%)
                2767 active+clean
                 304 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 223 MB/s, 60 objects/s
stdin: is not a tty

2017-06-09 07:16:09,882 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:16:09,882 INFO cluster.py [line:239] usefull PG number is 2767
2017-06-09 07:17:09,936 INFO cluster.py [line:247] cost 60 seconds, left 2917 seconds when check the ceph status
2017-06-09 07:17:09,936 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:17:10,302 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            303 pgs backfill_wait
            1 pgs backfilling
            304 pgs stuck unclean
            Difference in osd space utilization 64.3555% greater than 40%
            recovery 387239/1009325 objects misplaced (38.366%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6329: 10 osds: 10 up, 10 in; 304 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75686: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            387239/1009325 objects misplaced (38.366%)
                2768 active+clean
                 303 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 151 MB/s, 40 objects/s
  client io 1430 kB/s rd, 2134 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:17:10,303 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:17:10,303 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-09 07:18:10,363 INFO cluster.py [line:247] cost 61 seconds, left 2856 seconds when check the ceph status
2017-06-09 07:18:10,363 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:18:10,741 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            302 pgs backfill_wait
            1 pgs backfilling
            303 pgs stuck unclean
            Difference in osd space utilization 64.3555% greater than 40%
            recovery 385601/1008547 objects misplaced (38.233%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6331: 10 osds: 10 up, 10 in; 303 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75729: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            385601/1008547 objects misplaced (38.233%)
                2769 active+clean
                 302 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 157 MB/s, 42 objects/s
  client io 13424 B/s rd, 19 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:18:10,742 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:18:10,742 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-09 07:19:10,772 INFO cluster.py [line:247] cost 60 seconds, left 2796 seconds when check the ceph status
2017-06-09 07:19:10,772 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:19:11,152 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            299 pgs backfill_wait
            1 pgs backfilling
            300 pgs stuck unclean
            Difference in osd space utilization 64.3555% greater than 40%
            recovery 383860/1007705 objects misplaced (38.092%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6335: 10 osds: 10 up, 10 in; 300 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75774: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            383860/1007705 objects misplaced (38.092%)
                2772 active+clean
                 299 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 159 MB/s, 42 objects/s
  client io 9395 B/s rd, 13 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:19:11,152 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:19:11,152 INFO cluster.py [line:239] usefull PG number is 2772
2017-06-09 07:20:11,198 INFO cluster.py [line:247] cost 61 seconds, left 2735 seconds when check the ceph status
2017-06-09 07:20:11,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:20:11,557 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            296 pgs backfill_wait
            2 pgs backfilling
            298 pgs stuck unclean
            Difference in osd space utilization 64.3555% greater than 40%
            recovery 381034/1006175 objects misplaced (37.870%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6339: 10 osds: 10 up, 10 in; 298 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75827: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            381034/1006175 objects misplaced (37.870%)
                2774 active+clean
                 296 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 213 MB/s, 58 objects/s
  client io 39972 B/s rd, 39 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:20:11,557 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:20:11,558 INFO cluster.py [line:239] usefull PG number is 2774
2017-06-09 07:21:11,582 INFO cluster.py [line:247] cost 60 seconds, left 2675 seconds when check the ceph status
2017-06-09 07:21:11,582 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:21:11,998 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            295 pgs backfill_wait
            1 pgs backfilling
            296 pgs stuck unclean
            Difference in osd space utilization 63.99% greater than 40%
            recovery 378241/1004657 objects misplaced (37.649%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6343: 10 osds: 10 up, 10 in; 296 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75875: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            378241/1004657 objects misplaced (37.649%)
                2776 active+clean
                 295 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 213 MB/s, 57 objects/s
  client io 94515 B/s rd, 116 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:21:11,998 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:21:11,998 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-09 07:22:12,046 INFO cluster.py [line:247] cost 61 seconds, left 2614 seconds when check the ceph status
2017-06-09 07:22:12,047 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:22:12,476 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            294 pgs backfill_wait
            1 pgs backfilling
            295 pgs stuck unclean
            Difference in osd space utilization 63.6183% greater than 40%
            recovery 376586/1003878 objects misplaced (37.513%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6345: 10 osds: 10 up, 10 in; 295 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75917: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            376586/1003878 objects misplaced (37.513%)
                2777 active+clean
                 294 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 83723 B/s rd, 102 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:22:12,476 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:22:12,476 INFO cluster.py [line:239] usefull PG number is 2777
2017-06-09 07:23:12,505 INFO cluster.py [line:247] cost 60 seconds, left 2554 seconds when check the ceph status
2017-06-09 07:23:12,505 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:23:12,934 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            293 pgs backfill_wait
            1 pgs backfilling
            294 pgs stuck unclean
            Difference in osd space utilization 63.2407% greater than 40%
            recovery 374881/1003094 objects misplaced (37.372%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6347: 10 osds: 10 up, 10 in; 294 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75958: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            374881/1003094 objects misplaced (37.372%)
                2778 active+clean
                 293 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 231 MB/s, 62 objects/s
  client io 98593 B/s rd, 121 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:23:12,934 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:23:12,934 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-09 07:24:12,969 INFO cluster.py [line:247] cost 60 seconds, left 2494 seconds when check the ceph status
2017-06-09 07:24:12,969 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:24:13,359 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            292 pgs backfill_wait
            1 pgs backfilling
            293 pgs stuck unclean
            Difference in osd space utilization 62.8384% greater than 40%
            recovery 373226/1002253 objects misplaced (37.239%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6349: 10 osds: 10 up, 10 in; 293 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75999: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            373226/1002253 objects misplaced (37.239%)
                2779 active+clean
                 292 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 229 MB/s, 61 objects/s
  client io 104 kB/s rd, 131 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:24:13,359 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:24:13,359 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-09 07:25:13,420 INFO cluster.py [line:247] cost 61 seconds, left 2433 seconds when check the ceph status
2017-06-09 07:25:13,420 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:25:13,820 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            291 pgs backfill_wait
            1 pgs backfilling
            292 pgs stuck unclean
            Difference in osd space utilization 62.8384% greater than 40%
            recovery 370998/1001481 objects misplaced (37.045%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6351: 10 osds: 10 up, 10 in; 292 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76047: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2840 GB used, 4151 GB / 6992 GB avail
            370998/1001481 objects misplaced (37.045%)
                2780 active+clean
                 291 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 54190 B/s rd, 52 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:25:13,820 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:25:13,820 INFO cluster.py [line:239] usefull PG number is 2780
2017-06-09 07:26:13,864 INFO cluster.py [line:247] cost 60 seconds, left 2373 seconds when check the ceph status
2017-06-09 07:26:13,864 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:26:14,258 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            287 pgs backfill_wait
            1 pgs backfilling
            289 pgs stuck unclean
            Difference in osd space utilization 62.8133% greater than 40%
            recovery 367250/999062 objects misplaced (36.759%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6359: 10 osds: 10 up, 10 in; 287 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76103: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            367250/999062 objects misplaced (36.759%)
                2783 active+clean
                 287 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
  client io 30711 B/s rd, 44 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:26:14,258 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:26:14,259 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-09 07:27:14,311 INFO cluster.py [line:247] cost 61 seconds, left 2312 seconds when check the ceph status
2017-06-09 07:27:14,311 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:27:14,678 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            283 pgs backfill_wait
            1 pgs backfilling
            284 pgs stuck unclean
            Difference in osd space utilization 63.1547% greater than 40%
            recovery 363454/997186 objects misplaced (36.448%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6364: 10 osds: 10 up, 10 in; 284 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76148: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2842 GB used, 4150 GB / 6992 GB avail
            363454/997186 objects misplaced (36.448%)
                2788 active+clean
                 283 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 16314 B/s rd, 23 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:27:14,678 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:27:14,678 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-09 07:28:14,728 INFO cluster.py [line:247] cost 60 seconds, left 2252 seconds when check the ceph status
2017-06-09 07:28:14,728 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:28:15,120 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            282 pgs backfill_wait
            1 pgs backfilling
            283 pgs stuck unclean
            Difference in osd space utilization 63.1547% greater than 40%
            recovery 360245/995670 objects misplaced (36.181%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6366: 10 osds: 10 up, 10 in; 283 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76197: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            360245/995670 objects misplaced (36.181%)
                2789 active+clean
                 282 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 154 MB/s, 41 objects/s
  client io 51644 B/s rd, 57 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:28:15,121 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:28:15,121 INFO cluster.py [line:239] usefull PG number is 2789
2017-06-09 07:29:15,135 INFO cluster.py [line:247] cost 61 seconds, left 2191 seconds when check the ceph status
2017-06-09 07:29:15,135 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:29:15,531 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            281 pgs backfill_wait
            1 pgs backfilling
            282 pgs stuck unclean
            Difference in osd space utilization 63.1547% greater than 40%
            recovery 358695/994893 objects misplaced (36.054%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6368: 10 osds: 10 up, 10 in; 282 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76240: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            358695/994893 objects misplaced (36.054%)
                2790 active+clean
                 281 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 43329 B/s rd, 48 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:29:15,531 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:29:15,531 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-09 07:30:15,549 INFO cluster.py [line:247] cost 60 seconds, left 2131 seconds when check the ceph status
2017-06-09 07:30:15,550 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:30:15,930 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            280 pgs backfill_wait
            1 pgs backfilling
            281 pgs stuck unclean
            Difference in osd space utilization 63.1547% greater than 40%
            recovery 357080/994144 objects misplaced (35.918%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6370: 10 osds: 10 up, 10 in; 281 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76284: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            357080/994144 objects misplaced (35.918%)
                2791 active+clean
                 280 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 143 MB/s, 38 objects/s
  client io 68044 B/s rd, 99 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:30:15,930 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:30:15,931 INFO cluster.py [line:239] usefull PG number is 2791
2017-06-09 07:31:15,961 INFO cluster.py [line:247] cost 60 seconds, left 2071 seconds when check the ceph status
2017-06-09 07:31:15,961 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:31:16,339 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            276 pgs backfill_wait
            2 pgs backfilling
            278 pgs stuck unclean
            Difference in osd space utilization 63.1324% greater than 40%
            recovery 354895/993250 objects misplaced (35.731%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6375: 10 osds: 10 up, 10 in; 278 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76330: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            354895/993250 objects misplaced (35.731%)
                2794 active+clean
                 276 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 290 MB/s, 78 objects/s
  client io 41808 B/s rd, 61 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:31:16,339 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:31:16,339 INFO cluster.py [line:239] usefull PG number is 2794
2017-06-09 07:32:16,395 INFO cluster.py [line:247] cost 61 seconds, left 2010 seconds when check the ceph status
2017-06-09 07:32:16,396 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:32:16,785 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            1 pgs backfilling
            275 pgs stuck unclean
            Difference in osd space utilization 63.1067% greater than 40%
            recovery 352132/991705 objects misplaced (35.508%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6380: 10 osds: 10 up, 10 in; 275 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76374: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            352132/991705 objects misplaced (35.508%)
                2797 active+clean
                 274 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 115 MB/s, 31 objects/s
  client io 39745 B/s rd, 58 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:32:16,785 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:32:16,785 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-09 07:33:16,788 INFO cluster.py [line:247] cost 60 seconds, left 1950 seconds when check the ceph status
2017-06-09 07:33:16,788 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:33:17,169 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            270 pgs backfill_wait
            1 pgs backfilling
            271 pgs stuck unclean
            Difference in osd space utilization 62.382% greater than 40%
            recovery 347382/989261 objects misplaced (35.115%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6387: 10 osds: 10 up, 10 in; 271 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76420: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            347382/989261 objects misplaced (35.115%)
                2801 active+clean
                 270 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 115 kB/s rd, 143 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:33:17,169 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:33:17,169 INFO cluster.py [line:239] usefull PG number is 2801
2017-06-09 07:34:17,230 INFO cluster.py [line:247] cost 61 seconds, left 1889 seconds when check the ceph status
2017-06-09 07:34:17,230 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:34:17,667 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            268 pgs backfill_wait
            2 pgs backfilling
            270 pgs stuck unclean
            Difference in osd space utilization 61.9931% greater than 40%
            recovery 343016/987635 objects misplaced (34.731%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6391: 10 osds: 10 up, 10 in; 269 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76465: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4150 GB / 6992 GB avail
            343016/987635 objects misplaced (34.731%)
                2802 active+clean
                 268 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 55816 kB/s, 13 objects/s
stdin: is not a tty

2017-06-09 07:34:17,667 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:34:17,667 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-09 07:35:17,712 INFO cluster.py [line:247] cost 60 seconds, left 1829 seconds when check the ceph status
2017-06-09 07:35:17,713 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:35:18,089 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            262 pgs backfill_wait
            1 pgs backfilling
            263 pgs stuck unclean
            Difference in osd space utilization 61.9661% greater than 40%
            recovery 333390/982167 objects misplaced (33.944%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6400: 10 osds: 10 up, 10 in; 263 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76514: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            333390/982167 objects misplaced (33.944%)
                2809 active+clean
                 262 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 220 MB/s, 59 objects/s
  client io 116 kB/s rd, 145 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:35:18,089 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:35:18,089 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-09 07:36:18,124 INFO cluster.py [line:247] cost 61 seconds, left 1768 seconds when check the ceph status
2017-06-09 07:36:18,124 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:36:18,519 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            261 pgs backfill_wait
            1 pgs backfilling
            262 pgs stuck unclean
            Difference in osd space utilization 61.9661% greater than 40%
            recovery 331816/981400 objects misplaced (33.810%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6402: 10 osds: 10 up, 10 in; 262 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76555: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            331816/981400 objects misplaced (33.810%)
                2810 active+clean
                 261 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 124 kB/s rd, 156 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:36:18,519 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:36:18,519 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-09 07:37:18,572 INFO cluster.py [line:247] cost 60 seconds, left 1708 seconds when check the ceph status
2017-06-09 07:37:18,572 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:37:18,965 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            260 pgs backfill_wait
            1 pgs backfilling
            261 pgs stuck unclean
            Difference in osd space utilization 61.9661% greater than 40%
            recovery 330211/980628 objects misplaced (33.673%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6404: 10 osds: 10 up, 10 in; 261 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76597: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            330211/980628 objects misplaced (33.673%)
                2811 active+clean
                 260 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 58 objects/s
  client io 40036 B/s rd, 39 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:37:18,965 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:37:18,966 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-09 07:38:19,000 INFO cluster.py [line:247] cost 61 seconds, left 1647 seconds when check the ceph status
2017-06-09 07:38:19,001 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:38:19,389 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            259 pgs backfill_wait
            1 pgs backfilling
            260 pgs stuck unclean
            Difference in osd space utilization 61.9661% greater than 40%
            recovery 328744/979906 objects misplaced (33.549%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6406: 10 osds: 10 up, 10 in; 260 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76643: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            328744/979906 objects misplaced (33.549%)
                2812 active+clean
                 259 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 52985 B/s rd, 59 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:38:19,389 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:38:19,389 INFO cluster.py [line:239] usefull PG number is 2812
2017-06-09 07:39:19,410 INFO cluster.py [line:247] cost 60 seconds, left 1587 seconds when check the ceph status
2017-06-09 07:39:19,410 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:39:19,800 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            256 pgs backfill_wait
            2 pgs backfilling
            258 pgs stuck unclean
            Difference in osd space utilization 61.9661% greater than 40%
            recovery 324011/977591 objects misplaced (33.144%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6410: 10 osds: 10 up, 10 in; 258 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76688: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4150 GB / 6992 GB avail
            324011/977591 objects misplaced (33.144%)
                2814 active+clean
                 256 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 599 MB/s, 165 objects/s
  client io 23864 B/s rd, 23 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:39:19,801 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:39:19,801 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-09 07:40:19,842 INFO cluster.py [line:247] cost 60 seconds, left 1527 seconds when check the ceph status
2017-06-09 07:40:19,842 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:40:20,208 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            256 pgs backfill_wait
            1 pgs backfilling
            257 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 320449/976027 objects misplaced (32.832%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6414: 10 osds: 10 up, 10 in; 256 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76729: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            320449/976027 objects misplaced (32.832%)
                2815 active+clean
                 256 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 9105 B/s rd, 13 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:40:20,209 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:40:20,209 INFO cluster.py [line:239] usefull PG number is 2815
2017-06-09 07:41:20,261 INFO cluster.py [line:247] cost 61 seconds, left 1466 seconds when check the ceph status
2017-06-09 07:41:20,261 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:41:20,634 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            254 pgs backfill_wait
            1 pgs backfilling
            255 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 317504/974442 objects misplaced (32.583%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6416: 10 osds: 10 up, 10 in; 255 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76775: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            317504/974442 objects misplaced (32.583%)
                2817 active+clean
                 254 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 149 MB/s, 40 objects/s
  client io 14723 B/s rd, 21 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:41:20,634 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:41:20,635 INFO cluster.py [line:239] usefull PG number is 2817
2017-06-09 07:42:20,695 INFO cluster.py [line:247] cost 60 seconds, left 1406 seconds when check the ceph status
2017-06-09 07:42:20,695 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:42:21,073 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            253 pgs backfill_wait
            1 pgs backfilling
            254 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 315891/973682 objects misplaced (32.443%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6418: 10 osds: 10 up, 10 in; 254 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76817: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            315891/973682 objects misplaced (32.443%)
                2818 active+clean
                 253 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 156 MB/s, 41 objects/s
  client io 26636 B/s rd, 38 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:42:21,073 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:42:21,073 INFO cluster.py [line:239] usefull PG number is 2818
2017-06-09 07:43:21,115 INFO cluster.py [line:247] cost 61 seconds, left 1345 seconds when check the ceph status
2017-06-09 07:43:21,115 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:43:21,542 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            248 pgs backfill_wait
            1 pgs backfilling
            249 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 310792/971272 objects misplaced (31.998%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6425: 10 osds: 10 up, 10 in; 249 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76866: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            310792/971272 objects misplaced (31.998%)
                2823 active+clean
                 248 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 471 MB/s, 130 objects/s
  client io 47820 B/s rd, 70 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:43:21,543 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:43:21,543 INFO cluster.py [line:239] usefull PG number is 2823
2017-06-09 07:44:21,603 INFO cluster.py [line:247] cost 60 seconds, left 1285 seconds when check the ceph status
2017-06-09 07:44:21,603 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:44:22,014 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            247 pgs backfill_wait
            1 pgs backfilling
            248 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 308126/969804 objects misplaced (31.772%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6427: 10 osds: 10 up, 10 in; 248 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76907: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            308126/969804 objects misplaced (31.772%)
                2824 active+clean
                 247 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 199 MB/s, 53 objects/s
  client io 88944 B/s rd, 110 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:44:22,014 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:44:22,014 INFO cluster.py [line:239] usefull PG number is 2824
2017-06-09 07:45:22,037 INFO cluster.py [line:247] cost 61 seconds, left 1224 seconds when check the ceph status
2017-06-09 07:45:22,037 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:45:22,442 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            244 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            245 pgs stuck unclean
            Difference in osd space utilization 61.59% greater than 40%
            recovery 305662/968239 objects misplaced (31.569%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6432: 10 osds: 10 up, 10 in; 245 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76953: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            305662/968239 objects misplaced (31.569%)
                2826 active+clean
                 244 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 293 MB/s, 73 objects/s
  client io 121 kB/s rd, 150 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:45:22,442 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:45:22,442 INFO cluster.py [line:239] usefull PG number is 2826
2017-06-09 07:46:22,503 INFO cluster.py [line:247] cost 60 seconds, left 1164 seconds when check the ceph status
2017-06-09 07:46:22,503 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:46:22,918 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            238 pgs backfill_wait
            3 pgs backfilling
            241 pgs stuck unclean
            Difference in osd space utilization 60.7307% greater than 40%
            recovery 298263/965223 objects misplaced (30.901%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6441: 10 osds: 10 up, 10 in; 240 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77004: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2840 GB used, 4151 GB / 6992 GB avail
            298263/965223 objects misplaced (30.901%)
                2831 active+clean
                 238 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 477 MB/s, 128 objects/s
  client io 108 kB/s rd, 108 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:46:22,918 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:46:22,919 INFO cluster.py [line:239] usefull PG number is 2831
2017-06-09 07:47:22,959 INFO cluster.py [line:247] cost 60 seconds, left 1104 seconds when check the ceph status
2017-06-09 07:47:22,959 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:47:23,347 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            232 pgs backfill_wait
            1 pgs backfilling
            235 pgs stuck unclean
            Difference in osd space utilization 59.6582% greater than 40%
            recovery 291612/961987 objects misplaced (30.314%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6452: 10 osds: 10 up, 10 in; 233 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77054: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2841 GB used, 4151 GB / 6992 GB avail
            291612/961987 objects misplaced (30.314%)
                2837 active+clean
                 232 active+remapped+backfill_wait
                   2 active+remapped
                   1 active+remapped+backfilling
recovery io 56539 kB/s, 14 objects/s
  client io 30516 B/s rd, 44 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:47:23,348 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:47:23,348 INFO cluster.py [line:239] usefull PG number is 2837
2017-06-09 07:48:23,408 INFO cluster.py [line:247] cost 61 seconds, left 1043 seconds when check the ceph status
2017-06-09 07:48:23,408 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:48:23,802 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            228 pgs backfill_wait
            2 pgs backfilling
            230 pgs stuck unclean
            Difference in osd space utilization 58.9054% greater than 40%
            recovery 286921/958893 objects misplaced (29.922%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6458: 10 osds: 10 up, 10 in; 230 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77100: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            286921/958893 objects misplaced (29.922%)
                2842 active+clean
                 228 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 07:48:23,802 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:48:23,802 INFO cluster.py [line:239] usefull PG number is 2842
2017-06-09 07:49:23,862 INFO cluster.py [line:247] cost 60 seconds, left 983 seconds when check the ceph status
2017-06-09 07:49:23,862 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:49:24,286 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            225 pgs backfill_wait
            2 pgs backfilling
            227 pgs stuck unclean
            Difference in osd space utilization 58.456% greater than 40%
            recovery 283592/957245 objects misplaced (29.626%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6464: 10 osds: 10 up, 10 in; 226 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77148: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            283592/957245 objects misplaced (29.626%)
                2845 active+clean
                 225 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 72950 kB/s, 19 objects/s
stdin: is not a tty

2017-06-09 07:49:24,286 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:49:24,286 INFO cluster.py [line:239] usefull PG number is 2845
2017-06-09 07:50:24,344 INFO cluster.py [line:247] cost 61 seconds, left 922 seconds when check the ceph status
2017-06-09 07:50:24,344 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:50:24,760 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            222 pgs backfill_wait
            3 pgs backfilling
            225 pgs stuck unclean
            Difference in osd space utilization 58.1222% greater than 40%
            recovery 280582/956412 objects misplaced (29.337%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6468: 10 osds: 10 up, 10 in; 224 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77191: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            280582/956412 objects misplaced (29.337%)
                2847 active+clean
                 222 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 657 MB/s, 183 objects/s
stdin: is not a tty

2017-06-09 07:50:24,760 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:50:24,760 INFO cluster.py [line:239] usefull PG number is 2847
2017-06-09 07:51:24,783 INFO cluster.py [line:247] cost 60 seconds, left 862 seconds when check the ceph status
2017-06-09 07:51:24,783 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:51:25,170 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            218 pgs backfill_wait
            2 pgs backfilling
            220 pgs stuck unclean
            Difference in osd space utilization 57.4561% greater than 40%
            recovery 271561/951575 objects misplaced (28.538%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6476: 10 osds: 10 up, 10 in; 220 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77245: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            271561/951575 objects misplaced (28.538%)
                2852 active+clean
                 218 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 294 MB/s, 79 objects/s
stdin: is not a tty

2017-06-09 07:51:25,170 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:51:25,170 INFO cluster.py [line:239] usefull PG number is 2852
2017-06-09 07:52:25,198 INFO cluster.py [line:247] cost 61 seconds, left 801 seconds when check the ceph status
2017-06-09 07:52:25,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:52:25,599 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            214 pgs backfill_wait
            2 pgs backfilling
            216 pgs stuck unclean
            Difference in osd space utilization 56.8207% greater than 40%
            recovery 265327/948351 objects misplaced (27.978%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6484: 10 osds: 10 up, 10 in; 216 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77296: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            265327/948351 objects misplaced (27.978%)
                2856 active+clean
                 214 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 148 MB/s, 40 objects/s
stdin: is not a tty

2017-06-09 07:52:25,600 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:52:25,600 INFO cluster.py [line:239] usefull PG number is 2856
2017-06-09 07:53:25,658 INFO cluster.py [line:247] cost 60 seconds, left 741 seconds when check the ceph status
2017-06-09 07:53:25,658 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:53:26,089 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            212 pgs backfill_wait
            2 pgs backfilling
            214 pgs stuck unclean
            Difference in osd space utilization 56.4047% greater than 40%
            recovery 262083/946830 objects misplaced (27.680%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6488: 10 osds: 10 up, 10 in; 214 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77342: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            262083/946830 objects misplaced (27.680%)
                2858 active+clean
                 212 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 339 MB/s, 91 objects/s
stdin: is not a tty

2017-06-09 07:53:26,090 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:53:26,090 INFO cluster.py [line:239] usefull PG number is 2858
2017-06-09 07:54:26,130 INFO cluster.py [line:247] cost 61 seconds, left 680 seconds when check the ceph status
2017-06-09 07:54:26,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:54:26,509 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            209 pgs backfill_wait
            2 pgs backfilling
            211 pgs stuck unclean
            Difference in osd space utilization 55.6075% greater than 40%
            recovery 257528/944540 objects misplaced (27.265%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6494: 10 osds: 10 up, 10 in; 211 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77392: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            257528/944540 objects misplaced (27.265%)
                2861 active+clean
                 209 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 234 MB/s, 63 objects/s
stdin: is not a tty

2017-06-09 07:54:26,509 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:54:26,509 INFO cluster.py [line:239] usefull PG number is 2861
2017-06-09 07:55:26,545 INFO cluster.py [line:247] cost 60 seconds, left 620 seconds when check the ceph status
2017-06-09 07:55:26,545 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:55:26,972 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            204 pgs backfill_wait
            2 pgs backfilling
            206 pgs stuck unclean
            Difference in osd space utilization 54.427% greater than 40%
            recovery 250747/941167 objects misplaced (26.642%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6503: 10 osds: 10 up, 10 in; 206 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77447: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            250747/941167 objects misplaced (26.642%)
                2866 active+clean
                 204 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 225 MB/s, 60 objects/s
  client io 4345 kB/s rd, 4345 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:55:26,972 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:55:26,972 INFO cluster.py [line:239] usefull PG number is 2866
2017-06-09 07:56:27,001 INFO cluster.py [line:247] cost 61 seconds, left 559 seconds when check the ceph status
2017-06-09 07:56:27,001 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:56:27,456 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            200 pgs backfill_wait
            2 pgs backfilling
            202 pgs stuck unclean
            Difference in osd space utilization 53.9035% greater than 40%
            recovery 247338/939542 objects misplaced (26.325%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6511: 10 osds: 10 up, 10 in; 202 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77495: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            247338/939542 objects misplaced (26.325%)
                2870 active+clean
                 200 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 219 MB/s, 58 objects/s
  client io 33711 B/s rd, 32 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:56:27,457 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:56:27,457 INFO cluster.py [line:239] usefull PG number is 2870
2017-06-09 07:57:27,513 INFO cluster.py [line:247] cost 60 seconds, left 499 seconds when check the ceph status
2017-06-09 07:57:27,513 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:57:27,888 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            191 pgs backfill_wait
            2 pgs backfilling
            193 pgs stuck unclean
            Difference in osd space utilization 52.3074% greater than 40%
            recovery 238216/934577 objects misplaced (25.489%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6526: 10 osds: 10 up, 10 in; 193 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77548: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            238216/934577 objects misplaced (25.489%)
                2879 active+clean
                 191 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 158 MB/s, 42 objects/s
  client io 54517 B/s rd, 53 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:57:27,889 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:57:27,889 INFO cluster.py [line:239] usefull PG number is 2879
2017-06-09 07:58:27,949 INFO cluster.py [line:247] cost 60 seconds, left 439 seconds when check the ceph status
2017-06-09 07:58:27,949 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:58:28,309 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            187 pgs backfill_wait
            2 pgs backfilling
            189 pgs stuck unclean
            Difference in osd space utilization 51.8052% greater than 40%
            recovery 234238/933012 objects misplaced (25.106%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6532: 10 osds: 10 up, 10 in; 189 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77595: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            234238/933012 objects misplaced (25.106%)
                2883 active+clean
                 187 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 832 MB/s, 231 objects/s
  client io 124 kB/s rd, 159 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:58:28,310 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:58:28,310 INFO cluster.py [line:239] usefull PG number is 2883
2017-06-09 07:59:28,333 INFO cluster.py [line:247] cost 61 seconds, left 378 seconds when check the ceph status
2017-06-09 07:59:28,333 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 07:59:28,751 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            185 pgs backfill_wait
            1 pgs backfilling
            186 pgs stuck unclean
            Difference in osd space utilization 51.5986% greater than 40%
            recovery 226948/929191 objects misplaced (24.424%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6538: 10 osds: 10 up, 10 in; 186 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77648: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            226948/929191 objects misplaced (24.424%)
                2886 active+clean
                 185 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 816 MB/s, 226 objects/s
  client io 96083 B/s rd, 119 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 07:59:28,751 INFO cluster.py [line:238] PG number is 3072
2017-06-09 07:59:28,751 INFO cluster.py [line:239] usefull PG number is 2886
2017-06-09 08:00:28,798 INFO cluster.py [line:247] cost 60 seconds, left 318 seconds when check the ceph status
2017-06-09 08:00:28,798 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:00:29,225 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            183 pgs backfill_wait
            2 pgs backfilling
            185 pgs stuck unclean
            Difference in osd space utilization 50.8952% greater than 40%
            recovery 222264/927607 objects misplaced (23.961%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6540: 10 osds: 10 up, 10 in; 185 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77694: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2842 GB used, 4149 GB / 6992 GB avail
            222264/927607 objects misplaced (23.961%)
                2887 active+clean
                 183 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 374 MB/s, 104 objects/s
  client io 96170 B/s rd, 118 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:00:29,225 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:00:29,225 INFO cluster.py [line:239] usefull PG number is 2887
2017-06-09 08:01:29,280 INFO cluster.py [line:247] cost 61 seconds, left 257 seconds when check the ceph status
2017-06-09 08:01:29,281 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:01:29,731 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            180 pgs backfill_wait
            2 pgs backfilling
            182 pgs stuck unclean
            Difference in osd space utilization 49.7754% greater than 40%
            recovery 217125/924482 objects misplaced (23.486%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6546: 10 osds: 10 up, 10 in; 182 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77745: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            217125/924482 objects misplaced (23.486%)
                2890 active+clean
                 180 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 224 MB/s, 60 objects/s
  client io 83004 B/s rd, 105 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:01:29,731 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:01:29,731 INFO cluster.py [line:239] usefull PG number is 2890
2017-06-09 08:02:29,733 INFO cluster.py [line:247] cost 60 seconds, left 197 seconds when check the ceph status
2017-06-09 08:02:29,733 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:02:30,111 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            177 pgs backfill_wait
            2 pgs backfilling
            179 pgs stuck unclean
            Difference in osd space utilization 48.7347% greater than 40%
            recovery 209202/920448 objects misplaced (22.728%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6552: 10 osds: 10 up, 10 in; 179 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77794: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            209202/920448 objects misplaced (22.728%)
                2893 active+clean
                 177 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 186 MB/s, 50 objects/s
  client io 30071 B/s rd, 32 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:02:30,111 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:02:30,111 INFO cluster.py [line:239] usefull PG number is 2893
2017-06-09 08:03:30,172 INFO cluster.py [line:247] cost 61 seconds, left 136 seconds when check the ceph status
2017-06-09 08:03:30,172 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:03:30,669 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            172 pgs backfill_wait
            2 pgs backfilling
            174 pgs stuck unclean
            Difference in osd space utilization 48.2125% greater than 40%
            recovery 205570/918718 objects misplaced (22.376%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6562: 10 osds: 10 up, 10 in; 174 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77848: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            205570/918718 objects misplaced (22.376%)
                2898 active+clean
                 172 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 235 MB/s, 62 objects/s
  client io 19312 B/s rd, 28 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:03:30,670 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:03:30,670 INFO cluster.py [line:239] usefull PG number is 2898
2017-06-09 08:04:30,730 INFO cluster.py [line:247] cost 60 seconds, left 76 seconds when check the ceph status
2017-06-09 08:04:30,730 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:04:31,108 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            169 pgs backfill_wait
            2 pgs backfilling
            171 pgs stuck unclean
            Difference in osd space utilization 47.7757% greater than 40%
            recovery 199561/915736 objects misplaced (21.792%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6568: 10 osds: 10 up, 10 in; 171 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77895: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            199561/915736 objects misplaced (21.792%)
                2901 active+clean
                 169 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 159 MB/s, 43 objects/s
  client io 14769 B/s rd, 21 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:04:31,108 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:04:31,108 INFO cluster.py [line:239] usefull PG number is 2901
2017-06-09 08:05:31,168 INFO cluster.py [line:247] cost 61 seconds, left 15 seconds when check the ceph status
2017-06-09 08:05:31,169 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:05:31,605 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            162 pgs backfill_wait
            2 pgs backfilling
            164 pgs stuck unclean
            Difference in osd space utilization 46.9548% greater than 40%
            recovery 194779/913050 objects misplaced (21.333%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6582: 10 osds: 10 up, 10 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77951: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            194779/913050 objects misplaced (21.333%)
                2908 active+clean
                 162 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 148 MB/s, 40 objects/s
  client io 52531 B/s rd, 76 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:05:31,605 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:05:31,606 INFO cluster.py [line:239] usefull PG number is 2908
2017-06-09 08:06:31,666 INFO cluster.py [line:247] cost 60 seconds, left -45 seconds when check the ceph status
2017-06-09 08:06:31,666 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:85] status is HEALTH_ERROR
2017-06-09 08:06:31,666 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:86] TC47_48_49_50_51_remove_osds_on_single_node  runs failed
2017-06-09 08:06:31,666 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:06:32,111 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            159 pgs backfill_wait
            2 pgs backfilling
            161 pgs stuck unclean
            Difference in osd space utilization 46.5744% greater than 40%
            recovery 191259/911518 objects misplaced (20.982%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6588: 10 osds: 10 up, 10 in; 161 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77998: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            191259/911518 objects misplaced (20.982%)
                2911 active+clean
                 159 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 609 MB/s, 166 objects/s
  client io 93019 B/s rd, 136 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:06:32,112 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:06:32,112 INFO cluster.py [line:239] usefull PG number is 2911
2017-06-09 08:07:32,164 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-09 08:07:32,164 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:07:32,665 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            154 pgs backfill_wait
            2 pgs backfilling
            156 pgs stuck unclean
            Difference in osd space utilization 45.4229% greater than 40%
            recovery 185320/908482 objects misplaced (20.399%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6597: 10 osds: 10 up, 10 in; 156 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78052: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            185320/908482 objects misplaced (20.399%)
                2916 active+clean
                 154 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 231 MB/s, 62 objects/s
  client io 109 kB/s rd, 133 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:07:32,666 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:07:32,666 INFO cluster.py [line:239] usefull PG number is 2916
2017-06-09 08:08:32,700 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-09 08:08:32,700 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:08:33,090 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            151 pgs backfill_wait
            2 pgs backfilling
            153 pgs stuck unclean
            Difference in osd space utilization 44.476% greater than 40%
            recovery 181834/906843 objects misplaced (20.051%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6603: 10 osds: 10 up, 10 in; 153 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78104: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            181834/906843 objects misplaced (20.051%)
                2919 active+clean
                 151 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 245 MB/s, 66 objects/s
  client io 52090 B/s rd, 76 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:08:33,091 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:08:33,091 INFO cluster.py [line:239] usefull PG number is 2919
2017-06-09 08:09:33,101 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-09 08:09:33,101 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:09:33,502 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            144 pgs backfill_wait
            2 pgs backfilling
            146 pgs stuck unclean
            Difference in osd space utilization 43.409% greater than 40%
            recovery 175665/903626 objects misplaced (19.440%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6615: 10 osds: 10 up, 10 in; 146 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78158: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            175665/903626 objects misplaced (19.440%)
                2926 active+clean
                 144 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 220 MB/s, 59 objects/s
stdin: is not a tty

2017-06-09 08:09:33,502 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:09:33,502 INFO cluster.py [line:239] usefull PG number is 2926
2017-06-09 08:10:33,523 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-09 08:10:33,524 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:10:33,945 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            143 pgs backfill_wait
            1 pgs backfilling
            144 pgs stuck unclean
            Difference in osd space utilization 42.8855% greater than 40%
            recovery 172684/902093 objects misplaced (19.143%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6619: 10 osds: 10 up, 10 in; 144 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78204: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            172684/902093 objects misplaced (19.143%)
                2928 active+clean
                 143 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 228 MB/s, 61 objects/s
stdin: is not a tty

2017-06-09 08:10:33,945 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:10:33,946 INFO cluster.py [line:239] usefull PG number is 2928
2017-06-09 08:11:33,989 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-09 08:11:33,989 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:11:34,380 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            141 pgs backfill_wait
            1 pgs backfilling
            142 pgs stuck unclean
            Difference in osd space utilization 41.4693% greater than 40%
            recovery 169689/900517 objects misplaced (18.844%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6623: 10 osds: 10 up, 10 in; 142 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78252: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4155 GB / 6992 GB avail
            169689/900517 objects misplaced (18.844%)
                2930 active+clean
                 141 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 150 MB/s, 40 objects/s
stdin: is not a tty

2017-06-09 08:11:34,380 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:11:34,380 INFO cluster.py [line:239] usefull PG number is 2930
2017-06-09 08:12:34,441 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-09 08:12:34,441 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:12:34,815 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            140 pgs backfill_wait
            1 pgs backfilling
            141 pgs stuck unclean
            Difference in osd space utilization 41.0346% greater than 40%
            recovery 168103/899742 objects misplaced (18.683%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6625: 10 osds: 10 up, 10 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78292: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            168103/899742 objects misplaced (18.683%)
                2931 active+clean
                 140 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 147 MB/s, 39 objects/s
stdin: is not a tty

2017-06-09 08:12:34,815 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:12:34,816 INFO cluster.py [line:239] usefull PG number is 2931
2017-06-09 08:13:34,874 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-09 08:13:34,874 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:13:35,265 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            139 pgs backfill_wait
            1 pgs backfilling
            140 pgs stuck unclean
            Difference in osd space utilization 40.2597% greater than 40%
            recovery 166495/898948 objects misplaced (18.521%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6627: 10 osds: 10 up, 10 in; 140 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78336: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            166495/898948 objects misplaced (18.521%)
                2932 active+clean
                 139 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:13:35,265 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:13:35,265 INFO cluster.py [line:239] usefull PG number is 2932
2017-06-09 08:14:35,273 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-09 08:14:35,273 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:14:36,230 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            134 pgs backfill_wait
            1 pgs backfilling
            135 pgs stuck unclean
            recovery 163339/897218 objects misplaced (18.205%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6636: 10 osds: 10 up, 10 in; 135 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78386: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            163339/897218 objects misplaced (18.205%)
                2937 active+clean
                 134 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 151 MB/s, 40 objects/s
stdin: is not a tty

2017-06-09 08:14:36,231 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:14:36,231 INFO cluster.py [line:239] usefull PG number is 2937
2017-06-09 08:15:36,238 INFO cluster.py [line:247] cost 61 seconds, left 5455 seconds when check the ceph status
2017-06-09 08:15:36,239 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:15:36,653 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            133 pgs backfill_wait
            1 pgs backfilling
            134 pgs stuck unclean
            recovery 161816/896458 objects misplaced (18.051%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6638: 10 osds: 10 up, 10 in; 134 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78430: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            161816/896458 objects misplaced (18.051%)
                2938 active+clean
                 133 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:15:36,653 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:15:36,653 INFO cluster.py [line:239] usefull PG number is 2938
2017-06-09 08:16:36,713 INFO cluster.py [line:247] cost 60 seconds, left 5395 seconds when check the ceph status
2017-06-09 08:16:36,713 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:16:37,126 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            131 pgs backfill_wait
            1 pgs backfilling
            132 pgs stuck unclean
            recovery 157455/894207 objects misplaced (17.608%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6642: 10 osds: 10 up, 10 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78474: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4156 GB / 6992 GB avail
            157455/894207 objects misplaced (17.608%)
                2940 active+clean
                 131 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 27477 B/s rd, 40 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:16:37,126 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:16:37,126 INFO cluster.py [line:239] usefull PG number is 2940
2017-06-09 08:17:37,147 INFO cluster.py [line:247] cost 61 seconds, left 5334 seconds when check the ceph status
2017-06-09 08:17:37,147 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:17:37,669 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            130 pgs backfill_wait
            1 pgs backfilling
            131 pgs stuck unclean
            recovery 155630/893428 objects misplaced (17.419%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6644: 10 osds: 10 up, 10 in; 131 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78521: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            155630/893428 objects misplaced (17.419%)
                2941 active+clean
                 130 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 231 MB/s, 62 objects/s
  client io 6358 kB/s rd, 9510 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:17:37,670 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:17:37,670 INFO cluster.py [line:239] usefull PG number is 2941
2017-06-09 08:18:37,722 INFO cluster.py [line:247] cost 60 seconds, left 5274 seconds when check the ceph status
2017-06-09 08:18:37,723 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:18:38,144 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            125 pgs backfill_wait
            1 pgs backfilling
            126 pgs stuck unclean
            recovery 152760/891795 objects misplaced (17.129%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6654: 10 osds: 10 up, 10 in; 126 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78573: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
            152760/891795 objects misplaced (17.129%)
                2946 active+clean
                 125 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 150 MB/s, 39 objects/s
  client io 142 kB/s rd, 179 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:18:38,144 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:18:38,144 INFO cluster.py [line:239] usefull PG number is 2946
2017-06-09 08:19:38,198 INFO cluster.py [line:247] cost 61 seconds, left 5213 seconds when check the ceph status
2017-06-09 08:19:38,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:19:38,601 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            124 pgs backfill_wait
            1 pgs backfilling
            125 pgs stuck unclean
            recovery 151195/891004 objects misplaced (16.969%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6656: 10 osds: 10 up, 10 in; 125 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78616: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            151195/891004 objects misplaced (16.969%)
                2947 active+clean
                 124 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 100 kB/s rd, 126 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:19:38,601 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:19:38,602 INFO cluster.py [line:239] usefull PG number is 2947
2017-06-09 08:20:38,613 INFO cluster.py [line:247] cost 60 seconds, left 5153 seconds when check the ceph status
2017-06-09 08:20:38,614 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:20:39,023 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            123 pgs backfill_wait
            1 pgs backfilling
            124 pgs stuck unclean
            recovery 149587/890235 objects misplaced (16.803%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6658: 10 osds: 10 up, 10 in; 124 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78665: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
            149587/890235 objects misplaced (16.803%)
                2948 active+clean
                 123 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 227 MB/s, 60 objects/s
  client io 110 kB/s rd, 139 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:20:39,024 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:20:39,024 INFO cluster.py [line:239] usefull PG number is 2948
2017-06-09 08:21:39,084 INFO cluster.py [line:247] cost 61 seconds, left 5092 seconds when check the ceph status
2017-06-09 08:21:39,084 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:21:39,501 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            120 pgs backfill_wait
            122 pgs stuck unclean
            recovery 147852/889373 objects misplaced (16.624%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6665: 10 osds: 10 up, 10 in; 120 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78711: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
            147852/889373 objects misplaced (16.624%)
                2950 active+clean
                 120 active+remapped+backfill_wait
                   2 active+remapped
recovery io 189 MB/s, 47 objects/s
stdin: is not a tty

2017-06-09 08:21:39,502 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:21:39,502 INFO cluster.py [line:239] usefull PG number is 2950
2017-06-09 08:22:39,537 INFO cluster.py [line:247] cost 60 seconds, left 5032 seconds when check the ceph status
2017-06-09 08:22:39,537 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:22:39,923 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            118 pgs backfill_wait
            1 pgs backfilling
            119 pgs stuck unclean
            recovery 143564/887795 objects misplaced (16.171%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6668: 10 osds: 10 up, 10 in; 119 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78754: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            143564/887795 objects misplaced (16.171%)
                2953 active+clean
                 118 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 56647 B/s rd, 62 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:22:39,923 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:22:39,923 INFO cluster.py [line:239] usefull PG number is 2953
2017-06-09 08:23:39,947 INFO cluster.py [line:247] cost 60 seconds, left 4972 seconds when check the ceph status
2017-06-09 08:23:39,947 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:23:40,450 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            117 pgs backfill_wait
            1 pgs backfilling
            118 pgs stuck unclean
            recovery 140878/886225 objects misplaced (15.896%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6671: 10 osds: 10 up, 10 in; 117 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78804: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            140878/886225 objects misplaced (15.896%)
                2954 active+clean
                 117 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 38023 B/s rd, 55 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:23:40,450 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:23:40,450 INFO cluster.py [line:239] usefull PG number is 2954
2017-06-09 08:24:40,511 INFO cluster.py [line:247] cost 61 seconds, left 4911 seconds when check the ceph status
2017-06-09 08:24:40,511 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:24:40,911 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            116 pgs backfill_wait
            1 pgs backfilling
            117 pgs stuck unclean
            recovery 139329/885433 objects misplaced (15.736%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6672: 10 osds: 10 up, 10 in; 117 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78844: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            139329/885433 objects misplaced (15.736%)
                2955 active+clean
                 116 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 42526 B/s rd, 46 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:24:40,912 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:24:40,912 INFO cluster.py [line:239] usefull PG number is 2955
2017-06-09 08:25:40,921 INFO cluster.py [line:247] cost 60 seconds, left 4851 seconds when check the ceph status
2017-06-09 08:25:40,922 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:25:41,362 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            113 pgs backfill_wait
            1 pgs backfilling
            114 pgs stuck unclean
            recovery 137403/884466 objects misplaced (15.535%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6678: 10 osds: 10 up, 10 in; 113 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78893: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            137403/884466 objects misplaced (15.535%)
                2958 active+clean
                 113 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 91494 B/s rd, 134 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:25:41,362 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:25:41,363 INFO cluster.py [line:239] usefull PG number is 2958
2017-06-09 08:26:41,423 INFO cluster.py [line:247] cost 61 seconds, left 4790 seconds when check the ceph status
2017-06-09 08:26:41,423 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:26:41,813 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            109 pgs backfill_wait
            2 pgs backfilling
            111 pgs stuck unclean
            recovery 134916/882881 objects misplaced (15.281%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6683: 10 osds: 10 up, 10 in; 110 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78937: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4156 GB / 6992 GB avail
            134916/882881 objects misplaced (15.281%)
                2961 active+clean
                 109 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 99693 kB/s, 25 objects/s
  client io 112 kB/s rd, 169 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:26:41,813 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:26:41,814 INFO cluster.py [line:239] usefull PG number is 2961
2017-06-09 08:27:41,866 INFO cluster.py [line:247] cost 60 seconds, left 4730 seconds when check the ceph status
2017-06-09 08:27:41,866 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:27:42,254 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            108 pgs backfill_wait
            1 pgs backfilling
            109 pgs stuck unclean
            recovery 133301/882057 objects misplaced (15.113%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6687: 10 osds: 10 up, 10 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78981: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            133301/882057 objects misplaced (15.113%)
                2963 active+clean
                 108 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 103 kB/s rd, 155 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:27:42,254 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:27:42,254 INFO cluster.py [line:239] usefull PG number is 2963
2017-06-09 08:28:42,262 INFO cluster.py [line:247] cost 61 seconds, left 4669 seconds when check the ceph status
2017-06-09 08:28:42,262 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:28:42,670 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            106 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            107 pgs stuck unclean
            recovery 131611/881213 objects misplaced (14.935%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6690: 10 osds: 10 up, 10 in; 106 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79021: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            131611/881213 objects misplaced (14.935%)
                2964 active+clean
                 106 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 182 MB/s, 49 objects/s
  client io 70914 B/s rd, 103 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:28:42,670 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:28:42,670 INFO cluster.py [line:239] usefull PG number is 2964
2017-06-09 08:29:42,720 INFO cluster.py [line:247] cost 60 seconds, left 4609 seconds when check the ceph status
2017-06-09 08:29:42,720 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:29:43,133 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            104 pgs backfill_wait
            1 pgs backfilling
            105 pgs stuck unclean
            recovery 129961/880395 objects misplaced (14.762%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6692: 10 osds: 10 up, 10 in; 105 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79062: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            129961/880395 objects misplaced (14.762%)
                2967 active+clean
                 104 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 149 MB/s, 40 objects/s
  client io 107 kB/s rd, 135 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:29:43,133 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:29:43,133 INFO cluster.py [line:239] usefull PG number is 2967
2017-06-09 08:30:43,148 INFO cluster.py [line:247] cost 61 seconds, left 4548 seconds when check the ceph status
2017-06-09 08:30:43,148 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:30:43,584 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            103 pgs backfill_wait
            1 pgs backfilling
            104 pgs stuck unclean
            recovery 128304/879618 objects misplaced (14.586%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6694: 10 osds: 10 up, 10 in; 104 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79102: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
            128304/879618 objects misplaced (14.586%)
                2968 active+clean
                 103 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 221 MB/s, 59 objects/s
  client io 47153 B/s rd, 46 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:30:43,585 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:30:43,585 INFO cluster.py [line:239] usefull PG number is 2968
2017-06-09 08:31:43,594 INFO cluster.py [line:247] cost 60 seconds, left 4488 seconds when check the ceph status
2017-06-09 08:31:43,594 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:31:43,992 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            100 pgs backfill_wait
            1 pgs backfilling
            101 pgs stuck unclean
            recovery 126713/878787 objects misplaced (14.419%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6699: 10 osds: 10 up, 10 in; 101 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79151: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
            126713/878787 objects misplaced (14.419%)
                2971 active+clean
                 100 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 202 MB/s, 54 objects/s
  client io 149 kB/s rd, 193 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:31:43,992 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:31:43,992 INFO cluster.py [line:239] usefull PG number is 2971
2017-06-09 08:32:44,012 INFO cluster.py [line:247] cost 61 seconds, left 4427 seconds when check the ceph status
2017-06-09 08:32:44,013 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:32:44,414 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            99 pgs backfill_wait
            1 pgs backfilling
            100 pgs stuck unclean
            recovery 125114/877967 objects misplaced (14.250%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6703: 10 osds: 10 up, 10 in; 99 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79189: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            125114/877967 objects misplaced (14.250%)
                2972 active+clean
                  99 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:32:44,414 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:32:44,414 INFO cluster.py [line:239] usefull PG number is 2972
2017-06-09 08:33:44,430 INFO cluster.py [line:247] cost 60 seconds, left 4367 seconds when check the ceph status
2017-06-09 08:33:44,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:33:44,820 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            97 pgs backfill_wait
            1 pgs backfilling
            98 pgs stuck unclean
            recovery 123519/877175 objects misplaced (14.081%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6705: 10 osds: 10 up, 10 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79228: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            123519/877175 objects misplaced (14.081%)
                2974 active+clean
                  97 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:33:44,820 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:33:44,821 INFO cluster.py [line:239] usefull PG number is 2974
2017-06-09 08:34:44,866 INFO cluster.py [line:247] cost 60 seconds, left 4307 seconds when check the ceph status
2017-06-09 08:34:44,866 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:34:45,231 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            97 pgs stuck unclean
            recovery 121918/876442 objects misplaced (13.911%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6707: 10 osds: 10 up, 10 in; 97 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79265: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4156 GB / 6992 GB avail
            121918/876442 objects misplaced (13.911%)
                2975 active+clean
                  96 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 221 MB/s, 59 objects/s
stdin: is not a tty

2017-06-09 08:34:45,231 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:34:45,231 INFO cluster.py [line:239] usefull PG number is 2975
2017-06-09 08:35:45,254 INFO cluster.py [line:247] cost 61 seconds, left 4246 seconds when check the ceph status
2017-06-09 08:35:45,254 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:35:45,660 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            95 pgs backfill_wait
            1 pgs backfilling
            96 pgs stuck unclean
            recovery 120390/875720 objects misplaced (13.748%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6709: 10 osds: 10 up, 10 in; 96 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79310: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            120390/875720 objects misplaced (13.748%)
                2976 active+clean
                  95 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 231 MB/s, 62 objects/s
  client io 105 kB/s rd, 138 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:35:45,661 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:35:45,661 INFO cluster.py [line:239] usefull PG number is 2976
2017-06-09 08:36:45,721 INFO cluster.py [line:247] cost 60 seconds, left 4186 seconds when check the ceph status
2017-06-09 08:36:45,722 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:36:46,125 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            93 pgs backfill_wait
            1 pgs backfilling
            94 pgs stuck unclean
            recovery 118713/874905 objects misplaced (13.569%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6713: 10 osds: 10 up, 10 in; 94 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79351: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            118713/874905 objects misplaced (13.569%)
                2978 active+clean
                  93 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 97831 kB/s, 25 objects/s
  client io 73230 B/s rd, 96 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:36:46,126 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:36:46,126 INFO cluster.py [line:239] usefull PG number is 2978
2017-06-09 08:37:46,153 INFO cluster.py [line:247] cost 61 seconds, left 4125 seconds when check the ceph status
2017-06-09 08:37:46,153 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:37:46,575 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            92 pgs backfill_wait
            1 pgs backfilling
            93 pgs stuck unclean
            recovery 117189/874167 objects misplaced (13.406%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6715: 10 osds: 10 up, 10 in; 93 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79392: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            117189/874167 objects misplaced (13.406%)
                2979 active+clean
                  92 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 89221 B/s rd, 130 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:37:46,575 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:37:46,575 INFO cluster.py [line:239] usefull PG number is 2979
2017-06-09 08:38:46,628 INFO cluster.py [line:247] cost 60 seconds, left 4065 seconds when check the ceph status
2017-06-09 08:38:46,629 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:38:47,043 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            91 pgs backfill_wait
            1 pgs backfilling
            92 pgs stuck unclean
            recovery 115620/873402 objects misplaced (13.238%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6717: 10 osds: 10 up, 10 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79434: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            115620/873402 objects misplaced (13.238%)
                2980 active+clean
                  91 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 50466 B/s rd, 73 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:38:47,043 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:38:47,043 INFO cluster.py [line:239] usefull PG number is 2980
2017-06-09 08:39:47,061 INFO cluster.py [line:247] cost 61 seconds, left 4004 seconds when check the ceph status
2017-06-09 08:39:47,061 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:39:47,461 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            90 pgs backfill_wait
            1 pgs backfilling
            91 pgs stuck unclean
            recovery 114007/872676 objects misplaced (13.064%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6719: 10 osds: 10 up, 10 in; 91 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79470: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            114007/872676 objects misplaced (13.064%)
                2981 active+clean
                  90 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 29 objects/s
  client io 63626 B/s rd, 79 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:39:47,461 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:39:47,461 INFO cluster.py [line:239] usefull PG number is 2981
2017-06-09 08:40:47,521 INFO cluster.py [line:247] cost 60 seconds, left 3944 seconds when check the ceph status
2017-06-09 08:40:47,522 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:40:47,921 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            87 pgs backfill_wait
            1 pgs backfilling
            88 pgs stuck unclean
            recovery 112167/871746 objects misplaced (12.867%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6725: 10 osds: 10 up, 10 in; 88 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79514: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            112167/871746 objects misplaced (12.867%)
                2984 active+clean
                  87 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 226 MB/s, 61 objects/s
  client io 113 kB/s rd, 147 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:40:47,921 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:40:47,921 INFO cluster.py [line:239] usefull PG number is 2984
2017-06-09 08:41:47,954 INFO cluster.py [line:247] cost 60 seconds, left 3884 seconds when check the ceph status
2017-06-09 08:41:47,955 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:41:48,377 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            86 pgs backfill_wait
            1 pgs backfilling
            87 pgs stuck unclean
            recovery 110585/870963 objects misplaced (12.697%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6727: 10 osds: 10 up, 10 in; 87 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79554: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            110585/870963 objects misplaced (12.697%)
                2985 active+clean
                  86 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 94243 B/s rd, 117 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:41:48,377 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:41:48,377 INFO cluster.py [line:239] usefull PG number is 2985
2017-06-09 08:42:48,438 INFO cluster.py [line:247] cost 61 seconds, left 3823 seconds when check the ceph status
2017-06-09 08:42:48,438 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:42:48,850 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            85 pgs backfill_wait
            1 pgs backfilling
            86 pgs stuck unclean
            recovery 108978/870173 objects misplaced (12.524%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6729: 10 osds: 10 up, 10 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79596: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            108978/870173 objects misplaced (12.524%)
                2986 active+clean
                  85 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 106 kB/s rd, 136 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:42:48,850 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:42:48,850 INFO cluster.py [line:239] usefull PG number is 2986
2017-06-09 08:43:48,866 INFO cluster.py [line:247] cost 60 seconds, left 3763 seconds when check the ceph status
2017-06-09 08:43:48,866 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:43:49,268 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            84 pgs backfill_wait
            1 pgs backfilling
            85 pgs stuck unclean
            recovery 107358/869415 objects misplaced (12.348%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6731: 10 osds: 10 up, 10 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79635: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            107358/869415 objects misplaced (12.348%)
                2987 active+clean
                  84 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 118 MB/s, 31 objects/s
  client io 71395 B/s rd, 89 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:43:49,268 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:43:49,268 INFO cluster.py [line:239] usefull PG number is 2987
2017-06-09 08:44:49,328 INFO cluster.py [line:247] cost 61 seconds, left 3702 seconds when check the ceph status
2017-06-09 08:44:49,329 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:44:49,802 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            82 pgs backfill_wait
            2 pgs backfilling
            84 pgs stuck unclean
            recovery 105768/868661 objects misplaced (12.176%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6735: 10 osds: 10 up, 10 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79676: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            105768/868661 objects misplaced (12.176%)
                2988 active+clean
                  82 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 84843 kB/s, 22 objects/s
stdin: is not a tty

2017-06-09 08:44:49,802 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:44:49,802 INFO cluster.py [line:239] usefull PG number is 2988
2017-06-09 08:45:49,843 INFO cluster.py [line:247] cost 60 seconds, left 3642 seconds when check the ceph status
2017-06-09 08:45:49,843 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:45:50,295 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            82 pgs backfill_wait
            82 pgs stuck unclean
            recovery 103418/867111 objects misplaced (11.927%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6737: 10 osds: 10 up, 10 in; 82 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79725: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            103418/867111 objects misplaced (11.927%)
                2990 active+clean
                  82 active+remapped+backfill_wait
recovery io 130 MB/s, 35 objects/s
stdin: is not a tty

2017-06-09 08:45:50,296 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:45:50,296 INFO cluster.py [line:239] usefull PG number is 2990
2017-06-09 08:46:50,355 INFO cluster.py [line:247] cost 61 seconds, left 3581 seconds when check the ceph status
2017-06-09 08:46:50,355 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:46:50,780 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            80 pgs backfill_wait
            1 pgs backfilling
            81 pgs stuck unclean
            recovery 101867/866357 objects misplaced (11.758%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6739: 10 osds: 10 up, 10 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79764: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            101867/866357 objects misplaced (11.758%)
                2991 active+clean
                  80 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:46:50,780 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:46:50,780 INFO cluster.py [line:239] usefull PG number is 2991
2017-06-09 08:47:50,840 INFO cluster.py [line:247] cost 60 seconds, left 3521 seconds when check the ceph status
2017-06-09 08:47:50,841 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:47:51,259 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            79 pgs backfill_wait
            1 pgs backfilling
            80 pgs stuck unclean
            recovery 99910/865582 objects misplaced (11.543%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6741: 10 osds: 10 up, 10 in; 80 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79804: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            99910/865582 objects misplaced (11.543%)
                2992 active+clean
                  79 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 846 MB/s, 233 objects/s
stdin: is not a tty

2017-06-09 08:47:51,260 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:47:51,260 INFO cluster.py [line:239] usefull PG number is 2992
2017-06-09 08:48:51,284 INFO cluster.py [line:247] cost 61 seconds, left 3460 seconds when check the ceph status
2017-06-09 08:48:51,284 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:48:51,703 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            78 pgs backfill_wait
            1 pgs backfilling
            79 pgs stuck unclean
            recovery 96715/864038 objects misplaced (11.193%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6743: 10 osds: 10 up, 10 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79847: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            96715/864038 objects misplaced (11.193%)
                2993 active+clean
                  78 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 150 MB/s, 40 objects/s
  client io 66148 B/s rd, 96 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:48:51,703 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:48:51,703 INFO cluster.py [line:239] usefull PG number is 2993
2017-06-09 08:49:51,764 INFO cluster.py [line:247] cost 60 seconds, left 3400 seconds when check the ceph status
2017-06-09 08:49:51,764 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:49:52,158 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            77 pgs backfill_wait
            1 pgs backfilling
            78 pgs stuck unclean
            recovery 95144/863261 objects misplaced (11.021%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6745: 10 osds: 10 up, 10 in; 78 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79884: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            95144/863261 objects misplaced (11.021%)
                2994 active+clean
                  77 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 44659 B/s rd, 65 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:49:52,159 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:49:52,159 INFO cluster.py [line:239] usefull PG number is 2994
2017-06-09 08:50:52,211 INFO cluster.py [line:247] cost 61 seconds, left 3339 seconds when check the ceph status
2017-06-09 08:50:52,211 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:50:52,599 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            75 pgs backfill_wait
            1 pgs backfilling
            76 pgs stuck unclean
            recovery 93509/862464 objects misplaced (10.842%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6749: 10 osds: 10 up, 10 in; 76 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79932: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            93509/862464 objects misplaced (10.842%)
                2996 active+clean
                  75 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 90591 B/s rd, 114 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:50:52,599 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:50:52,599 INFO cluster.py [line:239] usefull PG number is 2996
2017-06-09 08:51:52,645 INFO cluster.py [line:247] cost 60 seconds, left 3279 seconds when check the ceph status
2017-06-09 08:51:52,645 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:51:53,070 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            73 pgs backfill_wait
            1 pgs backfilling
            74 pgs stuck unclean
            recovery 91840/861605 objects misplaced (10.659%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6753: 10 osds: 10 up, 10 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79975: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            91840/861605 objects misplaced (10.659%)
                2998 active+clean
                  73 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 209 MB/s, 56 objects/s
  client io 97387 B/s rd, 142 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:51:53,070 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:51:53,070 INFO cluster.py [line:239] usefull PG number is 2998
2017-06-09 08:52:53,131 INFO cluster.py [line:247] cost 61 seconds, left 3218 seconds when check the ceph status
2017-06-09 08:52:53,131 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:52:53,543 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            72 pgs backfill_wait
            1 pgs backfilling
            73 pgs stuck unclean
            recovery 90291/860856 objects misplaced (10.489%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6755: 10 osds: 10 up, 10 in; 73 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80010: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            90291/860856 objects misplaced (10.489%)
                2999 active+clean
                  72 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 70946 B/s rd, 103 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:52:53,543 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:52:53,543 INFO cluster.py [line:239] usefull PG number is 2999
2017-06-09 08:53:53,548 INFO cluster.py [line:247] cost 60 seconds, left 3158 seconds when check the ceph status
2017-06-09 08:53:53,548 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:53:53,924 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            67 pgs backfill_wait
            1 pgs backfilling
            68 pgs stuck unclean
            recovery 85681/858370 objects misplaced (9.982%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6765: 10 osds: 10 up, 10 in; 68 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80056: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            85681/858370 objects misplaced (9.982%)
                3004 active+clean
                  67 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 115 MB/s, 30 objects/s
  client io 34425 B/s rd, 50 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 08:53:53,924 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:53:53,924 INFO cluster.py [line:239] usefull PG number is 3004
2017-06-09 08:54:53,953 INFO cluster.py [line:247] cost 60 seconds, left 3098 seconds when check the ceph status
2017-06-09 08:54:53,953 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:54:54,386 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            66 pgs backfill_wait
            1 pgs backfilling
            67 pgs stuck unclean
            recovery 84043/857573 objects misplaced (9.800%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6767: 10 osds: 10 up, 10 in; 67 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80094: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            84043/857573 objects misplaced (9.800%)
                3005 active+clean
                  66 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 234 MB/s, 63 objects/s
stdin: is not a tty

2017-06-09 08:54:54,386 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:54:54,386 INFO cluster.py [line:239] usefull PG number is 3005
2017-06-09 08:55:54,447 INFO cluster.py [line:247] cost 61 seconds, left 3037 seconds when check the ceph status
2017-06-09 08:55:54,447 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:55:54,885 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            65 pgs backfill_wait
            1 pgs backfilling
            66 pgs stuck unclean
            recovery 82466/856808 objects misplaced (9.625%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6769: 10 osds: 10 up, 10 in; 66 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80131: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            82466/856808 objects misplaced (9.625%)
                3006 active+clean
                  65 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 08:55:54,885 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:55:54,885 INFO cluster.py [line:239] usefull PG number is 3006
2017-06-09 08:56:54,918 INFO cluster.py [line:247] cost 60 seconds, left 2977 seconds when check the ceph status
2017-06-09 08:56:54,918 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:56:55,359 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            64 pgs backfill_wait
            1 pgs backfilling
            65 pgs stuck unclean
            recovery 80726/856051 objects misplaced (9.430%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6771: 10 osds: 10 up, 10 in; 65 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80173: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            80726/856051 objects misplaced (9.430%)
                3007 active+clean
                  64 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 196 MB/s, 53 objects/s
stdin: is not a tty

2017-06-09 08:56:55,359 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:56:55,359 INFO cluster.py [line:239] usefull PG number is 3007
2017-06-09 08:57:55,396 INFO cluster.py [line:247] cost 61 seconds, left 2916 seconds when check the ceph status
2017-06-09 08:57:55,396 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:57:55,918 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            59 pgs backfill_wait
            1 pgs backfilling
            60 pgs stuck unclean
            recovery 75836/853488 objects misplaced (8.885%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6779: 10 osds: 10 up, 10 in; 60 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80221: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            75836/853488 objects misplaced (8.885%)
                3012 active+clean
                  59 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 120 MB/s, 32 objects/s
stdin: is not a tty

2017-06-09 08:57:55,918 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:57:55,918 INFO cluster.py [line:239] usefull PG number is 3012
2017-06-09 08:58:55,974 INFO cluster.py [line:247] cost 60 seconds, left 2856 seconds when check the ceph status
2017-06-09 08:58:55,974 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:58:56,386 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            58 pgs backfill_wait
            1 pgs backfilling
            59 pgs stuck unclean
            recovery 74215/852706 objects misplaced (8.703%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6781: 10 osds: 10 up, 10 in; 59 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80261: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            74215/852706 objects misplaced (8.703%)
                3013 active+clean
                  58 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 114 MB/s, 31 objects/s
stdin: is not a tty

2017-06-09 08:58:56,387 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:58:56,387 INFO cluster.py [line:239] usefull PG number is 3013
2017-06-09 08:59:56,420 INFO cluster.py [line:247] cost 61 seconds, left 2795 seconds when check the ceph status
2017-06-09 08:59:56,421 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 08:59:56,798 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            57 pgs backfill_wait
            1 pgs backfilling
            58 pgs stuck unclean
            recovery 72658/851931 objects misplaced (8.529%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6783: 10 osds: 10 up, 10 in; 58 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80300: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            72658/851931 objects misplaced (8.529%)
                3014 active+clean
                  57 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 145 MB/s, 38 objects/s
stdin: is not a tty

2017-06-09 08:59:56,798 INFO cluster.py [line:238] PG number is 3072
2017-06-09 08:59:56,798 INFO cluster.py [line:239] usefull PG number is 3014
2017-06-09 09:00:56,812 INFO cluster.py [line:247] cost 60 seconds, left 2735 seconds when check the ceph status
2017-06-09 09:00:56,813 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:00:57,182 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            56 pgs backfill_wait
            1 pgs backfilling
            57 pgs stuck unclean
            recovery 71085/851123 objects misplaced (8.352%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6785: 10 osds: 10 up, 10 in; 57 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80343: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            71085/851123 objects misplaced (8.352%)
                3015 active+clean
                  56 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 13975 B/s rd, 20 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:00:57,182 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:00:57,182 INFO cluster.py [line:239] usefull PG number is 3015
2017-06-09 09:01:57,223 INFO cluster.py [line:247] cost 61 seconds, left 2674 seconds when check the ceph status
2017-06-09 09:01:57,223 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:01:57,598 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            55 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 68830/850294 objects misplaced (8.095%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6787: 10 osds: 10 up, 10 in; 56 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80383: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4153 GB / 6992 GB avail
            68830/850294 objects misplaced (8.095%)
                3016 active+clean
                  55 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 215 MB/s, 59 objects/s
  client io 45134 B/s rd, 50 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:01:57,598 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:01:57,598 INFO cluster.py [line:239] usefull PG number is 3016
2017-06-09 09:02:57,639 INFO cluster.py [line:247] cost 60 seconds, left 2614 seconds when check the ceph status
2017-06-09 09:02:57,639 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:02:58,037 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            53 pgs backfill_wait
            1 pgs backfilling
            54 pgs stuck unclean
            recovery 66074/848710 objects misplaced (7.785%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6791: 10 osds: 10 up, 10 in; 54 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80422: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            66074/848710 objects misplaced (7.785%)
                3018 active+clean
                  53 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 99654 kB/s, 26 objects/s
  client io 68242 B/s rd, 86 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:02:58,037 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:02:58,037 INFO cluster.py [line:239] usefull PG number is 3018
2017-06-09 09:03:58,098 INFO cluster.py [line:247] cost 61 seconds, left 2553 seconds when check the ceph status
2017-06-09 09:03:58,098 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:03:58,507 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            49 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 64286/847740 objects misplaced (7.583%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6799: 10 osds: 10 up, 10 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80468: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            64286/847740 objects misplaced (7.583%)
                3022 active+clean
                  49 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 219 MB/s, 58 objects/s
  client io 108 kB/s rd, 137 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:03:58,508 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:03:58,508 INFO cluster.py [line:239] usefull PG number is 3022
2017-06-09 09:04:58,511 INFO cluster.py [line:247] cost 60 seconds, left 2493 seconds when check the ceph status
2017-06-09 09:04:58,511 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:04:58,906 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            48 pgs backfill_wait
            1 pgs backfilling
            49 pgs stuck unclean
            recovery 62757/846976 objects misplaced (7.410%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6801: 10 osds: 10 up, 10 in; 49 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80505: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            62757/846976 objects misplaced (7.410%)
                3023 active+clean
                  48 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 226 MB/s, 61 objects/s
  client io 147 kB/s rd, 188 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:04:58,906 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:04:58,906 INFO cluster.py [line:239] usefull PG number is 3023
2017-06-09 09:05:58,938 INFO cluster.py [line:247] cost 60 seconds, left 2433 seconds when check the ceph status
2017-06-09 09:05:58,938 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:05:59,433 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            47 pgs backfill_wait
            1 pgs backfilling
            48 pgs stuck unclean
            recovery 61113/846190 objects misplaced (7.222%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6803: 10 osds: 10 up, 10 in; 48 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80550: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            61113/846190 objects misplaced (7.222%)
                3024 active+clean
                  47 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 218 MB/s, 58 objects/s
  client io 68934 B/s rd, 67 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:05:59,434 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:05:59,434 INFO cluster.py [line:239] usefull PG number is 3024
2017-06-09 09:06:59,439 INFO cluster.py [line:247] cost 61 seconds, left 2372 seconds when check the ceph status
2017-06-09 09:06:59,440 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:06:59,953 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            45 pgs backfill_wait
            1 pgs backfilling
            46 pgs stuck unclean
            recovery 56921/843962 objects misplaced (6.744%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6807: 10 osds: 10 up, 10 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80594: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            56921/843962 objects misplaced (6.744%)
                3026 active+clean
                  45 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 239 MB/s, 64 objects/s
  client io 165 kB/s rd, 212 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:06:59,953 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:06:59,953 INFO cluster.py [line:239] usefull PG number is 3026
2017-06-09 09:07:59,954 INFO cluster.py [line:247] cost 60 seconds, left 2312 seconds when check the ceph status
2017-06-09 09:07:59,954 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:08:00,335 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            44 pgs backfill_wait
            1 pgs backfilling
            45 pgs stuck unclean
            recovery 55275/843181 objects misplaced (6.556%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6809: 10 osds: 10 up, 10 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80635: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            55275/843181 objects misplaced (6.556%)
                3027 active+clean
                  44 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 142 MB/s, 38 objects/s
  client io 43007 B/s rd, 41 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:08:00,335 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:08:00,335 INFO cluster.py [line:239] usefull PG number is 3027
2017-06-09 09:09:00,395 INFO cluster.py [line:247] cost 61 seconds, left 2251 seconds when check the ceph status
2017-06-09 09:09:00,396 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:09:00,785 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            44 pgs stuck unclean
            recovery 53729/842408 objects misplaced (6.378%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6811: 10 osds: 10 up, 10 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80674: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            53729/842408 objects misplaced (6.378%)
                3028 active+clean
                  43 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 162 MB/s, 43 objects/s
  client io 42847 B/s rd, 42 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:09:00,785 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:09:00,785 INFO cluster.py [line:239] usefull PG number is 3028
2017-06-09 09:10:00,845 INFO cluster.py [line:247] cost 60 seconds, left 2191 seconds when check the ceph status
2017-06-09 09:10:00,846 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:10:01,278 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            42 pgs backfill_wait
            1 pgs backfilling
            43 pgs stuck unclean
            recovery 52203/841646 objects misplaced (6.202%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6813: 10 osds: 10 up, 10 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80718: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            52203/841646 objects misplaced (6.202%)
                3029 active+clean
                  42 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 148 MB/s, 39 objects/s
  client io 40421 B/s rd, 39 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:10:01,279 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:10:01,279 INFO cluster.py [line:239] usefull PG number is 3029
2017-06-09 09:11:01,339 INFO cluster.py [line:247] cost 61 seconds, left 2130 seconds when check the ceph status
2017-06-09 09:11:01,339 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:11:01,741 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            41 pgs backfill_wait
            1 pgs backfilling
            42 pgs stuck unclean
            recovery 50549/840880 objects misplaced (6.011%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6815: 10 osds: 10 up, 10 in; 42 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80758: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            50549/840880 objects misplaced (6.011%)
                3030 active+clean
                  41 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 155 MB/s, 41 objects/s
  client io 73077 B/s rd, 107 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:11:01,742 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:11:01,742 INFO cluster.py [line:239] usefull PG number is 3030
2017-06-09 09:12:01,781 INFO cluster.py [line:247] cost 60 seconds, left 2070 seconds when check the ceph status
2017-06-09 09:12:01,782 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:12:02,182 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            40 pgs backfill_wait
            1 pgs backfilling
            41 pgs stuck unclean
            recovery 49005/840125 objects misplaced (5.833%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6817: 10 osds: 10 up, 10 in; 41 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80799: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            49005/840125 objects misplaced (5.833%)
                3031 active+clean
                  40 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 97384 B/s rd, 142 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:12:02,182 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:12:02,182 INFO cluster.py [line:239] usefull PG number is 3031
2017-06-09 09:13:02,217 INFO cluster.py [line:247] cost 61 seconds, left 2009 seconds when check the ceph status
2017-06-09 09:13:02,217 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:13:02,685 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            39 pgs backfill_wait
            1 pgs backfilling
            40 pgs stuck unclean
            recovery 47307/839394 objects misplaced (5.636%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6819: 10 osds: 10 up, 10 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80843: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            47307/839394 objects misplaced (5.636%)
                3032 active+clean
                  39 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 294 MB/s, 79 objects/s
  client io 156 kB/s rd, 200 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:13:02,685 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:13:02,686 INFO cluster.py [line:239] usefull PG number is 3032
2017-06-09 09:14:02,746 INFO cluster.py [line:247] cost 60 seconds, left 1949 seconds when check the ceph status
2017-06-09 09:14:02,746 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:14:03,169 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            38 pgs backfill_wait
            1 pgs peering
            38 pgs stuck unclean
            recovery 45020/837912 objects misplaced (5.373%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6823: 10 osds: 10 up, 10 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80882: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            45020/837912 objects misplaced (5.373%)
                3033 active+clean
                  38 active+remapped+backfill_wait
                   1 peering
recovery io 380 MB/s, 102 objects/s
  client io 158 kB/s rd, 237 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:14:03,169 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:14:03,170 INFO cluster.py [line:239] usefull PG number is 3033
2017-06-09 09:15:03,198 INFO cluster.py [line:247] cost 61 seconds, left 1888 seconds when check the ceph status
2017-06-09 09:15:03,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:15:03,588 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            36 pgs backfill_wait
            1 pgs backfilling
            37 pgs stuck unclean
            recovery 43445/837134 objects misplaced (5.190%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6825: 10 osds: 10 up, 10 in; 37 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80921: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            43445/837134 objects misplaced (5.190%)
                3035 active+clean
                  36 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 130 kB/s rd, 165 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:15:03,588 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:15:03,588 INFO cluster.py [line:239] usefull PG number is 3035
2017-06-09 09:16:03,630 INFO cluster.py [line:247] cost 60 seconds, left 1828 seconds when check the ceph status
2017-06-09 09:16:03,630 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:16:04,042 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            35 pgs backfill_wait
            1 pgs backfilling
            36 pgs stuck unclean
            recovery 41803/836345 objects misplaced (4.998%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6827: 10 osds: 10 up, 10 in; 36 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80965: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            41803/836345 objects misplaced (4.998%)
                3036 active+clean
                  35 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 283 MB/s, 76 objects/s
  client io 151 kB/s rd, 198 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:16:04,043 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:16:04,043 INFO cluster.py [line:239] usefull PG number is 3036
2017-06-09 09:17:04,096 INFO cluster.py [line:247] cost 61 seconds, left 1767 seconds when check the ceph status
2017-06-09 09:17:04,096 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:17:04,576 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            34 pgs backfill_wait
            1 pgs backfilling
            35 pgs stuck unclean
            recovery 39178/835538 objects misplaced (4.689%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6829: 10 osds: 10 up, 10 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81010: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2839 GB used, 4152 GB / 6992 GB avail
            39178/835538 objects misplaced (4.689%)
                3037 active+clean
                  34 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 41743 B/s rd, 40 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:17:04,577 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:17:04,577 INFO cluster.py [line:239] usefull PG number is 3037
2017-06-09 09:18:04,637 INFO cluster.py [line:247] cost 60 seconds, left 1707 seconds when check the ceph status
2017-06-09 09:18:04,637 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:18:05,019 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            33 pgs backfill_wait
            1 pgs backfilling
            34 pgs stuck unclean
            recovery 36395/833934 objects misplaced (4.364%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6831: 10 osds: 10 up, 10 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81058: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            36395/833934 objects misplaced (4.364%)
                3038 active+clean
                  33 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 232 MB/s, 62 objects/s
  client io 60892 B/s rd, 59 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:18:05,019 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:18:05,019 INFO cluster.py [line:239] usefull PG number is 3038
2017-06-09 09:19:05,045 INFO cluster.py [line:247] cost 61 seconds, left 1646 seconds when check the ceph status
2017-06-09 09:19:05,045 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:19:05,452 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            32 pgs backfill_wait
            1 pgs backfilling
            33 pgs stuck unclean
            recovery 34814/833127 objects misplaced (4.179%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6833: 10 osds: 10 up, 10 in; 33 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81099: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            34814/833127 objects misplaced (4.179%)
                3039 active+clean
                  32 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 222 MB/s, 59 objects/s
  client io 144 kB/s rd, 189 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:19:05,452 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:19:05,453 INFO cluster.py [line:239] usefull PG number is 3039
2017-06-09 09:20:05,513 INFO cluster.py [line:247] cost 60 seconds, left 1586 seconds when check the ceph status
2017-06-09 09:20:05,513 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:20:05,906 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            31 pgs backfill_wait
            1 pgs backfilling
            32 pgs stuck unclean
            recovery 33225/832362 objects misplaced (3.992%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6835: 10 osds: 10 up, 10 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81140: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            33225/832362 objects misplaced (3.992%)
                3040 active+clean
                  31 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 31528 B/s rd, 30 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:20:05,907 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:20:05,907 INFO cluster.py [line:239] usefull PG number is 3040
2017-06-09 09:21:05,946 INFO cluster.py [line:247] cost 60 seconds, left 1526 seconds when check the ceph status
2017-06-09 09:21:05,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:21:06,358 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 31542/831538 objects misplaced (3.793%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6837: 10 osds: 10 up, 10 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81178: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            31542/831538 objects misplaced (3.793%)
                3041 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 149 MB/s, 40 objects/s
  client io 32642 B/s rd, 31 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:21:06,358 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:21:06,358 INFO cluster.py [line:239] usefull PG number is 3041
2017-06-09 09:22:06,409 INFO cluster.py [line:247] cost 61 seconds, left 1465 seconds when check the ceph status
2017-06-09 09:22:06,409 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:22:06,823 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            29 pgs backfill_wait
            1 pgs backfilling
            30 pgs stuck unclean
            recovery 29933/830729 objects misplaced (3.603%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6839: 10 osds: 10 up, 10 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81221: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            29933/830729 objects misplaced (3.603%)
                3042 active+clean
                  29 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 148 MB/s, 39 objects/s
  client io 15114 B/s rd, 22 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:22:06,824 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:22:06,824 INFO cluster.py [line:239] usefull PG number is 3042
2017-06-09 09:23:06,884 INFO cluster.py [line:247] cost 60 seconds, left 1405 seconds when check the ceph status
2017-06-09 09:23:06,884 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:23:07,286 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            27 pgs backfill_wait
            1 pgs backfilling
            28 pgs stuck unclean
            recovery 28296/829900 objects misplaced (3.410%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6843: 10 osds: 10 up, 10 in; 28 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81272: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            28296/829900 objects misplaced (3.410%)
                3044 active+clean
                  27 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 102248 B/s rd, 149 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:23:07,300 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:23:07,300 INFO cluster.py [line:239] usefull PG number is 3044
2017-06-09 09:24:07,350 INFO cluster.py [line:247] cost 61 seconds, left 1344 seconds when check the ceph status
2017-06-09 09:24:07,350 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:24:07,714 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 24038/827458 objects misplaced (2.905%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6850: 10 osds: 10 up, 10 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81323: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            24038/827458 objects misplaced (2.905%)
                3048 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 98616 B/s rd, 144 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:24:07,714 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:24:07,714 INFO cluster.py [line:239] usefull PG number is 3048
2017-06-09 09:25:07,767 INFO cluster.py [line:247] cost 60 seconds, left 1284 seconds when check the ceph status
2017-06-09 09:25:07,768 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:25:08,223 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            22 pgs backfill_wait
            1 pgs backfilling
            23 pgs stuck unclean
            recovery 21872/826703 objects misplaced (2.646%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6852: 10 osds: 10 up, 10 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81374: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4154 GB / 6992 GB avail
            21872/826703 objects misplaced (2.646%)
                3049 active+clean
                  22 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 896 MB/s, 245 objects/s
  client io 63635 B/s rd, 93 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:25:08,223 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:25:08,223 INFO cluster.py [line:239] usefull PG number is 3049
2017-06-09 09:26:08,263 INFO cluster.py [line:247] cost 61 seconds, left 1223 seconds when check the ceph status
2017-06-09 09:26:08,264 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:26:08,675 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            19 pgs backfill_wait
            1 pgs backfilling
            20 pgs stuck unclean
            recovery 16346/823748 objects misplaced (1.984%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6858: 10 osds: 10 up, 10 in; 20 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81429: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            16346/823748 objects misplaced (1.984%)
                3052 active+clean
                  19 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 146 kB/s rd, 184 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:26:08,676 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:26:08,676 INFO cluster.py [line:239] usefull PG number is 3052
2017-06-09 09:27:08,726 INFO cluster.py [line:247] cost 60 seconds, left 1163 seconds when check the ceph status
2017-06-09 09:27:08,727 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:27:09,139 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 14819/823005 objects misplaced (1.801%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6860: 10 osds: 10 up, 10 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81480: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            14819/823005 objects misplaced (1.801%)
                3053 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 115 kB/s rd, 143 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:27:09,139 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:27:09,139 INFO cluster.py [line:239] usefull PG number is 3053
2017-06-09 09:28:09,198 INFO cluster.py [line:247] cost 61 seconds, left 1102 seconds when check the ceph status
2017-06-09 09:28:09,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:28:09,614 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs backfilling
            18 pgs stuck unclean
            recovery 13205/822227 objects misplaced (1.606%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6862: 10 osds: 10 up, 10 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81530: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            13205/822227 objects misplaced (1.606%)
                3054 active+clean
                  17 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 67451 B/s rd, 65 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:28:09,614 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:28:09,614 INFO cluster.py [line:239] usefull PG number is 3054
2017-06-09 09:29:09,675 INFO cluster.py [line:247] cost 60 seconds, left 1042 seconds when check the ceph status
2017-06-09 09:29:09,675 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:29:10,066 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            16 pgs backfill_wait
            1 pgs backfilling
            17 pgs stuck unclean
            recovery 11538/821438 objects misplaced (1.405%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6864: 10 osds: 10 up, 10 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81581: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            11538/821438 objects misplaced (1.405%)
                3055 active+clean
                  16 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 228 MB/s, 61 objects/s
  client io 62990 B/s rd, 61 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:29:10,066 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:29:10,066 INFO cluster.py [line:239] usefull PG number is 3055
2017-06-09 09:30:10,096 INFO cluster.py [line:247] cost 61 seconds, left 981 seconds when check the ceph status
2017-06-09 09:30:10,096 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:30:10,518 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            14 pgs backfill_wait
            1 pgs backfilling
            15 pgs stuck unclean
            recovery 9971/820624 objects misplaced (1.215%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6868: 10 osds: 10 up, 10 in; 15 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81633: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            9971/820624 objects misplaced (1.215%)
                3057 active+clean
                  14 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 52791 B/s rd, 51 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:30:10,518 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:30:10,518 INFO cluster.py [line:239] usefull PG number is 3057
2017-06-09 09:31:10,556 INFO cluster.py [line:247] cost 60 seconds, left 921 seconds when check the ceph status
2017-06-09 09:31:10,556 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:31:10,950 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 8374/819814 objects misplaced (1.021%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6870: 10 osds: 10 up, 10 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81682: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            8374/819814 objects misplaced (1.021%)
                3058 active+clean
                  13 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 74209 B/s rd, 72 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:31:10,951 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:31:10,951 INFO cluster.py [line:239] usefull PG number is 3058
2017-06-09 09:32:10,967 INFO cluster.py [line:247] cost 60 seconds, left 861 seconds when check the ceph status
2017-06-09 09:32:10,967 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:32:11,380 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 6742/819028 objects misplaced (0.823%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6872: 10 osds: 10 up, 10 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81730: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            6742/819028 objects misplaced (0.823%)
                3059 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 57 objects/s
stdin: is not a tty

2017-06-09 09:32:11,380 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:32:11,380 INFO cluster.py [line:239] usefull PG number is 3059
2017-06-09 09:33:11,429 INFO cluster.py [line:247] cost 61 seconds, left 800 seconds when check the ceph status
2017-06-09 09:33:11,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:33:11,861 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            9 pgs stuck unclean
            recovery 4878/818069 objects misplaced (0.596%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6879: 10 osds: 10 up, 10 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81782: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2837 GB used, 4154 GB / 6992 GB avail
            4878/818069 objects misplaced (0.596%)
                3063 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 149 MB/s, 40 objects/s
  client io 110 kB/s rd, 142 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:33:11,861 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:33:11,861 INFO cluster.py [line:239] usefull PG number is 3063
2017-06-09 09:34:11,874 INFO cluster.py [line:247] cost 60 seconds, left 740 seconds when check the ceph status
2017-06-09 09:34:11,874 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:34:12,391 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            3 pgs backfill_wait
            1 pgs backfilling
            4 pgs stuck unclean
            recovery 3005/817043 objects misplaced (0.368%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6887: 10 osds: 10 up, 10 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81835: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2836 GB used, 4155 GB / 6992 GB avail
            3005/817043 objects misplaced (0.368%)
                3068 active+clean
                   3 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 155 MB/s, 42 objects/s
  client io 72130 B/s rd, 105 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:34:12,391 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:34:12,391 INFO cluster.py [line:239] usefull PG number is 3068
2017-06-09 09:35:12,429 INFO cluster.py [line:247] cost 61 seconds, left 679 seconds when check the ceph status
2017-06-09 09:35:12,430 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:35:12,816 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs peering
            1 pgs stuck unclean
            recovery 82/815446 objects misplaced (0.010%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6893: 10 osds: 10 up, 10 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81885: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2838 GB used, 4153 GB / 6992 GB avail
            82/815446 objects misplaced (0.010%)
                3070 active+clean
                   1 active+remapped+backfilling
                   1 peering
recovery io 1288 MB/s, 345 objects/s
  client io 197 kB/s rd, 295 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:35:12,816 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:35:12,816 INFO cluster.py [line:239] usefull PG number is 3070
2017-06-09 09:36:12,857 INFO cluster.py [line:247] cost 60 seconds, left 619 seconds when check the ceph status
2017-06-09 09:36:12,858 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:36:13,250 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6895: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81934: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
                3072 active+clean
  client io 89619 B/s rd, 131 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:36:13,250 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:36:13,250 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 09:36:13,250 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:89] stop in cluster successfully
2017-06-09 09:36:13,251 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-09 09:36:25,444 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 09:36:25,444 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-09 09:36:25,444 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:36:25,838 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/11 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6897: 11 osds: 10 up, 11 in; 1040 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81946: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2835 GB used, 4156 GB / 6992 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-09 09:36:25,838 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:36:25,839 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 09:36:25,839 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-09 09:36:25,839 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme0n1
2017-06-09 09:36:38,148 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 09:36:38,148 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-09 09:36:38,148 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:36:38,570 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            5 pgs backfilling
            24 pgs degraded
            24 pgs recovery_wait
            123 pgs stuck unclean
            Difference in osd space utilization 50.5693% greater than 40%
            recovery 53/980571 objects degraded (0.005%)
            recovery 329606/980571 objects misplaced (33.614%)
            1/12 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6905: 12 osds: 11 up, 12 in; 1083 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v81960: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2847 GB used, 4844 GB / 7691 GB avail
            53/980571 objects degraded (0.005%)
            329606/980571 objects misplaced (33.614%)
                2769 active+clean
                 274 active+remapped+backfill_wait
                  24 active+recovery_wait+degraded
                   5 active+remapped+backfilling
  client io 37538 B/s rd, 54 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:36:38,570 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:36:38,570 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-09 09:37:38,630 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-09 09:37:38,631 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:37:39,045 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            413 pgs backfill_wait
            5 pgs backfilling
            10 pgs degraded
            2 pgs peering
            10 pgs recovery_wait
            201 pgs stuck unclean
            Difference in osd space utilization 50.94% greater than 40%
            recovery 22/1069387 objects degraded (0.002%)
            recovery 505230/1069387 objects misplaced (47.245%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6918: 12 osds: 12 up, 12 in; 417 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82022: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2863 GB used, 5527 GB / 8390 GB avail
            22/1069387 objects degraded (0.002%)
            505230/1069387 objects misplaced (47.245%)
                2642 active+clean
                 413 active+remapped+backfill_wait
                  10 active+recovery_wait+degraded
                   5 active+remapped+backfilling
                   2 peering
recovery io 850 MB/s, 229 objects/s
stdin: is not a tty

2017-06-09 09:37:39,045 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:37:39,045 INFO cluster.py [line:239] usefull PG number is 2642
2017-06-09 09:38:39,101 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-09 09:38:39,101 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:38:39,503 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            399 pgs backfill_wait
            5 pgs backfilling
            3 pgs degraded
            3 pgs recovery_wait
            204 pgs stuck unclean
            Difference in osd space utilization 50.859% greater than 40%
            recovery 6/1062114 objects degraded (0.001%)
            recovery 490888/1062114 objects misplaced (46.218%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6933: 12 osds: 12 up, 12 in; 403 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82085: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2861 GB used, 5529 GB / 8390 GB avail
            6/1062114 objects degraded (0.001%)
            490888/1062114 objects misplaced (46.218%)
                2665 active+clean
                 399 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   3 active+recovery_wait+degraded
recovery io 728 MB/s, 193 objects/s
stdin: is not a tty

2017-06-09 09:38:39,504 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:38:39,504 INFO cluster.py [line:239] usefull PG number is 2665
2017-06-09 09:39:39,519 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-09 09:39:39,519 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:39:39,912 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            386 pgs backfill_wait
            3 pgs backfilling
            197 pgs stuck unclean
            Difference in osd space utilization 50.071% greater than 40%
            recovery 473463/1053147 objects misplaced (44.957%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6955: 12 osds: 12 up, 12 in; 389 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82148: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2865 GB used, 5525 GB / 8390 GB avail
            473463/1053147 objects misplaced (44.957%)
                2682 active+clean
                 386 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 activating
recovery io 529 MB/s, 132 objects/s
stdin: is not a tty

2017-06-09 09:39:39,912 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:39:39,912 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-09 09:40:39,946 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-09 09:40:39,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:40:40,388 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            380 pgs backfill_wait
            3 pgs backfilling
            311 pgs stuck unclean
            Difference in osd space utilization 49.9635% greater than 40%
            recovery 459800/1046920 objects misplaced (43.919%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6968: 12 osds: 12 up, 12 in; 382 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82211: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2864 GB used, 5526 GB / 8390 GB avail
            459800/1046920 objects misplaced (43.919%)
                2689 active+clean
                 380 active+remapped+backfill_wait
                   3 active+remapped+backfilling
stdin: is not a tty

2017-06-09 09:40:40,388 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:40:40,389 INFO cluster.py [line:239] usefull PG number is 2689
2017-06-09 09:41:40,447 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-09 09:41:40,447 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:41:40,844 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            371 pgs backfill_wait
            3 pgs backfilling
            374 pgs stuck unclean
            Difference in osd space utilization 49.9715% greater than 40%
            recovery 446337/1039665 objects misplaced (42.931%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6983: 12 osds: 12 up, 12 in; 374 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82271: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2860 GB used, 5529 GB / 8390 GB avail
            446337/1039665 objects misplaced (42.931%)
                2698 active+clean
                 371 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 697 MB/s, 192 objects/s
stdin: is not a tty

2017-06-09 09:41:40,844 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:41:40,844 INFO cluster.py [line:239] usefull PG number is 2698
2017-06-09 09:42:40,874 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-09 09:42:40,874 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:42:41,290 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            365 pgs backfill_wait
            2 pgs backfilling
            367 pgs stuck unclean
            Difference in osd space utilization 49.9927% greater than 40%
            recovery 435323/1033428 objects misplaced (42.124%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e6995: 12 osds: 12 up, 12 in; 367 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82331: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5535 GB / 8390 GB avail
            435323/1033428 objects misplaced (42.124%)
                2705 active+clean
                 365 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 190 MB/s, 51 objects/s
stdin: is not a tty

2017-06-09 09:42:41,290 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:42:41,290 INFO cluster.py [line:239] usefull PG number is 2705
2017-06-09 09:43:41,314 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-09 09:43:41,315 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:43:41,707 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            363 pgs backfill_wait
            2 pgs backfilling
            365 pgs stuck unclean
            Difference in osd space utilization 50.3866% greater than 40%
            recovery 431119/1031917 objects misplaced (41.778%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7001: 12 osds: 12 up, 12 in; 364 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82382: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2859 GB used, 5531 GB / 8390 GB avail
            431119/1031917 objects misplaced (41.778%)
                2707 active+clean
                 363 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 188 MB/s, 50 objects/s
stdin: is not a tty

2017-06-09 09:43:41,707 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:43:41,707 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-09 09:44:41,767 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-09 09:44:41,768 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:44:42,158 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            354 pgs backfill_wait
            4 pgs backfilling
            358 pgs stuck unclean
            Difference in osd space utilization 49.9244% greater than 40%
            recovery 420331/1026333 objects misplaced (40.955%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7013: 12 osds: 12 up, 12 in; 358 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82440: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2857 GB used, 5532 GB / 8390 GB avail
            420331/1026333 objects misplaced (40.955%)
                2714 active+clean
                 354 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 673 MB/s, 180 objects/s
stdin: is not a tty

2017-06-09 09:44:42,158 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:44:42,158 INFO cluster.py [line:239] usefull PG number is 2714
2017-06-09 09:45:42,207 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-09 09:45:42,207 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:45:42,595 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            349 pgs backfill_wait
            3 pgs backfilling
            352 pgs stuck unclean
            Difference in osd space utilization 49.1385% greater than 40%
            recovery 413925/1023262 objects misplaced (40.452%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7021: 12 osds: 12 up, 12 in; 352 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82496: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2858 GB used, 5532 GB / 8390 GB avail
            413925/1023262 objects misplaced (40.452%)
                2720 active+clean
                 349 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 799 MB/s, 216 objects/s
stdin: is not a tty

2017-06-09 09:45:42,595 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:45:42,595 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-09 09:46:42,656 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-09 09:46:42,656 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:46:43,143 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            345 pgs backfill_wait
            3 pgs backfilling
            348 pgs stuck unclean
            Difference in osd space utilization 48.741% greater than 40%
            recovery 408055/1020184 objects misplaced (39.998%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7029: 12 osds: 12 up, 12 in; 348 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82553: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2858 GB used, 5532 GB / 8390 GB avail
            408055/1020184 objects misplaced (39.998%)
                2724 active+clean
                 345 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 237 MB/s, 63 objects/s
  client io 20389 B/s rd, 29 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:46:43,143 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:46:43,143 INFO cluster.py [line:239] usefull PG number is 2724
2017-06-09 09:47:43,204 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-09 09:47:43,204 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:47:43,597 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            340 pgs backfill_wait
            3 pgs backfilling
            343 pgs stuck unclean
            Difference in osd space utilization 48.6559% greater than 40%
            recovery 403065/1017803 objects misplaced (39.601%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7036: 12 osds: 12 up, 12 in; 343 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82608: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2858 GB used, 5532 GB / 8390 GB avail
            403065/1017803 objects misplaced (39.601%)
                2729 active+clean
                 340 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 498 MB/s, 133 objects/s
  client io 26890 B/s rd, 39 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:47:43,598 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:47:43,598 INFO cluster.py [line:239] usefull PG number is 2729
2017-06-09 09:48:43,648 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-09 09:48:43,648 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:48:44,056 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            334 pgs backfill_wait
            3 pgs backfilling
            337 pgs stuck unclean
            Difference in osd space utilization 48.3635% greater than 40%
            recovery 396819/1014571 objects misplaced (39.112%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7046: 12 osds: 12 up, 12 in; 337 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82665: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2858 GB used, 5532 GB / 8390 GB avail
            396819/1014571 objects misplaced (39.112%)
                2735 active+clean
                 334 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 299 MB/s, 80 objects/s
  client io 16484 B/s rd, 24 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:48:44,056 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:48:44,056 INFO cluster.py [line:239] usefull PG number is 2735
2017-06-09 09:49:44,073 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-09 09:49:44,073 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:49:44,489 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            332 pgs backfill_wait
            2 pgs backfilling
            334 pgs stuck unclean
            Difference in osd space utilization 47.3619% greater than 40%
            recovery 392674/1012282 objects misplaced (38.791%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7052: 12 osds: 12 up, 12 in; 334 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82718: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2856 GB used, 5533 GB / 8390 GB avail
            392674/1012282 objects misplaced (38.791%)
                2738 active+clean
                 332 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 412 MB/s, 111 objects/s
  client io 83919 B/s rd, 93 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:49:44,490 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:49:44,490 INFO cluster.py [line:239] usefull PG number is 2738
2017-06-09 09:50:44,544 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-09 09:50:44,545 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:50:44,919 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            328 pgs backfill_wait
            2 pgs backfilling
            330 pgs stuck unclean
            Difference in osd space utilization 46.9303% greater than 40%
            recovery 389524/1010637 objects misplaced (38.542%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7060: 12 osds: 12 up, 12 in; 330 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82770: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2856 GB used, 5534 GB / 8390 GB avail
            389524/1010637 objects misplaced (38.542%)
                2742 active+clean
                 328 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 09:50:44,919 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:50:44,919 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-09 09:51:44,977 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-09 09:51:44,978 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:51:45,375 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            325 pgs backfill_wait
            1 pgs backfilling
            326 pgs stuck unclean
            Difference in osd space utilization 46.4208% greater than 40%
            recovery 386444/1008866 objects misplaced (38.305%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7068: 12 osds: 12 up, 12 in; 326 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82829: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2854 GB used, 5536 GB / 8390 GB avail
            386444/1008866 objects misplaced (38.305%)
                2746 active+clean
                 325 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 266 MB/s, 71 objects/s
stdin: is not a tty

2017-06-09 09:51:45,376 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:51:45,376 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-09 09:52:45,386 INFO cluster.py [line:247] cost 61 seconds, left 5033 seconds when check the ceph status
2017-06-09 09:52:45,386 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:52:45,899 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            323 pgs backfill_wait
            1 pgs backfilling
            324 pgs stuck unclean
            Difference in osd space utilization 46.0355% greater than 40%
            recovery 384726/1008010 objects misplaced (38.167%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7072: 12 osds: 12 up, 12 in; 324 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82879: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2854 GB used, 5535 GB / 8390 GB avail
            384726/1008010 objects misplaced (38.167%)
                2748 active+clean
                 323 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 09:52:45,899 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:52:45,899 INFO cluster.py [line:239] usefull PG number is 2748
2017-06-09 09:53:45,946 INFO cluster.py [line:247] cost 60 seconds, left 4973 seconds when check the ceph status
2017-06-09 09:53:45,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:53:46,317 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            322 pgs backfill_wait
            1 pgs backfilling
            323 pgs stuck unclean
            Difference in osd space utilization 46.0355% greater than 40%
            recovery 383126/1007261 objects misplaced (38.036%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7074: 12 osds: 12 up, 12 in; 323 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82926: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5535 GB / 8390 GB avail
            383126/1007261 objects misplaced (38.036%)
                2749 active+clean
                 322 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 156 MB/s, 42 objects/s
stdin: is not a tty

2017-06-09 09:53:46,318 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:53:46,318 INFO cluster.py [line:239] usefull PG number is 2749
2017-06-09 09:54:46,378 INFO cluster.py [line:247] cost 61 seconds, left 4912 seconds when check the ceph status
2017-06-09 09:54:46,378 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:54:46,716 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            321 pgs backfill_wait
            1 pgs backfilling
            322 pgs stuck unclean
            Difference in osd space utilization 46.0355% greater than 40%
            recovery 381574/1006512 objects misplaced (37.911%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7076: 12 osds: 12 up, 12 in; 322 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v82978: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5535 GB / 8390 GB avail
            381574/1006512 objects misplaced (37.911%)
                2750 active+clean
                 321 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 215 MB/s, 57 objects/s
stdin: is not a tty

2017-06-09 09:54:46,716 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:54:46,716 INFO cluster.py [line:239] usefull PG number is 2750
2017-06-09 09:55:46,724 INFO cluster.py [line:247] cost 60 seconds, left 4852 seconds when check the ceph status
2017-06-09 09:55:46,724 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:55:47,167 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            319 pgs backfill_wait
            2 pgs backfilling
            321 pgs stuck unclean
            Difference in osd space utilization 45.296% greater than 40%
            recovery 379729/1005754 objects misplaced (37.756%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7080: 12 osds: 12 up, 12 in; 320 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83029: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2853 GB used, 5537 GB / 8390 GB avail
            379729/1005754 objects misplaced (37.756%)
                2751 active+clean
                 319 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 290 MB/s, 79 objects/s
stdin: is not a tty

2017-06-09 09:55:47,167 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:55:47,168 INFO cluster.py [line:239] usefull PG number is 2751
2017-06-09 09:56:47,206 INFO cluster.py [line:247] cost 61 seconds, left 4791 seconds when check the ceph status
2017-06-09 09:56:47,207 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:56:47,637 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            317 pgs backfill_wait
            2 pgs backfilling
            319 pgs stuck unclean
            Difference in osd space utilization 45.296% greater than 40%
            recovery 373918/1003333 objects misplaced (37.268%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7082: 12 osds: 12 up, 12 in; 319 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83079: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2859 GB used, 5531 GB / 8390 GB avail
            373918/1003333 objects misplaced (37.268%)
                2753 active+clean
                 317 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 609 MB/s, 167 objects/s
stdin: is not a tty

2017-06-09 09:56:47,638 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:56:47,638 INFO cluster.py [line:239] usefull PG number is 2753
2017-06-09 09:57:47,649 INFO cluster.py [line:247] cost 60 seconds, left 4731 seconds when check the ceph status
2017-06-09 09:57:47,649 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:57:48,002 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            316 pgs backfill_wait
            1 pgs backfilling
            317 pgs stuck unclean
            Difference in osd space utilization 45.296% greater than 40%
            recovery 370403/1000993 objects misplaced (37.004%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7086: 12 osds: 12 up, 12 in; 317 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83134: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5534 GB / 8390 GB avail
            370403/1000993 objects misplaced (37.004%)
                2755 active+clean
                 316 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 09:57:48,002 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:57:48,002 INFO cluster.py [line:239] usefull PG number is 2755
2017-06-09 09:58:48,056 INFO cluster.py [line:247] cost 61 seconds, left 4670 seconds when check the ceph status
2017-06-09 09:58:48,057 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:58:48,479 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            314 pgs backfill_wait
            1 pgs backfilling
            315 pgs stuck unclean
            Difference in osd space utilization 45.296% greater than 40%
            recovery 368755/1000173 objects misplaced (36.869%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7090: 12 osds: 12 up, 12 in; 315 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83183: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5534 GB / 8390 GB avail
            368755/1000173 objects misplaced (36.869%)
                2757 active+clean
                 314 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 217 MB/s, 58 objects/s
stdin: is not a tty

2017-06-09 09:58:48,479 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:58:48,479 INFO cluster.py [line:239] usefull PG number is 2757
2017-06-09 09:59:48,540 INFO cluster.py [line:247] cost 60 seconds, left 4610 seconds when check the ceph status
2017-06-09 09:59:48,540 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 09:59:48,935 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            313 pgs backfill_wait
            1 pgs backfilling
            314 pgs stuck unclean
            Difference in osd space utilization 45.296% greater than 40%
            recovery 367219/999420 objects misplaced (36.743%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7092: 12 osds: 12 up, 12 in; 314 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83229: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2856 GB used, 5534 GB / 8390 GB avail
            367219/999420 objects misplaced (36.743%)
                2758 active+clean
                 313 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24314 B/s rd, 35 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 09:59:48,936 INFO cluster.py [line:238] PG number is 3072
2017-06-09 09:59:48,936 INFO cluster.py [line:239] usefull PG number is 2758
2017-06-09 10:00:48,984 INFO cluster.py [line:247] cost 60 seconds, left 4550 seconds when check the ceph status
2017-06-09 10:00:48,984 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:00:49,399 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            305 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            306 pgs stuck unclean
            Difference in osd space utilization 44.9319% greater than 40%
            recovery 362692/996873 objects misplaced (36.383%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7108: 12 osds: 12 up, 12 in; 306 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83293: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2854 GB used, 5536 GB / 8390 GB avail
            362692/996873 objects misplaced (36.383%)
                2765 active+clean
                 305 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 408 MB/s, 106 objects/s
  client io 156 kB/s rd, 203 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 10:00:49,399 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:00:49,399 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-09 10:01:49,439 INFO cluster.py [line:247] cost 61 seconds, left 4489 seconds when check the ceph status
2017-06-09 10:01:49,439 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:01:49,832 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            303 pgs backfill_wait
            1 pgs backfilling
            304 pgs stuck unclean
            Difference in osd space utilization 44.5024% greater than 40%
            recovery 359192/995306 objects misplaced (36.089%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7112: 12 osds: 12 up, 12 in; 304 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83346: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5535 GB / 8390 GB avail
            359192/995306 objects misplaced (36.089%)
                2768 active+clean
                 303 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 144 kB/s rd, 186 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 10:01:49,832 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:01:49,832 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-09 10:02:49,892 INFO cluster.py [line:247] cost 60 seconds, left 4429 seconds when check the ceph status
2017-06-09 10:02:49,893 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:02:50,269 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            302 pgs backfill_wait
            1 pgs backfilling
            303 pgs stuck unclean
            Difference in osd space utilization 44.5024% greater than 40%
            recovery 357576/994541 objects misplaced (35.954%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7114: 12 osds: 12 up, 12 in; 303 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83394: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2855 GB used, 5535 GB / 8390 GB avail
            357576/994541 objects misplaced (35.954%)
                2769 active+clean
                 302 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 223 MB/s, 60 objects/s
  client io 118 kB/s rd, 155 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 10:02:50,270 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:02:50,270 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-09 10:03:50,294 INFO cluster.py [line:247] cost 61 seconds, left 4368 seconds when check the ceph status
2017-06-09 10:03:50,295 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:03:50,748 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            300 pgs backfill_wait
            1 pgs backfilling
            301 pgs stuck unclean
            Difference in osd space utilization 44.5024% greater than 40%
            recovery 355179/993080 objects misplaced (35.765%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7118: 12 osds: 12 up, 12 in; 301 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83444: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2853 GB used, 5536 GB / 8390 GB avail
            355179/993080 objects misplaced (35.765%)
                2771 active+clean
                 300 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 240 MB/s, 64 objects/s
  client io 136 kB/s rd, 177 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 10:03:50,748 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:03:50,749 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-09 10:04:50,779 INFO cluster.py [line:247] cost 60 seconds, left 4308 seconds when check the ceph status
2017-06-09 10:04:50,779 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:04:51,137 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            300 pgs backfill_wait
            1 pgs backfilling
            301 pgs stuck unclean
            Difference in osd space utilization 44.5166% greater than 40%
            recovery 354663/993080 objects misplaced (35.713%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7118: 12 osds: 12 up, 12 in; 301 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83495: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2857 GB used, 5533 GB / 8390 GB avail
            354663/993080 objects misplaced (35.713%)
                2771 active+clean
                 300 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 112 kB/s rd, 89855 kB/s wr, 142 op/s rd, 11231 op/s wr
stdin: is not a tty

2017-06-09 10:04:51,137 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:04:51,137 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-09 10:05:51,168 INFO cluster.py [line:247] cost 61 seconds, left 4247 seconds when check the ceph status
2017-06-09 10:05:51,168 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:05:51,541 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            297 pgs backfill_wait
            1 pgs backfilling
            298 pgs stuck unclean
            Difference in osd space utilization 44.5349% greater than 40%
            recovery 353467/992286 objects misplaced (35.621%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7122: 12 osds: 12 up, 12 in; 298 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83551: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2857 GB used, 5533 GB / 8390 GB avail
            353467/992286 objects misplaced (35.621%)
                2774 active+clean
                 297 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 101 MB/s, 27 objects/s
  client io 151 MB/s wr, 0 op/s rd, 19384 op/s wr
stdin: is not a tty

2017-06-09 10:05:51,541 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:05:51,541 INFO cluster.py [line:239] usefull PG number is 2774
2017-06-09 10:06:51,601 INFO cluster.py [line:247] cost 60 seconds, left 4187 seconds when check the ceph status
2017-06-09 10:06:51,602 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:06:51,982 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            297 pgs backfill_wait
            1 pgs backfilling
            298 pgs stuck unclean
            Difference in osd space utilization 44.568% greater than 40%
            recovery 353077/992286 objects misplaced (35.582%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7122: 12 osds: 12 up, 12 in; 298 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83604: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2860 GB used, 5530 GB / 8390 GB avail
            353077/992286 objects misplaced (35.582%)
                2774 active+clean
                 297 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 106 MB/s, 28 objects/s
  client io 171 MB/s wr, 0 op/s rd, 21944 op/s wr
stdin: is not a tty

2017-06-09 10:06:51,982 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:06:51,983 INFO cluster.py [line:239] usefull PG number is 2774
2017-06-09 10:07:52,014 INFO cluster.py [line:247] cost 61 seconds, left 4126 seconds when check the ceph status
2017-06-09 10:07:52,014 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:07:52,422 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            296 pgs backfill_wait
            1 pgs backfilling
            297 pgs stuck unclean
            Difference in osd space utilization 44.594% greater than 40%
            recovery 351962/991525 objects misplaced (35.497%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7124: 12 osds: 12 up, 12 in; 297 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83658: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2859 GB used, 5531 GB / 8390 GB avail
            351962/991525 objects misplaced (35.497%)
                2775 active+clean
                 296 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 169 MB/s wr, 0 op/s rd, 21738 op/s wr
stdin: is not a tty

2017-06-09 10:07:52,423 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:07:52,423 INFO cluster.py [line:239] usefull PG number is 2775
2017-06-09 10:08:52,458 INFO cluster.py [line:247] cost 60 seconds, left 4066 seconds when check the ceph status
2017-06-09 10:08:52,458 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:08:52,808 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            296 pgs backfill_wait
            1 pgs backfilling
            297 pgs stuck unclean
            Difference in osd space utilization 44.5847% greater than 40%
            recovery 351627/991525 objects misplaced (35.463%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7124: 12 osds: 12 up, 12 in; 297 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83711: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2861 GB used, 5529 GB / 8390 GB avail
            351627/991525 objects misplaced (35.463%)
                2775 active+clean
                 296 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 128 MB/s wr, 0 op/s rd, 16469 op/s wr
stdin: is not a tty

2017-06-09 10:08:52,809 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:08:52,809 INFO cluster.py [line:239] usefull PG number is 2775
2017-06-09 10:09:52,835 INFO cluster.py [line:247] cost 60 seconds, left 4006 seconds when check the ceph status
2017-06-09 10:09:52,835 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:09:53,268 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            294 pgs backfill_wait
            2 pgs backfilling
            296 pgs stuck unclean
            Difference in osd space utilization 44.6427% greater than 40%
            recovery 350399/990730 objects misplaced (35.368%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7126: 12 osds: 12 up, 12 in; 296 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83765: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2861 GB used, 5529 GB / 8390 GB avail
            350399/990730 objects misplaced (35.368%)
                2776 active+clean
                 294 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 24431 B/s rd, 93464 kB/s wr, 35 op/s rd, 11683 op/s wr
stdin: is not a tty

2017-06-09 10:09:53,268 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:09:53,268 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-09 10:10:53,273 INFO cluster.py [line:247] cost 61 seconds, left 3945 seconds when check the ceph status
2017-06-09 10:10:53,273 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:10:53,664 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            294 pgs backfill_wait
            2 pgs backfilling
            296 pgs stuck unclean
            Difference in osd space utilization 44.9043% greater than 40%
            recovery 349546/990730 objects misplaced (35.282%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7126: 12 osds: 12 up, 12 in; 296 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83818: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2864 GB used, 5526 GB / 8390 GB avail
            349546/990730 objects misplaced (35.282%)
                2776 active+clean
                 294 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 27588 B/s rd, 109 MB/s wr, 40 op/s rd, 13953 op/s wr
stdin: is not a tty

2017-06-09 10:10:53,664 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:10:53,665 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-09 10:11:53,705 INFO cluster.py [line:247] cost 60 seconds, left 3885 seconds when check the ceph status
2017-06-09 10:11:53,705 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:11:54,068 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            293 pgs backfill_wait
            1 pgs backfilling
            294 pgs stuck unclean
            Difference in osd space utilization 44.9924% greater than 40%
            recovery 347408/989179 objects misplaced (35.121%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7130: 12 osds: 12 up, 12 in; 294 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83872: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2861 GB used, 5529 GB / 8390 GB avail
            347408/989179 objects misplaced (35.121%)
                2778 active+clean
                 293 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 231 MB/s, 62 objects/s
  client io 23372 B/s rd, 113 MB/s wr, 34 op/s rd, 14554 op/s wr
stdin: is not a tty

2017-06-09 10:11:54,069 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:11:54,069 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-09 10:12:54,122 INFO cluster.py [line:247] cost 61 seconds, left 3824 seconds when check the ceph status
2017-06-09 10:12:54,122 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:12:54,534 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            293 pgs backfill_wait
            1 pgs backfilling
            294 pgs stuck unclean
            Difference in osd space utilization 44.9993% greater than 40%
            recovery 346759/989179 objects misplaced (35.055%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7130: 12 osds: 12 up, 12 in; 294 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83925: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2865 GB used, 5524 GB / 8390 GB avail
            346759/989179 objects misplaced (35.055%)
                2778 active+clean
                 293 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 141 MB/s, 38 objects/s
  client io 162 kB/s rd, 84288 kB/s wr, 210 op/s rd, 10536 op/s wr
stdin: is not a tty

2017-06-09 10:12:54,535 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:12:54,535 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-09 10:13:54,549 INFO cluster.py [line:247] cost 60 seconds, left 3764 seconds when check the ceph status
2017-06-09 10:13:54,550 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:13:54,971 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            292 pgs backfill_wait
            1 pgs backfilling
            293 pgs stuck unclean
            Difference in osd space utilization 44.6536% greater than 40%
            recovery 345603/988399 objects misplaced (34.966%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7132: 12 osds: 12 up, 12 in; 293 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v83981: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2865 GB used, 5525 GB / 8390 GB avail
            345603/988399 objects misplaced (34.966%)
                2779 active+clean
                 292 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 138 kB/s rd, 58227 kB/s wr, 174 op/s rd, 7278 op/s wr
stdin: is not a tty

2017-06-09 10:13:54,971 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:13:54,971 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-09 10:14:55,032 INFO cluster.py [line:247] cost 61 seconds, left 3703 seconds when check the ceph status
2017-06-09 10:14:55,032 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:14:55,447 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            292 pgs backfill_wait
            1 pgs backfilling
            293 pgs stuck unclean
            Difference in osd space utilization 44.6559% greater than 40%
            recovery 345239/988399 objects misplaced (34.929%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7132: 12 osds: 12 up, 12 in; 293 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84034: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2867 GB used, 5523 GB / 8390 GB avail
            345239/988399 objects misplaced (34.929%)
                2779 active+clean
                 292 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 120 kB/s rd, 67482 kB/s wr, 151 op/s rd, 8435 op/s wr
stdin: is not a tty

2017-06-09 10:14:55,448 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:14:55,448 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-09 10:15:55,471 INFO cluster.py [line:247] cost 60 seconds, left 3643 seconds when check the ceph status
2017-06-09 10:15:55,472 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:15:55,859 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            291 pgs backfill_wait
            1 pgs backfilling
            292 pgs stuck unclean
            Difference in osd space utilization 44.6493% greater than 40%
            recovery 344163/987616 objects misplaced (34.848%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7134: 12 osds: 12 up, 12 in; 292 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84088: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2865 GB used, 5525 GB / 8390 GB avail
            344163/987616 objects misplaced (34.848%)
                2780 active+clean
                 291 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 122 kB/s rd, 79719 kB/s wr, 154 op/s rd, 9964 op/s wr
stdin: is not a tty

2017-06-09 10:15:55,859 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:15:55,859 INFO cluster.py [line:239] usefull PG number is 2780
2017-06-09 10:16:55,906 INFO cluster.py [line:247] cost 60 seconds, left 3583 seconds when check the ceph status
2017-06-09 10:16:55,906 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:16:56,335 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            291 pgs backfill_wait
            1 pgs backfilling
            292 pgs stuck unclean
            Difference in osd space utilization 44.6883% greater than 40%
            recovery 343850/987616 objects misplaced (34.816%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7134: 12 osds: 12 up, 12 in; 292 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84142: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2868 GB used, 5522 GB / 8390 GB avail
            343850/987616 objects misplaced (34.816%)
                2780 active+clean
                 291 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 83303 kB/s, 21 objects/s
  client io 122 MB/s wr, 0 op/s rd, 15644 op/s wr
stdin: is not a tty

2017-06-09 10:16:56,336 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:16:56,336 INFO cluster.py [line:239] usefull PG number is 2780
2017-06-09 10:17:56,393 INFO cluster.py [line:247] cost 61 seconds, left 3522 seconds when check the ceph status
2017-06-09 10:17:56,394 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:17:56,788 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            290 pgs backfill_wait
            1 pgs backfilling
            291 pgs stuck unclean
            Difference in osd space utilization 44.6712% greater than 40%
            recovery 342844/986870 objects misplaced (34.741%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7136: 12 osds: 12 up, 12 in; 291 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84196: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2868 GB used, 5521 GB / 8390 GB avail
            342844/986870 objects misplaced (34.741%)
                2781 active+clean
                 290 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 10104 kB/s, 2 objects/s
  client io 155 kB/s rd, 125 MB/s wr, 195 op/s rd, 16095 op/s wr
stdin: is not a tty

2017-06-09 10:17:56,788 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:17:56,788 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-09 10:18:56,848 INFO cluster.py [line:247] cost 60 seconds, left 3462 seconds when check the ceph status
2017-06-09 10:18:56,849 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:18:57,248 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            289 pgs backfill_wait
            1 pgs backfilling
            290 pgs stuck unclean
            Difference in osd space utilization 44.6629% greater than 40%
            recovery 342425/986819 objects misplaced (34.700%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7138: 12 osds: 12 up, 12 in; 290 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84252: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2868 GB used, 5522 GB / 8390 GB avail
            342425/986819 objects misplaced (34.700%)
                2782 active+clean
                 289 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 153 MB/s wr, 0 op/s rd, 19675 op/s wr
stdin: is not a tty

2017-06-09 10:18:57,249 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:18:57,249 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-09 10:19:57,308 INFO cluster.py [line:247] cost 61 seconds, left 3401 seconds when check the ceph status
2017-06-09 10:19:57,309 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:19:57,844 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            289 pgs backfill_wait
            1 pgs backfilling
            290 pgs stuck unclean
            Difference in osd space utilization 44.6788% greater than 40%
            recovery 342043/986819 objects misplaced (34.661%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7138: 12 osds: 12 up, 12 in; 290 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84305: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2870 GB used, 5520 GB / 8390 GB avail
            342043/986819 objects misplaced (34.661%)
                2782 active+clean
                 289 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29050 B/s rd, 120 MB/s wr, 42 op/s rd, 15439 op/s wr
stdin: is not a tty

2017-06-09 10:19:57,844 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:19:57,844 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-09 10:20:57,882 INFO cluster.py [line:247] cost 60 seconds, left 3341 seconds when check the ceph status
2017-06-09 10:20:57,882 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:20:58,392 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            288 pgs backfill_wait
            1 pgs backfilling
            289 pgs stuck unclean
            Difference in osd space utilization 44.3391% greater than 40%
            recovery 340891/986072 objects misplaced (34.571%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7140: 12 osds: 12 up, 12 in; 289 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84359: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2870 GB used, 5520 GB / 8390 GB avail
            340891/986072 objects misplaced (34.571%)
                2783 active+clean
                 288 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 30 objects/s
  client io 29874 B/s rd, 139 MB/s wr, 43 op/s rd, 17847 op/s wr
stdin: is not a tty

2017-06-09 10:20:58,392 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:20:58,392 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-09 10:21:58,441 INFO cluster.py [line:247] cost 61 seconds, left 3280 seconds when check the ceph status
2017-06-09 10:21:58,441 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:21:58,809 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            288 pgs backfill_wait
            1 pgs backfilling
            289 pgs stuck unclean
            Difference in osd space utilization 44.3465% greater than 40%
            recovery 340507/986072 objects misplaced (34.532%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7140: 12 osds: 12 up, 12 in; 289 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84412: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2872 GB used, 5518 GB / 8390 GB avail
            340507/986072 objects misplaced (34.532%)
                2783 active+clean
                 288 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 30 objects/s
  client io 29031 B/s rd, 163 MB/s wr, 42 op/s rd, 20872 op/s wr
stdin: is not a tty

2017-06-09 10:21:58,810 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:21:58,810 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-09 10:22:58,870 INFO cluster.py [line:247] cost 60 seconds, left 3220 seconds when check the ceph status
2017-06-09 10:22:58,870 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:22:59,271 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            286 pgs backfill_wait
            1 pgs backfilling
            287 pgs stuck unclean
            Difference in osd space utilization 43.982% greater than 40%
            recovery 339318/985221 objects misplaced (34.441%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7144: 12 osds: 12 up, 12 in; 287 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84467: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2870 GB used, 5519 GB / 8390 GB avail
            339318/985221 objects misplaced (34.441%)
                2785 active+clean
                 286 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 182 kB/s rd, 54008 kB/s wr, 236 op/s rd, 6751 op/s wr
stdin: is not a tty

2017-06-09 10:22:59,271 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:22:59,271 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-09 10:23:59,313 INFO cluster.py [line:247] cost 61 seconds, left 3159 seconds when check the ceph status
2017-06-09 10:23:59,314 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:23:59,697 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            286 pgs backfill_wait
            1 pgs backfilling
            287 pgs stuck unclean
            Difference in osd space utilization 43.9764% greater than 40%
            recovery 338956/985221 objects misplaced (34.404%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7144: 12 osds: 12 up, 12 in; 287 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84520: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2871 GB used, 5519 GB / 8390 GB avail
            338956/985221 objects misplaced (34.404%)
                2785 active+clean
                 286 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 165 kB/s rd, 48431 kB/s wr, 214 op/s rd, 6053 op/s wr
stdin: is not a tty

2017-06-09 10:23:59,697 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:23:59,697 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-09 10:24:59,729 INFO cluster.py [line:247] cost 60 seconds, left 3099 seconds when check the ceph status
2017-06-09 10:24:59,730 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:25:00,103 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            285 pgs backfill_wait
            1 pgs backfilling
            286 pgs stuck unclean
            Difference in osd space utilization 43.6005% greater than 40%
            recovery 337805/984444 objects misplaced (34.314%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7146: 12 osds: 12 up, 12 in; 286 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84574: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2871 GB used, 5519 GB / 8390 GB avail
            337805/984444 objects misplaced (34.314%)
                2786 active+clean
                 285 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 106 MB/s, 28 objects/s
  client io 145 kB/s rd, 70729 kB/s wr, 188 op/s rd, 8841 op/s wr
stdin: is not a tty

2017-06-09 10:25:00,103 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:25:00,103 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-09 10:26:00,162 INFO cluster.py [line:247] cost 61 seconds, left 3038 seconds when check the ceph status
2017-06-09 10:26:00,162 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:26:00,549 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            285 pgs backfill_wait
            1 pgs backfilling
            286 pgs stuck unclean
            Difference in osd space utilization 43.6084% greater than 40%
            recovery 337430/984444 objects misplaced (34.276%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7146: 12 osds: 12 up, 12 in; 286 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84627: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2872 GB used, 5518 GB / 8390 GB avail
            337430/984444 objects misplaced (34.276%)
                2786 active+clean
                 285 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 113 kB/s rd, 65938 kB/s wr, 143 op/s rd, 8242 op/s wr
stdin: is not a tty

2017-06-09 10:26:00,549 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:26:00,550 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-09 10:27:00,610 INFO cluster.py [line:247] cost 60 seconds, left 2978 seconds when check the ceph status
2017-06-09 10:27:00,610 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:27:01,028 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            283 pgs backfill_wait
            1 pgs backfilling
            284 pgs stuck unclean
            Difference in osd space utilization 43.6238% greater than 40%
            recovery 336202/983579 objects misplaced (34.181%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7150: 12 osds: 12 up, 12 in; 284 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84683: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2873 GB used, 5517 GB / 8390 GB avail
            336202/983579 objects misplaced (34.181%)
                2788 active+clean
                 283 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 131 kB/s rd, 60576 kB/s wr, 165 op/s rd, 7572 op/s wr
stdin: is not a tty

2017-06-09 10:27:01,029 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:27:01,029 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-09 10:28:01,089 INFO cluster.py [line:247] cost 61 seconds, left 2917 seconds when check the ceph status
2017-06-09 10:28:01,089 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:28:01,461 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            283 pgs backfill_wait
            1 pgs backfilling
            284 pgs stuck unclean
            Difference in osd space utilization 43.6081% greater than 40%
            recovery 335853/983579 objects misplaced (34.146%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7150: 12 osds: 12 up, 12 in; 284 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84737: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2873 GB used, 5517 GB / 8390 GB avail
            335853/983579 objects misplaced (34.146%)
                2788 active+clean
                 283 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 80605 kB/s, 21 objects/s
  client io 150 kB/s rd, 78565 kB/s wr, 189 op/s rd, 9820 op/s wr
stdin: is not a tty

2017-06-09 10:28:01,461 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:28:01,462 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-09 10:29:01,487 INFO cluster.py [line:247] cost 60 seconds, left 2857 seconds when check the ceph status
2017-06-09 10:29:01,487 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:29:01,876 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            282 pgs backfill_wait
            1 pgs backfilling
            283 pgs stuck unclean
            Difference in osd space utilization 43.6264% greater than 40%
            recovery 334799/982851 objects misplaced (34.064%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7152: 12 osds: 12 up, 12 in; 283 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84791: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2874 GB used, 5516 GB / 8390 GB avail
            334799/982851 objects misplaced (34.064%)
                2789 active+clean
                 282 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 92300 kB/s, 24 objects/s
  client io 101 MB/s wr, 0 op/s rd, 12974 op/s wr
stdin: is not a tty

2017-06-09 10:29:01,876 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:29:01,876 INFO cluster.py [line:239] usefull PG number is 2789
2017-06-09 10:30:01,926 INFO cluster.py [line:247] cost 60 seconds, left 2797 seconds when check the ceph status
2017-06-09 10:30:01,926 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:30:02,290 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            280 pgs backfill_wait
            2 pgs backfilling
            282 pgs stuck unclean
            Difference in osd space utilization 43.6672% greater than 40%
            recovery 334067/982789 objects misplaced (33.992%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7154: 12 osds: 12 up, 12 in; 282 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84846: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2874 GB used, 5515 GB / 8390 GB avail
            334067/982789 objects misplaced (33.992%)
                2790 active+clean
                 280 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 102277 kB/s, 27 objects/s
  client io 104 MB/s wr, 0 op/s rd, 13405 op/s wr
stdin: is not a tty

2017-06-09 10:30:02,290 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:30:02,290 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-09 10:31:02,320 INFO cluster.py [line:247] cost 61 seconds, left 2736 seconds when check the ceph status
2017-06-09 10:31:02,320 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:31:02,710 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            280 pgs backfill_wait
            2 pgs backfilling
            282 pgs stuck unclean
            Difference in osd space utilization 43.6648% greater than 40%
            recovery 333318/982789 objects misplaced (33.916%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7154: 12 osds: 12 up, 12 in; 282 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84899: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2879 GB used, 5511 GB / 8390 GB avail
            333318/982789 objects misplaced (33.916%)
                2790 active+clean
                 280 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 75969 kB/s, 19 objects/s
  client io 122 MB/s wr, 0 op/s rd, 15738 op/s wr
stdin: is not a tty

2017-06-09 10:31:02,710 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:31:02,711 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-09 10:32:02,756 INFO cluster.py [line:247] cost 60 seconds, left 2676 seconds when check the ceph status
2017-06-09 10:32:02,756 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:32:03,146 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            279 pgs backfill_wait
            1 pgs backfilling
            280 pgs stuck unclean
            Difference in osd space utilization 43.2845% greater than 40%
            recovery 331013/981137 objects misplaced (33.738%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7158: 12 osds: 12 up, 12 in; 280 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v84953: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2875 GB used, 5515 GB / 8390 GB avail
            331013/981137 objects misplaced (33.738%)
                2792 active+clean
                 279 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 90233 kB/s, 23 objects/s
  client io 149 MB/s wr, 0 op/s rd, 19096 op/s wr
stdin: is not a tty

2017-06-09 10:32:03,147 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:32:03,147 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-09 10:33:03,198 INFO cluster.py [line:247] cost 61 seconds, left 2615 seconds when check the ceph status
2017-06-09 10:33:03,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:33:03,596 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            279 pgs backfill_wait
            1 pgs backfilling
            280 pgs stuck unclean
            Difference in osd space utilization 43.2938% greater than 40%
            recovery 330620/981137 objects misplaced (33.698%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7158: 12 osds: 12 up, 12 in; 280 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85006: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2877 GB used, 5513 GB / 8390 GB avail
            330620/981137 objects misplaced (33.698%)
                2792 active+clean
                 279 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 105 MB/s, 28 objects/s
  client io 25090 B/s rd, 149 MB/s wr, 36 op/s rd, 19171 op/s wr
stdin: is not a tty

2017-06-09 10:33:03,597 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:33:03,597 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-09 10:34:03,628 INFO cluster.py [line:247] cost 60 seconds, left 2555 seconds when check the ceph status
2017-06-09 10:34:03,628 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:34:03,989 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            278 pgs backfill_wait
            1 pgs backfilling
            279 pgs stuck unclean
            Difference in osd space utilization 43.2806% greater than 40%
            recovery 329051/980313 objects misplaced (33.566%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7160: 12 osds: 12 up, 12 in; 279 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85061: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2878 GB used, 5512 GB / 8390 GB avail
            329051/980313 objects misplaced (33.566%)
                2793 active+clean
                 278 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 18517 B/s rd, 87645 kB/s wr, 27 op/s rd, 10955 op/s wr
stdin: is not a tty

2017-06-09 10:34:03,989 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:34:03,989 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-09 10:35:04,043 INFO cluster.py [line:247] cost 61 seconds, left 2494 seconds when check the ceph status
2017-06-09 10:35:04,043 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:35:04,392 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            278 pgs backfill_wait
            1 pgs backfilling
            279 pgs stuck unclean
            Difference in osd space utilization 43.3271% greater than 40%
            recovery 328173/980313 objects misplaced (33.476%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7160: 12 osds: 12 up, 12 in; 279 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85113: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2882 GB used, 5508 GB / 8390 GB avail
            328173/980313 objects misplaced (33.476%)
                2793 active+clean
                 278 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29762 B/s rd, 125 MB/s wr, 43 op/s rd, 16004 op/s wr
stdin: is not a tty

2017-06-09 10:35:04,392 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:35:04,392 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-09 10:36:04,434 INFO cluster.py [line:247] cost 60 seconds, left 2434 seconds when check the ceph status
2017-06-09 10:36:04,434 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:36:04,832 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            277 pgs backfill_wait
            1 pgs backfilling
            278 pgs stuck unclean
            Difference in osd space utilization 43.3007% greater than 40%
            recovery 326153/978671 objects misplaced (33.326%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7162: 12 osds: 12 up, 12 in; 278 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85168: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2877 GB used, 5513 GB / 8390 GB avail
            326153/978671 objects misplaced (33.326%)
                2794 active+clean
                 277 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 143 kB/s rd, 87457 kB/s wr, 185 op/s rd, 10932 op/s wr
stdin: is not a tty

2017-06-09 10:36:04,833 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:36:04,833 INFO cluster.py [line:239] usefull PG number is 2794
2017-06-09 10:37:04,890 INFO cluster.py [line:247] cost 60 seconds, left 2374 seconds when check the ceph status
2017-06-09 10:37:04,890 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:37:05,276 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            277 pgs backfill_wait
            1 pgs backfilling
            278 pgs stuck unclean
            Difference in osd space utilization 43.2946% greater than 40%
            recovery 325838/978671 objects misplaced (33.294%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7162: 12 osds: 12 up, 12 in; 278 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85221: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2878 GB used, 5511 GB / 8390 GB avail
            325838/978671 objects misplaced (33.294%)
                2794 active+clean
                 277 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 138 kB/s rd, 57906 kB/s wr, 173 op/s rd, 7238 op/s wr
stdin: is not a tty

2017-06-09 10:37:05,277 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:37:05,277 INFO cluster.py [line:239] usefull PG number is 2794
2017-06-09 10:38:05,337 INFO cluster.py [line:247] cost 61 seconds, left 2313 seconds when check the ceph status
2017-06-09 10:38:05,337 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:38:05,688 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            276 pgs backfill_wait
            1 pgs backfilling
            277 pgs stuck unclean
            Difference in osd space utilization 42.9288% greater than 40%
            recovery 324701/977896 objects misplaced (33.204%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7164: 12 osds: 12 up, 12 in; 277 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85274: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2877 GB used, 5512 GB / 8390 GB avail
            324701/977896 objects misplaced (33.204%)
                2795 active+clean
                 276 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 159 kB/s rd, 86738 kB/s wr, 207 op/s rd, 10842 op/s wr
stdin: is not a tty

2017-06-09 10:38:05,688 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:38:05,688 INFO cluster.py [line:239] usefull PG number is 2795
2017-06-09 10:39:05,735 INFO cluster.py [line:247] cost 60 seconds, left 2253 seconds when check the ceph status
2017-06-09 10:39:05,736 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:39:06,180 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            276 pgs backfill_wait
            1 pgs backfilling
            277 pgs stuck unclean
            Difference in osd space utilization 42.9367% greater than 40%
            recovery 324350/977896 objects misplaced (33.168%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7164: 12 osds: 12 up, 12 in; 277 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85328: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2880 GB used, 5510 GB / 8390 GB avail
            324350/977896 objects misplaced (33.168%)
                2795 active+clean
                 276 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 130 kB/s rd, 98486 kB/s wr, 163 op/s rd, 12310 op/s wr
stdin: is not a tty

2017-06-09 10:39:06,181 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:39:06,181 INFO cluster.py [line:239] usefull PG number is 2795
2017-06-09 10:40:06,198 INFO cluster.py [line:247] cost 61 seconds, left 2192 seconds when check the ceph status
2017-06-09 10:40:06,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:40:06,576 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            1 pgs backfilling
            275 pgs stuck unclean
            Difference in osd space utilization 42.5594% greater than 40%
            recovery 323206/977103 objects misplaced (33.078%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7168: 12 osds: 12 up, 12 in; 275 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85383: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2879 GB used, 5510 GB / 8390 GB avail
            323206/977103 objects misplaced (33.078%)
                2797 active+clean
                 274 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 149 kB/s rd, 66855 kB/s wr, 187 op/s rd, 8356 op/s wr
stdin: is not a tty

2017-06-09 10:40:06,577 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:40:06,577 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-09 10:41:06,637 INFO cluster.py [line:247] cost 60 seconds, left 2132 seconds when check the ceph status
2017-06-09 10:41:06,637 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:41:07,059 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            1 pgs backfilling
            275 pgs stuck unclean
            Difference in osd space utilization 42.5622% greater than 40%
            recovery 322861/977103 objects misplaced (33.043%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7168: 12 osds: 12 up, 12 in; 275 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85437: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2879 GB used, 5511 GB / 8390 GB avail
            322861/977103 objects misplaced (33.043%)
                2797 active+clean
                 274 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 90847 kB/s, 24 objects/s
  client io 119 MB/s wr, 0 op/s rd, 15269 op/s wr
stdin: is not a tty

2017-06-09 10:41:07,059 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:41:07,059 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-09 10:42:07,086 INFO cluster.py [line:247] cost 61 seconds, left 2071 seconds when check the ceph status
2017-06-09 10:42:07,086 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:42:07,480 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            274 pgs backfill_wait
            1 pgs backfilling
            275 pgs stuck unclean
            Difference in osd space utilization 42.5587% greater than 40%
            recovery 322586/977103 objects misplaced (33.015%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7168: 12 osds: 12 up, 12 in; 275 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85490: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2881 GB used, 5509 GB / 8390 GB avail
            322586/977103 objects misplaced (33.015%)
                2797 active+clean
                 274 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 117 MB/s wr, 0 op/s rd, 14990 op/s wr
stdin: is not a tty

2017-06-09 10:42:07,480 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:42:07,480 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-09 10:43:07,525 INFO cluster.py [line:247] cost 60 seconds, left 2011 seconds when check the ceph status
2017-06-09 10:43:07,525 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:43:07,890 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            273 pgs backfill_wait
            1 pgs backfilling
            274 pgs stuck unclean
            Difference in osd space utilization 42.209% greater than 40%
            recovery 321382/976273 objects misplaced (32.919%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7170: 12 osds: 12 up, 12 in; 274 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85544: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2880 GB used, 5509 GB / 8390 GB avail
            321382/976273 objects misplaced (32.919%)
                2798 active+clean
                 273 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 22396 B/s rd, 182 MB/s wr, 32 op/s rd, 23412 op/s wr
stdin: is not a tty

2017-06-09 10:43:07,890 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:43:07,890 INFO cluster.py [line:239] usefull PG number is 2798
2017-06-09 10:44:07,946 INFO cluster.py [line:247] cost 60 seconds, left 1951 seconds when check the ceph status
2017-06-09 10:44:07,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:44:08,357 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            273 pgs backfill_wait
            1 pgs backfilling
            274 pgs stuck unclean
            Difference in osd space utilization 42.1857% greater than 40%
            recovery 321008/976273 objects misplaced (32.881%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7170: 12 osds: 12 up, 12 in; 274 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85597: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2883 GB used, 5507 GB / 8390 GB avail
            321008/976273 objects misplaced (32.881%)
                2798 active+clean
                 273 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 27287 B/s rd, 144 MB/s wr, 39 op/s rd, 18532 op/s wr
stdin: is not a tty

2017-06-09 10:44:08,357 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:44:08,358 INFO cluster.py [line:239] usefull PG number is 2798
2017-06-09 10:45:08,379 INFO cluster.py [line:247] cost 61 seconds, left 1890 seconds when check the ceph status
2017-06-09 10:45:08,379 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:45:08,780 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            272 pgs backfill_wait
            1 pgs backfilling
            273 pgs stuck unclean
            Difference in osd space utilization 42.1988% greater than 40%
            recovery 319541/975470 objects misplaced (32.758%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7172: 12 osds: 12 up, 12 in; 273 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85653: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2882 GB used, 5507 GB / 8390 GB avail
            319541/975470 objects misplaced (32.758%)
                2799 active+clean
                 272 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 27563 B/s rd, 133 MB/s wr, 40 op/s rd, 17138 op/s wr
stdin: is not a tty

2017-06-09 10:45:08,781 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:45:08,781 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-09 10:46:08,841 INFO cluster.py [line:247] cost 60 seconds, left 1830 seconds when check the ceph status
2017-06-09 10:46:08,842 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:46:09,292 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            272 pgs backfill_wait
            1 pgs backfilling
            273 pgs stuck unclean
            Difference in osd space utilization 42.2097% greater than 40%
            recovery 318741/975470 objects misplaced (32.676%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7172: 12 osds: 12 up, 12 in; 273 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85706: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2886 GB used, 5503 GB / 8390 GB avail
            318741/975470 objects misplaced (32.676%)
                2799 active+clean
                 272 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 22767 B/s rd, 106 MB/s wr, 33 op/s rd, 13606 op/s wr
stdin: is not a tty

2017-06-09 10:46:09,292 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:46:09,293 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-09 10:47:09,301 INFO cluster.py [line:247] cost 61 seconds, left 1769 seconds when check the ceph status
2017-06-09 10:47:09,301 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:47:09,687 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            269 pgs backfill_wait
            1 pgs backfilling
            270 pgs stuck unclean
            Difference in osd space utilization 41.8991% greater than 40%
            recovery 316232/973692 objects misplaced (32.478%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7178: 12 osds: 12 up, 12 in; 270 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85761: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2883 GB used, 5507 GB / 8390 GB avail
            316232/973692 objects misplaced (32.478%)
                2802 active+clean
                 269 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24820 B/s rd, 81432 kB/s wr, 36 op/s rd, 10179 op/s wr
stdin: is not a tty

2017-06-09 10:47:09,687 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:47:09,688 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-09 10:48:09,748 INFO cluster.py [line:247] cost 60 seconds, left 1709 seconds when check the ceph status
2017-06-09 10:48:09,748 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:48:10,181 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            269 pgs backfill_wait
            1 pgs backfilling
            270 pgs stuck unclean
            Difference in osd space utilization 41.9109% greater than 40%
            recovery 315844/973692 objects misplaced (32.438%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7178: 12 osds: 12 up, 12 in; 270 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85815: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2885 GB used, 5505 GB / 8390 GB avail
            315844/973692 objects misplaced (32.438%)
                2802 active+clean
                 269 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 125 kB/s rd, 56412 kB/s wr, 157 op/s rd, 7051 op/s wr
stdin: is not a tty

2017-06-09 10:48:10,181 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:48:10,181 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-09 10:49:10,223 INFO cluster.py [line:247] cost 61 seconds, left 1648 seconds when check the ceph status
2017-06-09 10:49:10,224 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:49:10,605 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            267 pgs backfill_wait
            1 pgs backfilling
            268 pgs stuck unclean
            Difference in osd space utilization 41.9197% greater than 40%
            recovery 314539/972800 objects misplaced (32.333%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7182: 12 osds: 12 up, 12 in; 268 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85870: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2883 GB used, 5507 GB / 8390 GB avail
            314539/972800 objects misplaced (32.333%)
                2804 active+clean
                 267 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 91160 kB/s, 23 objects/s
  client io 131 kB/s rd, 65339 kB/s wr, 165 op/s rd, 8167 op/s wr
stdin: is not a tty

2017-06-09 10:49:10,606 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:49:10,606 INFO cluster.py [line:239] usefull PG number is 2804
2017-06-09 10:50:10,609 INFO cluster.py [line:247] cost 60 seconds, left 1588 seconds when check the ceph status
2017-06-09 10:50:10,610 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:50:11,017 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            267 pgs backfill_wait
            1 pgs backfilling
            268 pgs stuck unclean
            Difference in osd space utilization 41.9079% greater than 40%
            recovery 314236/972800 objects misplaced (32.302%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7182: 12 osds: 12 up, 12 in; 268 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85923: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2884 GB used, 5506 GB / 8390 GB avail
            314236/972800 objects misplaced (32.302%)
                2804 active+clean
                 267 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 92694 kB/s, 24 objects/s
  client io 100197 B/s rd, 68204 kB/s wr, 123 op/s rd, 8525 op/s wr
stdin: is not a tty

2017-06-09 10:50:11,017 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:50:11,017 INFO cluster.py [line:239] usefull PG number is 2804
2017-06-09 10:51:11,018 INFO cluster.py [line:247] cost 61 seconds, left 1527 seconds when check the ceph status
2017-06-09 10:51:11,018 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:51:11,425 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            266 pgs backfill_wait
            1 pgs backfilling
            267 pgs stuck unclean
            Difference in osd space utilization 41.9009% greater than 40%
            recovery 313201/972081 objects misplaced (32.220%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7184: 12 osds: 12 up, 12 in; 267 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v85977: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2883 GB used, 5507 GB / 8390 GB avail
            313201/972081 objects misplaced (32.220%)
                2805 active+clean
                 266 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 116 kB/s rd, 78587 kB/s wr, 146 op/s rd, 9823 op/s wr
stdin: is not a tty

2017-06-09 10:51:11,425 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:51:11,425 INFO cluster.py [line:239] usefull PG number is 2805
2017-06-09 10:52:11,461 INFO cluster.py [line:247] cost 60 seconds, left 1467 seconds when check the ceph status
2017-06-09 10:52:11,462 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:52:11,858 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            266 pgs backfill_wait
            1 pgs backfilling
            267 pgs stuck unclean
            Difference in osd space utilization 41.942% greater than 40%
            recovery 312842/972081 objects misplaced (32.183%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7184: 12 osds: 12 up, 12 in; 267 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86030: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2886 GB used, 5504 GB / 8390 GB avail
            312842/972081 objects misplaced (32.183%)
                2805 active+clean
                 266 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 153 kB/s rd, 75614 kB/s wr, 192 op/s rd, 9451 op/s wr
stdin: is not a tty

2017-06-09 10:52:11,858 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:52:11,859 INFO cluster.py [line:239] usefull PG number is 2805
2017-06-09 10:53:11,906 INFO cluster.py [line:247] cost 60 seconds, left 1407 seconds when check the ceph status
2017-06-09 10:53:11,906 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:53:12,269 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            266 pgs backfill_wait
            1 pgs backfilling
            267 pgs stuck unclean
            Difference in osd space utilization 41.9602% greater than 40%
            recovery 312502/972081 objects misplaced (32.148%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7184: 12 osds: 12 up, 12 in; 267 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86084: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2887 GB used, 5503 GB / 8390 GB avail
            312502/972081 objects misplaced (32.148%)
                2805 active+clean
                 266 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 114 MB/s wr, 0 op/s rd, 14633 op/s wr
stdin: is not a tty

2017-06-09 10:53:12,270 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:53:12,270 INFO cluster.py [line:239] usefull PG number is 2805
2017-06-09 10:54:12,295 INFO cluster.py [line:247] cost 61 seconds, left 1346 seconds when check the ceph status
2017-06-09 10:54:12,295 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:54:12,720 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            265 pgs backfill_wait
            1 pgs backfilling
            266 pgs stuck unclean
            Difference in osd space utilization 41.5337% greater than 40%
            recovery 311291/971257 objects misplaced (32.050%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7186: 12 osds: 12 up, 12 in; 266 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86139: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2886 GB used, 5504 GB / 8390 GB avail
            311291/971257 objects misplaced (32.050%)
                2806 active+clean
                 265 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 90760 kB/s, 23 objects/s
  client io 130 MB/s wr, 0 op/s rd, 16661 op/s wr
stdin: is not a tty

2017-06-09 10:54:12,721 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:54:12,721 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-09 10:55:12,777 INFO cluster.py [line:247] cost 60 seconds, left 1286 seconds when check the ceph status
2017-06-09 10:55:12,778 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:55:13,195 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            265 pgs backfill_wait
            1 pgs backfilling
            266 pgs stuck unclean
            Difference in osd space utilization 41.5533% greater than 40%
            recovery 310908/971257 objects misplaced (32.011%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7186: 12 osds: 12 up, 12 in; 266 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86193: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            310908/971257 objects misplaced (32.011%)
                2806 active+clean
                 265 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 104 MB/s, 28 objects/s
  client io 28199 B/s rd, 129 MB/s wr, 41 op/s rd, 16603 op/s wr
stdin: is not a tty

2017-06-09 10:55:13,195 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:55:13,195 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-09 10:56:13,246 INFO cluster.py [line:247] cost 61 seconds, left 1225 seconds when check the ceph status
2017-06-09 10:56:13,246 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:56:13,605 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            263 pgs backfill_wait
            1 pgs backfilling
            264 pgs stuck unclean
            Difference in osd space utilization 41.5569% greater than 40%
            recovery 309692/970395 objects misplaced (31.914%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7190: 12 osds: 12 up, 12 in; 264 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86249: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2886 GB used, 5504 GB / 8390 GB avail
            309692/970395 objects misplaced (31.914%)
                2808 active+clean
                 263 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 122 MB/s, 32 objects/s
  client io 33460 B/s rd, 172 MB/s wr, 49 op/s rd, 22043 op/s wr
stdin: is not a tty

2017-06-09 10:56:13,605 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:56:13,606 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-09 10:57:13,655 INFO cluster.py [line:247] cost 60 seconds, left 1165 seconds when check the ceph status
2017-06-09 10:57:13,656 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:57:13,994 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            263 pgs backfill_wait
            1 pgs backfilling
            264 pgs stuck unclean
            Difference in osd space utilization 41.5595% greater than 40%
            recovery 309306/970395 objects misplaced (31.874%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7190: 12 osds: 12 up, 12 in; 264 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86302: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            309306/970395 objects misplaced (31.874%)
                2808 active+clean
                 263 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 129 MB/s, 34 objects/s
  client io 30844 B/s rd, 117 MB/s wr, 45 op/s rd, 15008 op/s wr
stdin: is not a tty

2017-06-09 10:57:13,995 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:57:13,995 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-09 10:58:14,055 INFO cluster.py [line:247] cost 61 seconds, left 1104 seconds when check the ceph status
2017-06-09 10:58:14,055 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:58:14,426 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            262 pgs backfill_wait
            1 pgs backfilling
            263 pgs stuck unclean
            Difference in osd space utilization 41.5798% greater than 40%
            recovery 308001/969617 objects misplaced (31.765%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7192: 12 osds: 12 up, 12 in; 263 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86356: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            308001/969617 objects misplaced (31.765%)
                2809 active+clean
                 262 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 146 kB/s rd, 101 MB/s wr, 189 op/s rd, 12976 op/s wr
stdin: is not a tty

2017-06-09 10:58:14,427 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:58:14,427 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-09 10:59:14,486 INFO cluster.py [line:247] cost 60 seconds, left 1044 seconds when check the ceph status
2017-06-09 10:59:14,486 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 10:59:14,857 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            262 pgs backfill_wait
            1 pgs backfilling
            263 pgs stuck unclean
            Difference in osd space utilization 41.5772% greater than 40%
            recovery 307293/969617 objects misplaced (31.692%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7192: 12 osds: 12 up, 12 in; 263 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86410: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            307293/969617 objects misplaced (31.692%)
                2809 active+clean
                 262 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 192 kB/s rd, 56311 kB/s wr, 248 op/s rd, 7038 op/s wr
stdin: is not a tty

2017-06-09 10:59:14,857 INFO cluster.py [line:238] PG number is 3072
2017-06-09 10:59:14,857 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-09 11:00:14,916 INFO cluster.py [line:247] cost 60 seconds, left 984 seconds when check the ceph status
2017-06-09 11:00:14,916 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:00:15,287 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            260 pgs backfill_wait
            2 pgs backfilling
            262 pgs stuck unclean
            Difference in osd space utilization 41.6786% greater than 40%
            recovery 304934/968089 objects misplaced (31.499%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7194: 12 osds: 12 up, 12 in; 262 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86463: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            304934/968089 objects misplaced (31.499%)
                2810 active+clean
                 260 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 165 kB/s rd, 75246 kB/s wr, 214 op/s rd, 9405 op/s wr
stdin: is not a tty

2017-06-09 11:00:15,287 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:00:15,287 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-09 11:01:15,348 INFO cluster.py [line:247] cost 61 seconds, left 923 seconds when check the ceph status
2017-06-09 11:01:15,348 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:01:15,735 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            260 pgs backfill_wait
            2 pgs backfilling
            262 pgs stuck unclean
            Difference in osd space utilization 41.9362% greater than 40%
            recovery 304010/968089 objects misplaced (31.403%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7194: 12 osds: 12 up, 12 in; 262 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86516: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            304010/968089 objects misplaced (31.403%)
                2810 active+clean
                 260 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 124 kB/s rd, 70249 kB/s wr, 157 op/s rd, 8781 op/s wr
stdin: is not a tty

2017-06-09 11:01:15,735 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:01:15,735 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-09 11:02:15,768 INFO cluster.py [line:247] cost 60 seconds, left 863 seconds when check the ceph status
2017-06-09 11:02:15,768 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:02:16,154 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            258 pgs backfill_wait
            1 pgs backfilling
            259 pgs stuck unclean
            Difference in osd space utilization 41.616% greater than 40%
            recovery 301854/966453 objects misplaced (31.233%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7200: 12 osds: 12 up, 12 in; 259 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86571: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            301854/966453 objects misplaced (31.233%)
                2813 active+clean
                 258 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 95649 kB/s, 24 objects/s
  client io 126 kB/s rd, 56058 kB/s wr, 159 op/s rd, 7007 op/s wr
stdin: is not a tty

2017-06-09 11:02:16,155 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:02:16,155 INFO cluster.py [line:239] usefull PG number is 2813
2017-06-09 11:03:16,198 INFO cluster.py [line:247] cost 61 seconds, left 802 seconds when check the ceph status
2017-06-09 11:03:16,198 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:03:16,579 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            258 pgs backfill_wait
            1 pgs backfilling
            259 pgs stuck unclean
            Difference in osd space utilization 41.6559% greater than 40%
            recovery 301498/966453 objects misplaced (31.196%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7200: 12 osds: 12 up, 12 in; 259 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86624: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            301498/966453 objects misplaced (31.196%)
                2813 active+clean
                 258 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 97958 kB/s, 25 objects/s
  client io 126 kB/s rd, 76191 kB/s wr, 158 op/s rd, 9523 op/s wr
stdin: is not a tty

2017-06-09 11:03:16,579 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:03:16,579 INFO cluster.py [line:239] usefull PG number is 2813
2017-06-09 11:04:16,638 INFO cluster.py [line:247] cost 60 seconds, left 742 seconds when check the ceph status
2017-06-09 11:04:16,639 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:04:17,014 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            257 pgs backfill_wait
            1 pgs backfilling
            258 pgs stuck unclean
            Difference in osd space utilization 41.6144% greater than 40%
            recovery 300374/965699 objects misplaced (31.104%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7202: 12 osds: 12 up, 12 in; 258 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86679: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            300374/965699 objects misplaced (31.104%)
                2814 active+clean
                 257 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 114 MB/s, 30 objects/s
  client io 130 MB/s wr, 0 op/s rd, 16673 op/s wr
stdin: is not a tty

2017-06-09 11:04:17,014 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:04:17,015 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-09 11:05:17,075 INFO cluster.py [line:247] cost 61 seconds, left 681 seconds when check the ceph status
2017-06-09 11:05:17,075 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:05:17,480 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            257 pgs backfill_wait
            1 pgs backfilling
            258 pgs stuck unclean
            Difference in osd space utilization 41.6665% greater than 40%
            recovery 299870/965699 objects misplaced (31.052%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7202: 12 osds: 12 up, 12 in; 258 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86732: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            299870/965699 objects misplaced (31.052%)
                2814 active+clean
                 257 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 155 MB/s, 42 objects/s
  client io 30975 B/s rd, 169 MB/s wr, 45 op/s rd, 21632 op/s wr
stdin: is not a tty

2017-06-09 11:05:17,480 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:05:17,481 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-09 11:06:17,490 INFO cluster.py [line:247] cost 60 seconds, left 621 seconds when check the ceph status
2017-06-09 11:06:17,490 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:06:17,895 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            255 pgs backfill_wait
            1 pgs backfilling
            256 pgs stuck unclean
            Difference in osd space utilization 41.6447% greater than 40%
            recovery 298583/964862 objects misplaced (30.946%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7206: 12 osds: 12 up, 12 in; 256 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86786: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            298583/964862 objects misplaced (30.946%)
                2816 active+clean
                 255 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 97637 kB/s, 25 objects/s
  client io 139 MB/s wr, 0 op/s rd, 17863 op/s wr
stdin: is not a tty

2017-06-09 11:06:17,896 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:06:17,896 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-09 11:07:17,956 INFO cluster.py [line:247] cost 60 seconds, left 561 seconds when check the ceph status
2017-06-09 11:07:17,957 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:07:18,414 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            255 pgs backfill_wait
            1 pgs backfilling
            256 pgs stuck unclean
            Difference in osd space utilization 41.6529% greater than 40%
            recovery 298223/964862 objects misplaced (30.908%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7206: 12 osds: 12 up, 12 in; 256 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86840: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            298223/964862 objects misplaced (30.908%)
                2816 active+clean
                 255 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 107 MB/s, 28 objects/s
  client io 162 MB/s wr, 0 op/s rd, 20785 op/s wr
stdin: is not a tty

2017-06-09 11:07:18,415 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:07:18,415 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-09 11:08:18,442 INFO cluster.py [line:247] cost 61 seconds, left 500 seconds when check the ceph status
2017-06-09 11:08:18,442 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:08:18,797 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            252 pgs backfill_wait
            1 pgs backfilling
            253 pgs stuck unclean
            Difference in osd space utilization 41.6579% greater than 40%
            recovery 297023/963994 objects misplaced (30.812%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7212: 12 osds: 12 up, 12 in; 253 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86898: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            297023/963994 objects misplaced (30.812%)
                2819 active+clean
                 252 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 102 MB/s wr, 0 op/s rd, 13056 op/s wr
stdin: is not a tty

2017-06-09 11:08:18,798 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:08:18,798 INFO cluster.py [line:239] usefull PG number is 2819
2017-06-09 11:09:18,808 INFO cluster.py [line:247] cost 60 seconds, left 440 seconds when check the ceph status
2017-06-09 11:09:18,808 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:09:19,295 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            252 pgs backfill_wait
            1 pgs backfilling
            253 pgs stuck unclean
            Difference in osd space utilization 41.6501% greater than 40%
            recovery 296627/963994 objects misplaced (30.771%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7212: 12 osds: 12 up, 12 in; 253 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v86951: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            296627/963994 objects misplaced (30.771%)
                2819 active+clean
                 252 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 11:09:19,295 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:09:19,295 INFO cluster.py [line:239] usefull PG number is 2819
2017-06-09 11:10:19,356 INFO cluster.py [line:247] cost 61 seconds, left 379 seconds when check the ceph status
2017-06-09 11:10:19,356 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:10:19,782 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            247 pgs backfill_wait
            2 pgs backfilling
            249 pgs stuck unclean
            Difference in osd space utilization 41.6501% greater than 40%
            recovery 294547/963109 objects misplaced (30.583%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7218: 12 osds: 12 up, 12 in; 249 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87004: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            294547/963109 objects misplaced (30.583%)
                2823 active+clean
                 247 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 11:10:19,782 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:10:19,782 INFO cluster.py [line:239] usefull PG number is 2823
2017-06-09 11:11:19,837 INFO cluster.py [line:247] cost 60 seconds, left 319 seconds when check the ceph status
2017-06-09 11:11:19,837 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:11:20,259 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            244 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            246 pgs stuck unclean
            Difference in osd space utilization 41.4653% greater than 40%
            recovery 290329/960840 objects misplaced (30.216%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7224: 12 osds: 12 up, 12 in; 246 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87062: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            290329/960840 objects misplaced (30.216%)
                2825 active+clean
                 244 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 168 MB/s, 45 objects/s
  client io 1176 kB/s rd, 147 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:11:20,259 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:11:20,260 INFO cluster.py [line:239] usefull PG number is 2825
2017-06-09 11:12:20,320 INFO cluster.py [line:247] cost 61 seconds, left 258 seconds when check the ceph status
2017-06-09 11:12:20,320 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:12:20,731 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            242 pgs backfill_wait
            2 pgs backfilling
            244 pgs stuck unclean
            Difference in osd space utilization 40.6818% greater than 40%
            recovery 287159/959259 objects misplaced (29.936%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7228: 12 osds: 12 up, 12 in; 244 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87115: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            287159/959259 objects misplaced (29.936%)
                2828 active+clean
                 242 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 11:12:20,732 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:12:20,732 INFO cluster.py [line:239] usefull PG number is 2828
2017-06-09 11:13:20,766 INFO cluster.py [line:247] cost 60 seconds, left 198 seconds when check the ceph status
2017-06-09 11:13:20,766 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:13:21,175 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            240 pgs backfill_wait
            2 pgs backfilling
            242 pgs stuck unclean
            Difference in osd space utilization 40.2499% greater than 40%
            recovery 283464/957730 objects misplaced (29.597%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7232: 12 osds: 12 up, 12 in; 242 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87171: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            283464/957730 objects misplaced (29.597%)
                2830 active+clean
                 240 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 73035 B/s rd, 106 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:13:21,175 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:13:21,175 INFO cluster.py [line:239] usefull PG number is 2830
2017-06-09 11:14:21,234 INFO cluster.py [line:247] cost 61 seconds, left 137 seconds when check the ceph status
2017-06-09 11:14:21,234 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:14:21,649 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            236 pgs backfill_wait
            2 pgs backfilling
            238 pgs stuck unclean
            recovery 278291/954680 objects misplaced (29.150%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7239: 12 osds: 12 up, 12 in; 238 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87226: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            278291/954680 objects misplaced (29.150%)
                2834 active+clean
                 236 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 191 MB/s, 51 objects/s
  client io 106 kB/s rd, 134 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:14:21,649 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:14:21,649 INFO cluster.py [line:239] usefull PG number is 2834
2017-06-09 11:15:21,709 INFO cluster.py [line:247] cost 60 seconds, left 77 seconds when check the ceph status
2017-06-09 11:15:21,710 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:15:22,131 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            234 pgs backfill_wait
            2 pgs backfilling
            236 pgs stuck unclean
            recovery 274655/953192 objects misplaced (28.814%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7243: 12 osds: 12 up, 12 in; 236 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87278: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            274655/953192 objects misplaced (28.814%)
                2836 active+clean
                 234 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 757 MB/s, 206 objects/s
stdin: is not a tty

2017-06-09 11:15:22,131 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:15:22,131 INFO cluster.py [line:239] usefull PG number is 2836
2017-06-09 11:16:22,192 INFO cluster.py [line:247] cost 61 seconds, left 16 seconds when check the ceph status
2017-06-09 11:16:22,192 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:16:22,577 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            228 pgs backfill_wait
            3 pgs backfilling
            231 pgs stuck unclean
            recovery 269827/950669 objects misplaced (28.383%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7251: 12 osds: 12 up, 12 in; 231 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87332: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            269827/950669 objects misplaced (28.383%)
                2841 active+clean
                 228 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 576 MB/s, 151 objects/s
stdin: is not a tty

2017-06-09 11:16:22,577 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:16:22,577 INFO cluster.py [line:239] usefull PG number is 2841
2017-06-09 11:17:22,614 INFO cluster.py [line:247] cost 60 seconds, left -44 seconds when check the ceph status
2017-06-09 11:17:22,615 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:85] status is HEALTH_ERROR
2017-06-09 11:17:22,615 ERROR TC47_48_49_50_51_remove_osds_on_single_node.py [line:86] TC47_48_49_50_51_remove_osds_on_single_node  runs failed
2017-06-09 11:17:22,615 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:17:23,112 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            224 pgs backfill_wait
            3 pgs backfilling
            227 pgs stuck unclean
            recovery 265150/948303 objects misplaced (27.960%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7258: 12 osds: 12 up, 12 in; 227 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87388: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            265150/948303 objects misplaced (27.960%)
                2845 active+clean
                 224 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 615 MB/s, 162 objects/s
  client io 4438 MB/s rd, 554 kop/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:17:23,112 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:17:23,113 INFO cluster.py [line:239] usefull PG number is 2845
2017-06-09 11:18:23,125 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-09 11:18:23,125 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:18:23,494 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            220 pgs backfill_wait
            3 pgs backfilling
            223 pgs stuck unclean
            recovery 261273/946668 objects misplaced (27.599%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7266: 12 osds: 12 up, 12 in; 223 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87445: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5496 GB / 8390 GB avail
            261273/946668 objects misplaced (27.599%)
                2849 active+clean
                 220 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 603 MB/s, 161 objects/s
  client io 64238 kB/s rd, 8029 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:18:23,494 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:18:23,494 INFO cluster.py [line:239] usefull PG number is 2849
2017-06-09 11:19:23,542 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-09 11:19:23,542 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:19:23,968 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            218 pgs backfill_wait
            2 pgs backfilling
            220 pgs stuck unclean
            recovery 256655/944383 objects misplaced (27.177%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7272: 12 osds: 12 up, 12 in; 220 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87503: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            256655/944383 objects misplaced (27.177%)
                2852 active+clean
                 218 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 228 MB/s, 61 objects/s
  client io 44525 kB/s rd, 5565 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:19:23,968 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:19:23,968 INFO cluster.py [line:239] usefull PG number is 2852
2017-06-09 11:20:24,005 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-09 11:20:24,005 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:20:24,392 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            215 pgs backfill_wait
            2 pgs backfilling
            217 pgs stuck unclean
            recovery 252829/942785 objects misplaced (26.817%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7278: 12 osds: 12 up, 12 in; 217 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87559: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2896 GB used, 5494 GB / 8390 GB avail
            252829/942785 objects misplaced (26.817%)
                2855 active+clean
                 215 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 329 MB/s, 89 objects/s
  client io 48937 kB/s rd, 6117 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:20:24,392 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:20:24,392 INFO cluster.py [line:239] usefull PG number is 2855
2017-06-09 11:21:24,415 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-09 11:21:24,415 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:21:24,807 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            212 pgs backfill_wait
            2 pgs backfilling
            214 pgs stuck unclean
            recovery 248826/940482 objects misplaced (26.457%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7286: 12 osds: 12 up, 12 in; 213 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87616: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            248826/940482 objects misplaced (26.457%)
                2858 active+clean
                 212 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 22815 kB/s rd, 3044 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:21:24,807 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:21:24,807 INFO cluster.py [line:239] usefull PG number is 2858
2017-06-09 11:22:24,868 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-09 11:22:24,868 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:22:25,274 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            210 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            211 pgs stuck unclean
            recovery 245024/938234 objects misplaced (26.115%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7291: 12 osds: 12 up, 12 in; 209 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87671: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            245024/938234 objects misplaced (26.115%)
                2860 active+clean
                 210 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 39896 kB/s, 10 objects/s
  client io 7857 kB/s rd, 1113 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:22:25,274 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:22:25,274 INFO cluster.py [line:239] usefull PG number is 2860
2017-06-09 11:23:25,334 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-09 11:23:25,335 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:23:25,751 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            202 pgs backfill_wait
            2 pgs backfilling
            204 pgs stuck unclean
            recovery 240298/935762 objects misplaced (25.679%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7300: 12 osds: 12 up, 12 in; 204 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87730: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            240298/935762 objects misplaced (25.679%)
                2868 active+clean
                 202 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 34229 kB/s rd, 4438 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:23:25,751 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:23:25,751 INFO cluster.py [line:239] usefull PG number is 2868
2017-06-09 11:24:25,812 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-09 11:24:25,812 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:24:26,194 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            200 pgs backfill_wait
            1 pgs backfilling
            201 pgs stuck unclean
            recovery 237136/934117 objects misplaced (25.386%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7304: 12 osds: 12 up, 12 in; 201 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87785: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            237136/934117 objects misplaced (25.386%)
                2871 active+clean
                 200 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 254 MB/s, 68 objects/s
  client io 31759 kB/s rd, 4190 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:24:26,195 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:24:26,195 INFO cluster.py [line:239] usefull PG number is 2871
2017-06-09 11:25:26,211 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-09 11:25:26,211 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:25:26,631 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            199 pgs backfill_wait
            1 pgs backfilling
            200 pgs stuck unclean
            recovery 235502/933325 objects misplaced (25.233%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7306: 12 osds: 12 up, 12 in; 200 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87839: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            235502/933325 objects misplaced (25.233%)
                2872 active+clean
                 199 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 34785 kB/s rd, 4538 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:25:26,631 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:25:26,631 INFO cluster.py [line:239] usefull PG number is 2872
2017-06-09 11:26:26,692 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-09 11:26:26,692 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:26:27,099 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            198 pgs backfill_wait
            1 pgs backfilling
            199 pgs stuck unclean
            recovery 233944/932562 objects misplaced (25.086%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7308: 12 osds: 12 up, 12 in; 199 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87894: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            233944/932562 objects misplaced (25.086%)
                2873 active+clean
                 198 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 215 MB/s, 57 objects/s
  client io 46353 kB/s rd, 5794 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:26:27,099 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:26:27,099 INFO cluster.py [line:239] usefull PG number is 2873
2017-06-09 11:27:27,159 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-09 11:27:27,160 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:27:27,547 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            197 pgs backfill_wait
            1 pgs backfilling
            198 pgs stuck unclean
            recovery 232491/931819 objects misplaced (24.950%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7310: 12 osds: 12 up, 12 in; 198 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v87947: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            232491/931819 objects misplaced (24.950%)
                2874 active+clean
                 197 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 47680 kB/s rd, 6000 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:27:27,548 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:27:27,548 INFO cluster.py [line:239] usefull PG number is 2874
2017-06-09 11:28:27,601 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-09 11:28:27,601 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:28:27,981 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            196 pgs backfill_wait
            1 pgs backfilling
            197 pgs stuck unclean
            recovery 230916/931051 objects misplaced (24.802%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7312: 12 osds: 12 up, 12 in; 197 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88002: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            230916/931051 objects misplaced (24.802%)
                2875 active+clean
                 196 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 206 MB/s, 55 objects/s
  client io 54277 kB/s rd, 6784 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:28:27,981 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:28:27,981 INFO cluster.py [line:239] usefull PG number is 2875
2017-06-09 11:29:28,038 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-09 11:29:28,038 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:29:28,442 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            192 pgs backfill_wait
            2 pgs backfilling
            194 pgs stuck unclean
            recovery 228144/930279 objects misplaced (24.524%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7316: 12 osds: 12 up, 12 in; 194 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88057: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            228144/930279 objects misplaced (24.524%)
                2878 active+clean
                 192 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 365 MB/s, 100 objects/s
  client io 61664 kB/s rd, 7708 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:29:28,442 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:29:28,442 INFO cluster.py [line:239] usefull PG number is 2878
2017-06-09 11:30:28,470 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-09 11:30:28,470 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:30:28,873 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            190 pgs backfill_wait
            2 pgs backfilling
            192 pgs stuck unclean
            recovery 224231/928024 objects misplaced (24.162%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7320: 12 osds: 12 up, 12 in; 192 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88112: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            224231/928024 objects misplaced (24.162%)
                2880 active+clean
                 190 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 442 MB/s, 117 objects/s
  client io 51394 kB/s rd, 6424 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:30:28,874 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:30:28,874 INFO cluster.py [line:239] usefull PG number is 2880
2017-06-09 11:31:28,934 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-09 11:31:28,934 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:31:29,381 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            187 pgs backfill_wait
            2 pgs backfilling
            189 pgs stuck unclean
            recovery 220938/926413 objects misplaced (23.849%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7327: 12 osds: 12 up, 12 in; 188 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88172: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            220938/926413 objects misplaced (23.849%)
                2883 active+clean
                 187 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 9718 kB/s rd, 1214 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:31:29,381 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:31:29,381 INFO cluster.py [line:239] usefull PG number is 2883
2017-06-09 11:32:29,433 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-09 11:32:29,433 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:32:29,895 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            184 pgs backfill_wait
            2 pgs backfilling
            186 pgs stuck unclean
            recovery 217812/924825 objects misplaced (23.552%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7332: 12 osds: 12 up, 12 in; 186 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88227: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            217812/924825 objects misplaced (23.552%)
                2886 active+clean
                 184 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 396 MB/s, 105 objects/s
  client io 46164 kB/s rd, 5770 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:32:29,895 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:32:29,896 INFO cluster.py [line:239] usefull PG number is 2886
2017-06-09 11:33:29,946 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-09 11:33:29,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:33:30,336 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            177 pgs backfill_wait
            2 pgs backfilling
            179 pgs stuck unclean
            recovery 214464/923027 objects misplaced (23.235%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7344: 12 osds: 12 up, 12 in; 179 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88288: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            214464/923027 objects misplaced (23.235%)
                2893 active+clean
                 177 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 19898 kB/s rd, 2635 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:33:30,336 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:33:30,336 INFO cluster.py [line:239] usefull PG number is 2893
2017-06-09 11:34:30,394 INFO cluster.py [line:247] cost 61 seconds, left 4972 seconds when check the ceph status
2017-06-09 11:34:30,394 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:34:30,753 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            175 pgs backfill_wait
            2 pgs backfilling
            177 pgs stuck unclean
            recovery 211316/921453 objects misplaced (22.933%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7348: 12 osds: 12 up, 12 in; 177 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88344: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            211316/921453 objects misplaced (22.933%)
                2895 active+clean
                 175 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 22298 kB/s rd, 2976 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:34:30,754 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:34:30,754 INFO cluster.py [line:239] usefull PG number is 2895
2017-06-09 11:35:30,814 INFO cluster.py [line:247] cost 60 seconds, left 4912 seconds when check the ceph status
2017-06-09 11:35:30,814 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:35:31,210 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            169 pgs backfill_wait
            2 pgs backfilling
            171 pgs stuck unclean
            recovery 207866/919534 objects misplaced (22.606%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7360: 12 osds: 12 up, 12 in; 171 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88402: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            207866/919534 objects misplaced (22.606%)
                2901 active+clean
                 169 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 32976 kB/s rd, 4155 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:35:31,211 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:35:31,211 INFO cluster.py [line:239] usefull PG number is 2901
2017-06-09 11:36:31,247 INFO cluster.py [line:247] cost 61 seconds, left 4851 seconds when check the ceph status
2017-06-09 11:36:31,248 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:36:31,671 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            167 pgs backfill_wait
            2 pgs backfilling
            169 pgs stuck unclean
            recovery 204217/917935 objects misplaced (22.247%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7364: 12 osds: 12 up, 12 in; 169 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88458: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            204217/917935 objects misplaced (22.247%)
                2903 active+clean
                 167 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 2519 kB/s rd, 346 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:36:31,672 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:36:31,672 INFO cluster.py [line:239] usefull PG number is 2903
2017-06-09 11:37:31,678 INFO cluster.py [line:247] cost 60 seconds, left 4791 seconds when check the ceph status
2017-06-09 11:37:31,678 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:37:32,108 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            166 pgs backfill_wait
            1 pgs backfilling
            167 pgs stuck unclean
            recovery 199798/915556 objects misplaced (21.823%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7367: 12 osds: 12 up, 12 in; 167 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88510: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            199798/915556 objects misplaced (21.823%)
                2905 active+clean
                 166 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 201 MB/s, 54 objects/s
  client io 3421 kB/s rd, 427 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:37:32,108 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:37:32,108 INFO cluster.py [line:239] usefull PG number is 2905
2017-06-09 11:38:32,140 INFO cluster.py [line:247] cost 61 seconds, left 4730 seconds when check the ceph status
2017-06-09 11:38:32,140 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:38:32,523 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            163 pgs backfill_wait
            1 pgs backfilling
            164 pgs stuck unclean
            recovery 197456/914613 objects misplaced (21.589%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7372: 12 osds: 12 up, 12 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88566: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            197456/914613 objects misplaced (21.589%)
                2908 active+clean
                 163 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 237 MB/s, 64 objects/s
  client io 1542 kB/s rd, 192 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:38:32,524 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:38:32,524 INFO cluster.py [line:239] usefull PG number is 2908
2017-06-09 11:39:32,584 INFO cluster.py [line:247] cost 60 seconds, left 4670 seconds when check the ceph status
2017-06-09 11:39:32,584 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:39:32,935 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            160 pgs backfill_wait
            2 pgs backfilling
            162 pgs stuck unclean
            recovery 194473/913005 objects misplaced (21.300%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7379: 12 osds: 12 up, 12 in; 160 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88620: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            194473/913005 objects misplaced (21.300%)
                2910 active+clean
                 160 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 41845 kB/s, 10 objects/s
  client io 22891 kB/s rd, 2861 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:39:32,935 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:39:32,935 INFO cluster.py [line:239] usefull PG number is 2910
2017-06-09 11:40:32,996 INFO cluster.py [line:247] cost 60 seconds, left 4610 seconds when check the ceph status
2017-06-09 11:40:32,996 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:40:33,396 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            158 pgs backfill_wait
            1 pgs backfilling
            159 pgs stuck unclean
            recovery 192039/911443 objects misplaced (21.070%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7382: 12 osds: 12 up, 12 in; 159 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88675: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            192039/911443 objects misplaced (21.070%)
                2913 active+clean
                 158 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 292 MB/s, 78 objects/s
  client io 15466 kB/s rd, 1933 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:40:33,396 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:40:33,397 INFO cluster.py [line:239] usefull PG number is 2913
2017-06-09 11:41:33,403 INFO cluster.py [line:247] cost 61 seconds, left 4549 seconds when check the ceph status
2017-06-09 11:41:33,403 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:41:33,794 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            155 pgs backfill_wait
            3 pgs backfilling
            158 pgs stuck unclean
            recovery 190467/910692 objects misplaced (20.915%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7386: 12 osds: 12 up, 12 in; 157 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88726: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            190467/910692 objects misplaced (20.915%)
                2914 active+clean
                 155 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 413 MB/s, 111 objects/s
  client io 18544 kB/s rd, 2318 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:41:33,795 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:41:33,795 INFO cluster.py [line:239] usefull PG number is 2914
2017-06-09 11:42:33,813 INFO cluster.py [line:247] cost 60 seconds, left 4489 seconds when check the ceph status
2017-06-09 11:42:33,813 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:42:34,224 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            149 pgs backfill_wait
            2 pgs backfilling
            152 pgs stuck unclean
            recovery 184238/908128 objects misplaced (20.288%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7396: 12 osds: 12 up, 12 in; 151 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88782: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            184238/908128 objects misplaced (20.288%)
                2920 active+clean
                 149 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 372 MB/s, 99 objects/s
  client io 4074 kB/s rd, 509 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:42:34,224 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:42:34,225 INFO cluster.py [line:239] usefull PG number is 2920
2017-06-09 11:43:34,246 INFO cluster.py [line:247] cost 61 seconds, left 4428 seconds when check the ceph status
2017-06-09 11:43:34,246 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:43:34,659 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            145 pgs backfill_wait
            2 pgs backfilling
            147 pgs stuck unclean
            recovery 179011/905009 objects misplaced (19.780%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7402: 12 osds: 12 up, 12 in; 147 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88839: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            179011/905009 objects misplaced (19.780%)
                2925 active+clean
                 145 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 336 MB/s, 89 objects/s
  client io 7174 kB/s rd, 896 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:43:34,660 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:43:34,660 INFO cluster.py [line:239] usefull PG number is 2925
2017-06-09 11:44:34,720 INFO cluster.py [line:247] cost 60 seconds, left 4368 seconds when check the ceph status
2017-06-09 11:44:34,720 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:44:35,108 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            141 pgs backfill_wait
            3 pgs backfilling
            144 pgs stuck unclean
            recovery 173614/902645 objects misplaced (19.234%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7408: 12 osds: 12 up, 12 in; 144 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88892: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            173614/902645 objects misplaced (19.234%)
                2928 active+clean
                 141 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 775 MB/s, 211 objects/s
  client io 1206 kB/s rd, 150 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:44:35,109 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:44:35,109 INFO cluster.py [line:239] usefull PG number is 2928
2017-06-09 11:45:35,153 INFO cluster.py [line:247] cost 61 seconds, left 4307 seconds when check the ceph status
2017-06-09 11:45:35,153 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:45:35,529 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            137 pgs backfill_wait
            3 pgs backfilling
            140 pgs stuck unclean
            recovery 165463/898742 objects misplaced (18.411%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7419: 12 osds: 12 up, 12 in; 138 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v88951: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5495 GB / 8390 GB avail
            165463/898742 objects misplaced (18.411%)
                2932 active+clean
                 137 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 641 MB/s, 171 objects/s
  client io 20937 kB/s rd, 2617 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:45:35,529 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:45:35,530 INFO cluster.py [line:239] usefull PG number is 2932
2017-06-09 11:46:35,562 INFO cluster.py [line:247] cost 60 seconds, left 4247 seconds when check the ceph status
2017-06-09 11:46:35,562 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:46:35,936 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            129 pgs backfill_wait
            3 pgs backfilling
            132 pgs stuck unclean
            recovery 154593/893381 objects misplaced (17.304%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7431: 12 osds: 12 up, 12 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89010: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            154593/893381 objects misplaced (17.304%)
                2940 active+clean
                 129 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 576 MB/s, 155 objects/s
  client io 31886 kB/s rd, 4140 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:46:35,936 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:46:35,936 INFO cluster.py [line:239] usefull PG number is 2940
2017-06-09 11:47:35,996 INFO cluster.py [line:247] cost 60 seconds, left 4187 seconds when check the ceph status
2017-06-09 11:47:35,997 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:47:36,426 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            126 pgs backfill_wait
            3 pgs backfilling
            129 pgs stuck unclean
            recovery 148787/890323 objects misplaced (16.712%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7437: 12 osds: 12 up, 12 in; 129 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89066: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            148787/890323 objects misplaced (16.712%)
                2943 active+clean
                 126 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 218 MB/s, 58 objects/s
  client io 29997 kB/s rd, 3875 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:47:36,426 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:47:36,426 INFO cluster.py [line:239] usefull PG number is 2943
2017-06-09 11:48:36,474 INFO cluster.py [line:247] cost 61 seconds, left 4126 seconds when check the ceph status
2017-06-09 11:48:36,475 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:48:36,864 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            119 pgs backfill_wait
            2 pgs backfilling
            121 pgs stuck unclean
            recovery 143468/887814 objects misplaced (16.160%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7449: 12 osds: 12 up, 12 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89123: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            143468/887814 objects misplaced (16.160%)
                2951 active+clean
                 119 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 375 MB/s, 101 objects/s
  client io 30214 kB/s rd, 3866 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:48:36,865 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:48:36,865 INFO cluster.py [line:239] usefull PG number is 2951
2017-06-09 11:49:36,922 INFO cluster.py [line:247] cost 60 seconds, left 4066 seconds when check the ceph status
2017-06-09 11:49:36,922 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:49:37,321 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            111 pgs backfill_wait
            4 pgs backfilling
            116 pgs stuck unclean
            recovery 134416/883831 objects misplaced (15.208%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7461: 12 osds: 12 up, 12 in; 115 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89182: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2896 GB used, 5494 GB / 8390 GB avail
            134416/883831 objects misplaced (15.208%)
                2956 active+clean
                 111 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 active+remapped
recovery io 875 MB/s, 238 objects/s
  client io 24695 kB/s rd, 3230 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:49:37,322 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:49:37,322 INFO cluster.py [line:239] usefull PG number is 2956
2017-06-09 11:50:37,382 INFO cluster.py [line:247] cost 61 seconds, left 4005 seconds when check the ceph status
2017-06-09 11:50:37,382 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:50:37,784 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            105 pgs backfill_wait
            2 pgs backfilling
            107 pgs stuck unclean
            recovery 127663/879753 objects misplaced (14.511%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7477: 12 osds: 12 up, 12 in; 107 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89244: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            127663/879753 objects misplaced (14.511%)
                2965 active+clean
                 105 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 214 MB/s, 58 objects/s
  client io 53385 kB/s rd, 6810 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:50:37,785 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:50:37,785 INFO cluster.py [line:239] usefull PG number is 2965
2017-06-09 11:51:37,845 INFO cluster.py [line:247] cost 60 seconds, left 3945 seconds when check the ceph status
2017-06-09 11:51:37,846 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:51:38,225 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            101 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            103 pgs stuck unclean
            recovery 120395/875890 objects misplaced (13.745%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7485: 12 osds: 12 up, 12 in; 102 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89298: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            120395/875890 objects misplaced (13.745%)
                2968 active+clean
                 101 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 164 MB/s, 44 objects/s
stdin: is not a tty

2017-06-09 11:51:38,226 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:51:38,226 INFO cluster.py [line:239] usefull PG number is 2968
2017-06-09 11:52:38,228 INFO cluster.py [line:247] cost 61 seconds, left 3884 seconds when check the ceph status
2017-06-09 11:52:38,228 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:52:38,624 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            96 pgs backfill_wait
            3 pgs backfilling
            99 pgs stuck unclean
            recovery 113297/872693 objects misplaced (12.982%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7492: 12 osds: 12 up, 12 in; 99 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89353: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            113297/872693 objects misplaced (12.982%)
                2973 active+clean
                  96 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 554 MB/s, 151 objects/s
  client io 29327 kB/s rd, 3665 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:52:38,624 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:52:38,624 INFO cluster.py [line:239] usefull PG number is 2973
2017-06-09 11:53:38,685 INFO cluster.py [line:247] cost 60 seconds, left 3824 seconds when check the ceph status
2017-06-09 11:53:38,685 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:53:39,116 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            93 pgs backfill_wait
            2 pgs backfilling
            95 pgs stuck unclean
            recovery 107477/869615 objects misplaced (12.359%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7500: 12 osds: 12 up, 12 in; 95 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89413: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            107477/869615 objects misplaced (12.359%)
                2977 active+clean
                  93 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 614 MB/s, 164 objects/s
  client io 39839 kB/s rd, 4979 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:53:39,117 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:53:39,117 INFO cluster.py [line:239] usefull PG number is 2977
2017-06-09 11:54:39,177 INFO cluster.py [line:247] cost 61 seconds, left 3763 seconds when check the ceph status
2017-06-09 11:54:39,177 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:54:39,595 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            87 pgs backfill_wait
            1 pgs backfilling
            88 pgs stuck unclean
            recovery 101506/866211 objects misplaced (11.718%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7511: 12 osds: 12 up, 12 in; 88 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89471: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            101506/866211 objects misplaced (11.718%)
                2984 active+clean
                  87 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 216 MB/s, 57 objects/s
  client io 32080 kB/s rd, 4010 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:54:39,595 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:54:39,595 INFO cluster.py [line:239] usefull PG number is 2984
2017-06-09 11:55:39,625 INFO cluster.py [line:247] cost 60 seconds, left 3703 seconds when check the ceph status
2017-06-09 11:55:39,625 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:55:40,029 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            86 pgs backfill_wait
            1 pgs backfilling
            87 pgs stuck unclean
            recovery 99916/865425 objects misplaced (11.545%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7513: 12 osds: 12 up, 12 in; 87 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89524: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            99916/865425 objects misplaced (11.545%)
                2985 active+clean
                  86 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 221 MB/s, 59 objects/s
  client io 25250 kB/s rd, 3156 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:55:40,029 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:55:40,029 INFO cluster.py [line:239] usefull PG number is 2985
2017-06-09 11:56:40,087 INFO cluster.py [line:247] cost 61 seconds, left 3642 seconds when check the ceph status
2017-06-09 11:56:40,087 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:56:40,583 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            85 pgs backfill_wait
            1 pgs backfilling
            86 pgs stuck unclean
            recovery 98360/864643 objects misplaced (11.376%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7515: 12 osds: 12 up, 12 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89577: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            98360/864643 objects misplaced (11.376%)
                2986 active+clean
                  85 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 3412 kB/s rd, 457 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:56:40,584 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:56:40,584 INFO cluster.py [line:239] usefull PG number is 2986
2017-06-09 11:57:40,596 INFO cluster.py [line:247] cost 60 seconds, left 3582 seconds when check the ceph status
2017-06-09 11:57:40,596 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:57:40,988 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            84 pgs backfill_wait
            1 pgs backfilling
            85 pgs stuck unclean
            recovery 96737/863835 objects misplaced (11.199%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7517: 12 osds: 12 up, 12 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89630: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            96737/863835 objects misplaced (11.199%)
                2987 active+clean
                  84 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 57 objects/s
  client io 6193 kB/s rd, 774 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:57:40,988 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:57:40,988 INFO cluster.py [line:239] usefull PG number is 2987
2017-06-09 11:58:41,030 INFO cluster.py [line:247] cost 61 seconds, left 3521 seconds when check the ceph status
2017-06-09 11:58:41,030 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:58:41,446 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            82 pgs backfill_wait
            1 pgs backfilling
            83 pgs stuck unclean
            recovery 95118/863001 objects misplaced (11.022%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7521: 12 osds: 12 up, 12 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89684: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            95118/863001 objects misplaced (11.022%)
                2989 active+clean
                  82 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 282 MB/s, 74 objects/s
  client io 25299 kB/s rd, 3162 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:58:41,446 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:58:41,447 INFO cluster.py [line:239] usefull PG number is 2989
2017-06-09 11:59:41,470 INFO cluster.py [line:247] cost 60 seconds, left 3461 seconds when check the ceph status
2017-06-09 11:59:41,471 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 11:59:41,863 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            81 pgs backfill_wait
            1 pgs backfilling
            82 pgs stuck unclean
            recovery 93566/862229 objects misplaced (10.852%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7523: 12 osds: 12 up, 12 in; 82 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89739: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            93566/862229 objects misplaced (10.852%)
                2990 active+clean
                  81 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 4728 kB/s rd, 591 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 11:59:41,864 INFO cluster.py [line:238] PG number is 3072
2017-06-09 11:59:41,864 INFO cluster.py [line:239] usefull PG number is 2990
2017-06-09 12:00:41,902 INFO cluster.py [line:247] cost 60 seconds, left 3401 seconds when check the ceph status
2017-06-09 12:00:41,902 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:00:42,273 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            80 pgs backfill_wait
            1 pgs backfilling
            81 pgs stuck unclean
            recovery 91984/861462 objects misplaced (10.678%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7525: 12 osds: 12 up, 12 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89791: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            91984/861462 objects misplaced (10.678%)
                2991 active+clean
                  80 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 28808 kB/s rd, 3601 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:00:42,273 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:00:42,274 INFO cluster.py [line:239] usefull PG number is 2991
2017-06-09 12:01:42,334 INFO cluster.py [line:247] cost 61 seconds, left 3340 seconds when check the ceph status
2017-06-09 12:01:42,334 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:01:42,728 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            78 pgs backfill_wait
            1 pgs backfilling
            79 pgs stuck unclean
            recovery 90291/860615 objects misplaced (10.491%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7529: 12 osds: 12 up, 12 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89843: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            90291/860615 objects misplaced (10.491%)
                2993 active+clean
                  78 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 12:01:42,729 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:01:42,729 INFO cluster.py [line:239] usefull PG number is 2993
2017-06-09 12:02:42,765 INFO cluster.py [line:247] cost 60 seconds, left 3280 seconds when check the ceph status
2017-06-09 12:02:42,765 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:02:43,185 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            77 pgs backfill_wait
            1 pgs backfilling
            78 pgs stuck unclean
            recovery 88384/859881 objects misplaced (10.279%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7531: 12 osds: 12 up, 12 in; 78 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89895: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            88384/859881 objects misplaced (10.279%)
                2994 active+clean
                  77 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 6483 kB/s rd, 903 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:02:43,186 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:02:43,186 INFO cluster.py [line:239] usefull PG number is 2994
2017-06-09 12:03:43,191 INFO cluster.py [line:247] cost 61 seconds, left 3219 seconds when check the ceph status
2017-06-09 12:03:43,191 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:03:43,644 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            74 pgs backfill_wait
            2 pgs backfilling
            76 pgs stuck unclean
            recovery 85225/858344 objects misplaced (9.929%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7536: 12 osds: 12 up, 12 in; 75 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v89951: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            85225/858344 objects misplaced (9.929%)
                2996 active+clean
                  74 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 104 MB/s, 27 objects/s
  client io 18735 kB/s rd, 2341 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:03:43,645 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:03:43,645 INFO cluster.py [line:239] usefull PG number is 2996
2017-06-09 12:04:43,654 INFO cluster.py [line:247] cost 60 seconds, left 3159 seconds when check the ceph status
2017-06-09 12:04:43,654 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:04:44,079 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            73 pgs backfill_wait
            1 pgs backfilling
            74 pgs stuck unclean
            recovery 82900/856874 objects misplaced (9.675%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7538: 12 osds: 12 up, 12 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90002: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            82900/856874 objects misplaced (9.675%)
                2998 active+clean
                  73 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 146 MB/s, 39 objects/s
  client io 55454 kB/s rd, 6931 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:04:44,080 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:04:44,080 INFO cluster.py [line:239] usefull PG number is 2998
2017-06-09 12:05:44,140 INFO cluster.py [line:247] cost 61 seconds, left 3098 seconds when check the ceph status
2017-06-09 12:05:44,140 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:05:44,544 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            72 pgs backfill_wait
            1 pgs backfilling
            73 pgs stuck unclean
            recovery 81156/856100 objects misplaced (9.480%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7540: 12 osds: 12 up, 12 in; 73 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90056: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            81156/856100 objects misplaced (9.480%)
                2999 active+clean
                  72 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 356 MB/s, 97 objects/s
  client io 48714 kB/s rd, 6089 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:05:44,544 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:05:44,544 INFO cluster.py [line:239] usefull PG number is 2999
2017-06-09 12:06:44,604 INFO cluster.py [line:247] cost 60 seconds, left 3038 seconds when check the ceph status
2017-06-09 12:06:44,605 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:06:45,001 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            69 pgs backfill_wait
            1 pgs backfilling
            70 pgs stuck unclean
            recovery 78029/854466 objects misplaced (9.132%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7544: 12 osds: 12 up, 12 in; 70 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90112: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            78029/854466 objects misplaced (9.132%)
                3002 active+clean
                  69 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 30507 kB/s rd, 3813 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:06:45,001 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:06:45,001 INFO cluster.py [line:239] usefull PG number is 3002
2017-06-09 12:07:45,057 INFO cluster.py [line:247] cost 61 seconds, left 2977 seconds when check the ceph status
2017-06-09 12:07:45,058 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:07:45,428 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            68 pgs backfill_wait
            1 pgs backfilling
            69 pgs stuck unclean
            recovery 76393/853623 objects misplaced (8.949%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7546: 12 osds: 12 up, 12 in; 69 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90164: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            76393/853623 objects misplaced (8.949%)
                3003 active+clean
                  68 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 229 MB/s, 61 objects/s
  client io 40518 kB/s rd, 5064 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:07:45,429 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:07:45,429 INFO cluster.py [line:239] usefull PG number is 3003
2017-06-09 12:08:45,451 INFO cluster.py [line:247] cost 60 seconds, left 2917 seconds when check the ceph status
2017-06-09 12:08:45,451 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:08:45,857 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            67 pgs backfill_wait
            1 pgs backfilling
            68 pgs stuck unclean
            recovery 74830/852842 objects misplaced (8.774%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7548: 12 osds: 12 up, 12 in; 68 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90217: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            74830/852842 objects misplaced (8.774%)
                3004 active+clean
                  67 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 23308 kB/s rd, 2939 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:08:45,858 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:08:45,858 INFO cluster.py [line:239] usefull PG number is 3004
2017-06-09 12:09:45,912 INFO cluster.py [line:247] cost 60 seconds, left 2857 seconds when check the ceph status
2017-06-09 12:09:45,913 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:09:46,307 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            66 pgs backfill_wait
            1 pgs backfilling
            67 pgs stuck unclean
            recovery 73209/852058 objects misplaced (8.592%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7550: 12 osds: 12 up, 12 in; 67 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90270: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            73209/852058 objects misplaced (8.592%)
                3005 active+clean
                  66 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 146 MB/s, 39 objects/s
  client io 35052 kB/s rd, 4472 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:09:46,308 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:09:46,308 INFO cluster.py [line:239] usefull PG number is 3005
2017-06-09 12:10:46,356 INFO cluster.py [line:247] cost 61 seconds, left 2796 seconds when check the ceph status
2017-06-09 12:10:46,357 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:10:46,786 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            65 pgs backfill_wait
            1 pgs backfilling
            66 pgs stuck unclean
            recovery 71705/851332 objects misplaced (8.423%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7552: 12 osds: 12 up, 12 in; 66 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90320: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            71705/851332 objects misplaced (8.423%)
                3006 active+clean
                  65 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29385 kB/s rd, 3766 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:10:46,787 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:10:46,787 INFO cluster.py [line:239] usefull PG number is 3006
2017-06-09 12:11:46,839 INFO cluster.py [line:247] cost 60 seconds, left 2736 seconds when check the ceph status
2017-06-09 12:11:46,839 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:11:47,333 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            63 pgs backfill_wait
            1 pgs backfilling
            64 pgs stuck unclean
            recovery 70078/850509 objects misplaced (8.240%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7556: 12 osds: 12 up, 12 in; 64 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90374: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            70078/850509 objects misplaced (8.240%)
                3008 active+clean
                  63 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 45327 kB/s rd, 5798 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:11:47,333 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:11:47,333 INFO cluster.py [line:239] usefull PG number is 3008
2017-06-09 12:12:47,356 INFO cluster.py [line:247] cost 61 seconds, left 2675 seconds when check the ceph status
2017-06-09 12:12:47,357 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:12:47,808 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            62 pgs backfill_wait
            1 pgs backfilling
            63 pgs stuck unclean
            recovery 68534/849767 objects misplaced (8.065%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7558: 12 osds: 12 up, 12 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90428: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            68534/849767 objects misplaced (8.065%)
                3009 active+clean
                  62 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 71718 kB/s rd, 9095 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:12:47,809 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:12:47,809 INFO cluster.py [line:239] usefull PG number is 3009
2017-06-09 12:13:47,869 INFO cluster.py [line:247] cost 60 seconds, left 2615 seconds when check the ceph status
2017-06-09 12:13:47,869 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:13:48,301 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            59 pgs backfill_wait
            1 pgs backfilling
            60 pgs stuck unclean
            recovery 66763/848883 objects misplaced (7.865%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7562: 12 osds: 12 up, 12 in; 60 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90481: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            66763/848883 objects misplaced (7.865%)
                3012 active+clean
                  59 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 220 MB/s, 59 objects/s
  client io 58208 kB/s rd, 7395 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:13:48,301 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:13:48,301 INFO cluster.py [line:239] usefull PG number is 3012
2017-06-09 12:14:48,333 INFO cluster.py [line:247] cost 61 seconds, left 2554 seconds when check the ceph status
2017-06-09 12:14:48,334 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:14:48,758 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            58 pgs backfill_wait
            1 pgs backfilling
            59 pgs stuck unclean
            recovery 65240/848149 objects misplaced (7.692%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7564: 12 osds: 12 up, 12 in; 59 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90534: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            65240/848149 objects misplaced (7.692%)
                3013 active+clean
                  58 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 46858 kB/s rd, 5857 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:14:48,759 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:14:48,759 INFO cluster.py [line:239] usefull PG number is 3013
2017-06-09 12:15:48,819 INFO cluster.py [line:247] cost 60 seconds, left 2494 seconds when check the ceph status
2017-06-09 12:15:48,819 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:15:49,214 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            55 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 63600/847295 objects misplaced (7.506%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7570: 12 osds: 12 up, 12 in; 56 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90588: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            63600/847295 objects misplaced (7.506%)
                3016 active+clean
                  55 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 49597 kB/s rd, 6199 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:15:49,214 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:15:49,215 INFO cluster.py [line:239] usefull PG number is 3016
2017-06-09 12:16:49,234 INFO cluster.py [line:247] cost 61 seconds, left 2433 seconds when check the ceph status
2017-06-09 12:16:49,234 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:16:49,632 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            54 pgs backfill_wait
            1 pgs backfilling
            55 pgs stuck unclean
            recovery 61982/846517 objects misplaced (7.322%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7572: 12 osds: 12 up, 12 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90640: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            61982/846517 objects misplaced (7.322%)
                3017 active+clean
                  54 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 209 MB/s, 56 objects/s
  client io 40563 kB/s rd, 5070 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:16:49,632 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:16:49,632 INFO cluster.py [line:239] usefull PG number is 3017
2017-06-09 12:17:49,672 INFO cluster.py [line:247] cost 60 seconds, left 2373 seconds when check the ceph status
2017-06-09 12:17:49,672 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:17:50,078 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            52 pgs backfill_wait
            1 pgs backfilling
            53 pgs stuck unclean
            recovery 60439/845720 objects misplaced (7.146%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7576: 12 osds: 12 up, 12 in; 53 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90693: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            60439/845720 objects misplaced (7.146%)
                3019 active+clean
                  52 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 45435 kB/s rd, 5679 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:17:50,079 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:17:50,079 INFO cluster.py [line:239] usefull PG number is 3019
2017-06-09 12:18:50,130 INFO cluster.py [line:247] cost 61 seconds, left 2312 seconds when check the ceph status
2017-06-09 12:18:50,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:18:50,550 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            50 pgs backfill_wait
            1 pgs backfilling
            51 pgs stuck unclean
            recovery 58727/844839 objects misplaced (6.951%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7580: 12 osds: 12 up, 12 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90746: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            58727/844839 objects misplaced (6.951%)
                3021 active+clean
                  50 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 228 MB/s, 61 objects/s
  client io 18121 kB/s rd, 2265 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:18:50,550 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:18:50,550 INFO cluster.py [line:239] usefull PG number is 3021
2017-06-09 12:19:50,594 INFO cluster.py [line:247] cost 60 seconds, left 2252 seconds when check the ceph status
2017-06-09 12:19:50,594 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:19:50,975 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            48 pgs backfill_wait
            1 pgs backfilling
            49 pgs stuck unclean
            recovery 57002/844024 objects misplaced (6.754%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7584: 12 osds: 12 up, 12 in; 49 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90800: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            57002/844024 objects misplaced (6.754%)
                3023 active+clean
                  48 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 333 MB/s, 91 objects/s
  client io 22648 kB/s rd, 2854 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:19:50,975 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:19:50,975 INFO cluster.py [line:239] usefull PG number is 3023
2017-06-09 12:20:51,030 INFO cluster.py [line:247] cost 61 seconds, left 2191 seconds when check the ceph status
2017-06-09 12:20:51,030 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:20:51,452 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            46 pgs backfill_wait
            1 pgs backfilling
            47 pgs stuck unclean
            recovery 53655/842360 objects misplaced (6.370%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7588: 12 osds: 12 up, 12 in; 47 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90854: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            53655/842360 objects misplaced (6.370%)
                3025 active+clean
                  46 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 22934 kB/s rd, 2892 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:20:51,453 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:20:51,453 INFO cluster.py [line:239] usefull PG number is 3025
2017-06-09 12:21:51,513 INFO cluster.py [line:247] cost 60 seconds, left 2131 seconds when check the ceph status
2017-06-09 12:21:51,513 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:21:51,889 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            45 pgs backfill_wait
            1 pgs backfilling
            46 pgs stuck unclean
            recovery 52055/841589 objects misplaced (6.185%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7590: 12 osds: 12 up, 12 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90907: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5500 GB / 8390 GB avail
            52055/841589 objects misplaced (6.185%)
                3026 active+clean
                  45 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29968 kB/s rd, 3829 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:21:51,889 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:21:51,889 INFO cluster.py [line:239] usefull PG number is 3026
2017-06-09 12:22:51,902 INFO cluster.py [line:247] cost 60 seconds, left 2071 seconds when check the ceph status
2017-06-09 12:22:51,902 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:22:52,283 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            44 pgs stuck unclean
            recovery 50319/840747 objects misplaced (5.985%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7594: 12 osds: 12 up, 12 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v90962: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5500 GB / 8390 GB avail
            50319/840747 objects misplaced (5.985%)
                3028 active+clean
                  43 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 266 MB/s, 71 objects/s
  client io 29820 kB/s rd, 3842 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:22:52,283 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:22:52,283 INFO cluster.py [line:239] usefull PG number is 3028
2017-06-09 12:23:52,343 INFO cluster.py [line:247] cost 61 seconds, left 2010 seconds when check the ceph status
2017-06-09 12:23:52,344 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:23:52,772 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            42 pgs backfill_wait
            1 pgs backfilling
            43 pgs stuck unclean
            recovery 48258/840013 objects misplaced (5.745%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7596: 12 osds: 12 up, 12 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91014: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5498 GB / 8390 GB avail
            48258/840013 objects misplaced (5.745%)
                3029 active+clean
                  42 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 46256 kB/s rd, 5860 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:23:52,772 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:23:52,772 INFO cluster.py [line:239] usefull PG number is 3029
2017-06-09 12:24:52,807 INFO cluster.py [line:247] cost 60 seconds, left 1950 seconds when check the ceph status
2017-06-09 12:24:52,808 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:24:53,200 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            41 pgs backfill_wait
            1 pgs backfilling
            42 pgs stuck unclean
            recovery 45404/838395 objects misplaced (5.416%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7598: 12 osds: 12 up, 12 in; 42 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91068: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            45404/838395 objects misplaced (5.416%)
                3030 active+clean
                  41 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 216 MB/s, 57 objects/s
  client io 49670 kB/s rd, 6347 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:24:53,200 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:24:53,200 INFO cluster.py [line:239] usefull PG number is 3030
2017-06-09 12:25:53,234 INFO cluster.py [line:247] cost 61 seconds, left 1889 seconds when check the ceph status
2017-06-09 12:25:53,234 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:25:53,677 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            39 pgs backfill_wait
            1 pgs backfilling
            41 pgs stuck unclean
            recovery 43752/837648 objects misplaced (5.223%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7602: 12 osds: 12 up, 12 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91122: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            43752/837648 objects misplaced (5.223%)
                3031 active+clean
                  39 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 69670 kB/s, 18 objects/s
  client io 53638 kB/s rd, 6704 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:25:53,678 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:25:53,678 INFO cluster.py [line:239] usefull PG number is 3031
2017-06-09 12:26:53,734 INFO cluster.py [line:247] cost 60 seconds, left 1829 seconds when check the ceph status
2017-06-09 12:26:53,734 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:26:54,162 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            37 pgs backfill_wait
            1 pgs backfilling
            38 pgs stuck unclean
            recovery 41484/836146 objects misplaced (4.961%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7606: 12 osds: 12 up, 12 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91176: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            41484/836146 objects misplaced (4.961%)
                3034 active+clean
                  37 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 100 MB/s, 25 objects/s
  client io 47685 kB/s rd, 5960 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:26:54,162 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:26:54,162 INFO cluster.py [line:239] usefull PG number is 3034
2017-06-09 12:27:54,186 INFO cluster.py [line:247] cost 61 seconds, left 1768 seconds when check the ceph status
2017-06-09 12:27:54,186 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:27:54,560 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            36 pgs backfill_wait
            1 pgs backfilling
            37 pgs stuck unclean
            recovery 39894/835392 objects misplaced (4.775%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7608: 12 osds: 12 up, 12 in; 37 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91228: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            39894/835392 objects misplaced (4.775%)
                3035 active+clean
                  36 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 202 MB/s, 54 objects/s
  client io 40946 kB/s rd, 5118 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:27:54,560 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:27:54,560 INFO cluster.py [line:239] usefull PG number is 3035
2017-06-09 12:28:54,609 INFO cluster.py [line:247] cost 60 seconds, left 1708 seconds when check the ceph status
2017-06-09 12:28:54,609 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:28:55,007 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            35 pgs backfill_wait
            1 pgs backfilling
            36 pgs stuck unclean
            recovery 38328/834589 objects misplaced (4.592%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7610: 12 osds: 12 up, 12 in; 36 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91281: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            38328/834589 objects misplaced (4.592%)
                3036 active+clean
                  35 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 147 MB/s, 39 objects/s
  client io 134 MB/s rd, 17200 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:28:55,007 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:28:55,007 INFO cluster.py [line:239] usefull PG number is 3036
2017-06-09 12:29:55,053 INFO cluster.py [line:247] cost 61 seconds, left 1647 seconds when check the ceph status
2017-06-09 12:29:55,053 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:29:55,484 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            34 pgs backfill_wait
            1 pgs backfilling
            35 pgs stuck unclean
            recovery 36739/833774 objects misplaced (4.406%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7613: 12 osds: 12 up, 12 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91333: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5499 GB / 8390 GB avail
            36739/833774 objects misplaced (4.406%)
                3037 active+clean
                  34 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 9753 kB/s rd, 1219 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:29:55,484 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:29:55,484 INFO cluster.py [line:239] usefull PG number is 3037
2017-06-09 12:30:55,544 INFO cluster.py [line:247] cost 60 seconds, left 1587 seconds when check the ceph status
2017-06-09 12:30:55,545 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:30:56,027 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            31 pgs backfill_wait
            1 pgs backfilling
            32 pgs stuck unclean
            recovery 34918/832914 objects misplaced (4.192%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7618: 12 osds: 12 up, 12 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91388: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            34918/832914 objects misplaced (4.192%)
                3040 active+clean
                  31 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29896 kB/s rd, 3737 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:30:56,027 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:30:56,027 INFO cluster.py [line:239] usefull PG number is 3040
2017-06-09 12:31:56,075 INFO cluster.py [line:247] cost 61 seconds, left 1526 seconds when check the ceph status
2017-06-09 12:31:56,076 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:31:56,508 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 31724/831352 objects misplaced (3.816%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7620: 12 osds: 12 up, 12 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91442: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            31724/831352 objects misplaced (3.816%)
                3041 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 28652 kB/s rd, 3709 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:31:56,508 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:31:56,508 INFO cluster.py [line:239] usefull PG number is 3041
2017-06-09 12:32:56,568 INFO cluster.py [line:247] cost 60 seconds, left 1466 seconds when check the ceph status
2017-06-09 12:32:56,569 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:32:56,957 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            29 pgs backfill_wait
            1 pgs backfilling
            30 pgs stuck unclean
            recovery 30130/830607 objects misplaced (3.627%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7622: 12 osds: 12 up, 12 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91495: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            30130/830607 objects misplaced (3.627%)
                3042 active+clean
                  29 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 225 MB/s, 60 objects/s
  client io 43562 kB/s rd, 5596 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:32:56,958 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:32:56,958 INFO cluster.py [line:239] usefull PG number is 3042
2017-06-09 12:33:56,994 INFO cluster.py [line:247] cost 60 seconds, left 1406 seconds when check the ceph status
2017-06-09 12:33:56,994 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:33:57,439 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            28 pgs backfill_wait
            1 pgs backfilling
            29 pgs stuck unclean
            recovery 28685/829883 objects misplaced (3.457%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7624: 12 osds: 12 up, 12 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91550: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            28685/829883 objects misplaced (3.457%)
                3043 active+clean
                  28 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 38522 kB/s rd, 4942 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:33:57,439 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:33:57,439 INFO cluster.py [line:239] usefull PG number is 3043
2017-06-09 12:34:57,500 INFO cluster.py [line:247] cost 61 seconds, left 1345 seconds when check the ceph status
2017-06-09 12:34:57,500 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:34:57,916 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            27 pgs backfill_wait
            1 pgs backfilling
            28 pgs stuck unclean
            recovery 27068/829124 objects misplaced (3.265%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7626: 12 osds: 12 up, 12 in; 28 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91604: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            27068/829124 objects misplaced (3.265%)
                3044 active+clean
                  27 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 141 MB/s, 37 objects/s
  client io 38495 kB/s rd, 4890 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:34:57,917 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:34:57,917 INFO cluster.py [line:239] usefull PG number is 3044
2017-06-09 12:35:57,946 INFO cluster.py [line:247] cost 60 seconds, left 1285 seconds when check the ceph status
2017-06-09 12:35:57,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:35:58,311 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            25 pgs backfill_wait
            1 pgs backfilling
            26 pgs stuck unclean
            recovery 25426/828270 objects misplaced (3.070%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7630: 12 osds: 12 up, 12 in; 26 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91659: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            25426/828270 objects misplaced (3.070%)
                3046 active+clean
                  25 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 54739 kB/s rd, 6917 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:35:58,311 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:35:58,311 INFO cluster.py [line:239] usefull PG number is 3046
2017-06-09 12:36:58,348 INFO cluster.py [line:247] cost 61 seconds, left 1224 seconds when check the ceph status
2017-06-09 12:36:58,348 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:36:58,772 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            24 pgs backfill_wait
            1 pgs backfilling
            25 pgs stuck unclean
            recovery 23815/827537 objects misplaced (2.878%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7632: 12 osds: 12 up, 12 in; 25 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91712: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            23815/827537 objects misplaced (2.878%)
                3047 active+clean
                  24 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 227 MB/s, 60 objects/s
  client io 44862 kB/s rd, 5607 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:36:58,772 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:36:58,772 INFO cluster.py [line:239] usefull PG number is 3047
2017-06-09 12:37:58,826 INFO cluster.py [line:247] cost 60 seconds, left 1164 seconds when check the ceph status
2017-06-09 12:37:58,826 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:37:59,252 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            20 pgs backfill_wait
            1 pgs backfilling
            21 pgs stuck unclean
            recovery 22120/826581 objects misplaced (2.676%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7640: 12 osds: 12 up, 12 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91770: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            22120/826581 objects misplaced (2.676%)
                3051 active+clean
                  20 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 204 MB/s, 54 objects/s
  client io 38201 kB/s rd, 4775 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:37:59,253 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:37:59,253 INFO cluster.py [line:239] usefull PG number is 3051
2017-06-09 12:38:59,254 INFO cluster.py [line:247] cost 61 seconds, left 1103 seconds when check the ceph status
2017-06-09 12:38:59,254 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:38:59,700 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            19 pgs backfill_wait
            1 pgs backfilling
            20 pgs stuck unclean
            recovery 20558/825788 objects misplaced (2.490%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7642: 12 osds: 12 up, 12 in; 20 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91822: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            20558/825788 objects misplaced (2.490%)
                3052 active+clean
                  19 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 38160 kB/s rd, 4770 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:38:59,701 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:38:59,701 INFO cluster.py [line:239] usefull PG number is 3052
2017-06-09 12:39:59,711 INFO cluster.py [line:247] cost 60 seconds, left 1043 seconds when check the ceph status
2017-06-09 12:39:59,712 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:40:00,144 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 18900/824983 objects misplaced (2.291%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7644: 12 osds: 12 up, 12 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91874: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5501 GB / 8390 GB avail
            18900/824983 objects misplaced (2.291%)
                3053 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 280 MB/s, 75 objects/s
  client io 25186 kB/s rd, 3148 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:40:00,144 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:40:00,144 INFO cluster.py [line:239] usefull PG number is 3053
2017-06-09 12:41:00,202 INFO cluster.py [line:247] cost 61 seconds, left 982 seconds when check the ceph status
2017-06-09 12:41:00,202 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:41:00,591 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 16906/823960 objects misplaced (2.052%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7654: 12 osds: 12 up, 12 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91931: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            16906/823960 objects misplaced (2.052%)
                3058 active+clean
                  13 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 25395 kB/s rd, 3174 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:41:00,591 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:41:00,591 INFO cluster.py [line:239] usefull PG number is 3058
2017-06-09 12:42:00,639 INFO cluster.py [line:247] cost 60 seconds, left 922 seconds when check the ceph status
2017-06-09 12:42:00,640 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:42:01,014 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 15301/823184 objects misplaced (1.859%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7656: 12 osds: 12 up, 12 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v91986: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            15301/823184 objects misplaced (1.859%)
                3059 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 47092 kB/s rd, 5923 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:42:01,014 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:42:01,014 INFO cluster.py [line:239] usefull PG number is 3059
2017-06-09 12:43:01,074 INFO cluster.py [line:247] cost 61 seconds, left 861 seconds when check the ceph status
2017-06-09 12:43:01,074 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:43:01,493 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            11 pgs backfill_wait
            1 pgs backfilling
            12 pgs stuck unclean
            recovery 13808/822451 objects misplaced (1.679%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7658: 12 osds: 12 up, 12 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92039: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            13808/822451 objects misplaced (1.679%)
                3060 active+clean
                  11 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 26072 kB/s rd, 3287 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:43:01,493 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:43:01,493 INFO cluster.py [line:239] usefull PG number is 3060
2017-06-09 12:44:01,553 INFO cluster.py [line:247] cost 60 seconds, left 801 seconds when check the ceph status
2017-06-09 12:44:01,554 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:44:01,955 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            10 pgs backfill_wait
            1 pgs backfilling
            11 pgs stuck unclean
            recovery 12237/821699 objects misplaced (1.489%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7660: 12 osds: 12 up, 12 in; 11 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92090: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            12237/821699 objects misplaced (1.489%)
                3061 active+clean
                  10 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 42932 kB/s rd, 5392 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:44:01,955 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:44:01,956 INFO cluster.py [line:239] usefull PG number is 3061
2017-06-09 12:45:02,003 INFO cluster.py [line:247] cost 61 seconds, left 740 seconds when check the ceph status
2017-06-09 12:45:02,003 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:45:02,393 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 10637/820932 objects misplaced (1.296%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7662: 12 osds: 12 up, 12 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92144: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            10637/820932 objects misplaced (1.296%)
                3062 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 211 MB/s, 56 objects/s
  client io 60362 kB/s rd, 7581 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:45:02,394 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:45:02,394 INFO cluster.py [line:239] usefull PG number is 3062
2017-06-09 12:46:02,397 INFO cluster.py [line:247] cost 60 seconds, left 680 seconds when check the ceph status
2017-06-09 12:46:02,398 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:46:02,807 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            9 pgs stuck unclean
            recovery 9104/820140 objects misplaced (1.110%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7664: 12 osds: 12 up, 12 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92197: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            9104/820140 objects misplaced (1.110%)
                3063 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 55836 kB/s rd, 7008 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:46:02,808 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:46:02,808 INFO cluster.py [line:239] usefull PG number is 3063
2017-06-09 12:47:02,848 INFO cluster.py [line:247] cost 60 seconds, left 620 seconds when check the ceph status
2017-06-09 12:47:02,848 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:47:03,209 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            7 pgs backfill_wait
            1 pgs backfilling
            8 pgs stuck unclean
            recovery 7526/819387 objects misplaced (0.918%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7666: 12 osds: 12 up, 12 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92249: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            7526/819387 objects misplaced (0.918%)
                3064 active+clean
                   7 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 218 MB/s, 58 objects/s
  client io 10199 kB/s rd, 1306 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:47:03,209 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:47:03,210 INFO cluster.py [line:239] usefull PG number is 3064
2017-06-09 12:48:03,266 INFO cluster.py [line:247] cost 61 seconds, left 559 seconds when check the ceph status
2017-06-09 12:48:03,266 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:48:03,687 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            5 pgs backfill_wait
            1 pgs backfilling
            6 pgs stuck unclean
            recovery 5899/818581 objects misplaced (0.721%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7669: 12 osds: 12 up, 12 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92304: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            5899/818581 objects misplaced (0.721%)
                3066 active+clean
                   5 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 5878 kB/s rd, 734 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:48:03,687 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:48:03,687 INFO cluster.py [line:239] usefull PG number is 3066
2017-06-09 12:49:03,722 INFO cluster.py [line:247] cost 60 seconds, left 499 seconds when check the ceph status
2017-06-09 12:49:03,722 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:49:04,109 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            3 pgs backfill_wait
            1 pgs backfilling
            4 pgs stuck unclean
            recovery 4260/817762 objects misplaced (0.521%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7673: 12 osds: 12 up, 12 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92360: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            4260/817762 objects misplaced (0.521%)
                3068 active+clean
                   3 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 211 MB/s, 56 objects/s
  client io 15715 kB/s rd, 1964 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:49:04,110 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:49:04,110 INFO cluster.py [line:239] usefull PG number is 3068
2017-06-09 12:50:04,155 INFO cluster.py [line:247] cost 61 seconds, left 438 seconds when check the ceph status
2017-06-09 12:50:04,155 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:50:04,532 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            3 pgs stuck unclean
            recovery 2684/816938 objects misplaced (0.329%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7675: 12 osds: 12 up, 12 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92414: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2889 GB used, 5501 GB / 8390 GB avail
            2684/816938 objects misplaced (0.329%)
                3069 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 12079 kB/s rd, 1509 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:50:04,532 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:50:04,532 INFO cluster.py [line:239] usefull PG number is 3069
2017-06-09 12:51:04,592 INFO cluster.py [line:247] cost 60 seconds, left 378 seconds when check the ceph status
2017-06-09 12:51:04,592 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:51:04,958 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 830/816149 objects misplaced (0.102%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7680: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92467: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2890 GB used, 5500 GB / 8390 GB avail
            830/816149 objects misplaced (0.102%)
                3071 active+clean
                   1 active+remapped+backfilling
  client io 15726 kB/s rd, 1965 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:51:04,959 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:51:04,959 INFO cluster.py [line:239] usefull PG number is 3071
2017-06-09 12:52:04,989 INFO cluster.py [line:247] cost 60 seconds, left 318 seconds when check the ceph status
2017-06-09 12:52:04,990 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:52:05,375 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7681: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92519: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2887 GB used, 5502 GB / 8390 GB avail
                3072 active+clean
  client io 19600 kB/s rd, 2450 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:52:05,375 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:52:05,375 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 12:52:05,375 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:89] stop in cluster successfully
2017-06-09 12:52:05,375 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-09 12:52:17,791 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 12:52:17,791 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on CW113 successfully.
Detail:
stdin: is not a tty

2017-06-09 12:52:17,791 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 12:52:18,189 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1/13 in osds are down
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e7683: 13 osds: 12 up, 13 in; 779 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v92531: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2887 GB used, 5502 GB / 8390 GB avail
                3072 active+clean
  client io 8485 kB/s rd, 1060 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 12:52:18,190 INFO cluster.py [line:238] PG number is 3072
2017-06-09 12:52:18,190 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 12:52:18,190 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.4 create succesfully
2017-06-09 12:52:20,260 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node CW113 create succesfully
2017-06-09 12:52:20,537 INFO client.py [line:172] ['oot     138413 131990  0 02:03 pts/2    00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg3 -rw=randwrite -bs=8K -size=400G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg3', 'root     138470 138413 99 02:04 pts/2    03:18:43 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client103 -pool=reliablityTestPool -rbdname=client103rbdImg3 -rw=randwrite -bs=8K -size=400G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client103rbdImg3', 'denali   188516 188515  0 04:52 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   188518 188516  0 04:52 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-09 12:52:20,538 INFO client.py [line:174] IO is running
2017-06-09 12:52:20,754 INFO node.py [line:185] 0
2017-06-09 12:52:20,754 INFO node.py [line:192] nvme2n1
2017-06-09 12:52:20,754 INFO node.py [line:185] 0
2017-06-09 12:52:20,754 INFO node.py [line:192] nvme2n1
2017-06-09 12:52:20,754 INFO node.py [line:185] 0
2017-06-09 12:52:20,754 INFO node.py [line:192] nvme2n1
2017-06-09 12:52:20,755 INFO node.py [line:185] 1
2017-06-09 12:52:20,755 INFO node.py [line:192] nvme1n1
2017-06-09 12:52:20,755 INFO node.py [line:185] 1
2017-06-09 12:52:20,755 INFO node.py [line:192] nvme1n1
2017-06-09 12:52:20,755 INFO node.py [line:185] 1
2017-06-09 12:52:20,755 INFO node.py [line:192] nvme1n1
2017-06-09 12:52:20,755 INFO node.py [line:185] 2
2017-06-09 12:52:20,755 INFO node.py [line:192] nvme4n1
2017-06-09 12:52:20,755 INFO node.py [line:185] 2
2017-06-09 12:52:20,756 INFO node.py [line:192] nvme4n1
2017-06-09 12:52:20,756 INFO node.py [line:185] 2
2017-06-09 12:52:20,756 INFO node.py [line:192] nvme4n1
2017-06-09 12:52:20,756 INFO node.py [line:185] 3
2017-06-09 12:52:20,756 INFO node.py [line:192] nvme0n1
2017-06-09 12:52:20,756 INFO node.py [line:185] 3
2017-06-09 12:52:20,756 INFO node.py [line:192] nvme0n1
2017-06-09 12:52:20,756 INFO node.py [line:185] 3
2017-06-09 12:52:20,756 INFO node.py [line:192] nvme0n1
2017-06-09 12:52:20,757 INFO node.py [line:185] 4
2017-06-09 12:52:20,757 INFO node.py [line:192] nvme3n1
2017-06-09 12:52:20,757 INFO node.py [line:185] 4
2017-06-09 12:52:20,757 INFO node.py [line:192] nvme3n1
2017-06-09 12:52:20,757 INFO node.py [line:185] 4
2017-06-09 12:52:20,757 INFO node.py [line:192] nvme3n1
2017-06-09 12:52:20,757 INFO node.py [line:185] 
2017-06-09 12:52:20,757 INFO node.py [line:192] nvme3n1
2017-06-09 12:52:20,758 INFO node.py [line:200] osd.0  ---> disk nvme2n1
2017-06-09 12:52:20,758 INFO node.py [line:200] osd.1  ---> disk nvme1n1
2017-06-09 12:52:20,758 INFO node.py [line:200] osd.2  ---> disk nvme4n1
2017-06-09 12:52:20,758 INFO node.py [line:200] osd.3  ---> disk nvme0n1
2017-06-09 12:52:20,758 INFO node.py [line:200] osd.4  ---> disk nvme3n1
2017-06-09 12:52:20,758 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node CW113 
2017-06-09 12:52:20,758 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-09 14:22:52,096 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 14:22:52,557 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e8090: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v97287: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
                3072 active+clean
  client io 72262 B/s rd, 80 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 14:22:52,558 INFO cluster.py [line:238] PG number is 3072
2017-06-09 14:22:52,558 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 14:22:52,558 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-09 14:22:52,558 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-09 16:42:17,013 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:42:17,379 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_ERR
            42 pgs are stuck inactive for more than 300 seconds
            118 pgs peering
            42 pgs stuck inactive
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9125: 12 osds: 12 up, 12 in; 158 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v104777: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
                2954 active+clean
                 118 remapped+peering
stdin: is not a tty

2017-06-09 16:42:17,379 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-09 16:43:17,421 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:43:17,899 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            148 pgs backfill_wait
            4 pgs backfilling
            17 pgs degraded
            17 pgs recovery_wait
            112 pgs stuck unclean
            recovery 44/913169 objects degraded (0.005%)
            recovery 193320/913169 objects misplaced (21.170%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9136: 12 osds: 12 up, 12 in; 152 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v104835: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5494 GB / 8390 GB avail
            44/913169 objects degraded (0.005%)
            193320/913169 objects misplaced (21.170%)
                2903 active+clean
                 148 active+remapped+backfill_wait
                  17 active+recovery_wait+degraded
                   4 active+remapped+backfilling
recovery io 198 MB/s, 53 objects/s
  client io 127 kB/s rd, 165 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 16:43:17,900 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:43:17,900 INFO cluster.py [line:239] usefull PG number is 2903
2017-06-09 16:44:17,943 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-09 16:44:17,943 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:44:18,416 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            140 pgs backfill_wait
            5 pgs backfilling
            7 pgs degraded
            1 pgs recovering
            6 pgs recovery_wait
            112 pgs stuck unclean
            recovery 21/907729 objects degraded (0.002%)
            recovery 182188/907729 objects misplaced (20.071%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9151: 12 osds: 12 up, 12 in; 144 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v104896: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2896 GB used, 5494 GB / 8390 GB avail
            21/907729 objects degraded (0.002%)
            182188/907729 objects misplaced (20.071%)
                2920 active+clean
                 140 active+remapped+backfill_wait
                   6 active+recovery_wait+degraded
                   5 active+remapped+backfilling
                   1 active+recovering+degraded
recovery io 1037 MB/s, 279 objects/s
  client io 19152 B/s rd, 28 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 16:44:18,416 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:44:18,417 INFO cluster.py [line:239] usefull PG number is 2920
2017-06-09 16:45:18,442 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-09 16:45:18,442 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:45:18,870 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            128 pgs backfill_wait
            5 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            115 pgs stuck unclean
            recovery 3/899757 objects degraded (0.000%)
            recovery 166373/899757 objects misplaced (18.491%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9169: 12 osds: 12 up, 12 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v104960: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2896 GB used, 5494 GB / 8390 GB avail
            3/899757 objects degraded (0.000%)
            166373/899757 objects misplaced (18.491%)
                2936 active+clean
                 128 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   2 active+recovery_wait+degraded
                   1 active+remapped
recovery io 639 MB/s, 170 objects/s
  client io 33425 B/s rd, 48 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 16:45:18,871 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:45:18,871 INFO cluster.py [line:239] usefull PG number is 2936
2017-06-09 16:46:18,931 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-09 16:46:18,931 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:46:19,343 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            116 pgs backfill_wait
            5 pgs backfilling
            1 pgs degraded
            1 pgs recovery_wait
            114 pgs stuck unclean
            recovery 1/890381 objects degraded (0.000%)
            recovery 148701/890381 objects misplaced (16.701%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9190: 12 osds: 12 up, 12 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105025: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            1/890381 objects degraded (0.000%)
            148701/890381 objects misplaced (16.701%)
                2950 active+clean
                 116 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 active+recovery_wait+degraded
recovery io 197 MB/s, 52 objects/s
stdin: is not a tty

2017-06-09 16:46:19,343 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:46:19,344 INFO cluster.py [line:239] usefull PG number is 2950
2017-06-09 16:47:19,371 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-09 16:47:19,371 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:47:19,757 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            110 pgs backfill_wait
            4 pgs backfilling
            1 pgs degraded
            1 pgs recovery_wait
            115 pgs stuck unclean
            recovery 1/885701 objects degraded (0.000%)
            recovery 138649/885701 objects misplaced (15.654%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9204: 12 osds: 12 up, 12 in; 114 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105084: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2897 GB used, 5493 GB / 8390 GB avail
            1/885701 objects degraded (0.000%)
            138649/885701 objects misplaced (15.654%)
                2957 active+clean
                 110 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 active+recovery_wait+degraded
recovery io 1787 MB/s, 482 objects/s
stdin: is not a tty

2017-06-09 16:47:19,757 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:47:19,757 INFO cluster.py [line:239] usefull PG number is 2957
2017-06-09 16:48:19,818 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-09 16:48:19,818 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:48:20,226 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            95 pgs backfill_wait
            6 pgs backfilling
            101 pgs stuck unclean
            recovery 123694/878461 objects misplaced (14.081%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9224: 12 osds: 12 up, 12 in; 101 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105145: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2896 GB used, 5494 GB / 8390 GB avail
            123694/878461 objects misplaced (14.081%)
                2971 active+clean
                  95 active+remapped+backfill_wait
                   6 active+remapped+backfilling
recovery io 348 MB/s, 93 objects/s
stdin: is not a tty

2017-06-09 16:48:20,226 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:48:20,226 INFO cluster.py [line:239] usefull PG number is 2971
2017-06-09 16:49:20,241 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-09 16:49:20,241 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:49:20,665 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            89 pgs backfill_wait
            3 pgs backfilling
            92 pgs stuck unclean
            recovery 113063/872227 objects misplaced (12.963%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9237: 12 osds: 12 up, 12 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105204: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            113063/872227 objects misplaced (12.963%)
                2980 active+clean
                  89 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 689 MB/s, 186 objects/s
stdin: is not a tty

2017-06-09 16:49:20,665 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:49:20,665 INFO cluster.py [line:239] usefull PG number is 2980
2017-06-09 16:50:20,673 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-09 16:50:20,673 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:50:21,061 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            82 pgs backfill_wait
            5 pgs backfilling
            88 pgs stuck unclean
            recovery 105837/869051 objects misplaced (12.178%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9246: 12 osds: 12 up, 12 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105260: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            105837/869051 objects misplaced (12.178%)
                2984 active+clean
                  82 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 active+remapped
recovery io 964 MB/s, 254 objects/s
stdin: is not a tty

2017-06-09 16:50:21,062 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:50:21,062 INFO cluster.py [line:239] usefull PG number is 2984
2017-06-09 16:51:21,122 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-09 16:51:21,122 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:51:21,521 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            78 pgs backfill_wait
            3 pgs backfilling
            81 pgs stuck unclean
            recovery 96046/864352 objects misplaced (11.112%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9256: 12 osds: 12 up, 12 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105317: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            96046/864352 objects misplaced (11.112%)
                2991 active+clean
                  78 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 1024 MB/s, 279 objects/s
stdin: is not a tty

2017-06-09 16:51:21,522 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:51:21,522 INFO cluster.py [line:239] usefull PG number is 2991
2017-06-09 16:52:21,535 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-09 16:52:21,536 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:52:21,934 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            70 pgs backfill_wait
            6 pgs backfilling
            76 pgs stuck unclean
            recovery 84048/859634 objects misplaced (9.777%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9267: 12 osds: 12 up, 12 in; 75 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105371: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2902 GB used, 5488 GB / 8390 GB avail
            84048/859634 objects misplaced (9.777%)
                2996 active+clean
                  70 active+remapped+backfill_wait
                   6 active+remapped+backfilling
recovery io 1646 MB/s, 450 objects/s
stdin: is not a tty

2017-06-09 16:52:21,935 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:52:21,935 INFO cluster.py [line:239] usefull PG number is 2996
2017-06-09 16:53:21,946 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-09 16:53:21,946 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:53:22,375 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            63 pgs backfill_wait
            3 pgs backfilling
            66 pgs stuck unclean
            recovery 71292/851588 objects misplaced (8.372%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9281: 12 osds: 12 up, 12 in; 66 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105429: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5495 GB / 8390 GB avail
            71292/851588 objects misplaced (8.372%)
                3006 active+clean
                  63 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 416 MB/s, 110 objects/s
stdin: is not a tty

2017-06-09 16:53:22,375 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:53:22,376 INFO cluster.py [line:239] usefull PG number is 3006
2017-06-09 16:54:22,401 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-09 16:54:22,401 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:54:22,796 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            57 pgs backfill_wait
            4 pgs backfilling
            61 pgs stuck unclean
            recovery 64735/849182 objects misplaced (7.623%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9290: 12 osds: 12 up, 12 in; 61 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105486: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2897 GB used, 5493 GB / 8390 GB avail
            64735/849182 objects misplaced (7.623%)
                3011 active+clean
                  57 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 1075 MB/s, 292 objects/s
stdin: is not a tty

2017-06-09 16:54:22,796 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:54:22,797 INFO cluster.py [line:239] usefull PG number is 3011
2017-06-09 16:55:22,857 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-09 16:55:22,857 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:55:23,247 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            41 pgs backfill_wait
            5 pgs backfilling
            46 pgs stuck unclean
            recovery 49655/840995 objects misplaced (5.904%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9316: 12 osds: 12 up, 12 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105555: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2895 GB used, 5494 GB / 8390 GB avail
            49655/840995 objects misplaced (5.904%)
                3026 active+clean
                  41 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 311 MB/s, 85 objects/s
  client io 18539 B/s rd, 27 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 16:55:23,247 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:55:23,247 INFO cluster.py [line:239] usefull PG number is 3026
2017-06-09 16:56:23,307 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-09 16:56:23,308 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:56:23,815 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            37 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            41 pgs stuck unclean
            recovery 41948/837057 objects misplaced (5.011%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9326: 12 osds: 12 up, 12 in; 41 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105612: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2897 GB used, 5493 GB / 8390 GB avail
            41948/837057 objects misplaced (5.011%)
                3030 active+clean
                  37 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 816 MB/s, 216 objects/s
stdin: is not a tty

2017-06-09 16:56:23,815 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:56:23,815 INFO cluster.py [line:239] usefull PG number is 3030
2017-06-09 16:57:23,875 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-09 16:57:23,876 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:57:24,289 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            32 pgs backfill_wait
            3 pgs backfilling
            35 pgs stuck unclean
            recovery 36576/834541 objects misplaced (4.383%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9337: 12 osds: 12 up, 12 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105670: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2893 GB used, 5497 GB / 8390 GB avail
            36576/834541 objects misplaced (4.383%)
                3037 active+clean
                  32 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 431 MB/s, 2 keys/s, 115 objects/s
stdin: is not a tty

2017-06-09 16:57:24,289 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:57:24,289 INFO cluster.py [line:239] usefull PG number is 3037
2017-06-09 16:58:24,349 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-09 16:58:24,350 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:58:24,783 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            27 pgs backfill_wait
            3 pgs backfilling
            30 pgs stuck unclean
            recovery 31471/832068 objects misplaced (3.782%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9347: 12 osds: 12 up, 12 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105724: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            31471/832068 objects misplaced (3.782%)
                3042 active+clean
                  27 active+remapped+backfill_wait
                   3 active+remapped+backfilling
stdin: is not a tty

2017-06-09 16:58:24,783 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:58:24,783 INFO cluster.py [line:239] usefull PG number is 3042
2017-06-09 16:59:24,789 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-09 16:59:24,790 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 16:59:25,267 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            21 pgs backfill_wait
            2 pgs backfilling
            23 pgs stuck unclean
            recovery 27010/829537 objects misplaced (3.256%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9357: 12 osds: 12 up, 12 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105779: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5498 GB / 8390 GB avail
            27010/829537 objects misplaced (3.256%)
                3049 active+clean
                  21 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 148 MB/s, 39 objects/s
stdin: is not a tty

2017-06-09 16:59:25,267 INFO cluster.py [line:238] PG number is 3072
2017-06-09 16:59:25,268 INFO cluster.py [line:239] usefull PG number is 3049
2017-06-09 17:00:25,312 INFO cluster.py [line:247] cost 61 seconds, left 4972 seconds when check the ceph status
2017-06-09 17:00:25,313 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:00:25,703 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            18 pgs backfill_wait
            3 pgs backfilling
            21 pgs stuck unclean
            recovery 23150/827999 objects misplaced (2.796%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9361: 12 osds: 12 up, 12 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105832: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2894 GB used, 5496 GB / 8390 GB avail
            23150/827999 objects misplaced (2.796%)
                3051 active+clean
                  18 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 459 MB/s, 123 objects/s
stdin: is not a tty

2017-06-09 17:00:25,703 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:00:25,703 INFO cluster.py [line:239] usefull PG number is 3051
2017-06-09 17:01:25,707 INFO cluster.py [line:247] cost 60 seconds, left 4912 seconds when check the ceph status
2017-06-09 17:01:25,708 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:01:26,097 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            14 pgs backfill_wait
            3 pgs backfilling
            17 pgs stuck unclean
            recovery 19105/825660 objects misplaced (2.314%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9369: 12 osds: 12 up, 12 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105884: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            19105/825660 objects misplaced (2.314%)
                3055 active+clean
                  14 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 52725 kB/s, 13 objects/s
stdin: is not a tty

2017-06-09 17:01:26,097 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:01:26,097 INFO cluster.py [line:239] usefull PG number is 3055
2017-06-09 17:02:26,130 INFO cluster.py [line:247] cost 61 seconds, left 4851 seconds when check the ceph status
2017-06-09 17:02:26,130 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:02:26,498 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            12 pgs backfill_wait
            2 pgs backfilling
            14 pgs stuck unclean
            recovery 15842/824082 objects misplaced (1.922%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9374: 12 osds: 12 up, 12 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105938: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            15842/824082 objects misplaced (1.922%)
                3058 active+clean
                  12 active+remapped+backfill_wait
                   2 active+remapped+backfilling
stdin: is not a tty

2017-06-09 17:02:26,499 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:02:26,499 INFO cluster.py [line:239] usefull PG number is 3058
2017-06-09 17:03:26,536 INFO cluster.py [line:247] cost 60 seconds, left 4791 seconds when check the ceph status
2017-06-09 17:03:26,537 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:03:26,932 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            4 pgs backfill_wait
            3 pgs backfilling
            7 pgs stuck unclean
            recovery 9362/820112 objects misplaced (1.142%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9386: 12 osds: 12 up, 12 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v105995: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2892 GB used, 5497 GB / 8390 GB avail
            9362/820112 objects misplaced (1.142%)
                3065 active+clean
                   4 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 359 MB/s, 97 objects/s
stdin: is not a tty

2017-06-09 17:03:26,933 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:03:26,933 INFO cluster.py [line:239] usefull PG number is 3065
2017-06-09 17:04:26,950 INFO cluster.py [line:247] cost 60 seconds, left 4731 seconds when check the ceph status
2017-06-09 17:04:26,950 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:04:27,373 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            3 pgs stuck unclean
            recovery 4790/817824 objects misplaced (0.586%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9392: 12 osds: 12 up, 12 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v106052: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2891 GB used, 5499 GB / 8390 GB avail
            4790/817824 objects misplaced (0.586%)
                3069 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 126 MB/s, 33 objects/s
stdin: is not a tty

2017-06-09 17:04:27,373 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:04:27,374 INFO cluster.py [line:239] usefull PG number is 3069
2017-06-09 17:05:27,434 INFO cluster.py [line:247] cost 61 seconds, left 4670 seconds when check the ceph status
2017-06-09 17:05:27,434 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:05:27,831 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 3122/816975 objects misplaced (0.382%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9394: 12 osds: 12 up, 12 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v106101: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2887 GB used, 5502 GB / 8390 GB avail
            3122/816975 objects misplaced (0.382%)
                3070 active+clean
                   1 active+remapped+backfill_wait
                   1 active+remapped+backfilling
stdin: is not a tty

2017-06-09 17:05:27,831 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:05:27,832 INFO cluster.py [line:239] usefull PG number is 3070
2017-06-09 17:06:27,856 INFO cluster.py [line:247] cost 60 seconds, left 4610 seconds when check the ceph status
2017-06-09 17:06:27,856 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:06:28,281 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 1524/816230 objects misplaced (0.187%)
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9396: 12 osds: 12 up, 12 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v106151: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2888 GB used, 5502 GB / 8390 GB avail
            1524/816230 objects misplaced (0.187%)
                3071 active+clean
                   1 active+remapped+backfilling
recovery io 226 MB/s, 61 objects/s
  client io 118 kB/s rd, 153 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 17:06:28,281 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:06:28,281 INFO cluster.py [line:239] usefull PG number is 3071
2017-06-09 17:07:28,330 INFO cluster.py [line:247] cost 61 seconds, left 4549 seconds when check the ceph status
2017-06-09 17:07:28,330 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:07:28,721 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9398: 12 osds: 12 up, 12 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v106197: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2887 GB used, 5502 GB / 8390 GB avail
                3072 active+clean
  client io 82852 B/s rd, 104 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 17:07:28,721 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:07:28,721 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 17:07:28,722 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-09 17:07:28,722 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-09 17:44:00,087 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 17:44:00,450 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e9789: 11 osds: 11 up, 11 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v108293: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2879 GB used, 4811 GB / 7691 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-09 17:44:00,451 INFO cluster.py [line:238] PG number is 3072
2017-06-09 17:44:00,451 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 17:44:00,451 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-09 17:44:00,451 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme0n1
2017-06-09 18:33:44,275 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 18:33:44,695 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e10280: 10 osds: 10 up, 10 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v111133: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2871 GB used, 4121 GB / 6992 GB avail
                3072 active+clean
  client io 85134 B/s rd, 83 op/s rd, 0 op/s wr
stdin: is not a tty

2017-06-09 18:33:44,695 INFO cluster.py [line:238] PG number is 3072
2017-06-09 18:33:44,695 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 18:33:44,696 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-09 18:33:44,696 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-09 19:44:17,513 INFO cluster.py [line:211] execute command is sudo -i ceph -s
2017-06-09 19:44:17,887 INFO cluster.py [line:213]    cluster 9afd408f-471c-4742-8db0-071924668d84
     health HEALTH_OK
     monmap e3: 3 mons at {CW113=192.168.1.113:6789/0,CW114=192.168.1.114:6789/0,CW115=192.168.1.115:6789/0}
            election epoch 6, quorum 0,1,2 CW113,CW114,CW115
     osdmap e10778: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v114381: 3072 pgs, 11 pools, 1590 GB data, 398 kobjects
            2862 GB used, 3430 GB / 6293 GB avail
                3072 active+clean
stdin: is not a tty

2017-06-09 19:44:17,888 INFO cluster.py [line:238] PG number is 3072
2017-06-09 19:44:17,888 INFO cluster.py [line:239] usefull PG number is 3072
2017-06-09 19:44:17,888 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-09 19:44:20,765 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node CW113 delete succesfully
2017-06-09 19:44:20,765 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node CW113 
2017-06-09 19:44:20,766 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-09 19:44:21,465 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 19:44:21,465 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
ERROR: found part label of /dev/nvme2n1 in /etc/ceph/ceph.conf, this means /dev/nvme2n1 is in use by another osd
Reslut:Create osd on CW113 failed.
Detail:/dev/nvme2n1 is in use by another osd.
stdin: is not a tty

2017-06-09 19:44:21,466 ERROR node.py [line:215] Error when create osd
2017-06-09 19:44:21,466 ERROR node.py [line:216] sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-09 19:44:21,466 ERROR node.py [line:217] NFO: osd_num_in_each_disk=1
ERROR: found part label of /dev/nvme2n1 in /etc/ceph/ceph.conf, this means /dev/nvme2n1 is in use by another osd
Reslut:Create osd on CW113 failed.
Detail:/dev/nvme2n1 is in use by another osd.
stdin: is not a tty

