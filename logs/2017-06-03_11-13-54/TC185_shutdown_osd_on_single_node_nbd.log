2017-06-03 11:27:54,264 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. stop all osds in sequence
4. start all osds in sequence
5. check the cluster status
6. repeat step 2-5 on the other node

2017-06-03 11:27:54,264 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:25] the timeout is 6000
2017-06-03 11:27:54,925 INFO monitors.py [line:126]    "quorum_leader_name": "ubuntu-A",
stdin: is not a tty

2017-06-03 11:27:54,925 INFO monitors.py [line:129]    "quorum_leader_name": "ubuntu-A",
2017-06-03 11:27:54,925 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:31] start to check cluster status before case running
2017-06-03 11:27:56,931 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:27:57,352 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e231: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1410: 1536 pgs, 2 pools, 6698 MB data, 1925 objects
            185 GB used, 56439 GB / 56625 GB avail
                1536 active+clean
2017-06-03 03:27:59.074593 7f8b6a70c700 -1 asok(0x7f8b64000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.41789.140236654907776.asok': (13) Permission denied

2017-06-03 11:27:57,352 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:27:57,353 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 11:27:57,353 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:34] health status is OK
2017-06-03 11:27:57,353 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:39] 
Step 1: start IO from clients
2017-06-03 11:27:57,869 INFO client.py [line:172] 
stdin: is not a tty

2017-06-03 11:27:57,869 INFO client.py [line:174] IO is running
2017-06-03 11:28:57,908 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:47] 
Step 2: stop osd and check IO
2017-06-03 11:28:57,908 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:50] 
Now operate osd on ubuntu-A
2017-06-03 11:28:57,908 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.0
2017-06-03 11:28:57,908 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.0 pid for kill
2017-06-03 11:28:58,154 INFO node.py [line:150] osd.0  ---> processId 
2017-06-03 11:28:58,154 INFO node.py [line:150] osd.1  ---> processId 
2017-06-03 11:28:58,155 INFO node.py [line:150] osd.2  ---> processId 
2017-06-03 11:28:58,155 INFO node.py [line:150] osd.3  ---> processId 
2017-06-03 11:28:58,155 INFO node.py [line:150] osd.4  ---> processId 
2017-06-03 11:28:58,155 INFO node.py [line:150] osd.5  ---> processId 
2017-06-03 11:28:58,155 INFO node.py [line:150] osd.6  ---> processId 
2017-06-03 11:28:58,155 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.0 by kill
2017-06-03 11:28:58,155 INFO osd.py [line:53] execute command is sudo -i kill  & sleep 3
2017-06-03 11:29:06,593 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.0
2017-06-03 11:29:06,594 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:29:06,594 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:29:36,748 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:29:36,749 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:29:36,749 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:29:36,989 INFO osd.py [line:118] enali   42687 42686  0 03:29 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   42689 42687  0 03:29 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:29:36,989 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:29:36,989 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:29:36,990 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:30:07,175 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:30:07,175 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:30:07,175 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:30:07,417 INFO osd.py [line:118] enali   42965 42964  0 03:30 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   42967 42965  0 03:30 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:30:07,417 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:30:07,417 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:30:07,417 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:30:37,715 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:30:37,715 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:30:37,715 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:30:37,960 INFO osd.py [line:118] enali   43243 43242  0 03:30 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   43245 43243  0 03:30 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:30:37,961 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:30:37,961 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:30:37,961 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:31:08,147 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:31:08,147 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:31:08,147 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:31:08,392 INFO osd.py [line:118] enali   43523 43522  0 03:31 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   43525 43523  0 03:31 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:31:08,393 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:31:08,393 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:31:08,393 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:31:38,578 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:31:38,578 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:31:38,578 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:31:38,823 INFO osd.py [line:118] enali   43802 43800  0 03:31 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   43804 43802  0 03:31 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:31:38,823 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:31:38,824 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:31:38,824 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:32:09,009 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:32:09,010 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:32:09,010 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:32:09,217 INFO osd.py [line:118] enali   44163 44162  0 03:32 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   44165 44163  0 03:32 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:32:09,217 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:32:09,218 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:32:09,218 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:32:39,403 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:32:39,403 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:32:39,403 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:32:39,618 INFO osd.py [line:118] enali   44441 44440  0 03:32 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   44443 44441  0 03:32 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:32:39,618 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:32:39,618 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:32:39,618 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:33:09,804 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:33:09,804 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:33:09,804 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:33:10,052 INFO osd.py [line:118] enali   44732 44731  0 03:33 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   44734 44732  0 03:33 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:33:10,052 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:33:10,053 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:33:10,053 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:33:40,238 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:33:40,239 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:33:40,239 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:33:40,468 INFO osd.py [line:118] enali   45018 45017  0 03:33 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   45020 45018  0 03:33 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:33:40,468 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:33:40,468 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:33:40,468 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:34:10,653 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:34:10,653 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:34:10,653 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:34:10,893 INFO osd.py [line:118] enali   45297 45296  0 03:34 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   45299 45297  0 03:34 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:34:10,893 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:34:10,893 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:34:10,894 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:34:41,079 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:34:41,079 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:34:41,079 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-06-03 11:34:41,324 INFO osd.py [line:118] enali   45578 45576  0 03:34 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   45580 45578  0 03:34 ?        00:00:00 grep ceph-osd -i 0

2017-06-03 11:34:41,324 INFO osd.py [line:123] osd.0has not started, start again
2017-06-03 11:34:41,324 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:34:41,324 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-03 11:35:11,509 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-03 11:35:11,509 ERROR TC185_shutdown_osd_on_single_node_nbd.py [line:71] osd.0 cannot start
2017-06-03 11:35:41,766 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:35:42,128 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e231: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1412: 1536 pgs, 2 pools, 6698 MB data, 1925 objects
            185 GB used, 56439 GB / 56625 GB avail
                1536 active+clean
2017-06-03 03:35:43.877975 7f5689e9b700 -1 asok(0x7f5684000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.46111.140009558512000.asok': (13) Permission denied

2017-06-03 11:35:42,129 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:35:42,129 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 11:35:42,129 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.0 in cluster successfully
2017-06-03 11:35:42,716 INFO client.py [line:172] 
stdin: is not a tty

2017-06-03 11:35:42,716 INFO client.py [line:174] IO is running
2017-06-03 11:35:42,716 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.1
2017-06-03 11:35:42,716 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.1 pid for kill
2017-06-03 11:35:42,921 INFO node.py [line:150] osd.0  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.1  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.2  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.3  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.4  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.5  ---> processId 
2017-06-03 11:35:42,922 INFO node.py [line:150] osd.6  ---> processId 
2017-06-03 11:35:42,922 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.1 by kill
2017-06-03 11:35:42,922 INFO osd.py [line:53] execute command is sudo -i kill  & sleep 3
2017-06-03 11:35:46,343 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.1
2017-06-03 11:35:46,344 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:35:46,344 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:36:16,530 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:36:16,530 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:36:16,530 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:36:16,736 INFO osd.py [line:118] enali   46480 46479  0 03:36 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   46482 46480  0 03:36 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:36:16,736 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:36:16,736 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:36:16,736 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:36:46,959 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:36:46,959 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:36:46,959 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:36:47,194 INFO osd.py [line:118] enali   46781 46775  0 03:36 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   46783 46781  0 03:36 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:36:47,194 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:36:47,194 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:36:47,194 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:37:17,380 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:37:17,380 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:37:17,380 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:37:17,621 INFO osd.py [line:118] enali   47145 47144  0 03:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   47147 47145  0 03:37 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:37:17,621 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:37:17,621 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:37:17,622 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:37:47,807 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:37:47,807 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:37:47,807 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:37:48,047 INFO osd.py [line:118] enali   47424 47422  0 03:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   47426 47424  0 03:37 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:37:48,047 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:37:48,047 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:37:48,048 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:38:18,232 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:38:18,233 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:38:18,233 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:38:18,467 INFO osd.py [line:118] enali   47783 47782  0 03:38 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   47785 47783  0 03:38 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:38:18,467 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:38:18,467 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:38:18,467 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:38:48,683 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:38:48,684 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:38:48,684 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:38:48,911 INFO osd.py [line:118] enali   48063 48062  0 03:38 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   48065 48063  0 03:38 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:38:48,912 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:38:48,912 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:38:48,912 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:39:19,104 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:39:19,104 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:39:19,105 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:39:19,357 INFO osd.py [line:118] enali   48350 48348  0 03:39 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   48352 48350  0 03:39 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:39:19,357 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:39:19,357 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:39:19,357 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:39:49,542 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:39:49,542 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:39:49,542 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:39:49,772 INFO osd.py [line:118] enali   48633 48632  0 03:39 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   48635 48633  0 03:39 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:39:49,773 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:39:49,773 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:39:49,773 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:40:19,958 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:40:19,958 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:40:19,958 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:40:20,216 INFO osd.py [line:118] enali   49002 49001  0 03:40 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   49004 49002  0 03:40 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:40:20,217 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:40:20,217 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:40:20,217 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:40:50,401 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:40:50,401 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:40:50,401 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:40:50,647 INFO osd.py [line:118] enali   49283 49281  0 03:40 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   49285 49283  0 03:40 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:40:50,647 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:40:50,647 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:40:50,647 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:41:20,865 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:41:20,865 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:41:20,865 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-06-03 11:41:21,147 INFO osd.py [line:118] enali   49569 49564  0 03:41 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   49571 49569  0 03:41 ?        00:00:00 grep ceph-osd -i 1

2017-06-03 11:41:21,147 INFO osd.py [line:123] osd.1has not started, start again
2017-06-03 11:41:21,148 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:41:21,148 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-03 11:41:51,301 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-03 11:41:51,301 ERROR TC185_shutdown_osd_on_single_node_nbd.py [line:71] osd.1 cannot start
2017-06-03 11:42:21,611 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:42:21,981 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e237: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1573: 1536 pgs, 2 pools, 167 GB data, 45950 objects
            504 GB used, 56121 GB / 56625 GB avail
                1536 active+clean
  client io 1087 kB/s rd, 841 MB/s wr, 766 op/s rd, 7247 op/s wr
2017-06-03 03:42:23.708035 7f0fb37c8700 -1 asok(0x7f0fac000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.50098.139705286922624.asok': (13) Permission denied

2017-06-03 11:42:21,981 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:42:21,981 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 11:42:21,981 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.1 in cluster successfully
2017-06-03 11:42:22,629 INFO client.py [line:172] 2
stdin: is not a tty

2017-06-03 11:42:22,629 INFO client.py [line:174] IO is running
2017-06-03 11:42:22,629 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.2
2017-06-03 11:42:22,629 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.2 pid for kill
2017-06-03 11:42:22,878 INFO node.py [line:150] osd.0  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.1  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.2  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.3  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.4  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.5  ---> processId 
2017-06-03 11:42:22,879 INFO node.py [line:150] osd.6  ---> processId 
2017-06-03 11:42:22,879 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.2 by kill
2017-06-03 11:42:22,879 INFO osd.py [line:53] execute command is sudo -i kill  & sleep 3
2017-06-03 11:42:26,366 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.2
2017-06-03 11:42:26,366 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:42:26,367 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:42:56,552 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:42:56,552 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:42:56,552 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:42:56,799 INFO osd.py [line:118] enali   50465 50464  0 03:42 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   50467 50465  0 03:42 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:42:56,800 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:42:56,800 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:42:56,800 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:43:26,985 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:43:26,986 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:43:26,986 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:43:27,224 INFO osd.py [line:118] enali   50753 50752  0 03:43 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   50755 50753  0 03:43 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:43:27,224 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:43:27,225 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:43:27,225 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:43:57,523 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:43:57,523 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:43:57,523 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:43:57,772 INFO osd.py [line:118] enali   51031 51030  0 03:43 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   51033 51031  0 03:43 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:43:57,772 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:43:57,772 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:43:57,772 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:44:27,990 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:44:27,990 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:44:27,990 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:44:28,232 INFO osd.py [line:118] enali   51319 51314  0 03:44 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   51321 51319  0 03:44 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:44:28,232 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:44:28,232 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:44:28,232 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:44:58,419 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:44:58,420 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:44:58,420 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:44:58,668 INFO osd.py [line:118] enali   51614 51612  0 03:45 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   51616 51614  0 03:45 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:44:58,669 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:44:58,669 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:44:58,669 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:45:28,891 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:45:28,891 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:45:28,891 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:45:29,143 INFO osd.py [line:118] enali   51900 51898  0 03:45 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   51902 51900  0 03:45 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:45:29,144 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:45:29,144 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:45:29,144 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:45:59,329 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:45:59,330 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:45:59,330 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:45:59,518 INFO osd.py [line:118] enali   52247 52246  0 03:46 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   52249 52247  0 03:46 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:45:59,518 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:45:59,518 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:45:59,518 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:46:29,704 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:46:29,705 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:46:29,705 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:46:29,904 INFO osd.py [line:118] enali   52555 52554  0 03:46 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   52558 52555  0 03:46 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:46:29,904 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:46:29,904 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:46:29,904 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:47:00,089 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:47:00,089 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:47:00,089 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:47:00,334 INFO osd.py [line:118] enali   52843 52842  0 03:47 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   52845 52843  0 03:47 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:47:00,335 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:47:00,335 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:47:00,335 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:47:30,520 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:47:30,520 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:47:30,520 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:47:30,751 INFO osd.py [line:118] enali   53124 53123  0 03:47 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   53126 53124  0 03:47 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:47:30,751 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:47:30,752 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:47:30,752 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:48:00,911 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:48:00,911 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:48:00,911 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 2'
2017-06-03 11:48:01,194 INFO osd.py [line:118] enali   53406 53404  0 03:48 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 2'
denali   53408 53406  0 03:48 ?        00:00:00 grep ceph-osd -i 2

2017-06-03 11:48:01,194 INFO osd.py [line:123] osd.2has not started, start again
2017-06-03 11:48:01,195 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:48:01,195 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-03 11:48:31,380 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-03 11:48:31,381 ERROR TC185_shutdown_osd_on_single_node_nbd.py [line:71] osd.2 cannot start
2017-06-03 11:49:01,643 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:49:02,289 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            168 pgs degraded
            108 pgs stuck unclean
            168 pgs undersized
            recovery 9232/158994 objects degraded (5.807%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e239: 20 osds: 19 up, 20 in; 168 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1822: 1536 pgs, 2 pools, 298 GB data, 79497 objects
            768 GB used, 55857 GB / 56625 GB avail
            9232/158994 objects degraded (5.807%)
                1368 active+clean
                 168 active+undersized+degraded
  client io 41856 kB/s wr, 0 op/s rd, 5230 op/s wr
2017-06-03 03:49:03.745993 7f6bab53e700 -1 asok(0x7f6ba4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.54176.140100289696128.asok': (13) Permission denied

2017-06-03 11:49:02,289 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:49:02,289 INFO cluster.py [line:239] usefull PG number is 1368
2017-06-03 11:50:02,319 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 11:50:02,320 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:50:02,693 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            44 pgs degraded
            2 pgs recovering
            42 pgs recovery_wait
            recovery 1563/159006 objects degraded (0.983%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e247: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1867: 1536 pgs, 2 pools, 298 GB data, 79503 objects
            768 GB used, 55857 GB / 56625 GB avail
            1563/159006 objects degraded (0.983%)
                1492 active+clean
                  42 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 493 MB/s, 124 objects/s
  client io 7396 kB/s wr, 0 op/s rd, 923 op/s wr
2017-06-03 03:50:04.421704 7f2a22750700 -1 asok(0x7f2a1c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.54906.139818835120512.asok': (13) Permission denied

2017-06-03 11:50:02,694 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:50:02,694 INFO cluster.py [line:239] usefull PG number is 1492
2017-06-03 11:51:02,754 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 11:51:02,754 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:51:03,113 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            149 pgs degraded
            54 pgs stuck unclean
            149 pgs undersized
            recovery 8333/159018 objects degraded (5.240%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e254: 20 osds: 19 up, 20 in; 149 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1917: 1536 pgs, 2 pools, 298 GB data, 79509 objects
            768 GB used, 55857 GB / 56625 GB avail
            8333/159018 objects degraded (5.240%)
                1387 active+clean
                 149 active+undersized+degraded
  client io 38135 kB/s wr, 0 op/s rd, 4765 op/s wr
2017-06-03 03:51:04.862763 7fbed9bff700 -1 asok(0x7fbed4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.55635.140457577288064.asok': (13) Permission denied

2017-06-03 11:51:03,113 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:51:03,113 INFO cluster.py [line:239] usefull PG number is 1387
2017-06-03 11:52:03,173 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-03 11:52:03,174 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:52:03,557 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            29 pgs degraded
            3 pgs recovering
            26 pgs recovery_wait
            recovery 1048/159030 objects degraded (0.659%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e262: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v1971: 1536 pgs, 2 pools, 298 GB data, 79515 objects
            768 GB used, 55857 GB / 56625 GB avail
            1048/159030 objects degraded (0.659%)
                1507 active+clean
                  26 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 200 MB/s, 50 objects/s
  client io 24748 kB/s wr, 0 op/s rd, 3092 op/s wr
2017-06-03 03:52:05.280664 7f198565a700 -1 asok(0x7f1980000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.56336.139747498398080.asok': (13) Permission denied

2017-06-03 11:52:03,557 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:52:03,557 INFO cluster.py [line:239] usefull PG number is 1507
2017-06-03 11:53:03,613 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-03 11:53:03,613 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:53:04,000 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            184 pgs degraded
            3 pgs recovering
            18 pgs recovery_wait
            51 pgs stuck unclean
            163 pgs undersized
            recovery 10093/159042 objects degraded (6.346%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e269: 20 osds: 19 up, 20 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2023: 1536 pgs, 2 pools, 298 GB data, 79521 objects
            768 GB used, 55857 GB / 56625 GB avail
            10093/159042 objects degraded (6.346%)
                1352 active+clean
                 163 active+undersized+degraded
                  18 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 497 MB/s, 124 objects/s
  client io 26407 kB/s wr, 0 op/s rd, 3299 op/s wr
2017-06-03 03:53:05.728326 7f582bf45700 -1 asok(0x7f5824000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.57055.140016537833856.asok': (13) Permission denied

2017-06-03 11:53:04,001 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:53:04,001 INFO cluster.py [line:239] usefull PG number is 1352
2017-06-03 11:54:04,061 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-03 11:54:04,062 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:54:04,405 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e272: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2072: 1536 pgs, 2 pools, 298 GB data, 79527 objects
            768 GB used, 55857 GB / 56625 GB avail
                1536 active+clean
  client io 36011 kB/s wr, 0 op/s rd, 4500 op/s wr
2017-06-03 03:54:06.153665 7fba4df98700 -1 asok(0x7fba48000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.57658.140438048608640.asok': (13) Permission denied

2017-06-03 11:54:04,405 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:54:04,405 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 11:54:04,406 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.2 in cluster successfully
2017-06-03 11:54:04,924 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 11:54:04,924 INFO client.py [line:174] IO is running
2017-06-03 11:54:04,924 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.3
2017-06-03 11:54:04,924 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.3 pid for kill
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.0  ---> processId 54133
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.1  ---> processId 54628
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.2  ---> processId 55108
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.3  ---> processId 55548
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.4  ---> processId 56032
2017-06-03 11:54:05,157 INFO node.py [line:150] osd.5  ---> processId 56507
2017-06-03 11:54:05,158 INFO node.py [line:150] osd.6  ---> processId 56939
2017-06-03 11:54:05,158 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.3 by kill
2017-06-03 11:54:05,158 INFO osd.py [line:53] execute command is sudo -i kill 55548 & sleep 3
2017-06-03 11:54:08,560 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.3
2017-06-03 11:54:08,561 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:54:08,561 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 3 & sleep 30
2017-06-03 11:54:38,748 INFO osd.py [line:107] osd osd.3 is start successfully
2017-06-03 11:54:38,748 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:54:38,748 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 3'
2017-06-03 11:54:38,994 INFO osd.py [line:118] enali   58061 58060  0 03:54 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 3'
denali   58063 58061  0 03:54 ?        00:00:00 grep ceph-osd -i 3

2017-06-03 11:54:38,995 INFO osd.py [line:123] osd.3has not started, start again
2017-06-03 11:54:38,995 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 11:54:38,995 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 3 & sleep 30
2017-06-03 11:55:09,181 INFO osd.py [line:107] osd osd.3 is start successfully
2017-06-03 11:55:09,181 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 11:55:09,182 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 3'
2017-06-03 11:55:09,410 INFO osd.py [line:118] oot     58084     1 99 03:54 ?        00:00:40 ceph-osd -i 3
denali   58427 58426  0 03:55 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 3'
denali   58429 58427  0 03:55 ?        00:00:00 grep ceph-osd -i 3

2017-06-03 11:55:09,410 INFO osd.py [line:127] osd.3has already started
2017-06-03 11:55:39,668 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:55:40,048 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            26 pgs degraded
            1 pgs recovering
            25 pgs recovery_wait
            recovery 1073/159074 objects degraded (0.675%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e277: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2150: 1536 pgs, 2 pools, 298 GB data, 79537 objects
            768 GB used, 55857 GB / 56625 GB avail
            1073/159074 objects degraded (0.675%)
                1510 active+clean
                  25 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 537 MB/s, 134 objects/s
  client io 2019 B/s rd, 12458 kB/s wr, 1 op/s rd, 1558 op/s wr
2017-06-03 03:55:41.776964 7f5278e0d700 -1 asok(0x7f5274000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.58718.139992110207360.asok': (13) Permission denied

2017-06-03 11:55:40,048 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:55:40,048 INFO cluster.py [line:239] usefull PG number is 1510
2017-06-03 11:56:40,078 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 11:56:40,078 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:56:40,455 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            152 pgs degraded
            84 pgs stuck unclean
            152 pgs undersized
            recovery 8376/159084 objects degraded (5.265%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e279: 20 osds: 19 up, 20 in; 152 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2198: 1536 pgs, 2 pools, 298 GB data, 79542 objects
            768 GB used, 55857 GB / 56625 GB avail
            8376/159084 objects degraded (5.265%)
                1384 active+clean
                 152 active+undersized+degraded
  client io 4701 B/s rd, 30262 kB/s wr, 3 op/s rd, 3783 op/s wr
2017-06-03 03:56:42.175241 7f2ebdd79700 -1 asok(0x7f2eb8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.59315.139838632235392.asok': (13) Permission denied

2017-06-03 11:56:40,456 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:56:40,456 INFO cluster.py [line:239] usefull PG number is 1384
2017-06-03 11:57:40,458 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 11:57:40,458 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:57:40,840 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            47 pgs degraded
            1 pgs recovering
            46 pgs recovery_wait
            recovery 2435/159096 objects degraded (1.531%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e287: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2254: 1536 pgs, 2 pools, 298 GB data, 79548 objects
            768 GB used, 55857 GB / 56625 GB avail
            2435/159096 objects degraded (1.531%)
                1489 active+clean
                  46 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 860 MB/s, 215 objects/s
  client io 3524 B/s rd, 8088 kB/s wr, 2 op/s rd, 1010 op/s wr
2017-06-03 03:57:42.566457 7f44737f3700 -1 asok(0x7f446c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.59828.139931846447488.asok': (13) Permission denied

2017-06-03 11:57:40,840 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:57:40,840 INFO cluster.py [line:239] usefull PG number is 1489
2017-06-03 11:58:40,895 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-03 11:58:40,895 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:58:41,287 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            201 pgs degraded
            2 pgs recovering
            25 pgs recovery_wait
            76 pgs stuck unclean
            174 pgs undersized
            recovery 9639/159108 objects degraded (6.058%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e294: 20 osds: 19 up, 20 in; 174 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2315: 1536 pgs, 2 pools, 298 GB data, 79554 objects
            768 GB used, 55857 GB / 56625 GB avail
            9639/159108 objects degraded (6.058%)
                1335 active+clean
                 174 active+undersized+degraded
                  25 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 942 MB/s, 236 objects/s
  client io 7024 B/s rd, 23040 kB/s wr, 4 op/s rd, 2880 op/s wr
2017-06-03 03:58:43.035186 7fc163922700 -1 asok(0x7fc15c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.60353.140468448924032.asok': (13) Permission denied

2017-06-03 11:58:41,287 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:58:41,287 INFO cluster.py [line:239] usefull PG number is 1335
2017-06-03 11:59:41,336 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-03 11:59:41,337 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 11:59:41,699 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            35 pgs degraded
            1 pgs recovering
            34 pgs recovery_wait
            recovery 1471/159118 objects degraded (0.924%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e302: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2378: 1536 pgs, 2 pools, 298 GB data, 79559 objects
            768 GB used, 55857 GB / 56625 GB avail
            1471/159118 objects degraded (0.924%)
                1501 active+clean
                  34 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 579 MB/s, 145 objects/s
  client io 18101 kB/s wr, 0 op/s rd, 2261 op/s wr
2017-06-03 03:59:43.441270 7fcce75ec700 -1 asok(0x7fcce0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.60867.140517908156800.asok': (13) Permission denied

2017-06-03 11:59:41,700 INFO cluster.py [line:238] PG number is 1536
2017-06-03 11:59:41,700 INFO cluster.py [line:239] usefull PG number is 1501
2017-06-03 12:00:41,760 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-03 12:00:41,760 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:00:42,132 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            37 pgs degraded
            2 pgs recovering
            35 pgs recovery_wait
            recovery 1337/159130 objects degraded (0.840%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e308: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2440: 1536 pgs, 2 pools, 298 GB data, 79565 objects
            768 GB used, 55857 GB / 56625 GB avail
            1337/159130 objects degraded (0.840%)
                1499 active+clean
                  35 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 719 MB/s, 179 objects/s
  client io 19001 kB/s wr, 0 op/s rd, 2373 op/s wr
2017-06-03 04:00:43.854995 7fa753e81700 -1 asok(0x7fa74c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.61390.140356511338880.asok': (13) Permission denied

2017-06-03 12:00:42,132 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:00:42,132 INFO cluster.py [line:239] usefull PG number is 1499
2017-06-03 12:01:42,170 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-03 12:01:42,170 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:01:42,537 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            156 pgs degraded
            63 pgs stuck unclean
            156 pgs undersized
            recovery 7815/159142 objects degraded (4.911%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e310: 20 osds: 19 up, 20 in; 156 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2500: 1536 pgs, 2 pools, 298 GB data, 79571 objects
            768 GB used, 55857 GB / 56625 GB avail
            7815/159142 objects degraded (4.911%)
                1380 active+clean
                 156 active+undersized+degraded
  client io 35691 kB/s wr, 0 op/s rd, 4459 op/s wr
2017-06-03 04:01:44.266452 7f3e56731700 -1 asok(0x7f3e50000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.61907.139905606881664.asok': (13) Permission denied

2017-06-03 12:01:42,538 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:01:42,538 INFO cluster.py [line:239] usefull PG number is 1380
2017-06-03 12:02:42,582 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-03 12:02:42,582 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:02:42,962 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            37 pgs degraded
            4 pgs recovering
            33 pgs recovery_wait
            recovery 1374/159154 objects degraded (0.863%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e318: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2564: 1536 pgs, 2 pools, 298 GB data, 79577 objects
            768 GB used, 55857 GB / 56625 GB avail
            1374/159154 objects degraded (0.863%)
                1499 active+clean
                  33 active+recovery_wait+degraded
                   4 active+recovering+degraded
recovery io 439 MB/s, 109 objects/s
  client io 21921 kB/s wr, 0 op/s rd, 2737 op/s wr
2017-06-03 04:02:44.683421 7f297087b700 -1 asok(0x7f296c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.62419.139815882330496.asok': (13) Permission denied

2017-06-03 12:02:42,963 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:02:42,963 INFO cluster.py [line:239] usefull PG number is 1499
2017-06-03 12:03:42,989 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-03 12:03:42,989 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:03:43,370 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            174 pgs degraded
            2 pgs recovering
            21 pgs recovery_wait
            68 pgs stuck unclean
            151 pgs undersized
            recovery 7644/159166 objects degraded (4.803%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e325: 20 osds: 19 up, 20 in; 151 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2628: 1536 pgs, 2 pools, 298 GB data, 79583 objects
            768 GB used, 55857 GB / 56625 GB avail
            7644/159166 objects degraded (4.803%)
                1362 active+clean
                 151 active+undersized+degraded
                  21 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 431 MB/s, 107 objects/s
  client io 19696 kB/s wr, 0 op/s rd, 2460 op/s wr
2017-06-03 04:03:45.095734 7f5d6a351700 -1 asok(0x7f5d64000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.62940.140039086412160.asok': (13) Permission denied

2017-06-03 12:03:43,370 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:03:43,370 INFO cluster.py [line:239] usefull PG number is 1362
2017-06-03 12:04:43,419 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-03 12:04:43,419 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:04:43,801 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            47 pgs degraded
            2 pgs recovering
            45 pgs recovery_wait
            recovery 2457/159178 objects degraded (1.544%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e333: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2690: 1536 pgs, 2 pools, 298 GB data, 79589 objects
            768 GB used, 55857 GB / 56625 GB avail
            2457/159178 objects degraded (1.544%)
                1489 active+clean
                  45 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 912 MB/s, 229 objects/s
  client io 14210 kB/s wr, 0 op/s rd, 1775 op/s wr
2017-06-03 04:04:45.524559 7f8280414700 -1 asok(0x7f8278000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.63454.140198335746432.asok': (13) Permission denied

2017-06-03 12:04:43,802 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:04:43,802 INFO cluster.py [line:239] usefull PG number is 1489
2017-06-03 12:05:43,862 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-03 12:05:43,862 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:05:44,231 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            160 pgs degraded
            1 pgs recovering
            14 pgs recovery_wait
            84 pgs stuck unclean
            145 pgs undersized
            recovery 7453/159190 objects degraded (4.682%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e340: 20 osds: 19 up, 20 in; 145 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2753: 1536 pgs, 2 pools, 298 GB data, 79595 objects
            768 GB used, 55857 GB / 56625 GB avail
            7453/159190 objects degraded (4.682%)
                1376 active+clean
                 145 active+undersized+degraded
                  14 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 482 MB/s, 120 objects/s
  client io 23624 kB/s wr, 0 op/s rd, 2951 op/s wr
2017-06-03 04:05:45.974263 7fc0a751b700 -1 asok(0x7fc0a0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.63971.140465294807424.asok': (13) Permission denied

2017-06-03 12:05:44,232 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:05:44,232 INFO cluster.py [line:239] usefull PG number is 1376
2017-06-03 12:06:44,240 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-03 12:06:44,240 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:06:44,623 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e343: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2813: 1536 pgs, 2 pools, 298 GB data, 79601 objects
            768 GB used, 55857 GB / 56625 GB avail
                1536 active+clean
  client io 20262 kB/s wr, 0 op/s rd, 2532 op/s wr
2017-06-03 04:06:46.353636 7f3f0fbdc700 -1 asok(0x7f3f08000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.64483.139908693889408.asok': (13) Permission denied

2017-06-03 12:06:44,624 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:06:44,624 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 12:06:44,624 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.3 in cluster successfully
2017-06-03 12:06:45,101 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 12:06:45,102 INFO client.py [line:174] IO is running
2017-06-03 12:06:45,102 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.4
2017-06-03 12:06:45,102 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.4 pid for kill
2017-06-03 12:06:45,346 INFO node.py [line:150] osd.0  ---> processId 54133
2017-06-03 12:06:45,346 INFO node.py [line:150] osd.1  ---> processId 54628
2017-06-03 12:06:45,347 INFO node.py [line:150] osd.2  ---> processId 55108
2017-06-03 12:06:45,347 INFO node.py [line:150] osd.3  ---> processId 58084
2017-06-03 12:06:45,347 INFO node.py [line:150] osd.4  ---> processId 56032
2017-06-03 12:06:45,347 INFO node.py [line:150] osd.5  ---> processId 56507
2017-06-03 12:06:45,347 INFO node.py [line:150] osd.6  ---> processId 56939
2017-06-03 12:06:45,347 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.4 by kill
2017-06-03 12:06:45,347 INFO osd.py [line:53] execute command is sudo -i kill 56032 & sleep 3
2017-06-03 12:06:48,877 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.4
2017-06-03 12:06:48,877 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:06:48,878 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 4 & sleep 30
2017-06-03 12:07:19,100 INFO osd.py [line:107] osd osd.4 is start successfully
2017-06-03 12:07:19,100 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:07:19,100 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 4'
2017-06-03 12:07:19,379 INFO osd.py [line:118] enali   64862 64861  0 04:07 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 4'
denali   64864 64862  0 04:07 ?        00:00:00 grep ceph-osd -i 4

2017-06-03 12:07:19,379 INFO osd.py [line:123] osd.4has not started, start again
2017-06-03 12:07:19,379 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:07:19,380 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 4 & sleep 30
2017-06-03 12:07:49,565 INFO osd.py [line:107] osd osd.4 is start successfully
2017-06-03 12:07:49,565 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:07:49,565 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 4'
2017-06-03 12:07:49,803 INFO osd.py [line:118] oot     64883     1 99 04:07 ?        00:00:40 ceph-osd -i 4
denali   65223 65222  0 04:07 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 4'
denali   65225 65223  0 04:07 ?        00:00:00 grep ceph-osd -i 4

2017-06-03 12:07:49,803 INFO osd.py [line:127] osd.4has already started
2017-06-03 12:08:20,058 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:08:20,434 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            10 pgs degraded
            2 pgs recovering
            8 pgs recovery_wait
            recovery 338/159222 objects degraded (0.212%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e348: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2909: 1536 pgs, 2 pools, 298 GB data, 79611 objects
            768 GB used, 55857 GB / 56625 GB avail
            338/159222 objects degraded (0.212%)
                1526 active+clean
                   8 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 437 MB/s, 109 objects/s
  client io 15800 kB/s wr, 0 op/s rd, 1975 op/s wr
2017-06-03 04:08:22.163847 7f33bf472700 -1 asok(0x7f33b8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.65487.139860107071872.asok': (13) Permission denied

2017-06-03 12:08:20,434 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:08:20,434 INFO cluster.py [line:239] usefull PG number is 1526
2017-06-03 12:09:20,458 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 12:09:20,458 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:09:20,842 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e348: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v2969: 1536 pgs, 2 pools, 298 GB data, 79617 objects
            768 GB used, 55857 GB / 56625 GB avail
                1536 active+clean
  client io 17814 kB/s wr, 0 op/s rd, 2225 op/s wr
2017-06-03 04:09:22.568221 7f6481c92700 -1 asok(0x7f647c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.66150.140069553836416.asok': (13) Permission denied

2017-06-03 12:09:20,842 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:09:20,842 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 12:09:20,842 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.4 in cluster successfully
2017-06-03 12:09:21,366 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 12:09:21,366 INFO client.py [line:174] IO is running
2017-06-03 12:09:21,366 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.5
2017-06-03 12:09:21,367 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.5 pid for kill
2017-06-03 12:09:21,613 INFO node.py [line:150] osd.0  ---> processId 54133
2017-06-03 12:09:21,613 INFO node.py [line:150] osd.1  ---> processId 54628
2017-06-03 12:09:21,613 INFO node.py [line:150] osd.2  ---> processId 55108
2017-06-03 12:09:21,614 INFO node.py [line:150] osd.3  ---> processId 58084
2017-06-03 12:09:21,614 INFO node.py [line:150] osd.4  ---> processId 64883
2017-06-03 12:09:21,614 INFO node.py [line:150] osd.5  ---> processId 56507
2017-06-03 12:09:21,614 INFO node.py [line:150] osd.6  ---> processId 56939
2017-06-03 12:09:21,614 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.5 by kill
2017-06-03 12:09:21,614 INFO osd.py [line:53] execute command is sudo -i kill 56507 & sleep 3
2017-06-03 12:09:25,068 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.5
2017-06-03 12:09:25,068 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:09:25,068 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 5 & sleep 30
2017-06-03 12:09:55,255 INFO osd.py [line:107] osd osd.5 is start successfully
2017-06-03 12:09:55,255 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:09:55,255 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 5'
2017-06-03 12:09:55,470 INFO osd.py [line:118] enali   66678 66677  0 04:09 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 5'
denali   66680 66678  0 04:09 ?        00:00:00 grep ceph-osd -i 5

2017-06-03 12:09:55,471 INFO osd.py [line:123] osd.5has not started, start again
2017-06-03 12:09:55,471 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:09:55,471 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 5 & sleep 30
2017-06-03 12:10:25,623 INFO osd.py [line:107] osd osd.5 is start successfully
2017-06-03 12:10:25,624 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:10:25,624 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 5'
2017-06-03 12:10:25,871 INFO osd.py [line:118] oot     66700     1 99 04:09 ?        00:00:41 ceph-osd -i 5
denali   67144 67143  0 04:10 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 5'
denali   67146 67144  0 04:10 ?        00:00:00 grep ceph-osd -i 5

2017-06-03 12:10:25,871 INFO osd.py [line:127] osd.5has already started
2017-06-03 12:10:56,117 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:10:56,478 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            18 pgs degraded
            2 pgs recovering
            16 pgs recovery_wait
            recovery 502/159250 objects degraded (0.315%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e362: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3070: 1536 pgs, 2 pools, 298 GB data, 79625 objects
            768 GB used, 55857 GB / 56625 GB avail
            502/159250 objects degraded (0.315%)
                1518 active+clean
                  16 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 373 MB/s, 93 objects/s
  client io 17530 kB/s wr, 0 op/s rd, 2190 op/s wr
2017-06-03 04:10:58.228941 7f451cfa0700 -1 asok(0x7f4518000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.67509.139934732128640.asok': (13) Permission denied

2017-06-03 12:10:56,479 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:10:56,479 INFO cluster.py [line:239] usefull PG number is 1518
2017-06-03 12:11:56,539 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 12:11:56,539 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:11:56,875 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e362: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3129: 1536 pgs, 2 pools, 298 GB data, 79631 objects
            768 GB used, 55857 GB / 56625 GB avail
                1536 active+clean
  client io 28276 kB/s wr, 0 op/s rd, 3533 op/s wr
2017-06-03 04:11:58.631366 7f78b9853700 -1 asok(0x7f78b4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.68182.140156392706432.asok': (13) Permission denied

2017-06-03 12:11:56,875 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:11:56,875 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 12:11:56,875 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.5 in cluster successfully
2017-06-03 12:11:57,454 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 12:11:57,454 INFO client.py [line:174] IO is running
2017-06-03 12:11:57,454 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.6
2017-06-03 12:11:57,454 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.6 pid for kill
2017-06-03 12:11:57,691 INFO node.py [line:150] osd.0  ---> processId 54133
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.1  ---> processId 54628
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.2  ---> processId 55108
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.3  ---> processId 58084
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.4  ---> processId 64883
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.5  ---> processId 66700
2017-06-03 12:11:57,692 INFO node.py [line:150] osd.6  ---> processId 56939
2017-06-03 12:11:57,692 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.6 by kill
2017-06-03 12:11:57,693 INFO osd.py [line:53] execute command is sudo -i kill 56939 & sleep 3
2017-06-03 12:12:01,117 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.6
2017-06-03 12:12:01,117 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:12:01,117 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 6 & sleep 30
2017-06-03 12:12:31,338 INFO osd.py [line:107] osd osd.6 is start successfully
2017-06-03 12:12:31,338 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:12:31,339 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 6'
2017-06-03 12:12:31,586 INFO osd.py [line:118] enali   68620 68619  0 04:12 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 6'
denali   68622 68620  0 04:12 ?        00:00:00 grep ceph-osd -i 6

2017-06-03 12:12:31,586 INFO osd.py [line:123] osd.6has not started, start again
2017-06-03 12:12:31,586 INFO osd.py [line:102] node is  ubuntu-A
2017-06-03 12:12:31,586 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 6 & sleep 30
2017-06-03 12:13:01,778 INFO osd.py [line:107] osd osd.6 is start successfully
2017-06-03 12:13:01,778 INFO osd.py [line:115] node is  ubuntu-A
2017-06-03 12:13:01,779 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 6'
2017-06-03 12:13:01,992 INFO osd.py [line:118] oot     68650     1 99 04:12 ?        00:00:45 ceph-osd -i 6
denali   69065 69064  0 04:13 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 6'
denali   69067 69065  0 04:13 ?        00:00:00 grep ceph-osd -i 6

2017-06-03 12:13:01,992 INFO osd.py [line:127] osd.6has already started
2017-06-03 12:13:32,258 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:13:32,641 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            38 pgs degraded
            2 pgs recovering
            36 pgs recovery_wait
            recovery 1890/159282 objects degraded (1.187%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e367: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3226: 1536 pgs, 2 pools, 298 GB data, 79641 objects
            768 GB used, 55857 GB / 56625 GB avail
            1890/159282 objects degraded (1.187%)
                1498 active+clean
                  36 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 583 MB/s, 146 objects/s
  client io 14208 kB/s wr, 0 op/s rd, 1774 op/s wr
2017-06-03 04:13:34.372702 7f78a02ac700 -1 asok(0x7f7898000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.69326.140155922944384.asok': (13) Permission denied

2017-06-03 12:13:32,642 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:13:32,642 INFO cluster.py [line:239] usefull PG number is 1498
2017-06-03 12:14:32,702 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 12:14:32,702 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:14:33,071 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            76 pgs backfill_wait
            4 pgs backfilling
            86 pgs degraded
            2 pgs recovering
            84 pgs recovery_wait
            59 pgs stuck unclean
            recovery 335/173839 objects degraded (0.193%)
            recovery 28327/173839 objects misplaced (16.295%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e381: 20 osds: 20 up, 20 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3294: 1536 pgs, 2 pools, 298 GB data, 79647 objects
            771 GB used, 55853 GB / 56625 GB avail
            335/173839 objects degraded (0.193%)
            28327/173839 objects misplaced (16.295%)
                1369 active+clean
                  84 active+recovery_wait+degraded
                  76 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   2 active+recovering+degraded
                   1 active+remapped
recovery io 2692 MB/s, 700 objects/s
  client io 15535 kB/s wr, 0 op/s rd, 1941 op/s wr
2017-06-03 04:14:34.810011 7f370f1f9700 -1 asok(0x7f3708000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.70699.139874334151040.asok': (13) Permission denied

2017-06-03 12:14:33,072 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:14:33,072 INFO cluster.py [line:239] usefull PG number is 1369
2017-06-03 12:15:33,132 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-03 12:15:33,133 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:15:33,513 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            27 pgs backfill_wait
            3 pgs backfilling
            recovery 1/164674 objects degraded (0.001%)
            recovery 10349/164674 objects misplaced (6.285%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e425: 20 osds: 20 up, 20 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3375: 1536 pgs, 2 pools, 298 GB data, 79653 objects
            769 GB used, 55855 GB / 56625 GB avail
            1/164674 objects degraded (0.001%)
            10349/164674 objects misplaced (6.285%)
                1505 active+clean
                  27 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 active+remapped
recovery io 710 MB/s, 185 objects/s
  client io 14275 kB/s wr, 0 op/s rd, 1783 op/s wr
2017-06-03 04:15:35.243907 7f28767c7700 -1 asok(0x7f2870000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.73677.139811654472064.asok': (13) Permission denied

2017-06-03 12:15:33,513 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:15:33,513 INFO cluster.py [line:239] usefull PG number is 1505
2017-06-03 12:16:33,557 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-03 12:16:33,557 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:16:33,930 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            17 pgs backfill_wait
            recovery 1/162291 objects degraded (0.001%)
            recovery 5946/162291 objects misplaced (3.664%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e448: 20 osds: 20 up, 20 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3451: 1536 pgs, 2 pools, 298 GB data, 79659 objects
            768 GB used, 55856 GB / 56625 GB avail
            1/162291 objects degraded (0.001%)
            5946/162291 objects misplaced (3.664%)
                1519 active+clean
                  17 active+remapped+backfill_wait
recovery io 87983 kB/s, 21 objects/s
  client io 29095 kB/s wr, 0 op/s rd, 3636 op/s wr
2017-06-03 04:16:35.663154 7f4a3fdc5700 -1 asok(0x7f4a38000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.4054.139956743836032.asok': (13) Permission denied

2017-06-03 12:16:33,930 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:16:33,930 INFO cluster.py [line:239] usefull PG number is 1519
2017-06-03 12:17:33,971 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-03 12:17:33,972 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:17:34,336 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            recovery 3048/160875 objects misplaced (1.895%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e464: 20 osds: 20 up, 20 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3523: 1536 pgs, 2 pools, 298 GB data, 79665 objects
            768 GB used, 55856 GB / 56625 GB avail
            3048/160875 objects misplaced (1.895%)
                1526 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
  client io 18417 kB/s wr, 0 op/s rd, 2300 op/s wr
2017-06-03 04:17:36.089299 7f7d34fe9700 -1 asok(0x7f7d30000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.7606.140175652950400.asok': (13) Permission denied

2017-06-03 12:17:34,337 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:17:34,337 INFO cluster.py [line:239] usefull PG number is 1526
2017-06-03 12:18:34,359 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-03 12:18:34,360 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:18:34,696 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            1 pgs backfilling
            recovery 207/159488 objects misplaced (0.130%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e482: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3599: 1536 pgs, 2 pools, 298 GB data, 79671 objects
            769 GB used, 55855 GB / 56625 GB avail
            207/159488 objects misplaced (0.130%)
                1535 active+clean
                   1 active+remapped+backfilling
  client io 19110 kB/s wr, 0 op/s rd, 2388 op/s wr
2017-06-03 04:18:36.439743 7f5b037a2700 -1 asok(0x7f5afc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.10575.140028751647104.asok': (13) Permission denied

2017-06-03 12:18:34,697 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:18:34,697 INFO cluster.py [line:239] usefull PG number is 1535
2017-06-03 12:19:34,754 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-03 12:19:34,754 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:19:35,122 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            55 pgs backfill_wait
            8 pgs backfilling
            7 pgs degraded
            7 pgs recovery_wait
            4 pgs stuck unclean
            recovery 30/170078 objects degraded (0.018%)
            recovery 20838/170078 objects misplaced (12.252%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e522: 19 osds: 19 up, 19 in; 62 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3680: 1536 pgs, 2 pools, 298 GB data, 79677 objects
            763 GB used, 53030 GB / 53794 GB avail
            30/170078 objects degraded (0.018%)
            20838/170078 objects misplaced (12.252%)
                1466 active+clean
                  55 active+remapped+backfill_wait
                   8 active+remapped+backfilling
                   7 active+recovery_wait+degraded
recovery io 2357 MB/s, 620 objects/s
  client io 17355 kB/s wr, 0 op/s rd, 2169 op/s wr
2017-06-03 04:19:36.845277 7fca868b8700 -1 asok(0x7fca80000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.13362.140507707609472.asok': (13) Permission denied

2017-06-03 12:19:35,123 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:19:35,123 INFO cluster.py [line:239] usefull PG number is 1466
2017-06-03 12:20:35,170 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-03 12:20:35,170 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:20:35,541 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            24 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            recovery 8405/163626 objects misplaced (5.137%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e565: 19 osds: 19 up, 19 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3761: 1536 pgs, 2 pools, 298 GB data, 79683 objects
            760 GB used, 53033 GB / 53794 GB avail
            8405/163626 objects misplaced (5.137%)
                1510 active+clean
                  24 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 655 MB/s, 170 objects/s
  client io 28053 kB/s wr, 0 op/s rd, 3507 op/s wr
2017-06-03 04:20:37.284187 7fe74df88700 -1 asok(0x7fe748000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.16325.140631322136960.asok': (13) Permission denied

2017-06-03 12:20:35,541 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:20:35,541 INFO cluster.py [line:239] usefull PG number is 1510
2017-06-03 12:21:35,582 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-03 12:21:35,582 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:21:36,053 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            recovery 5500/162242 objects misplaced (3.390%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e584: 19 osds: 19 up, 19 in; 15 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3838: 1536 pgs, 2 pools, 298 GB data, 79689 objects
            760 GB used, 53033 GB / 53794 GB avail
            5500/162242 objects misplaced (3.390%)
                1520 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 29541 kB/s wr, 0 op/s rd, 3692 op/s wr
2017-06-03 04:21:37.678232 7fed58942700 -1 asok(0x7fed54000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.19291.140657293267328.asok': (13) Permission denied

2017-06-03 12:21:36,053 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:21:36,053 INFO cluster.py [line:239] usefull PG number is 1520
2017-06-03 12:22:36,111 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-03 12:22:36,111 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:22:36,511 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            5 pgs backfill_wait
            recovery 1548/160162 objects misplaced (0.967%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e604: 19 osds: 19 up, 19 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3915: 1536 pgs, 2 pools, 298 GB data, 79694 objects
            760 GB used, 53033 GB / 53794 GB avail
            1548/160162 objects misplaced (0.967%)
                1531 active+clean
                   5 active+remapped+backfill_wait
recovery io 337 MB/s, 89 objects/s
  client io 25652 kB/s wr, 0 op/s rd, 3207 op/s wr
2017-06-03 04:22:38.244827 7f65dc1d7700 -1 asok(0x7f65d4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.22258.140075325198720.asok': (13) Permission denied

2017-06-03 12:22:36,511 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:22:36,511 INFO cluster.py [line:239] usefull PG number is 1531
2017-06-03 12:23:36,560 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-03 12:23:36,560 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:23:36,893 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_ERR
            4 pgs are stuck inactive for more than 300 seconds
            87 pgs backfill_wait
            12 pgs backfilling
            180 pgs degraded
            78 pgs recovery_wait
            4 pgs stuck inactive
            25 pgs stuck unclean
            recovery 693/176723 objects degraded (0.392%)
            recovery 33816/176723 objects misplaced (19.135%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e624: 18 osds: 18 up, 18 in; 97 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v3990: 1536 pgs, 2 pools, 298 GB data, 79699 objects
            753 GB used, 50209 GB / 50962 GB avail
            693/176723 objects degraded (0.392%)
            33816/176723 objects misplaced (19.135%)
                1257 active+clean
                  91 active+degraded
                  87 active+remapped+backfill_wait
                  78 active+recovery_wait+degraded
                  12 active+remapped+backfilling
                  11 activating+degraded
recovery io 1514 MB/s, 4 keys/s, 399 objects/s
  client io 6901 B/s rd, 19333 kB/s wr, 4 op/s rd, 1954 op/s wr
2017-06-03 04:23:38.635619 7f6a7ecd9700 -1 asok(0x7f6a78000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.24995.140095256531328.asok': (13) Permission denied

2017-06-03 12:23:36,893 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-03 12:24:36,954 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:24:37,295 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            32 pgs backfill_wait
            5 pgs backfilling
            1 pgs peering
            recovery 1/165798 objects degraded (0.001%)
            recovery 12384/165798 objects misplaced (7.469%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e674: 18 osds: 18 up, 18 in; 37 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4077: 1536 pgs, 2 pools, 298 GB data, 79705 objects
            753 GB used, 50209 GB / 50962 GB avail
            1/165798 objects degraded (0.001%)
            12384/165798 objects misplaced (7.469%)
                1498 active+clean
                  32 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 peering
recovery io 1591 MB/s, 415 objects/s
  client io 6940 B/s rd, 21232 kB/s wr, 4 op/s rd, 2652 op/s wr
2017-06-03 04:24:39.046925 7f0164c16700 -1 asok(0x7f0160000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.27941.139643882312064.asok': (13) Permission denied

2017-06-03 12:24:37,295 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:24:37,295 INFO cluster.py [line:239] usefull PG number is 1498
2017-06-03 12:25:37,348 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-03 12:25:37,348 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:25:37,701 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            12 pgs backfill_wait
            2 pgs backfilling
            recovery 1/161866 objects degraded (0.001%)
            recovery 4739/161866 objects misplaced (2.928%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e709: 18 osds: 18 up, 18 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4161: 1536 pgs, 2 pools, 298 GB data, 79711 objects
            751 GB used, 50211 GB / 50962 GB avail
            1/161866 objects degraded (0.001%)
            4739/161866 objects misplaced (2.928%)
                1522 active+clean
                  12 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 142 MB/s, 38 objects/s
  client io 15595 kB/s wr, 0 op/s rd, 1948 op/s wr
2017-06-03 04:25:39.440890 7f3da75dc700 -1 asok(0x7f3da0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.30909.139902654091648.asok': (13) Permission denied

2017-06-03 12:25:37,701 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:25:37,701 INFO cluster.py [line:239] usefull PG number is 1522
2017-06-03 12:26:37,761 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-03 12:26:37,762 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:26:38,119 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            recovery 910/159901 objects misplaced (0.569%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e729: 18 osds: 18 up, 18 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4239: 1536 pgs, 2 pools, 298 GB data, 79717 objects
            751 GB used, 50211 GB / 50962 GB avail
            910/159901 objects misplaced (0.569%)
                1533 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 295 MB/s, 76 objects/s
  client io 21059 kB/s wr, 0 op/s rd, 2631 op/s wr
2017-06-03 04:26:39.873148 7f0af701b700 -1 asok(0x7f0af0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.33881.139684952936832.asok': (13) Permission denied

2017-06-03 12:26:38,120 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:26:38,120 INFO cluster.py [line:239] usefull PG number is 1533
2017-06-03 12:27:38,174 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-03 12:27:38,174 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:27:38,669 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            94 pgs backfill_wait
            4 pgs backfilling
            108 pgs degraded
            1 pgs recovering
            107 pgs recovery_wait
            42 pgs stuck unclean
            recovery 464/175927 objects degraded (0.264%)
            recovery 32566/175927 objects misplaced (18.511%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e756: 17 osds: 17 up, 17 in; 97 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4317: 1536 pgs, 2 pools, 298 GB data, 79723 objects
            744 GB used, 47386 GB / 48131 GB avail
            464/175927 objects degraded (0.264%)
            32566/175927 objects misplaced (18.511%)
                1329 active+clean
                 107 active+recovery_wait+degraded
                  94 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 active+recovering+degraded
                   1 active+remapped
recovery io 696 MB/s, 186 objects/s
  client io 12347 kB/s wr, 0 op/s rd, 1542 op/s wr
2017-06-03 04:27:40.288367 7fc28d96a700 -1 asok(0x7fc288000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.36597.140473482088832.asok': (13) Permission denied

2017-06-03 12:27:38,670 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:27:38,670 INFO cluster.py [line:239] usefull PG number is 1329
2017-06-03 12:28:38,714 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-03 12:28:38,714 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:28:39,086 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            39 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            recovery 1/166387 objects degraded (0.001%)
            recovery 13570/166387 objects misplaced (8.156%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e803: 17 osds: 17 up, 17 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4399: 1536 pgs, 2 pools, 298 GB data, 79729 objects
            744 GB used, 47387 GB / 48131 GB avail
            1/166387 objects degraded (0.001%)
            13570/166387 objects misplaced (8.156%)
                1492 active+clean
                  39 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 397 MB/s, 104 objects/s
  client io 11868 kB/s wr, 0 op/s rd, 1482 op/s wr
2017-06-03 04:28:40.813272 7fbb64f24700 -1 asok(0x7fbb60000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.39579.140442746229120.asok': (13) Permission denied

2017-06-03 12:28:39,087 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:28:39,087 INFO cluster.py [line:239] usefull PG number is 1492
2017-06-03 12:29:39,123 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-03 12:29:39,124 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:29:39,498 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            19 pgs backfill_wait
            2 pgs backfilling
            recovery 1/162925 objects degraded (0.001%)
            recovery 6773/162925 objects misplaced (4.157%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e834: 17 osds: 17 up, 17 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4479: 1536 pgs, 2 pools, 298 GB data, 79735 objects
            743 GB used, 47388 GB / 48131 GB avail
            1/162925 objects degraded (0.001%)
            6773/162925 objects misplaced (4.157%)
                1515 active+clean
                  19 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 953 MB/s, 247 objects/s
  client io 15851 kB/s wr, 0 op/s rd, 1980 op/s wr
2017-06-03 04:29:41.244151 7fe80eaa1700 -1 asok(0x7fe808000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.42524.140634543362432.asok': (13) Permission denied

2017-06-03 12:29:39,499 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:29:39,499 INFO cluster.py [line:239] usefull PG number is 1515
2017-06-03 12:30:39,559 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-03 12:30:39,560 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:30:39,937 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            10 pgs backfill_wait
            1 pgs backfilling
            recovery 1/161273 objects degraded (0.001%)
            recovery 3497/161273 objects misplaced (2.168%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e854: 17 osds: 17 up, 17 in; 11 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4555: 1536 pgs, 2 pools, 298 GB data, 79741 objects
            743 GB used, 47387 GB / 48131 GB avail
            1/161273 objects degraded (0.001%)
            3497/161273 objects misplaced (2.168%)
                1525 active+clean
                  10 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 17900 kB/s wr, 0 op/s rd, 2236 op/s wr
2017-06-03 04:30:41.675482 7f05d26ae700 -1 asok(0x7f05cc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.45477.139662874120576.asok': (13) Permission denied

2017-06-03 12:30:39,937 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:30:39,937 INFO cluster.py [line:239] usefull PG number is 1525
2017-06-03 12:31:39,974 INFO cluster.py [line:247] cost 60 seconds, left 4973 seconds when check the ceph status
2017-06-03 12:31:39,974 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:31:40,347 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            1 pgs backfilling
            recovery 160/159623 objects misplaced (0.100%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e876: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4632: 1536 pgs, 2 pools, 298 GB data, 79747 objects
            742 GB used, 47388 GB / 48131 GB avail
            160/159623 objects misplaced (0.100%)
                1535 active+clean
                   1 active+remapped+backfilling
  client io 32510 kB/s wr, 0 op/s rd, 4063 op/s wr
2017-06-03 04:31:42.072285 7f017d02e700 -1 asok(0x7f0178000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.48451.139644284965248.asok': (13) Permission denied

2017-06-03 12:31:40,347 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:31:40,347 INFO cluster.py [line:239] usefull PG number is 1535
2017-06-03 12:32:40,388 INFO cluster.py [line:247] cost 61 seconds, left 4912 seconds when check the ceph status
2017-06-03 12:32:40,388 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:32:40,762 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            91 pgs backfill_wait
            5 pgs backfilling
            recovery 2/176618 objects degraded (0.001%)
            recovery 33983/176618 objects misplaced (19.241%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e908: 17 osds: 17 up, 16 in; 96 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4709: 1536 pgs, 2 pools, 298 GB data, 79753 objects
            737 GB used, 44563 GB / 45300 GB avail
            2/176618 objects degraded (0.001%)
            33983/176618 objects misplaced (19.241%)
                1440 active+clean
                  91 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 1016 MB/s, 266 objects/s
  client io 14499 kB/s wr, 0 op/s rd, 1812 op/s wr
2017-06-03 04:32:42.490647 7f742f5b7700 -1 asok(0x7f7428000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.51252.140136864027008.asok': (13) Permission denied

2017-06-03 12:32:40,762 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:32:40,762 INFO cluster.py [line:239] usefull PG number is 1440
2017-06-03 12:33:40,822 INFO cluster.py [line:247] cost 60 seconds, left 4852 seconds when check the ceph status
2017-06-03 12:33:40,823 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:33:41,209 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            47 pgs backfill_wait
            6 pgs backfilling
            recovery 18631/169162 objects misplaced (11.014%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e955: 17 osds: 17 up, 16 in; 52 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4788: 1536 pgs, 2 pools, 298 GB data, 79759 objects
            736 GB used, 44563 GB / 45300 GB avail
            18631/169162 objects misplaced (11.014%)
                1482 active+clean
                  47 active+remapped+backfill_wait
                   6 active+remapped+backfilling
                   1 active+remapped
recovery io 2901 MB/s, 761 objects/s
  client io 25356 kB/s wr, 0 op/s rd, 3169 op/s wr
2017-06-03 04:33:42.933261 7ff77f7ea700 -1 asok(0x7ff778000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.54213.140700846920064.asok': (13) Permission denied

2017-06-03 12:33:41,210 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:33:41,210 INFO cluster.py [line:239] usefull PG number is 1482
2017-06-03 12:34:41,246 INFO cluster.py [line:247] cost 61 seconds, left 4791 seconds when check the ceph status
2017-06-03 12:34:41,246 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:34:41,619 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            23 pgs backfill_wait
            2 pgs backfilling
            recovery 8333/163768 objects misplaced (5.088%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e989: 17 osds: 17 up, 16 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4867: 1536 pgs, 2 pools, 298 GB data, 79765 objects
            735 GB used, 44564 GB / 45300 GB avail
            8333/163768 objects misplaced (5.088%)
                1511 active+clean
                  23 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 20512 kB/s wr, 0 op/s rd, 2561 op/s wr
2017-06-03 04:34:43.347476 7faf18f06700 -1 asok(0x7faf14000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.57134.140389931553152.asok': (13) Permission denied

2017-06-03 12:34:41,620 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:34:41,620 INFO cluster.py [line:239] usefull PG number is 1511
2017-06-03 12:35:41,635 INFO cluster.py [line:247] cost 60 seconds, left 4731 seconds when check the ceph status
2017-06-03 12:35:41,636 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:35:42,022 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            11 pgs backfill_wait
            recovery 4232/161656 objects misplaced (2.618%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1014: 17 osds: 17 up, 16 in; 11 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v4944: 1536 pgs, 2 pools, 298 GB data, 79770 objects
            734 GB used, 44565 GB / 45300 GB avail
            4232/161656 objects misplaced (2.618%)
                1525 active+clean
                  11 active+remapped+backfill_wait
recovery io 381 MB/s, 97 objects/s
  client io 29903 kB/s wr, 0 op/s rd, 3736 op/s wr
2017-06-03 04:35:43.752071 7fbd300dd700 -1 asok(0x7fbd28000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.60173.140450396639616.asok': (13) Permission denied

2017-06-03 12:35:42,023 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:35:42,023 INFO cluster.py [line:239] usefull PG number is 1525
2017-06-03 12:36:42,083 INFO cluster.py [line:247] cost 61 seconds, left 4670 seconds when check the ceph status
2017-06-03 12:36:42,083 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:36:42,447 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1038: 17 osds: 17 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5024: 1536 pgs, 2 pools, 298 GB data, 79776 objects
            725 GB used, 41743 GB / 42468 GB avail
                1536 active+clean
  client io 26262 kB/s wr, 0 op/s rd, 3280 op/s wr
2017-06-03 04:36:44.181157 7f22b2a83700 -1 asok(0x7f22ac000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.63050.139786891301248.asok': (13) Permission denied

2017-06-03 12:36:42,448 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:36:42,448 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 12:36:42,448 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.6 in cluster successfully
2017-06-03 12:36:43,024 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 12:36:43,024 INFO client.py [line:174] IO is running
2017-06-03 12:36:43,024 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:50] 
Now operate osd on ubuntu-B
2017-06-03 12:36:43,025 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.7
2017-06-03 12:36:43,025 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.7 pid for kill
2017-06-03 12:36:43,307 INFO node.py [line:150] osd.7  ---> processId 54412
2017-06-03 12:36:43,307 INFO node.py [line:150] osd.8  ---> processId 54858
2017-06-03 12:36:43,307 INFO node.py [line:150] osd.9  ---> processId 55305
2017-06-03 12:36:43,307 INFO node.py [line:150] osd.10  ---> processId 55757
2017-06-03 12:36:43,308 INFO node.py [line:150] osd.11  ---> processId 56200
2017-06-03 12:36:43,308 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 12:36:43,308 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.7 by kill
2017-06-03 12:36:43,308 INFO osd.py [line:53] execute command is sudo -i kill 54412 & sleep 3
2017-06-03 12:36:46,800 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.7
2017-06-03 12:36:46,800 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 12:36:46,800 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 7 & sleep 30
2017-06-03 12:37:17,020 INFO osd.py [line:107] osd osd.7 is start successfully
2017-06-03 12:37:17,020 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 12:37:17,020 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 7'
2017-06-03 12:37:17,296 INFO osd.py [line:118] enali    2003  2002  0 04:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 7'
denali    2005  2003  0 04:37 ?        00:00:00 grep ceph-osd -i 7

2017-06-03 12:37:17,296 INFO osd.py [line:123] osd.7has not started, start again
2017-06-03 12:37:17,297 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 12:37:17,297 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 7 & sleep 30
2017-06-03 12:37:47,565 INFO osd.py [line:107] osd osd.7 is start successfully
2017-06-03 12:37:47,565 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 12:37:47,565 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 7'
2017-06-03 12:37:47,829 INFO osd.py [line:118] oot      2025     1 99 04:37 ?        00:00:43 ceph-osd -i 7
denali    2379  2378  0 04:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 7'
denali    2381  2379  0 04:37 ?        00:00:00 grep ceph-osd -i 7

2017-06-03 12:37:47,830 INFO osd.py [line:127] osd.7has already started
2017-06-03 12:38:18,087 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:38:18,438 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            73 pgs backfill_wait
            2 pgs backfilling
            53 pgs degraded
            2 pgs recovering
            50 pgs recovery_wait
            3 pgs stuck unclean
            recovery 1913/173915 objects degraded (1.100%)
            recovery 28537/173915 objects misplaced (16.409%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1098: 17 osds: 17 up, 15 in; 78 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5150: 1536 pgs, 2 pools, 298 GB data, 79786 objects
            730 GB used, 41738 GB / 42468 GB avail
            1913/173915 objects degraded (1.100%)
            28537/173915 objects misplaced (16.409%)
                1409 active+clean
                  73 active+remapped+backfill_wait
                  47 active+recovery_wait+degraded
                   3 active+recovery_wait+degraded+remapped
                   2 active+recovering+degraded
                   1 active+remapped+backfilling
                   1 active+degraded+remapped+backfilling
recovery io 157 MB/s, 40 objects/s
  client io 3556 kB/s wr, 0 op/s rd, 445 op/s wr
2017-06-03 04:38:20.192450 7fe5b40aa700 -1 asok(0x7fe5ac000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.2723.140624409923968.asok': (13) Permission denied

2017-06-03 12:38:18,438 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:38:18,439 INFO cluster.py [line:239] usefull PG number is 1409
2017-06-03 12:39:18,462 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 12:39:18,462 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:39:18,850 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            51 pgs backfill_wait
            1 pgs backfilling
            15 pgs degraded
            1 pgs peering
            1 pgs recovering
            14 pgs recovery_wait
            recovery 159/168894 objects degraded (0.094%)
            recovery 18606/168894 objects misplaced (11.016%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1138: 17 osds: 17 up, 15 in; 52 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5233: 1536 pgs, 2 pools, 298 GB data, 79792 objects
            726 GB used, 41742 GB / 42468 GB avail
            159/168894 objects degraded (0.094%)
            18606/168894 objects misplaced (11.016%)
                1468 active+clean
                  51 active+remapped+backfill_wait
                  14 active+recovery_wait+degraded
                   1 active+remapped+backfilling
                   1 active+recovering+degraded
                   1 peering
recovery io 241 MB/s, 62 objects/s
  client io 5987 B/s rd, 16119 kB/s wr, 4 op/s rd, 2016 op/s wr
2017-06-03 04:39:20.601529 7fcfb7072700 -1 asok(0x7fcfb0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.3256.140529987752320.asok': (13) Permission denied

2017-06-03 12:39:18,850 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:39:18,850 INFO cluster.py [line:239] usefull PG number is 1468
2017-06-03 12:40:18,863 INFO cluster.py [line:247] cost 60 seconds, left 5880 seconds when check the ceph status
2017-06-03 12:40:18,863 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:40:19,258 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            33 pgs backfill_wait
            2 pgs backfilling
            recovery 1/165762 objects degraded (0.001%)
            recovery 12023/165762 objects misplaced (7.253%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1165: 17 osds: 17 up, 15 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5317: 1536 pgs, 2 pools, 298 GB data, 79796 objects
            725 GB used, 41743 GB / 42468 GB avail
            1/165762 objects degraded (0.001%)
            12023/165762 objects misplaced (7.253%)
                1500 active+clean
                  33 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
  client io 3026 B/s rd, 12290 kB/s wr, 2 op/s rd, 1537 op/s wr
2017-06-03 04:40:21.015806 7fe55b870700 -1 asok(0x7fe554000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.4031.140622933528960.asok': (13) Permission denied

2017-06-03 12:40:19,259 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:40:19,259 INFO cluster.py [line:239] usefull PG number is 1500
2017-06-03 12:41:19,319 INFO cluster.py [line:247] cost 61 seconds, left 5819 seconds when check the ceph status
2017-06-03 12:41:19,320 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:41:19,712 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            24 pgs backfill_wait
            1 pgs backfilling
            recovery 1/164100 objects degraded (0.001%)
            recovery 8915/164100 objects misplaced (5.433%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1180: 17 osds: 17 up, 15 in; 25 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5387: 1536 pgs, 2 pools, 298 GB data, 79802 objects
            725 GB used, 41743 GB / 42468 GB avail
            1/164100 objects degraded (0.001%)
            8915/164100 objects misplaced (5.433%)
                1511 active+clean
                  24 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 3518 B/s rd, 16509 kB/s wr, 2 op/s rd, 2064 op/s wr
2017-06-03 04:41:21.453859 7f6446efc700 -1 asok(0x7f6440000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.4790.140068547203456.asok': (13) Permission denied

2017-06-03 12:41:19,712 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:41:19,713 INFO cluster.py [line:239] usefull PG number is 1511
2017-06-03 12:42:19,766 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-03 12:42:19,766 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:42:20,228 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            9 pgs stuck unclean
            recovery 3546/161466 objects misplaced (2.196%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1208: 17 osds: 17 up, 15 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5465: 1536 pgs, 2 pools, 298 GB data, 79808 objects
            726 GB used, 41742 GB / 42468 GB avail
            3546/161466 objects misplaced (2.196%)
                1526 active+clean
                   8 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 607 MB/s, 159 objects/s
  client io 14481 kB/s wr, 0 op/s rd, 1810 op/s wr
2017-06-03 04:42:21.956295 7fd105773700 -1 asok(0x7fd100000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.5622.140535624896896.asok': (13) Permission denied

2017-06-03 12:42:20,228 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:42:20,228 INFO cluster.py [line:239] usefull PG number is 1526
2017-06-03 12:43:20,256 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-03 12:43:20,256 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:43:20,637 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 372/159960 objects misplaced (0.233%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1224: 17 osds: 17 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5537: 1536 pgs, 2 pools, 298 GB data, 79814 objects
            725 GB used, 41743 GB / 42468 GB avail
            372/159960 objects misplaced (0.233%)
                1535 active+clean
                   1 active+remapped+backfilling
  client io 40668 kB/s wr, 0 op/s rd, 5083 op/s wr
2017-06-03 04:43:22.391043 7f4ded1d2700 -1 asok(0x7f4de8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.6144.139972581527936.asok': (13) Permission denied

2017-06-03 12:43:20,637 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:43:20,637 INFO cluster.py [line:239] usefull PG number is 1535
2017-06-03 12:44:20,676 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-03 12:44:20,677 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:44:21,086 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            64 pgs backfill_wait
            7 pgs backfilling
            1 pgs peering
            recovery 1/172839 objects degraded (0.001%)
            recovery 25846/172839 objects misplaced (14.954%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1262: 17 osds: 17 up, 14 in; 69 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5622: 1536 pgs, 2 pools, 298 GB data, 79820 objects
            717 GB used, 38920 GB / 39637 GB avail
            1/172839 objects degraded (0.001%)
            25846/172839 objects misplaced (14.954%)
                1463 active+clean
                  64 active+remapped+backfill_wait
                   7 active+remapped+backfilling
                   1 active+remapped
                   1 peering
recovery io 2149 MB/s, 19 keys/s, 563 objects/s
  client io 22442 kB/s wr, 0 op/s rd, 2805 op/s wr
2017-06-03 04:44:22.817857 7ff82425c700 -1 asok(0x7ff81c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.6686.140703598383488.asok': (13) Permission denied

2017-06-03 12:44:21,086 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:44:21,086 INFO cluster.py [line:239] usefull PG number is 1463
2017-06-03 12:45:21,147 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-03 12:45:21,147 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:45:21,596 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            31 pgs backfill_wait
            2 pgs backfilling
            recovery 1/166533 objects degraded (0.001%)
            recovery 13476/166533 objects misplaced (8.092%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1306: 17 osds: 17 up, 14 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5703: 1536 pgs, 2 pools, 298 GB data, 79825 objects
            718 GB used, 38919 GB / 39637 GB avail
            1/166533 objects degraded (0.001%)
            13476/166533 objects misplaced (8.092%)
                1502 active+clean
                  31 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 813 MB/s, 216 objects/s
  client io 36565 kB/s wr, 0 op/s rd, 4568 op/s wr
2017-06-03 04:45:23.331936 7f68ad009700 -1 asok(0x7f68a8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.7212.140087471903104.asok': (13) Permission denied

2017-06-03 12:45:21,596 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:45:21,596 INFO cluster.py [line:239] usefull PG number is 1502
2017-06-03 12:46:21,638 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-03 12:46:21,639 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:46:22,020 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            recovery 8320/163930 objects misplaced (5.075%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1333: 17 osds: 17 up, 14 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5786: 1536 pgs, 2 pools, 298 GB data, 79831 objects
            716 GB used, 38921 GB / 39637 GB avail
            8320/163930 objects misplaced (5.075%)
                1517 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 550 MB/s, 144 objects/s
  client io 31059 kB/s wr, 0 op/s rd, 3881 op/s wr
2017-06-03 04:46:23.783115 7f77cfb8c700 -1 asok(0x7f77c8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.7736.140152433283456.asok': (13) Permission denied

2017-06-03 12:46:22,021 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:46:22,021 INFO cluster.py [line:239] usefull PG number is 1517
2017-06-03 12:47:22,081 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-03 12:47:22,082 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:47:22,506 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            9 pgs backfill_wait
            2 pgs backfilling
            recovery 4394/161959 objects misplaced (2.713%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1351: 17 osds: 17 up, 14 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5859: 1536 pgs, 2 pools, 298 GB data, 79837 objects
            717 GB used, 38920 GB / 39637 GB avail
            4394/161959 objects misplaced (2.713%)
                1525 active+clean
                   9 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 198 MB/s, 50 objects/s
  client io 17234 kB/s wr, 0 op/s rd, 2153 op/s wr
2017-06-03 04:47:24.238650 7f2a6936b700 -1 asok(0x7f2a64000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.8255.139820043080064.asok': (13) Permission denied

2017-06-03 12:47:22,507 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:47:22,507 INFO cluster.py [line:239] usefull PG number is 1525
2017-06-03 12:48:22,526 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-03 12:48:22,526 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:48:22,962 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1373: 17 osds: 17 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v5936: 1536 pgs, 2 pools, 298 GB data, 79843 objects
            708 GB used, 36098 GB / 36806 GB avail
                1536 active+clean
  client io 7325 kB/s wr, 0 op/s rd, 915 op/s wr
2017-06-03 04:48:24.701417 7f95861b6700 -1 asok(0x7f9580000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.8777.140280074342784.asok': (13) Permission denied

2017-06-03 12:48:22,963 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:48:22,963 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 12:48:22,963 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.7 in cluster successfully
2017-06-03 12:48:23,514 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 12:48:23,514 INFO client.py [line:174] IO is running
2017-06-03 12:48:23,514 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.8
2017-06-03 12:48:23,514 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.8 pid for kill
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.7  ---> processId 2025
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.8  ---> processId 54858
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.9  ---> processId 55305
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.10  ---> processId 55757
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.11  ---> processId 56200
2017-06-03 12:48:23,794 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 12:48:23,794 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.8 by kill
2017-06-03 12:48:23,794 INFO osd.py [line:53] execute command is sudo -i kill 54858 & sleep 3
2017-06-03 12:48:27,255 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.8
2017-06-03 12:48:27,256 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 12:48:27,256 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 8 & sleep 30
2017-06-03 12:48:57,477 INFO osd.py [line:107] osd osd.8 is start successfully
2017-06-03 12:48:57,477 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 12:48:57,477 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 8'
2017-06-03 12:48:57,762 INFO osd.py [line:118] enali    9173  9172  0 04:48 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 8'
denali    9175  9173  0 04:48 ?        00:00:00 grep ceph-osd -i 8

2017-06-03 12:48:57,762 INFO osd.py [line:123] osd.8has not started, start again
2017-06-03 12:48:57,762 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 12:48:57,763 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 8 & sleep 30
2017-06-03 12:49:27,985 INFO osd.py [line:107] osd osd.8 is start successfully
2017-06-03 12:49:27,985 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 12:49:27,985 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 8'
2017-06-03 12:49:28,298 INFO osd.py [line:118] oot      9198     1 99 04:48 ?        00:00:42 ceph-osd -i 8
denali    9540  9539  0 04:49 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 8'
denali    9542  9540  0 04:49 ?        00:00:00 grep ceph-osd -i 8

2017-06-03 12:49:28,298 INFO osd.py [line:127] osd.8has already started
2017-06-03 12:49:58,535 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:49:58,954 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            79 pgs backfill_wait
            1 pgs backfilling
            92 pgs degraded
            1 pgs recovering
            87 pgs recovery_wait
            29 pgs stuck unclean
            4 pgs undersized
            recovery 4459/173856 objects degraded (2.565%)
            recovery 28726/173856 objects misplaced (16.523%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1401: 18 osds: 18 up, 14 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6048: 1536 pgs, 2 pools, 298 GB data, 79853 objects
            717 GB used, 38919 GB / 39637 GB avail
            4459/173856 objects degraded (2.565%)
            28726/173856 objects misplaced (16.523%)
                1368 active+clean
                  81 active+recovery_wait+degraded
                  75 active+remapped+backfill_wait
                   6 active+recovery_wait+degraded+remapped
                   4 active+undersized+degraded+remapped+backfill_wait
                   1 active+recovering+degraded
                   1 active+remapped+backfilling
recovery io 279 MB/s, 70 objects/s
  client io 6943 kB/s wr, 0 op/s rd, 867 op/s wr
2017-06-03 04:50:00.692397 7f752e33a700 -1 asok(0x7f7528000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.9795.140141158994304.asok': (13) Permission denied

2017-06-03 12:49:58,954 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:49:58,955 INFO cluster.py [line:239] usefull PG number is 1368
2017-06-03 12:50:59,015 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 12:50:59,015 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:50:59,441 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            75 pgs backfill_wait
            53 pgs degraded
            52 pgs recovery_wait
            19 pgs stuck unclean
            1 pgs undersized
            recovery 795/173057 objects degraded (0.459%)
            recovery 26675/173057 objects misplaced (15.414%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1415: 18 osds: 18 up, 14 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6120: 1536 pgs, 2 pools, 298 GB data, 79859 objects
            717 GB used, 38920 GB / 39637 GB avail
            795/173057 objects degraded (0.459%)
            26675/173057 objects misplaced (15.414%)
                1409 active+clean
                  74 active+remapped+backfill_wait
                  48 active+recovery_wait+degraded
                   4 active+recovery_wait+degraded+remapped
                   1 active+undersized+degraded+remapped+backfill_wait
recovery io 341 MB/s, 88 objects/s
  client io 6745 kB/s wr, 0 op/s rd, 843 op/s wr
2017-06-03 04:51:01.167658 7f309dfd7700 -1 asok(0x7f3098000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.10319.139846685299072.asok': (13) Permission denied

2017-06-03 12:50:59,441 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:50:59,442 INFO cluster.py [line:239] usefull PG number is 1409
2017-06-03 12:51:59,495 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 12:51:59,495 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:51:59,935 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            71 pgs backfill_wait
            2 pgs backfilling
            3 pgs degraded
            1 pgs recovery_wait
            1 pgs undersized
            recovery 169/172153 objects degraded (0.098%)
            recovery 24728/172153 objects misplaced (14.364%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1429: 18 osds: 18 up, 14 in; 72 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6190: 1536 pgs, 2 pools, 298 GB data, 79865 objects
            717 GB used, 38920 GB / 39637 GB avail
            169/172153 objects degraded (0.098%)
            24728/172153 objects misplaced (14.364%)
                1462 active+clean
                  71 active+remapped+backfill_wait
                   1 active+undersized+degraded+remapped+backfilling
                   1 active+recovery_wait+degraded
                   1 active+degraded+remapped+backfilling
  client io 13522 kB/s wr, 0 op/s rd, 1687 op/s wr
2017-06-03 04:52:01.669007 7f397f494700 -1 asok(0x7f3978000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.10849.139884803133824.asok': (13) Permission denied

2017-06-03 12:51:59,935 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:51:59,935 INFO cluster.py [line:239] usefull PG number is 1462
2017-06-03 12:52:59,972 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-03 12:52:59,972 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:53:00,353 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            64 pgs backfill_wait
            2 pgs backfilling
            recovery 6/171111 objects degraded (0.004%)
            recovery 22392/171111 objects misplaced (13.086%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1443: 18 osds: 18 up, 14 in; 65 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6258: 1536 pgs, 2 pools, 298 GB data, 79871 objects
            717 GB used, 38920 GB / 39637 GB avail
            6/171111 objects degraded (0.004%)
            22392/171111 objects misplaced (13.086%)
                1470 active+clean
                  64 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 3037 B/s rd, 15203 kB/s wr, 2 op/s rd, 1901 op/s wr
2017-06-03 04:53:02.109694 7f6f110dd700 -1 asok(0x7f6f0c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.11363.140114919428480.asok': (13) Permission denied

2017-06-03 12:53:00,353 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:53:00,353 INFO cluster.py [line:239] usefull PG number is 1470
2017-06-03 12:54:00,413 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-03 12:54:00,414 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:54:00,810 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            58 pgs backfill_wait
            1 pgs backfilling
            59 pgs stuck unclean
            recovery 6/169847 objects degraded (0.004%)
            recovery 20003/169847 objects misplaced (11.777%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1455: 18 osds: 18 up, 14 in; 59 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6327: 1536 pgs, 2 pools, 298 GB data, 79876 objects
            718 GB used, 38919 GB / 39637 GB avail
            6/169847 objects degraded (0.004%)
            20003/169847 objects misplaced (11.777%)
                1477 active+clean
                  58 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 27954 kB/s wr, 0 op/s rd, 3493 op/s wr
2017-06-03 04:54:02.567444 7f952105b700 -1 asok(0x7f951c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.11886.140278396621184.asok': (13) Permission denied

2017-06-03 12:54:00,811 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:54:00,811 INFO cluster.py [line:239] usefull PG number is 1477
2017-06-03 12:55:00,865 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-03 12:55:00,865 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:55:01,300 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            51 pgs backfill_wait
            1 pgs backfilling
            52 pgs stuck unclean
            recovery 7/168812 objects degraded (0.004%)
            recovery 17840/168812 objects misplaced (10.568%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1471: 18 osds: 18 up, 14 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6397: 1536 pgs, 2 pools, 299 GB data, 79882 objects
            717 GB used, 38919 GB / 39637 GB avail
            7/168812 objects degraded (0.004%)
            17840/168812 objects misplaced (10.568%)
                1484 active+clean
                  51 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 41881 kB/s wr, 0 op/s rd, 5232 op/s wr
2017-06-03 04:55:03.035487 7f32249b5700 -1 asok(0x7f3220000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.12411.139853261967744.asok': (13) Permission denied

2017-06-03 12:55:01,300 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:55:01,300 INFO cluster.py [line:239] usefull PG number is 1484
2017-06-03 12:56:01,360 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-03 12:56:01,361 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:56:01,792 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            44 pgs backfill_wait
            1 pgs backfilling
            45 pgs stuck unclean
            recovery 6/167772 objects degraded (0.004%)
            recovery 15739/167772 objects misplaced (9.381%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1483: 18 osds: 18 up, 14 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6465: 1536 pgs, 2 pools, 299 GB data, 79889 objects
            718 GB used, 38919 GB / 39637 GB avail
            6/167772 objects degraded (0.004%)
            15739/167772 objects misplaced (9.381%)
                1491 active+clean
                  44 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 292 MB/s, 74 objects/s
  client io 26063 kB/s wr, 0 op/s rd, 3257 op/s wr
2017-06-03 04:56:03.548840 7fd14134f700 -1 asok(0x7fd13c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.12943.140536631529856.asok': (13) Permission denied

2017-06-03 12:56:01,793 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:56:01,793 INFO cluster.py [line:239] usefull PG number is 1491
2017-06-03 12:57:01,803 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-03 12:57:01,803 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:57:02,162 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            37 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            38 pgs stuck unclean
            recovery 7/166599 objects degraded (0.004%)
            recovery 13442/166599 objects misplaced (8.068%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1497: 18 osds: 18 up, 14 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6536: 1536 pgs, 2 pools, 299 GB data, 79894 objects
            717 GB used, 38920 GB / 39637 GB avail
            7/166599 objects degraded (0.004%)
            13442/166599 objects misplaced (8.068%)
                1497 active+clean
                  37 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 289 MB/s, 74 objects/s
  client io 3519 B/s rd, 31212 kB/s wr, 2 op/s rd, 3902 op/s wr
2017-06-03 04:57:03.921190 7f51c63f7700 -1 asok(0x7f51c0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.13459.139989090308480.asok': (13) Permission denied

2017-06-03 12:57:02,162 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:57:02,162 INFO cluster.py [line:239] usefull PG number is 1497
2017-06-03 12:58:02,218 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-03 12:58:02,218 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:58:02,650 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 7/165411 objects degraded (0.004%)
            recovery 11102/165411 objects misplaced (6.712%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1511: 18 osds: 18 up, 14 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6608: 1536 pgs, 2 pools, 299 GB data, 79899 objects
            717 GB used, 38919 GB / 39637 GB avail
            7/165411 objects degraded (0.004%)
            11102/165411 objects misplaced (6.712%)
                1505 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 202 MB/s, 53 objects/s
  client io 21235 kB/s wr, 0 op/s rd, 2654 op/s wr
2017-06-03 04:58:04.389086 7f71ebbc7700 -1 asok(0x7f71e4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.13976.140127133241728.asok': (13) Permission denied

2017-06-03 12:58:02,650 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:58:02,650 INFO cluster.py [line:239] usefull PG number is 1505
2017-06-03 12:59:02,710 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-03 12:59:02,711 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 12:59:03,239 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            22 pgs backfill_wait
            1 pgs backfilling
            23 pgs stuck unclean
            recovery 4/163882 objects degraded (0.002%)
            recovery 8082/163882 objects misplaced (4.932%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1527: 18 osds: 18 up, 14 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6680: 1536 pgs, 2 pools, 299 GB data, 79905 objects
            717 GB used, 38920 GB / 39637 GB avail
            4/163882 objects degraded (0.002%)
            8082/163882 objects misplaced (4.932%)
                1513 active+clean
                  22 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 19052 kB/s wr, 0 op/s rd, 2381 op/s wr
2017-06-03 04:59:04.866213 7f71d9c2c700 -1 asok(0x7f71d4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.14494.140126864806272.asok': (13) Permission denied

2017-06-03 12:59:03,240 INFO cluster.py [line:238] PG number is 1536
2017-06-03 12:59:03,240 INFO cluster.py [line:239] usefull PG number is 1513
2017-06-03 13:00:03,300 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-03 13:00:03,301 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:00:03,677 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            16 pgs backfill_wait
            1 pgs backfilling
            17 pgs stuck unclean
            recovery 3/162944 objects degraded (0.002%)
            recovery 6120/162944 objects misplaced (3.756%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1539: 18 osds: 18 up, 14 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6749: 1536 pgs, 2 pools, 299 GB data, 79911 objects
            717 GB used, 38920 GB / 39637 GB avail
            3/162944 objects degraded (0.002%)
            6120/162944 objects misplaced (3.756%)
                1519 active+clean
                  16 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 15367 kB/s wr, 0 op/s rd, 1920 op/s wr
2017-06-03 05:00:05.438202 7f9bf3811700 -1 asok(0x7f9bec000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.15028.140307656085888.asok': (13) Permission denied

2017-06-03 13:00:03,677 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:00:03,677 INFO cluster.py [line:239] usefull PG number is 1519
2017-06-03 13:01:03,722 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-03 13:01:03,722 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:01:04,091 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            9 pgs stuck unclean
            recovery 2/161334 objects degraded (0.001%)
            recovery 2993/161334 objects misplaced (1.855%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1555: 18 osds: 18 up, 14 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6822: 1536 pgs, 2 pools, 299 GB data, 79917 objects
            717 GB used, 38920 GB / 39637 GB avail
            2/161334 objects degraded (0.001%)
            2993/161334 objects misplaced (1.855%)
                1527 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 16136 kB/s wr, 0 op/s rd, 2017 op/s wr
2017-06-03 05:01:05.855681 7f85a044c700 -1 asok(0x7f8598000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.15547.140211757519232.asok': (13) Permission denied

2017-06-03 13:01:04,092 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:01:04,092 INFO cluster.py [line:239] usefull PG number is 1527
2017-06-03 13:02:04,130 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-03 13:02:04,131 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:02:04,549 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            3 pgs stuck unclean
            recovery 1/160441 objects degraded (0.001%)
            recovery 1148/160441 objects misplaced (0.716%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1567: 18 osds: 18 up, 14 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6891: 1536 pgs, 2 pools, 299 GB data, 79923 objects
            716 GB used, 38920 GB / 39637 GB avail
            1/160441 objects degraded (0.001%)
            1148/160441 objects misplaced (0.716%)
                1533 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 11233 kB/s wr, 0 op/s rd, 1404 op/s wr
2017-06-03 05:02:06.286357 7f926478f700 -1 asok(0x7f925c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.16061.140266585461120.asok': (13) Permission denied

2017-06-03 13:02:04,549 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:02:04,550 INFO cluster.py [line:239] usefull PG number is 1533
2017-06-03 13:03:04,582 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-03 13:03:04,582 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:03:05,001 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1574: 19 osds: 18 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v6957: 1536 pgs, 2 pools, 299 GB data, 79929 objects
            716 GB used, 38920 GB / 39637 GB avail
                1536 active+clean
  client io 12866 kB/s wr, 0 op/s rd, 1608 op/s wr
2017-06-03 05:03:06.735777 7f37a2a5a700 -1 asok(0x7f379c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.16589.139876817179008.asok': (13) Permission denied

2017-06-03 13:03:05,001 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:03:05,001 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:03:05,001 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.8 in cluster successfully
2017-06-03 13:03:05,573 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:03:05,573 INFO client.py [line:174] IO is running
2017-06-03 13:03:05,573 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.9
2017-06-03 13:03:05,573 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.9 pid for kill
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.7  ---> processId 2025
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.8  ---> processId 9198
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.9  ---> processId 55305
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.10  ---> processId 55757
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.11  ---> processId 56200
2017-06-03 13:03:05,859 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 13:03:05,860 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.9 by kill
2017-06-03 13:03:05,860 INFO osd.py [line:53] execute command is sudo -i kill 55305 & sleep 3
2017-06-03 13:03:09,353 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.9
2017-06-03 13:03:09,353 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:03:09,354 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 9 & sleep 30
2017-06-03 13:03:39,543 INFO osd.py [line:107] osd osd.9 is start successfully
2017-06-03 13:03:39,543 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:03:39,543 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 9'
2017-06-03 13:03:39,813 INFO osd.py [line:118] enali   16957 16956  0 05:03 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 9'
denali   16959 16957  0 05:03 ?        00:00:00 grep ceph-osd -i 9

2017-06-03 13:03:39,813 INFO osd.py [line:123] osd.9has not started, start again
2017-06-03 13:03:39,814 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:03:39,814 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 9 & sleep 30
2017-06-03 13:04:10,036 INFO osd.py [line:107] osd osd.9 is start successfully
2017-06-03 13:04:10,036 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:04:10,036 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 9'
2017-06-03 13:04:10,305 INFO osd.py [line:118] oot     16982     1 99 05:03 ?        00:00:46 ceph-osd -i 9
denali   17329 17328  0 05:04 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 9'
denali   17331 17329  0 05:04 ?        00:00:00 grep ceph-osd -i 9

2017-06-03 13:04:10,305 INFO osd.py [line:127] osd.9has already started
2017-06-03 13:04:40,547 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:04:40,988 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            103 pgs backfill_wait
            2 pgs backfilling
            78 pgs degraded
            1 pgs peering
            1 pgs recovering
            67 pgs recovery_wait
            20 pgs stuck unclean
            10 pgs undersized
            recovery 4153/176306 objects degraded (2.356%)
            recovery 34236/176306 objects misplaced (19.419%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1618: 19 osds: 19 up, 15 in; 106 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7081: 1536 pgs, 2 pools, 299 GB data, 79939 objects
            727 GB used, 41741 GB / 42468 GB avail
            4153/176306 objects degraded (2.356%)
            34236/176306 objects misplaced (19.419%)
                1362 active+clean
                  94 active+remapped+backfill_wait
                  66 active+recovery_wait+degraded
                   9 active+undersized+degraded+remapped+backfill_wait
                   1 active+recovering+degraded
                   1 peering
                   1 active+recovery_wait+degraded+remapped
                   1 active+undersized+degraded+remapped+backfilling
                   1 active+remapped+backfilling
recovery io 528 MB/s, 134 objects/s
  client io 9912 kB/s wr, 0 op/s rd, 1239 op/s wr
2017-06-03 05:04:42.733782 7f295a8d9700 -1 asok(0x7f2954000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.17584.139815479677312.asok': (13) Permission denied

2017-06-03 13:04:40,989 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:04:40,989 INFO cluster.py [line:239] usefull PG number is 1362
2017-06-03 13:05:41,049 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:05:41,049 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:05:41,442 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            91 pgs backfill_wait
            2 pgs backfilling
            16 pgs degraded
            12 pgs recovery_wait
            3 pgs stuck unclean
            3 pgs undersized
            recovery 613/174873 objects degraded (0.351%)
            recovery 30242/174873 objects misplaced (17.294%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1641: 19 osds: 19 up, 15 in; 93 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7159: 1536 pgs, 2 pools, 299 GB data, 79945 objects
            726 GB used, 41742 GB / 42468 GB avail
            613/174873 objects degraded (0.351%)
            30242/174873 objects misplaced (17.294%)
                1431 active+clean
                  88 active+remapped+backfill_wait
                  12 active+recovery_wait+degraded
                   2 active+undersized+degraded+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+degraded+remapped+backfill_wait
                   1 active+undersized+degraded+remapped+backfilling
recovery io 299 MB/s, 79 objects/s
  client io 20910 kB/s wr, 0 op/s rd, 2613 op/s wr
2017-06-03 05:05:43.198317 7f3449bc4700 -1 asok(0x7f3444000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.18107.139862455882112.asok': (13) Permission denied

2017-06-03 13:05:41,442 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:05:41,442 INFO cluster.py [line:239] usefull PG number is 1431
2017-06-03 13:06:41,495 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 13:06:41,495 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:06:41,898 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            78 pgs backfill_wait
            1 pgs backfilling
            recovery 3/173334 objects degraded (0.002%)
            recovery 26537/173334 objects misplaced (15.310%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1665: 19 osds: 19 up, 15 in; 78 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7235: 1536 pgs, 2 pools, 299 GB data, 79951 objects
            726 GB used, 41742 GB / 42468 GB avail
            3/173334 objects degraded (0.002%)
            26537/173334 objects misplaced (15.310%)
                1456 active+clean
                  78 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
  client io 25150 kB/s wr, 0 op/s rd, 3143 op/s wr
2017-06-03 05:06:43.633242 7fe85b589700 -1 asok(0x7fe854000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.18646.140635818430848.asok': (13) Permission denied

2017-06-03 13:06:41,899 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:06:41,899 INFO cluster.py [line:239] usefull PG number is 1456
2017-06-03 13:07:41,934 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-03 13:07:41,934 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:07:42,345 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            64 pgs backfill_wait
            2 pgs backfilling
            recovery 4/171164 objects degraded (0.002%)
            recovery 22346/171164 objects misplaced (13.055%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1688: 19 osds: 19 up, 15 in; 66 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7313: 1536 pgs, 2 pools, 299 GB data, 79957 objects
            726 GB used, 41742 GB / 42468 GB avail
            4/171164 objects degraded (0.002%)
            22346/171164 objects misplaced (13.055%)
                1470 active+clean
                  64 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 222 MB/s, 58 objects/s
  client io 28127 kB/s wr, 0 op/s rd, 3515 op/s wr
2017-06-03 05:07:44.104287 7f4809e71700 -1 asok(0x7f4804000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.19166.139947281486208.asok': (13) Permission denied

2017-06-03 13:07:42,345 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:07:42,346 INFO cluster.py [line:239] usefull PG number is 1470
2017-06-03 13:08:42,352 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-03 13:08:42,352 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:08:42,743 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            56 pgs backfill_wait
            1 pgs backfilling
            57 pgs stuck unclean
            recovery 5/169673 objects degraded (0.003%)
            recovery 19334/169673 objects misplaced (11.395%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1706: 19 osds: 19 up, 15 in; 57 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7389: 1536 pgs, 2 pools, 299 GB data, 79963 objects
            726 GB used, 41742 GB / 42468 GB avail
            5/169673 objects degraded (0.003%)
            19334/169673 objects misplaced (11.395%)
                1479 active+clean
                  56 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 314 MB/s, 81 objects/s
  client io 28732 kB/s wr, 0 op/s rd, 3591 op/s wr
2017-06-03 05:08:44.492998 7f0f31012700 -1 asok(0x7f0f2c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.19681.139703139438976.asok': (13) Permission denied

2017-06-03 13:08:42,743 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:08:42,743 INFO cluster.py [line:239] usefull PG number is 1479
2017-06-03 13:09:42,803 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-03 13:09:42,804 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:09:43,208 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            50 pgs backfill_wait
            1 pgs peering
            50 pgs stuck unclean
            recovery 6/168417 objects degraded (0.004%)
            recovery 16912/168417 objects misplaced (10.042%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1720: 19 osds: 19 up, 15 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7459: 1536 pgs, 2 pools, 299 GB data, 79969 objects
            726 GB used, 41742 GB / 42468 GB avail
            6/168417 objects degraded (0.004%)
            16912/168417 objects misplaced (10.042%)
                1485 active+clean
                  50 active+remapped+backfill_wait
                   1 peering
2017-06-03 05:09:44.957778 7f764485d700 -1 asok(0x7f7640000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.20198.140145856614784.asok': (13) Permission denied

2017-06-03 13:09:43,208 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:09:43,209 INFO cluster.py [line:239] usefull PG number is 1485
2017-06-03 13:10:43,244 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-03 13:10:43,245 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:10:43,724 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            44 pgs stuck unclean
            recovery 6/167529 objects degraded (0.004%)
            recovery 15007/167529 objects misplaced (8.958%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1732: 19 osds: 19 up, 15 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7529: 1536 pgs, 2 pools, 299 GB data, 79975 objects
            725 GB used, 41743 GB / 42468 GB avail
            6/167529 objects degraded (0.004%)
            15007/167529 objects misplaced (8.958%)
                1492 active+clean
                  43 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 9304 kB/s wr, 0 op/s rd, 1163 op/s wr
2017-06-03 05:10:45.462442 7fd5acbf4700 -1 asok(0x7fd5a8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.20710.140555623338368.asok': (13) Permission denied

2017-06-03 13:10:43,724 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:10:43,724 INFO cluster.py [line:239] usefull PG number is 1492
2017-06-03 13:11:43,760 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-03 13:11:43,761 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:11:44,158 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            36 pgs backfill_wait
            1 pgs backfilling
            37 pgs stuck unclean
            recovery 5/166306 objects degraded (0.003%)
            recovery 12611/166306 objects misplaced (7.583%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1746: 19 osds: 19 up, 15 in; 37 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7598: 1536 pgs, 2 pools, 299 GB data, 79980 objects
            725 GB used, 41743 GB / 42468 GB avail
            5/166306 objects degraded (0.003%)
            12611/166306 objects misplaced (7.583%)
                1499 active+clean
                  36 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 154 MB/s, 40 objects/s
  client io 3009 B/s rd, 9654 kB/s wr, 2 op/s rd, 1207 op/s wr
2017-06-03 05:11:45.915057 7f7ec4dd7700 -1 asok(0x7f7ec0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.21232.140182363836800.asok': (13) Permission denied

2017-06-03 13:11:44,158 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:11:44,158 INFO cluster.py [line:239] usefull PG number is 1499
2017-06-03 13:12:44,219 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-03 13:12:44,219 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:12:44,641 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 6/165334 objects degraded (0.004%)
            recovery 10606/165334 objects misplaced (6.415%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1758: 19 osds: 19 up, 15 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7668: 1536 pgs, 2 pools, 299 GB data, 79987 objects
            726 GB used, 41742 GB / 42468 GB avail
            6/165334 objects degraded (0.004%)
            10606/165334 objects misplaced (6.415%)
                1505 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 436 MB/s, 113 objects/s
  client io 3018 B/s rd, 12887 kB/s wr, 2 op/s rd, 1612 op/s wr
2017-06-03 05:12:46.377345 7fc21bf09700 -1 asok(0x7fc214000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.21750.140471535931776.asok': (13) Permission denied

2017-06-03 13:12:44,642 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:12:44,642 INFO cluster.py [line:239] usefull PG number is 1505
2017-06-03 13:13:44,646 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-03 13:13:44,647 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:13:45,081 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            24 pgs backfill_wait
            24 pgs stuck unclean
            recovery 6/164161 objects degraded (0.004%)
            recovery 8327/164161 objects misplaced (5.072%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1772: 19 osds: 19 up, 15 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7740: 1536 pgs, 2 pools, 299 GB data, 79992 objects
            726 GB used, 41742 GB / 42468 GB avail
            6/164161 objects degraded (0.004%)
            8327/164161 objects misplaced (5.072%)
                1512 active+clean
                  24 active+remapped+backfill_wait
recovery io 54889 kB/s, 13 objects/s
  client io 3048 B/s rd, 13893 kB/s wr, 2 op/s rd, 1737 op/s wr
2017-06-03 05:13:46.837706 7fef69bb4700 -1 asok(0x7fef64000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.22267.140666151637376.asok': (13) Permission denied

2017-06-03 13:13:45,081 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:13:45,082 INFO cluster.py [line:239] usefull PG number is 1512
2017-06-03 13:14:45,131 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-03 13:14:45,131 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:14:45,547 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs backfilling
            18 pgs stuck unclean
            recovery 4/163238 objects degraded (0.002%)
            recovery 6443/163238 objects misplaced (3.947%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1784: 19 osds: 19 up, 15 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7809: 1536 pgs, 2 pools, 299 GB data, 79997 objects
            725 GB used, 41743 GB / 42468 GB avail
            4/163238 objects degraded (0.002%)
            6443/163238 objects misplaced (3.947%)
                1518 active+clean
                  17 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 19618 kB/s wr, 0 op/s rd, 2452 op/s wr
2017-06-03 05:14:47.286724 7fe35545b700 -1 asok(0x7fe350000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.22782.140614276485504.asok': (13) Permission denied

2017-06-03 13:14:45,547 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:14:45,547 INFO cluster.py [line:239] usefull PG number is 1518
2017-06-03 13:15:45,591 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-03 13:15:45,592 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:15:45,998 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            11 pgs backfill_wait
            1 pgs backfilling
            12 pgs stuck unclean
            recovery 3/162184 objects degraded (0.002%)
            recovery 4294/162184 objects misplaced (2.648%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1796: 19 osds: 19 up, 15 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7879: 1536 pgs, 2 pools, 299 GB data, 80003 objects
            726 GB used, 41742 GB / 42468 GB avail
            3/162184 objects degraded (0.002%)
            4294/162184 objects misplaced (2.648%)
                1524 active+clean
                  11 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24440 kB/s wr, 0 op/s rd, 3055 op/s wr
2017-06-03 05:15:47.733903 7f9047b7c700 -1 asok(0x7f9040000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.23324.140257525764480.asok': (13) Permission denied

2017-06-03 13:15:45,998 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:15:45,998 INFO cluster.py [line:239] usefull PG number is 1524
2017-06-03 13:16:46,007 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-03 13:16:46,007 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:16:46,404 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            4 pgs backfill_wait
            1 pgs backfilling
            5 pgs stuck unclean
            recovery 1/160781 objects degraded (0.001%)
            recovery 1386/160781 objects misplaced (0.862%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1810: 19 osds: 19 up, 15 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v7949: 1536 pgs, 2 pools, 299 GB data, 80009 objects
            726 GB used, 41742 GB / 42468 GB avail
            1/160781 objects degraded (0.001%)
            1386/160781 objects misplaced (0.862%)
                1531 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 292 MB/s, 76 objects/s
  client io 26111 kB/s wr, 0 op/s rd, 3263 op/s wr
2017-06-03 05:16:48.149676 7f6e218d9700 -1 asok(0x7f6e1c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.23839.140110892896640.asok': (13) Permission denied

2017-06-03 13:16:46,404 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:16:46,404 INFO cluster.py [line:239] usefull PG number is 1531
2017-06-03 13:17:46,426 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-03 13:17:46,427 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:17:46,835 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1820: 19 osds: 19 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8019: 1536 pgs, 2 pools, 299 GB data, 80015 objects
            725 GB used, 41743 GB / 42468 GB avail
                1536 active+clean
  client io 40685 kB/s wr, 0 op/s rd, 5085 op/s wr
2017-06-03 05:17:48.583351 7fcd9fca0700 -1 asok(0x7fcd98000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.24361.140520995164544.asok': (13) Permission denied

2017-06-03 13:17:46,835 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:17:46,835 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:17:46,835 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.9 in cluster successfully
2017-06-03 13:17:47,354 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:17:47,354 INFO client.py [line:174] IO is running
2017-06-03 13:17:47,354 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.10
2017-06-03 13:17:47,354 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.10 pid for kill
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.7  ---> processId 2025
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.8  ---> processId 9198
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.9  ---> processId 16982
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.10  ---> processId 55757
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.11  ---> processId 56200
2017-06-03 13:17:47,633 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 13:17:47,633 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.10 by kill
2017-06-03 13:17:47,633 INFO osd.py [line:53] execute command is sudo -i kill 55757 & sleep 3
2017-06-03 13:17:51,119 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.10
2017-06-03 13:17:51,119 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:17:51,119 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 10 & sleep 30
2017-06-03 13:18:21,372 INFO osd.py [line:107] osd osd.10 is start successfully
2017-06-03 13:18:21,372 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:18:21,373 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 10'
2017-06-03 13:18:21,653 INFO osd.py [line:118] enali   24733 24732  0 05:18 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 10'
denali   24735 24733  0 05:18 ?        00:00:00 grep ceph-osd -i 10

2017-06-03 13:18:21,653 INFO osd.py [line:123] osd.10has not started, start again
2017-06-03 13:18:21,653 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:18:21,653 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 10 & sleep 30
2017-06-03 13:18:51,882 INFO osd.py [line:107] osd osd.10 is start successfully
2017-06-03 13:18:51,882 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:18:51,883 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 10'
2017-06-03 13:18:52,168 INFO osd.py [line:118] oot     24755     1 99 05:18 ?        00:00:52 ceph-osd -i 10
denali   25098 25097  0 05:18 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 10'
denali   25100 25098  0 05:18 ?        00:00:00 grep ceph-osd -i 10

2017-06-03 13:18:52,168 INFO osd.py [line:127] osd.10has already started
2017-06-03 13:19:22,432 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:19:22,830 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            52 pgs degraded
            2 pgs recovering
            50 pgs recovery_wait
            recovery 3078/160050 objects degraded (1.923%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1825: 19 osds: 19 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8117: 1536 pgs, 2 pools, 299 GB data, 80025 objects
            725 GB used, 41743 GB / 42468 GB avail
            3078/160050 objects degraded (1.923%)
                1484 active+clean
                  50 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 851 MB/s, 213 objects/s
  client io 10665 kB/s wr, 0 op/s rd, 1333 op/s wr
2017-06-03 05:19:24.594698 7fb7b03c5700 -1 asok(0x7fb7a8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.25356.140426774319488.asok': (13) Permission denied

2017-06-03 13:19:22,831 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:19:22,831 INFO cluster.py [line:239] usefull PG number is 1484
2017-06-03 13:20:22,873 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 13:20:22,873 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:20:23,277 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1825: 19 osds: 19 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8176: 1536 pgs, 2 pools, 299 GB data, 80031 objects
            725 GB used, 41743 GB / 42468 GB avail
                1536 active+clean
  client io 27371 kB/s wr, 0 op/s rd, 3421 op/s wr
2017-06-03 05:20:25.011656 7f5cca098700 -1 asok(0x7f5cc4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.25869.140036402057600.asok': (13) Permission denied

2017-06-03 13:20:23,277 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:20:23,277 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:20:23,277 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.10 in cluster successfully
2017-06-03 13:20:23,855 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:20:23,856 INFO client.py [line:174] IO is running
2017-06-03 13:20:23,856 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.11
2017-06-03 13:20:23,856 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.11 pid for kill
2017-06-03 13:20:24,139 INFO node.py [line:150] osd.7  ---> processId 2025
2017-06-03 13:20:24,139 INFO node.py [line:150] osd.8  ---> processId 9198
2017-06-03 13:20:24,139 INFO node.py [line:150] osd.9  ---> processId 16982
2017-06-03 13:20:24,140 INFO node.py [line:150] osd.10  ---> processId 24755
2017-06-03 13:20:24,140 INFO node.py [line:150] osd.11  ---> processId 56200
2017-06-03 13:20:24,140 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 13:20:24,140 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.11 by kill
2017-06-03 13:20:24,140 INFO osd.py [line:53] execute command is sudo -i kill 56200 & sleep 3
2017-06-03 13:20:27,666 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.11
2017-06-03 13:20:27,666 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:20:27,666 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 11 & sleep 30
2017-06-03 13:20:57,887 INFO osd.py [line:107] osd osd.11 is start successfully
2017-06-03 13:20:57,888 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:20:57,888 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 11'
2017-06-03 13:20:58,154 INFO osd.py [line:118] enali   26246 26245  0 05:20 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 11'
denali   26248 26246  0 05:20 ?        00:00:00 grep ceph-osd -i 11

2017-06-03 13:20:58,155 INFO osd.py [line:123] osd.11has not started, start again
2017-06-03 13:20:58,155 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:20:58,155 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 11 & sleep 30
2017-06-03 13:21:28,377 INFO osd.py [line:107] osd osd.11 is start successfully
2017-06-03 13:21:28,377 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:21:28,377 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 11'
2017-06-03 13:21:28,649 INFO osd.py [line:118] oot     26267     1 99 05:20 ?        00:00:47 ceph-osd -i 11
denali   26606 26605  0 05:21 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 11'
denali   26608 26606  0 05:21 ?        00:00:00 grep ceph-osd -i 11

2017-06-03 13:21:28,649 INFO osd.py [line:127] osd.11has already started
2017-06-03 13:21:58,906 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:21:59,316 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            93 pgs backfill_wait
            3 pgs backfilling
            65 pgs degraded
            61 pgs recovery_wait
            18 pgs stuck unclean
            3 pgs undersized
            recovery 2291/176685 objects degraded (1.297%)
            recovery 33442/176685 objects misplaced (18.927%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1869: 20 osds: 20 up, 16 in; 99 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8301: 1536 pgs, 2 pools, 299 GB data, 80041 objects
            736 GB used, 44563 GB / 45300 GB avail
            2291/176685 objects degraded (1.297%)
            33442/176685 objects misplaced (18.927%)
                1379 active+clean
                  90 active+remapped+backfill_wait
                  57 active+recovery_wait+degraded
                   4 active+recovery_wait+degraded+remapped
                   2 active+undersized+degraded+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+undersized+degraded+remapped+backfilling
                   1 active+degraded+remapped+backfill_wait
recovery io 225 MB/s, 58 objects/s
  client io 3577 B/s rd, 8128 kB/s wr, 2 op/s rd, 1017 op/s wr
2017-06-03 05:22:01.065942 7fb915100700 -1 asok(0x7fb910000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.26884.140432814117248.asok': (13) Permission denied

2017-06-03 13:21:59,316 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:21:59,316 INFO cluster.py [line:239] usefull PG number is 1379
2017-06-03 13:22:59,319 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:22:59,319 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:22:59,744 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            76 pgs backfill_wait
            3 pgs backfilling
            10 pgs degraded
            9 pgs recovery_wait
            recovery 116/173667 objects degraded (0.067%)
            recovery 26774/173667 objects misplaced (15.417%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1901: 20 osds: 20 up, 16 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8385: 1536 pgs, 2 pools, 299 GB data, 80047 objects
            736 GB used, 44564 GB / 45300 GB avail
            116/173667 objects degraded (0.067%)
            26774/173667 objects misplaced (15.417%)
                1448 active+clean
                  75 active+remapped+backfill_wait
                   7 active+recovery_wait+degraded
                   3 active+remapped+backfilling
                   2 active+recovery_wait+degraded+remapped
                   1 active+degraded+remapped+backfill_wait
recovery io 736 MB/s, 193 objects/s
  client io 5825 kB/s wr, 0 op/s rd, 728 op/s wr
2017-06-03 05:23:01.479682 7fe73c0cd700 -1 asok(0x7fe734000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.27398.140630986592640.asok': (13) Permission denied

2017-06-03 13:22:59,745 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:22:59,745 INFO cluster.py [line:239] usefull PG number is 1448
2017-06-03 13:23:59,773 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 13:23:59,773 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:24:00,143 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            60 pgs backfill_wait
            1 pgs backfilling
            3 pgs degraded
            3 pgs recovery_wait
            recovery 11/170475 objects degraded (0.006%)
            recovery 20573/170475 objects misplaced (12.068%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1931: 20 osds: 20 up, 16 in; 61 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8465: 1536 pgs, 2 pools, 299 GB data, 80051 objects
            735 GB used, 44565 GB / 45300 GB avail
            11/170475 objects degraded (0.006%)
            20573/170475 objects misplaced (12.068%)
                1472 active+clean
                  60 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
                   1 active+recovery_wait+degraded+remapped
  client io 11236 kB/s wr, 0 op/s rd, 1403 op/s wr
2017-06-03 05:24:01.882301 7f90be30d700 -1 asok(0x7f90b8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.27911.140259539030400.asok': (13) Permission denied

2017-06-03 13:24:00,144 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:24:00,144 INFO cluster.py [line:239] usefull PG number is 1472
2017-06-03 13:25:00,202 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-03 13:25:00,203 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:25:00,646 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            46 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            recovery 1/168178 objects degraded (0.001%)
            recovery 15747/168178 objects misplaced (9.363%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1957: 20 osds: 20 up, 16 in; 47 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8541: 1536 pgs, 2 pools, 299 GB data, 80057 objects
            735 GB used, 44564 GB / 45300 GB avail
            1/168178 objects degraded (0.001%)
            15747/168178 objects misplaced (9.363%)
                1487 active+clean
                  46 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 511 MB/s, 133 objects/s
  client io 11300 kB/s wr, 0 op/s rd, 1411 op/s wr
2017-06-03 05:25:02.387877 7f36c23b3700 -1 asok(0x7f36bc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.28449.139873059082624.asok': (13) Permission denied

2017-06-03 13:25:00,646 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:25:00,646 INFO cluster.py [line:239] usefull PG number is 1487
2017-06-03 13:26:00,693 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-03 13:26:00,693 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:26:01,112 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            39 pgs backfill_wait
            1 pgs backfilling
            40 pgs stuck unclean
            recovery 2/166771 objects degraded (0.001%)
            recovery 13139/166771 objects misplaced (7.878%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1972: 20 osds: 20 up, 16 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8608: 1536 pgs, 2 pools, 299 GB data, 80063 objects
            734 GB used, 44565 GB / 45300 GB avail
            2/166771 objects degraded (0.001%)
            13139/166771 objects misplaced (7.878%)
                1496 active+clean
                  39 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 304 MB/s, 79 objects/s
  client io 20558 kB/s wr, 0 op/s rd, 2569 op/s wr
2017-06-03 05:26:02.846443 7f08854bf700 -1 asok(0x7f0880000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.28963.139674483954048.asok': (13) Permission denied

2017-06-03 13:26:01,112 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:26:01,112 INFO cluster.py [line:239] usefull PG number is 1496
2017-06-03 13:27:01,131 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-03 13:27:01,131 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:27:01,550 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            33 pgs backfill_wait
            1 pgs backfilling
            34 pgs stuck unclean
            recovery 10267/165330 objects misplaced (6.210%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1984: 20 osds: 20 up, 16 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8678: 1536 pgs, 2 pools, 299 GB data, 80068 objects
            734 GB used, 44565 GB / 45300 GB avail
            10267/165330 objects misplaced (6.210%)
                1502 active+clean
                  33 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 346 MB/s, 93 objects/s
  client io 24956 kB/s wr, 0 op/s rd, 3119 op/s wr
2017-06-03 05:27:03.291851 7ff331756700 -1 asok(0x7ff32c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.29478.140682391982464.asok': (13) Permission denied

2017-06-03 13:27:01,550 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:27:01,550 INFO cluster.py [line:239] usefull PG number is 1502
2017-06-03 13:28:01,593 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-03 13:28:01,593 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:28:02,009 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            27 pgs stuck unclean
            recovery 1/164231 objects degraded (0.001%)
            recovery 8042/164231 objects misplaced (4.897%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1996: 20 osds: 20 up, 16 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8748: 1536 pgs, 2 pools, 299 GB data, 80074 objects
            734 GB used, 44565 GB / 45300 GB avail
            1/164231 objects degraded (0.001%)
            8042/164231 objects misplaced (4.897%)
                1509 active+clean
                  26 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 297 MB/s, 75 objects/s
  client io 27281 kB/s wr, 0 op/s rd, 3410 op/s wr
2017-06-03 05:28:03.753642 7fd004e02700 -1 asok(0x7fd000000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.29996.140531329929600.asok': (13) Permission denied

2017-06-03 13:28:02,009 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:28:02,009 INFO cluster.py [line:239] usefull PG number is 1509
2017-06-03 13:29:02,070 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-03 13:29:02,070 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:29:02,462 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            20 pgs backfill_wait
            1 pgs backfilling
            21 pgs stuck unclean
            recovery 1/163318 objects degraded (0.001%)
            recovery 6177/163318 objects misplaced (3.782%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2008: 20 osds: 20 up, 16 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8818: 1536 pgs, 2 pools, 299 GB data, 80080 objects
            734 GB used, 44565 GB / 45300 GB avail
            1/163318 objects degraded (0.001%)
            6177/163318 objects misplaced (3.782%)
                1515 active+clean
                  20 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 310 MB/s, 80 objects/s
  client io 34747 kB/s wr, 0 op/s rd, 4342 op/s wr
2017-06-03 05:29:04.229909 7f22a7bea700 -1 asok(0x7f22a0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.30518.139786689974656.asok': (13) Permission denied

2017-06-03 13:29:02,462 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:29:02,462 INFO cluster.py [line:239] usefull PG number is 1515
2017-06-03 13:30:02,520 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-03 13:30:02,520 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:30:02,905 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            14 pgs backfill_wait
            1 pgs backfilling
            15 pgs stuck unclean
            recovery 1/162425 objects degraded (0.001%)
            recovery 4367/162425 objects misplaced (2.689%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2020: 20 osds: 20 up, 16 in; 15 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8889: 1536 pgs, 2 pools, 299 GB data, 80086 objects
            734 GB used, 44565 GB / 45300 GB avail
            1/162425 objects degraded (0.001%)
            4367/162425 objects misplaced (2.689%)
                1521 active+clean
                  14 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 24317 kB/s wr, 0 op/s rd, 3038 op/s wr
2017-06-03 05:30:04.669762 7fb7d3f19700 -1 asok(0x7fb7cc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.31034.140427378299264.asok': (13) Permission denied

2017-06-03 13:30:02,906 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:30:02,906 INFO cluster.py [line:239] usefull PG number is 1521
2017-06-03 13:31:02,955 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-03 13:31:02,955 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:31:03,371 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs peering
            8 pgs stuck unclean
            recovery 1/161369 objects degraded (0.001%)
            recovery 2370/161369 objects misplaced (1.469%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2034: 20 osds: 20 up, 16 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v8961: 1536 pgs, 2 pools, 299 GB data, 80092 objects
            734 GB used, 44565 GB / 45300 GB avail
            1/161369 objects degraded (0.001%)
            2370/161369 objects misplaced (1.469%)
                1527 active+clean
                   8 active+remapped+backfill_wait
                   1 peering
2017-06-03 05:31:05.109302 7fb0e2d57700 -1 asok(0x7fb0dc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.31567.140397581963648.asok': (13) Permission denied

2017-06-03 13:31:03,372 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:31:03,372 INFO cluster.py [line:239] usefull PG number is 1527
2017-06-03 13:32:03,432 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-03 13:32:03,432 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:32:03,819 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            3 pgs stuck unclean
            recovery 769/160635 objects misplaced (0.479%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2046: 20 osds: 20 up, 16 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9031: 1536 pgs, 2 pools, 299 GB data, 80098 objects
            734 GB used, 44565 GB / 45300 GB avail
            769/160635 objects misplaced (0.479%)
                1533 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 6435 kB/s wr, 0 op/s rd, 804 op/s wr
2017-06-03 05:32:05.581902 7fac60dac700 -1 asok(0x7fac5c000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.32079.140378254610816.asok': (13) Permission denied

2017-06-03 13:32:03,820 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:32:03,820 INFO cluster.py [line:239] usefull PG number is 1533
2017-06-03 13:33:03,868 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-03 13:33:03,869 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:33:04,315 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2050: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9093: 1536 pgs, 2 pools, 299 GB data, 80104 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 23019 kB/s wr, 0 op/s rd, 2877 op/s wr
2017-06-03 05:33:06.066061 7fb0dd1e7700 -1 asok(0x7fb0d8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.32606.140397514854784.asok': (13) Permission denied

2017-06-03 13:33:04,315 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:33:04,315 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:33:04,315 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.11 in cluster successfully
2017-06-03 13:33:04,838 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:33:04,838 INFO client.py [line:174] IO is running
2017-06-03 13:33:04,838 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.12
2017-06-03 13:33:04,838 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.12 pid for kill
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.7  ---> processId 2025
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.8  ---> processId 9198
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.9  ---> processId 16982
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.10  ---> processId 24755
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.11  ---> processId 26267
2017-06-03 13:33:05,102 INFO node.py [line:150] osd.12  ---> processId 56652
2017-06-03 13:33:05,102 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.12 by kill
2017-06-03 13:33:05,103 INFO osd.py [line:53] execute command is sudo -i kill 56652 & sleep 3
2017-06-03 13:33:08,622 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.12
2017-06-03 13:33:08,622 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:33:08,622 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 12 & sleep 30
2017-06-03 13:33:38,845 INFO osd.py [line:107] osd osd.12 is start successfully
2017-06-03 13:33:38,845 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:33:38,845 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 12'
2017-06-03 13:33:39,118 INFO osd.py [line:118] enali   32977 32976  0 05:33 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 12'
denali   32979 32977  0 05:33 ?        00:00:00 grep ceph-osd -i 12

2017-06-03 13:33:39,118 INFO osd.py [line:123] osd.12has not started, start again
2017-06-03 13:33:39,118 INFO osd.py [line:102] node is  ubuntu-B
2017-06-03 13:33:39,118 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 12 & sleep 30
2017-06-03 13:34:09,372 INFO osd.py [line:107] osd osd.12 is start successfully
2017-06-03 13:34:09,373 INFO osd.py [line:115] node is  ubuntu-B
2017-06-03 13:34:09,373 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 12'
2017-06-03 13:34:09,655 INFO osd.py [line:118] oot     33005     1 99 05:33 ?        00:00:45 ceph-osd -i 12
denali   33347 33346  0 05:34 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 12'
denali   33349 33347  0 05:34 ?        00:00:00 grep ceph-osd -i 12

2017-06-03 13:34:09,655 INFO osd.py [line:127] osd.12has already started
2017-06-03 13:34:39,907 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:34:40,330 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            56 pgs degraded
            2 pgs recovering
            54 pgs recovery_wait
            recovery 3863/160228 objects degraded (2.411%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2055: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9189: 1536 pgs, 2 pools, 299 GB data, 80114 objects
            734 GB used, 44566 GB / 45300 GB avail
            3863/160228 objects degraded (2.411%)
                1480 active+clean
                  54 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 105 MB/s, 26 objects/s
  client io 4144 kB/s wr, 0 op/s rd, 516 op/s wr
2017-06-03 05:34:42.072999 7f3314969700 -1 asok(0x7f3310000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.33610.139857288499584.asok': (13) Permission denied

2017-06-03 13:34:40,330 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:34:40,331 INFO cluster.py [line:239] usefull PG number is 1480
2017-06-03 13:35:40,383 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:35:40,383 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:35:40,782 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            5 pgs degraded
            2 pgs recovering
            3 pgs recovery_wait
            recovery 76/160236 objects degraded (0.047%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2055: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9249: 1536 pgs, 2 pools, 299 GB data, 80118 objects
            734 GB used, 44566 GB / 45300 GB avail
            76/160236 objects degraded (0.047%)
                1531 active+clean
                   3 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 200 MB/s, 50 objects/s
  client io 12754 kB/s wr, 0 op/s rd, 1593 op/s wr
2017-06-03 05:35:42.528220 7fda58a7c700 -1 asok(0x7fda54000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.34131.140575688888704.asok': (13) Permission denied

2017-06-03 13:35:40,783 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:35:40,783 INFO cluster.py [line:239] usefull PG number is 1531
2017-06-03 13:36:40,832 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-03 13:36:40,832 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:36:41,225 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2055: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9307: 1536 pgs, 2 pools, 299 GB data, 80124 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 18991 kB/s wr, 0 op/s rd, 2372 op/s wr
2017-06-03 05:36:42.986756 7fc90cbea700 -1 asok(0x7fc908000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.34651.140501399376256.asok': (13) Permission denied

2017-06-03 13:36:41,225 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:36:41,225 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:36:41,225 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.12 in cluster successfully
2017-06-03 13:36:41,741 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:36:41,742 INFO client.py [line:174] IO is running
2017-06-03 13:36:41,742 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:50] 
Now operate osd on ubuntu-C
2017-06-03 13:36:41,742 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.13
2017-06-03 13:36:41,742 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.13 pid for kill
2017-06-03 13:36:42,022 INFO node.py [line:150] osd.13  ---> processId 57600
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.14  ---> processId 58045
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.15  ---> processId 58491
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.16  ---> processId 58929
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.17  ---> processId 59370
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:36:42,023 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:36:42,023 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.13 by kill
2017-06-03 13:36:42,023 INFO osd.py [line:53] execute command is sudo -i kill 57600 & sleep 3
2017-06-03 13:36:45,488 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.13
2017-06-03 13:36:45,488 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:36:45,488 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 13 & sleep 30
2017-06-03 13:37:15,742 INFO osd.py [line:107] osd osd.13 is start successfully
2017-06-03 13:37:15,742 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:37:15,742 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 13'
2017-06-03 13:37:16,028 INFO osd.py [line:118] enali   33011 33010  0 05:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 13'
denali   33013 33011  0 05:37 ?        00:00:00 grep ceph-osd -i 13

2017-06-03 13:37:16,028 INFO osd.py [line:123] osd.13has not started, start again
2017-06-03 13:37:16,028 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:37:16,028 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 13 & sleep 30
2017-06-03 13:37:46,281 INFO osd.py [line:107] osd osd.13 is start successfully
2017-06-03 13:37:46,282 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:37:46,282 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 13'
2017-06-03 13:37:46,676 INFO osd.py [line:118] oot     33033     1 99 05:37 ?        00:00:47 ceph-osd -i 13
denali   33372 33371  0 05:37 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 13'
denali   33374 33372  0 05:37 ?        00:00:00 grep ceph-osd -i 13

2017-06-03 13:37:46,676 INFO osd.py [line:127] osd.13has already started
2017-06-03 13:38:16,951 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:38:17,333 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            51 pgs degraded
            3 pgs recovering
            48 pgs recovery_wait
            recovery 3320/160264 objects degraded (2.072%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2060: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9402: 1536 pgs, 2 pools, 299 GB data, 80132 objects
            734 GB used, 44566 GB / 45300 GB avail
            3320/160264 objects degraded (2.072%)
                1485 active+clean
                  48 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 76698 kB/s, 18 objects/s
  client io 9524 kB/s wr, 0 op/s rd, 1190 op/s wr
2017-06-03 05:38:19.107055 7fd4a8bab700 -1 asok(0x7fd4a4000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.33633.140551261262208.asok': (13) Permission denied

2017-06-03 13:38:17,334 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:38:17,334 INFO cluster.py [line:239] usefull PG number is 1485
2017-06-03 13:39:17,366 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:39:17,367 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:39:17,760 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2060: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9462: 1536 pgs, 2 pools, 299 GB data, 80138 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
recovery io 165 MB/s, 41 objects/s
  client io 37791 kB/s wr, 0 op/s rd, 4723 op/s wr
2017-06-03 05:39:19.532009 7f002cd33700 -1 asok(0x7f0028000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.34150.139638647820672.asok': (13) Permission denied

2017-06-03 13:39:17,761 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:39:17,761 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:39:17,761 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.13 in cluster successfully
2017-06-03 13:39:18,279 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:39:18,279 INFO client.py [line:174] IO is running
2017-06-03 13:39:18,279 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.14
2017-06-03 13:39:18,280 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.14 pid for kill
2017-06-03 13:39:18,555 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:39:18,555 INFO node.py [line:150] osd.14  ---> processId 58045
2017-06-03 13:39:18,555 INFO node.py [line:150] osd.15  ---> processId 58491
2017-06-03 13:39:18,555 INFO node.py [line:150] osd.16  ---> processId 58929
2017-06-03 13:39:18,555 INFO node.py [line:150] osd.17  ---> processId 59370
2017-06-03 13:39:18,556 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:39:18,556 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:39:18,556 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.14 by kill
2017-06-03 13:39:18,556 INFO osd.py [line:53] execute command is sudo -i kill 58045 & sleep 3
2017-06-03 13:39:22,050 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.14
2017-06-03 13:39:22,050 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:39:22,050 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 14 & sleep 30
2017-06-03 13:39:52,303 INFO osd.py [line:107] osd osd.14 is start successfully
2017-06-03 13:39:52,303 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:39:52,303 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 14'
2017-06-03 13:39:52,582 INFO osd.py [line:118] enali   34523 34522  0 05:39 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 14'
denali   34525 34523  0 05:39 ?        00:00:00 grep ceph-osd -i 14

2017-06-03 13:39:52,582 INFO osd.py [line:123] osd.14has not started, start again
2017-06-03 13:39:52,582 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:39:52,582 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 14 & sleep 30
2017-06-03 13:40:22,805 INFO osd.py [line:107] osd osd.14 is start successfully
2017-06-03 13:40:22,805 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:40:22,805 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 14'
2017-06-03 13:40:23,080 INFO osd.py [line:118] oot     34546     1 99 05:39 ?        00:00:51 ceph-osd -i 14
denali   34891 34890  0 05:40 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 14'
denali   34893 34891  0 05:40 ?        00:00:00 grep ceph-osd -i 14

2017-06-03 13:40:23,080 INFO osd.py [line:127] osd.14has already started
2017-06-03 13:40:53,341 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:40:53,738 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            34 pgs degraded
            2 pgs recovering
            32 pgs recovery_wait
            recovery 1665/160296 objects degraded (1.039%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2065: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9556: 1536 pgs, 2 pools, 299 GB data, 80148 objects
            734 GB used, 44566 GB / 45300 GB avail
            1665/160296 objects degraded (1.039%)
                1502 active+clean
                  32 active+recovery_wait+degraded
                   2 active+recovering+degraded
recovery io 407 MB/s, 101 objects/s
  client io 13828 kB/s wr, 0 op/s rd, 1728 op/s wr
2017-06-03 05:40:55.508376 7f8aa532a700 -1 asok(0x7f8aa0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.35151.140233366573440.asok': (13) Permission denied

2017-06-03 13:40:53,738 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:40:53,738 INFO cluster.py [line:239] usefull PG number is 1502
2017-06-03 13:41:53,799 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 13:41:53,799 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:41:54,207 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2065: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9613: 1536 pgs, 2 pools, 299 GB data, 80154 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 26676 kB/s wr, 0 op/s rd, 3334 op/s wr
2017-06-03 05:41:55.956759 7f2bb0185700 -1 asok(0x7f2ba8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.35670.139825478898048.asok': (13) Permission denied

2017-06-03 13:41:54,208 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:41:54,208 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:41:54,208 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.14 in cluster successfully
2017-06-03 13:41:54,764 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:41:54,765 INFO client.py [line:174] IO is running
2017-06-03 13:41:54,765 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.15
2017-06-03 13:41:54,765 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.15 pid for kill
2017-06-03 13:41:55,048 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:41:55,048 INFO node.py [line:150] osd.14  ---> processId 34546
2017-06-03 13:41:55,048 INFO node.py [line:150] osd.15  ---> processId 58491
2017-06-03 13:41:55,049 INFO node.py [line:150] osd.16  ---> processId 58929
2017-06-03 13:41:55,049 INFO node.py [line:150] osd.17  ---> processId 59370
2017-06-03 13:41:55,049 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:41:55,049 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:41:55,049 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.15 by kill
2017-06-03 13:41:55,049 INFO osd.py [line:53] execute command is sudo -i kill 58491 & sleep 3
2017-06-03 13:41:58,536 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.15
2017-06-03 13:41:58,537 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:41:58,537 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 15 & sleep 30
2017-06-03 13:42:28,790 INFO osd.py [line:107] osd osd.15 is start successfully
2017-06-03 13:42:28,790 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:42:28,790 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 15'
2017-06-03 13:42:29,101 INFO osd.py [line:118] enali   36042 36041  0 05:42 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 15'
denali   36044 36042  0 05:42 ?        00:00:00 grep ceph-osd -i 15

2017-06-03 13:42:29,101 INFO osd.py [line:123] osd.15has not started, start again
2017-06-03 13:42:29,101 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:42:29,101 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 15 & sleep 30
2017-06-03 13:42:59,355 INFO osd.py [line:107] osd osd.15 is start successfully
2017-06-03 13:42:59,355 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:42:59,356 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 15'
2017-06-03 13:42:59,639 INFO osd.py [line:118] oot     36063     1 99 05:42 ?        00:00:51 ceph-osd -i 15
denali   36404 36403  0 05:43 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 15'
denali   36406 36404  0 05:43 ?        00:00:00 grep ceph-osd -i 15

2017-06-03 13:42:59,639 INFO osd.py [line:127] osd.15has already started
2017-06-03 13:43:29,894 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:43:30,316 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            49 pgs degraded
            3 pgs recovering
            46 pgs recovery_wait
            recovery 2740/160328 objects degraded (1.709%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2070: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9708: 1536 pgs, 2 pools, 299 GB data, 80164 objects
            734 GB used, 44566 GB / 45300 GB avail
            2740/160328 objects degraded (1.709%)
                1487 active+clean
                  46 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 746 MB/s, 186 objects/s
  client io 3503 B/s rd, 9205 kB/s wr, 2 op/s rd, 1150 op/s wr
2017-06-03 05:43:32.057603 7f02d197a700 -1 asok(0x7f02cc000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.36662.139649989218688.asok': (13) Permission denied

2017-06-03 13:43:30,316 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:43:30,316 INFO cluster.py [line:239] usefull PG number is 1487
2017-06-03 13:44:30,373 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:44:30,374 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:44:30,792 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2070: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9764: 1536 pgs, 2 pools, 299 GB data, 80169 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
recovery io 115 MB/s, 28 objects/s
  client io 3504 B/s rd, 21013 kB/s wr, 2 op/s rd, 2626 op/s wr
2017-06-03 05:44:32.541541 7fb0cde40700 -1 asok(0x7fb0c8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.37185.140397246419328.asok': (13) Permission denied

2017-06-03 13:44:30,792 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:44:30,792 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:44:30,792 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.15 in cluster successfully
2017-06-03 13:44:31,309 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:44:31,309 INFO client.py [line:174] IO is running
2017-06-03 13:44:31,309 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.16
2017-06-03 13:44:31,309 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.16 pid for kill
2017-06-03 13:44:31,586 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.14  ---> processId 34546
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.15  ---> processId 36063
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.16  ---> processId 58929
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.17  ---> processId 59370
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:44:31,587 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:44:31,587 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.16 by kill
2017-06-03 13:44:31,587 INFO osd.py [line:53] execute command is sudo -i kill 58929 & sleep 3
2017-06-03 13:44:35,118 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.16
2017-06-03 13:44:35,118 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:44:35,118 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 16 & sleep 30
2017-06-03 13:45:05,371 INFO osd.py [line:107] osd osd.16 is start successfully
2017-06-03 13:45:06,010 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:45:06,010 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 16'
2017-06-03 13:45:06,283 INFO osd.py [line:118] enali   37568 37566  0 05:45 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 16'
denali   37570 37568  0 05:45 ?        00:00:00 grep ceph-osd -i 16

2017-06-03 13:45:06,283 INFO osd.py [line:123] osd.16has not started, start again
2017-06-03 13:45:06,284 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:45:06,284 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 16 & sleep 30
2017-06-03 13:45:36,542 INFO osd.py [line:107] osd osd.16 is start successfully
2017-06-03 13:45:36,543 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:45:36,543 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 16'
2017-06-03 13:45:36,825 INFO osd.py [line:118] oot     37618     1 99 05:45 ?        00:00:53 ceph-osd -i 16
denali   37957 37956  0 05:45 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 16'
denali   37959 37957  0 05:45 ?        00:00:00 grep ceph-osd -i 16

2017-06-03 13:45:36,825 INFO osd.py [line:127] osd.16has already started
2017-06-03 13:46:07,091 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:46:07,513 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            33 pgs degraded
            3 pgs recovering
            30 pgs recovery_wait
            recovery 1501/160356 objects degraded (0.936%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2075: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9858: 1536 pgs, 2 pools, 299 GB data, 80178 objects
            734 GB used, 44566 GB / 45300 GB avail
            1501/160356 objects degraded (0.936%)
                1503 active+clean
                  30 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 294 MB/s, 73 objects/s
  client io 19215 kB/s wr, 0 op/s rd, 2400 op/s wr
2017-06-03 05:46:09.258728 7f0a69183700 -1 asok(0x7f0a64000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.38220.139682604126592.asok': (13) Permission denied

2017-06-03 13:46:07,513 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:46:07,513 INFO cluster.py [line:239] usefull PG number is 1503
2017-06-03 13:47:07,572 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 13:47:07,572 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:47:07,955 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2075: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v9913: 1536 pgs, 2 pools, 299 GB data, 80184 objects
            734 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 35893 kB/s wr, 0 op/s rd, 4485 op/s wr
2017-06-03 05:47:09.728652 7f3ce696c700 -1 asok(0x7f3ce0000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.38742.139899432866176.asok': (13) Permission denied

2017-06-03 13:47:07,956 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:47:07,956 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:47:07,956 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.16 in cluster successfully
2017-06-03 13:47:08,511 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:47:08,511 INFO client.py [line:174] IO is running
2017-06-03 13:47:08,511 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.17
2017-06-03 13:47:08,511 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.17 pid for kill
2017-06-03 13:47:08,789 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:47:08,789 INFO node.py [line:150] osd.14  ---> processId 34546
2017-06-03 13:47:08,790 INFO node.py [line:150] osd.15  ---> processId 36063
2017-06-03 13:47:08,790 INFO node.py [line:150] osd.16  ---> processId 37618
2017-06-03 13:47:08,790 INFO node.py [line:150] osd.17  ---> processId 59370
2017-06-03 13:47:08,790 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:47:08,790 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:47:08,790 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.17 by kill
2017-06-03 13:47:08,790 INFO osd.py [line:53] execute command is sudo -i kill 59370 & sleep 3
2017-06-03 13:47:12,246 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.17
2017-06-03 13:47:12,246 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:47:12,246 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 17 & sleep 30
2017-06-03 13:47:42,500 INFO osd.py [line:107] osd osd.17 is start successfully
2017-06-03 13:47:42,500 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:47:42,501 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 17'
2017-06-03 13:47:42,770 INFO osd.py [line:118] enali   39110 39109  0 05:47 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 17'
denali   39112 39110  0 05:47 ?        00:00:00 grep ceph-osd -i 17

2017-06-03 13:47:42,770 INFO osd.py [line:123] osd.17has not started, start again
2017-06-03 13:47:42,771 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:47:42,771 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 17 & sleep 30
2017-06-03 13:48:13,179 INFO osd.py [line:107] osd osd.17 is start successfully
2017-06-03 13:48:13,179 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:48:13,179 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 17'
2017-06-03 13:48:13,455 INFO osd.py [line:118] oot     39131     1 99 05:47 ?        00:00:46 ceph-osd -i 17
denali   39471 39470  0 05:48 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 17'
denali   39473 39471  0 05:48 ?        00:00:00 grep ceph-osd -i 17

2017-06-03 13:48:13,455 INFO osd.py [line:127] osd.17has already started
2017-06-03 13:48:43,722 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:48:44,127 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            43 pgs degraded
            1 pgs recovering
            42 pgs recovery_wait
            recovery 2795/160388 objects degraded (1.743%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2080: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10003: 1536 pgs, 2 pools, 299 GB data, 80194 objects
            733 GB used, 44566 GB / 45300 GB avail
            2795/160388 objects degraded (1.743%)
                1493 active+clean
                  42 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 292 MB/s, 73 objects/s
  client io 9974 kB/s wr, 0 op/s rd, 1245 op/s wr
2017-06-03 05:48:45.891145 7f94f1443700 -1 asok(0x7f94ec000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.39730.140277591314816.asok': (13) Permission denied

2017-06-03 13:48:44,127 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:48:44,127 INFO cluster.py [line:239] usefull PG number is 1493
2017-06-03 13:49:44,188 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:49:44,188 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:49:44,574 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2080: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10062: 1536 pgs, 2 pools, 299 GB data, 80200 objects
            733 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 20733 kB/s wr, 0 op/s rd, 2590 op/s wr
2017-06-03 05:49:46.343569 7f947baf9700 -1 asok(0x7f9474000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.40247.140275578048896.asok': (13) Permission denied

2017-06-03 13:49:44,575 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:49:44,575 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:49:44,575 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.17 in cluster successfully
2017-06-03 13:49:45,126 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:49:45,126 INFO client.py [line:174] IO is running
2017-06-03 13:49:45,126 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.18
2017-06-03 13:49:45,126 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.18 pid for kill
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.14  ---> processId 34546
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.15  ---> processId 36063
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.16  ---> processId 37618
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.17  ---> processId 39131
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.18  ---> processId 59833
2017-06-03 13:49:45,391 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:49:45,392 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.18 by kill
2017-06-03 13:49:45,392 INFO osd.py [line:53] execute command is sudo -i kill 59833 & sleep 3
2017-06-03 13:49:48,856 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.18
2017-06-03 13:49:48,856 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:49:48,857 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 18 & sleep 30
2017-06-03 13:50:19,078 INFO osd.py [line:107] osd osd.18 is start successfully
2017-06-03 13:50:19,078 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:50:19,079 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 18'
2017-06-03 13:50:19,387 INFO osd.py [line:118] enali   40618 40617  0 05:50 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 18'
denali   40620 40618  0 05:50 ?        00:00:00 grep ceph-osd -i 18

2017-06-03 13:50:19,387 INFO osd.py [line:123] osd.18has not started, start again
2017-06-03 13:50:19,388 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:50:19,388 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 18 & sleep 30
2017-06-03 13:50:49,609 INFO osd.py [line:107] osd osd.18 is start successfully
2017-06-03 13:50:49,609 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:50:49,609 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 18'
2017-06-03 13:50:49,878 INFO osd.py [line:118] oot     40639     1 99 05:50 ?        00:00:50 ceph-osd -i 18
denali   40978 40977  0 05:50 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 18'
denali   40980 40978  0 05:50 ?        00:00:00 grep ceph-osd -i 18

2017-06-03 13:50:49,878 INFO osd.py [line:127] osd.18has already started
2017-06-03 13:51:20,136 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:51:20,554 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            45 pgs degraded
            1 pgs recovering
            44 pgs recovery_wait
            recovery 2639/160420 objects degraded (1.645%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2085: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10157: 1536 pgs, 2 pools, 299 GB data, 80210 objects
            733 GB used, 44566 GB / 45300 GB avail
            2639/160420 objects degraded (1.645%)
                1491 active+clean
                  44 active+recovery_wait+degraded
                   1 active+recovering+degraded
recovery io 793 MB/s, 198 objects/s
  client io 6725 kB/s wr, 0 op/s rd, 838 op/s wr
2017-06-03 05:51:22.298207 7f93356d2700 -1 asok(0x7f9330000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.41240.140270142230912.asok': (13) Permission denied

2017-06-03 13:51:20,554 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:51:20,554 INFO cluster.py [line:239] usefull PG number is 1491
2017-06-03 13:52:20,610 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-03 13:52:20,610 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:52:21,025 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2085: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10215: 1536 pgs, 2 pools, 299 GB data, 80215 objects
            733 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 16081 kB/s wr, 0 op/s rd, 2007 op/s wr
2017-06-03 05:52:22.773335 7f25bd0c9700 -1 asok(0x7f25b8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.41755.139799977529728.asok': (13) Permission denied

2017-06-03 13:52:21,025 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:52:21,025 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:52:21,025 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.18 in cluster successfully
2017-06-03 13:52:21,538 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:52:21,539 INFO client.py [line:174] IO is running
2017-06-03 13:52:21,581 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:53] 
Now operate osd.19
2017-06-03 13:52:21,581 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:56] Set the osd.19 pid for kill
2017-06-03 13:52:21,846 INFO node.py [line:150] osd.13  ---> processId 33033
2017-06-03 13:52:21,846 INFO node.py [line:150] osd.14  ---> processId 34546
2017-06-03 13:52:21,846 INFO node.py [line:150] osd.15  ---> processId 36063
2017-06-03 13:52:21,846 INFO node.py [line:150] osd.16  ---> processId 37618
2017-06-03 13:52:21,846 INFO node.py [line:150] osd.17  ---> processId 39131
2017-06-03 13:52:21,847 INFO node.py [line:150] osd.18  ---> processId 40639
2017-06-03 13:52:21,847 INFO node.py [line:150] osd.19  ---> processId 60277
2017-06-03 13:52:21,847 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:58] shutdown osd.19 by kill
2017-06-03 13:52:21,847 INFO osd.py [line:53] execute command is sudo -i kill 60277 & sleep 3
2017-06-03 13:52:25,335 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:63] start osd.19
2017-06-03 13:52:25,335 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:52:25,335 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 19 & sleep 30
2017-06-03 13:52:55,595 INFO osd.py [line:107] osd osd.19 is start successfully
2017-06-03 13:52:55,595 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:52:55,595 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 19'
2017-06-03 13:52:55,861 INFO osd.py [line:118] enali   42126 42125  0 05:52 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 19'
denali   42128 42126  0 05:52 ?        00:00:00 grep ceph-osd -i 19

2017-06-03 13:52:55,861 INFO osd.py [line:123] osd.19has not started, start again
2017-06-03 13:52:55,861 INFO osd.py [line:102] node is  ubuntu-C
2017-06-03 13:52:55,861 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 19 & sleep 30
2017-06-03 13:53:26,116 INFO osd.py [line:107] osd osd.19 is start successfully
2017-06-03 13:53:26,116 INFO osd.py [line:115] node is  ubuntu-C
2017-06-03 13:53:26,116 INFO osd.py [line:116] execute command is ps -ef | grep 'ceph-osd -i 19'
2017-06-03 13:53:26,402 INFO osd.py [line:118] oot     42148     1 99 05:52 ?        00:00:51 ceph-osd -i 19
denali   42486 42485  0 05:53 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 19'
denali   42488 42486  0 05:53 ?        00:00:00 grep ceph-osd -i 19

2017-06-03 13:53:26,402 INFO osd.py [line:127] osd.19has already started
2017-06-03 13:53:56,701 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:53:57,113 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_WARN
            40 pgs degraded
            3 pgs recovering
            37 pgs recovery_wait
            recovery 2195/160448 objects degraded (1.368%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2090: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10312: 1536 pgs, 2 pools, 299 GB data, 80224 objects
            733 GB used, 44566 GB / 45300 GB avail
            2195/160448 objects degraded (1.368%)
                1496 active+clean
                  37 active+recovery_wait+degraded
                   3 active+recovering+degraded
recovery io 655 MB/s, 164 objects/s
  client io 12162 kB/s wr, 0 op/s rd, 1520 op/s wr
2017-06-03 05:53:58.879603 7f76af396700 -1 asok(0x7f76a8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.42751.140147601445248.asok': (13) Permission denied

2017-06-03 13:53:57,113 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:53:57,113 INFO cluster.py [line:239] usefull PG number is 1496
2017-06-03 13:54:57,167 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-03 13:54:57,167 INFO cluster.py [line:211] execute command is ceph -s
2017-06-03 13:54:57,545 INFO cluster.py [line:213]    cluster e93f3143-8693-4060-a247-132bae28385e
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 8, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2090: 20 osds: 20 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v10371: 1536 pgs, 2 pools, 299 GB data, 80230 objects
            733 GB used, 44566 GB / 45300 GB avail
                1536 active+clean
  client io 24169 kB/s wr, 0 op/s rd, 3021 op/s wr
2017-06-03 05:54:59.322648 7fe2ee01a700 -1 asok(0x7fe2e8000fe0) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-client.admin.43276.140612531655040.asok': (13) Permission denied

2017-06-03 13:54:57,545 INFO cluster.py [line:238] PG number is 1536
2017-06-03 13:54:57,546 INFO cluster.py [line:239] usefull PG number is 1536
2017-06-03 13:54:57,546 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:79] stop osd.19 in cluster successfully
2017-06-03 13:54:58,055 INFO client.py [line:172] 4
stdin: is not a tty

2017-06-03 13:54:58,055 INFO client.py [line:174] IO is running
2017-06-03 13:54:58,055 INFO TC185_shutdown_osd_on_single_node_nbd.py [line:97] TC185_shutdown_osd_on_single_node_nbd runs complete
