2017-05-24 14:11:51,026 INFO TC39_shutdown_osd_on_single_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. stop all osds in sequence
4. start all osds in sequence
5. check the cluster status
6. repeat step 2-5 on the other node

2017-05-24 14:11:51,042 INFO TC39_shutdown_osd_on_single_node.py [line:25] the timeout is 6000
2017-05-24 14:11:52,618 INFO monitors.py [line:123]    "quorum_leader_name": "denali01",

2017-05-24 14:11:52,618 INFO monitors.py [line:126]    "quorum_leader_name": "denali01",
2017-05-24 14:11:52,618 INFO TC39_shutdown_osd_on_single_node.py [line:31] start to check cluster status before case running
2017-05-24 14:11:52,680 INFO cluster.py [line:203] execute command is ceph -s
2017-05-24 14:11:53,460 INFO cluster.py [line:205]    cluster 06eb5bdc-13bc-4ee0-bcb3-b3881e7eef0a
     health HEALTH_OK
     monmap e3: 3 mons at {denali01=192.168.28.26:6789/0,denali02=192.168.28.33:6789/0,denali03=192.168.28.34:6789/0}
            election epoch 6, quorum 0,1,2 denali01,denali02,denali03
     osdmap e71: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v495: 3016 pgs, 13 pools, 17776 bytes data, 228 objects
            13634 MB used, 325 GB / 338 GB avail
                3016 active+clean
  client io 7026 B/s rd, 8029 B/s wr, 14 op/s rd, 7 op/s wr

2017-05-24 14:11:53,460 INFO cluster.py [line:230] PG number is 3016
2017-05-24 14:11:53,460 INFO cluster.py [line:231] usefull PG number is 3016
2017-05-24 14:11:53,460 INFO TC39_shutdown_osd_on_single_node.py [line:34] health status is OK
2017-05-24 14:11:53,476 INFO TC39_shutdown_osd_on_single_node.py [line:39] 
Step 1: start IO from clients
2017-05-24 14:11:53,476 INFO base.py [line:35] 
Now start IO on  clientrbdImg0
2017-05-24 14:12:04,272 INFO client.py [line:125] pid info is 12106
2017-05-24 14:12:04,272 INFO client.py [line:125] pid info is 12107
2017-05-24 14:12:04,272 INFO base.py [line:35] 
Now start IO on  clientrbdImg1
2017-05-24 14:12:09,861 INFO client.py [line:125] pid info is 12312
2017-05-24 14:12:09,861 INFO client.py [line:125] pid info is 12313
2017-05-24 14:12:09,861 INFO base.py [line:35] 
Now start IO on  clientrbdImg2
2017-05-24 14:12:10,625 INFO client.py [line:125] pid info is 12361
2017-05-24 14:12:10,625 INFO client.py [line:125] pid info is 12362
2017-05-24 14:12:10,625 INFO base.py [line:35] 
Now start IO on  clientrbdImg3
2017-05-24 14:12:11,265 INFO client.py [line:125] pid info is 12410
2017-05-24 14:12:11,265 INFO client.py [line:125] pid info is 12411
2017-05-24 14:12:11,265 INFO base.py [line:35] 
Now start IO on  clientrbdImg4
2017-05-24 14:12:12,029 INFO client.py [line:125] pid info is 12458
2017-05-24 14:12:12,029 INFO client.py [line:125] pid info is 12459
2017-05-24 14:12:12,029 INFO base.py [line:35] 
Now start IO on  clientrbdImg5
2017-05-24 14:12:12,716 INFO client.py [line:125] pid info is 12520
2017-05-24 14:12:12,716 INFO client.py [line:125] pid info is 12527
2017-05-24 14:12:12,716 INFO base.py [line:35] 
Now start IO on  clientrbdImg6
2017-05-24 14:12:13,448 INFO client.py [line:125] pid info is 12616
2017-05-24 14:12:13,448 INFO client.py [line:125] pid info is 12617
2017-05-24 14:12:13,448 INFO base.py [line:35] 
Now start IO on  clientrbdImg7
2017-05-24 14:12:14,417 INFO client.py [line:125] pid info is 12676
2017-05-24 14:12:14,417 INFO client.py [line:125] pid info is 12682
2017-05-24 14:12:14,417 INFO base.py [line:35] 
Now start IO on  clientrbdImg8
2017-05-24 14:12:15,229 INFO client.py [line:125] pid info is 12732
2017-05-24 14:12:15,229 INFO client.py [line:125] pid info is 12733
2017-05-24 14:12:15,229 INFO base.py [line:35] 
Now start IO on  clientrbdImg9
2017-05-24 14:12:21,188 INFO client.py [line:125] pid info is 12860
2017-05-24 14:12:21,188 INFO client.py [line:125] pid info is 12861
2017-05-24 14:12:21,188 INFO base.py [line:35] 
Now start IO on  clientrbdImg0
2017-05-24 14:12:22,108 INFO client.py [line:125] pid info is 12106
2017-05-24 14:12:22,108 INFO client.py [line:125] pid info is 12107
2017-05-24 14:12:22,108 INFO client.py [line:125] pid info is 12890
2017-05-24 14:12:22,108 INFO client.py [line:125] pid info is 12891
2017-05-24 14:12:22,108 INFO base.py [line:35] 
Now start IO on  clientrbdImg1
2017-05-24 14:12:22,904 INFO client.py [line:125] pid info is 12312
2017-05-24 14:12:22,904 INFO client.py [line:125] pid info is 12313
2017-05-24 14:12:22,904 INFO client.py [line:125] pid info is 12963
2017-05-24 14:12:22,904 INFO client.py [line:125] pid info is 12966
2017-05-24 14:12:22,904 INFO base.py [line:35] 
Now start IO on  clientrbdImg2
2017-05-24 14:12:23,903 INFO client.py [line:125] pid info is 12361
2017-05-24 14:12:23,903 INFO client.py [line:125] pid info is 12362
2017-05-24 14:12:23,903 INFO client.py [line:125] pid info is 13060
2017-05-24 14:12:23,903 INFO client.py [line:125] pid info is 13066
2017-05-24 14:12:23,903 INFO base.py [line:35] 
Now start IO on  clientrbdImg3
2017-05-24 14:12:24,655 INFO client.py [line:125] pid info is 12410
2017-05-24 14:12:24,655 INFO client.py [line:125] pid info is 12411
2017-05-24 14:12:24,655 INFO client.py [line:125] pid info is 13116
2017-05-24 14:12:24,655 INFO client.py [line:125] pid info is 13117
2017-05-24 14:12:24,655 INFO base.py [line:35] 
Now start IO on  clientrbdImg4
2017-05-24 14:12:25,561 INFO client.py [line:125] pid info is 12458
2017-05-24 14:12:25,561 INFO client.py [line:125] pid info is 12459
2017-05-24 14:12:25,561 INFO client.py [line:125] pid info is 13165
2017-05-24 14:12:25,561 INFO client.py [line:125] pid info is 13166
2017-05-24 14:12:25,561 INFO base.py [line:35] 
Now start IO on  clientrbdImg5
2017-05-24 14:12:31,336 INFO client.py [line:125] pid info is 12520
2017-05-24 14:12:31,336 INFO client.py [line:125] pid info is 12527
2017-05-24 14:12:31,336 INFO client.py [line:125] pid info is 13206
2017-05-24 14:12:31,336 INFO client.py [line:125] pid info is 13207
2017-05-24 14:12:31,336 INFO base.py [line:35] 
Now start IO on  clientrbdImg6
2017-05-24 14:12:36,384 INFO client.py [line:125] pid info is 12616
2017-05-24 14:12:36,384 INFO client.py [line:125] pid info is 12617
2017-05-24 14:12:36,384 INFO client.py [line:125] pid info is 13358
2017-05-24 14:12:36,384 INFO client.py [line:125] pid info is 13385
2017-05-24 14:12:36,384 INFO base.py [line:35] 
Now start IO on  clientrbdImg7
2017-05-24 14:12:41,989 INFO client.py [line:125] pid info is 12676
2017-05-24 14:12:41,989 INFO client.py [line:125] pid info is 12682
2017-05-24 14:12:41,989 INFO client.py [line:125] pid info is 13454
2017-05-24 14:12:41,989 INFO client.py [line:125] pid info is 13456
2017-05-24 14:12:41,989 INFO base.py [line:35] 
Now start IO on  clientrbdImg8
2017-05-24 14:12:43,019 INFO client.py [line:125] pid info is 12732
2017-05-24 14:12:43,019 INFO client.py [line:125] pid info is 12733
2017-05-24 14:12:43,019 INFO client.py [line:125] pid info is 13561
2017-05-24 14:12:43,019 INFO client.py [line:125] pid info is 13562
2017-05-24 14:12:43,019 INFO base.py [line:35] 
Now start IO on  clientrbdImg9
2017-05-24 14:12:48,763 INFO client.py [line:125] pid info is 12860
2017-05-24 14:12:48,763 INFO client.py [line:125] pid info is 12861
2017-05-24 14:12:48,763 INFO client.py [line:125] pid info is 13730
2017-05-24 14:12:48,763 INFO client.py [line:125] pid info is 13744
2017-05-24 14:13:48,765 INFO TC39_shutdown_osd_on_single_node.py [line:44] 
Step 2: stop osd and check IO
2017-05-24 14:13:48,765 INFO TC39_shutdown_osd_on_single_node.py [line:47] 
Now operate osd on denali01
2017-05-24 14:13:48,765 INFO TC39_shutdown_osd_on_single_node.py [line:50] 
Now operate osd.0
2017-05-24 14:13:48,765 INFO TC39_shutdown_osd_on_single_node.py [line:53] Set the osd.0 pid for kill
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.0  ---> processId 
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.1  ---> processId 
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.2  ---> processId 
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.0  ---> processId 
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.1  ---> processId 
2017-05-24 14:13:49,436 INFO node.py [line:166] osd.2  ---> processId 
2017-05-24 14:13:49,450 INFO TC39_shutdown_osd_on_single_node.py [line:55] shutdown osd.0 by kill
2017-05-24 14:13:49,450 INFO osd.py [line:51] execute command is sudo -i kill  & sleep 3
2017-05-24 14:13:53,762 INFO client.py [line:159] home/denali

2017-05-24 14:13:54,494 INFO client.py [line:159] home/denali

2017-05-24 14:13:54,884 INFO TC39_shutdown_osd_on_single_node.py [line:60] start osd.0
2017-05-24 14:13:54,884 INFO osd.py [line:100] node is  denali01
2017-05-24 14:13:54,884 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:14:25,546 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:14:25,546 INFO osd.py [line:113] node is  denali01
2017-05-24 14:14:25,546 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:14:26,232 INFO osd.py [line:116] enali   26700 26674  0 14:14 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   26702 26700  0 14:14 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:14:26,232 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:14:26,232 INFO osd.py [line:100] node is  denali01
2017-05-24 14:14:26,232 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:14:56,851 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:14:56,851 INFO osd.py [line:113] node is  denali01
2017-05-24 14:14:56,851 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:14:58,099 INFO osd.py [line:116] enali   27686 27679  0 14:15 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   27688 27686  0 14:15 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:14:58,099 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:14:58,099 INFO osd.py [line:100] node is  denali01
2017-05-24 14:14:58,099 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:15:28,763 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:15:28,763 INFO osd.py [line:113] node is  denali01
2017-05-24 14:15:28,763 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:15:29,371 INFO osd.py [line:116] enali   28557 28556  0 14:15 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   28559 28557  0 14:15 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:15:29,371 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:15:29,371 INFO osd.py [line:100] node is  denali01
2017-05-24 14:15:29,371 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:15:59,954 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:15:59,954 INFO osd.py [line:113] node is  denali01
2017-05-24 14:15:59,954 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:16:00,687 INFO osd.py [line:116] enali   29426 29425  0 14:16 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   29428 29426  0 14:16 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:16:00,687 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:16:00,687 INFO osd.py [line:100] node is  denali01
2017-05-24 14:16:00,687 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:16:31,490 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:16:31,490 INFO osd.py [line:113] node is  denali01
2017-05-24 14:16:31,490 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:16:32,441 INFO osd.py [line:116] enali   30427 30423  0 14:16 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   30429 30427  0 14:16 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:16:32,441 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:16:32,441 INFO osd.py [line:100] node is  denali01
2017-05-24 14:16:32,441 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:17:03,839 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:17:03,839 INFO osd.py [line:113] node is  denali01
2017-05-24 14:17:03,839 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:17:04,510 INFO osd.py [line:116] enali   31298 31297  0 14:17 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   31300 31298  0 14:17 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:17:04,510 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:17:04,510 INFO osd.py [line:100] node is  denali01
2017-05-24 14:17:04,510 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:17:35,163 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:17:35,163 INFO osd.py [line:113] node is  denali01
2017-05-24 14:17:35,163 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:17:35,834 INFO osd.py [line:116] enali   32166 32165  0 14:17 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali   32168 32166  0 14:17 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:17:35,834 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:17:35,834 INFO osd.py [line:100] node is  denali01
2017-05-24 14:17:35,834 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:18:06,463 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:18:06,463 INFO osd.py [line:113] node is  denali01
2017-05-24 14:18:06,463 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:18:07,213 INFO osd.py [line:116] enali     788   737  0 14:18 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali     790   788  0 14:18 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:18:07,213 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:18:07,213 INFO osd.py [line:100] node is  denali01
2017-05-24 14:18:07,213 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:18:37,926 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:18:37,926 INFO osd.py [line:113] node is  denali01
2017-05-24 14:18:37,926 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:18:38,601 INFO osd.py [line:116] enali    1682  1681  0 14:18 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali    1684  1682  0 14:18 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:18:38,601 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:18:38,601 INFO osd.py [line:100] node is  denali01
2017-05-24 14:18:38,601 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:19:09,336 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:19:09,336 INFO osd.py [line:113] node is  denali01
2017-05-24 14:19:09,336 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:19:10,055 INFO osd.py [line:116] enali    2853  2852  0 14:19 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali    2855  2853  0 14:19 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:19:10,055 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:19:10,055 INFO osd.py [line:100] node is  denali01
2017-05-24 14:19:10,055 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:19:40,710 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:19:40,710 INFO osd.py [line:113] node is  denali01
2017-05-24 14:19:40,710 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 0'
2017-05-24 14:19:41,365 INFO osd.py [line:116] enali    3730  3726  0 14:19 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 0'
denali    3732  3730  0 14:19 ?        00:00:00 grep ceph-osd -i 0

2017-05-24 14:19:41,365 INFO osd.py [line:121] osd.0has not started, start again
2017-05-24 14:19:41,365 INFO osd.py [line:100] node is  denali01
2017-05-24 14:19:41,365 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-05-24 14:20:12,186 INFO osd.py [line:105] osd osd.0 is start successfully
2017-05-24 14:20:12,186 ERROR TC39_shutdown_osd_on_single_node.py [line:68] osd.0 cannot start
2017-05-24 14:20:42,946 INFO client.py [line:159] home/denali

2017-05-24 14:20:43,898 INFO client.py [line:159] home/denali

2017-05-24 14:20:44,365 INFO cluster.py [line:203] execute command is ceph -s
2017-05-24 14:20:45,395 INFO cluster.py [line:205]    cluster 06eb5bdc-13bc-4ee0-bcb3-b3881e7eef0a
     health HEALTH_OK
     monmap e3: 3 mons at {denali01=192.168.28.26:6789/0,denali02=192.168.28.33:6789/0,denali03=192.168.28.34:6789/0}
            election epoch 6, quorum 0,1,2 denali01,denali02,denali03
     osdmap e71: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v982: 3016 pgs, 13 pools, 234 GB data, 79602 objects
            16513 MB used, 322 GB / 338 GB avail
                3016 active+clean
  client io 277 kB/s rd, 4121 kB/s wr, 220 op/s rd, 1103 op/s wr

2017-05-24 14:20:45,395 INFO cluster.py [line:230] PG number is 3016
2017-05-24 14:20:45,395 INFO cluster.py [line:231] usefull PG number is 3016
2017-05-24 14:20:45,395 INFO TC39_shutdown_osd_on_single_node.py [line:76] stop osd.0 in cluster successfully
2017-05-24 14:20:45,411 INFO TC39_shutdown_osd_on_single_node.py [line:50] 
Now operate osd.1
2017-05-24 14:20:45,411 INFO TC39_shutdown_osd_on_single_node.py [line:53] Set the osd.1 pid for kill
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.0  ---> processId 
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.1  ---> processId 
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.2  ---> processId 
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.0  ---> processId 
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.1  ---> processId 
2017-05-24 14:20:46,082 INFO node.py [line:166] osd.2  ---> processId 
2017-05-24 14:20:46,082 INFO TC39_shutdown_osd_on_single_node.py [line:55] shutdown osd.1 by kill
2017-05-24 14:20:46,082 INFO osd.py [line:51] execute command is sudo -i kill  & sleep 3
2017-05-24 14:20:50,065 INFO client.py [line:159] home/denali

2017-05-24 14:20:50,880 INFO client.py [line:159] home/denali

2017-05-24 14:20:51,255 INFO TC39_shutdown_osd_on_single_node.py [line:60] start osd.1
2017-05-24 14:20:51,255 INFO osd.py [line:100] node is  denali01
2017-05-24 14:20:51,255 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:21:21,865 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:21:21,865 INFO osd.py [line:113] node is  denali01
2017-05-24 14:21:21,865 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:21:22,769 INFO osd.py [line:116] enali    6767  6766  0 14:21 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali    6769  6767  0 14:21 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:21:22,769 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:21:22,769 INFO osd.py [line:100] node is  denali01
2017-05-24 14:21:22,769 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:21:53,658 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:21:53,658 INFO osd.py [line:113] node is  denali01
2017-05-24 14:21:53,658 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:21:54,345 INFO osd.py [line:116] enali    7868  7867  0 14:21 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali    7870  7868  0 14:21 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:21:54,345 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:21:54,345 INFO osd.py [line:100] node is  denali01
2017-05-24 14:21:54,345 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:22:24,963 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:22:24,963 INFO osd.py [line:113] node is  denali01
2017-05-24 14:22:24,963 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:22:25,789 INFO osd.py [line:116] enali    8854  8853  0 14:22 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali    8856  8854  0 14:22 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:22:25,789 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:22:25,789 INFO osd.py [line:100] node is  denali01
2017-05-24 14:22:25,789 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:22:56,492 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:22:56,492 INFO osd.py [line:113] node is  denali01
2017-05-24 14:22:56,492 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:22:57,473 INFO osd.py [line:116] enali   10004  9982  0 14:22 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   10006 10004  0 14:22 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:22:57,473 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:22:57,473 INFO osd.py [line:100] node is  denali01
2017-05-24 14:22:57,473 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:23:28,263 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:23:28,263 INFO osd.py [line:113] node is  denali01
2017-05-24 14:23:28,263 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:23:28,996 INFO osd.py [line:116] enali   11049 11048  0 14:23 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   11051 11049  0 14:23 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:23:28,996 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:23:28,996 INFO osd.py [line:100] node is  denali01
2017-05-24 14:23:28,996 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:23:59,661 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:23:59,661 INFO osd.py [line:113] node is  denali01
2017-05-24 14:23:59,661 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:24:00,332 INFO osd.py [line:116] enali   11949 11948  0 14:24 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   11951 11949  0 14:24 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:24:00,332 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:24:00,332 INFO osd.py [line:100] node is  denali01
2017-05-24 14:24:00,332 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:24:31,028 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:24:31,028 INFO osd.py [line:113] node is  denali01
2017-05-24 14:24:31,028 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:24:31,808 INFO osd.py [line:116] enali   12827 12817  0 14:24 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   12829 12827  0 14:24 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:24:31,808 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:24:31,808 INFO osd.py [line:100] node is  denali01
2017-05-24 14:24:31,808 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:25:02,401 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:25:02,401 INFO osd.py [line:113] node is  denali01
2017-05-24 14:25:02,401 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:25:03,227 INFO osd.py [line:116] enali   13896 13872  0 14:25 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   13898 13896  0 14:25 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:25:03,227 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:25:03,227 INFO osd.py [line:100] node is  denali01
2017-05-24 14:25:03,227 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:25:33,885 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:25:33,888 INFO osd.py [line:113] node is  denali01
2017-05-24 14:25:33,890 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:25:34,625 INFO osd.py [line:116] enali   14817 14816  0 14:25 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   14819 14817  0 14:25 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:25:34,625 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:25:34,625 INFO osd.py [line:100] node is  denali01
2017-05-24 14:25:34,625 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:26:05,319 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:26:05,319 INFO osd.py [line:113] node is  denali01
2017-05-24 14:26:05,319 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:26:05,992 INFO osd.py [line:116] enali   15685 15684  0 14:26 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   15687 15685  0 14:26 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:26:05,992 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:26:05,992 INFO osd.py [line:100] node is  denali01
2017-05-24 14:26:05,992 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:26:36,726 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:26:36,726 INFO osd.py [line:113] node is  denali01
2017-05-24 14:26:36,726 INFO osd.py [line:114] execute command is ps -ef | grep 'ceph-osd -i 1'
2017-05-24 14:26:37,463 INFO osd.py [line:116] enali   16592 16575  0 14:26 ?        00:00:00 bash -c ps -ef | grep 'ceph-osd -i 1'
denali   16594 16592  0 14:26 ?        00:00:00 grep ceph-osd -i 1

2017-05-24 14:26:37,463 INFO osd.py [line:121] osd.1has not started, start again
2017-05-24 14:26:37,463 INFO osd.py [line:100] node is  denali01
2017-05-24 14:26:37,463 INFO osd.py [line:101] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-05-24 14:27:08,078 INFO osd.py [line:105] osd osd.1 is start successfully
2017-05-24 14:27:08,078 ERROR TC39_shutdown_osd_on_single_node.py [line:68] osd.1 cannot start
