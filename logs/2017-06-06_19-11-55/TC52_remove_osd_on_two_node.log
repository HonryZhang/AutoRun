2017-06-07 07:28:04,565 INFO TC52_remove_osd_on_two_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. remove one osd from the first node
4. login the second node
5. remove one osd from the second node

2017-06-07 07:28:05,222 INFO monitors.py [line:126]    "quorum_leader_name": "ubuntu-A",
stdin: is not a tty

2017-06-07 07:28:05,253 INFO monitors.py [line:129]    "quorum_leader_name": "ubuntu-A",
2017-06-07 07:28:05,253 INFO TC52_remove_osd_on_two_node.py [line:29] start to check cluster status before case running
2017-06-07 07:28:07,256 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:28:07,648 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_ERR
            62 pgs are stuck inactive for more than 300 seconds
            44 pgs backfill_wait
            9 pgs backfilling
            130 pgs peering
            62 pgs stuck inactive
            42 pgs stuck unclean
            recovery 20533/135384 objects misplaced (15.166%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21163: 20 osds: 20 up, 20 in; 89 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79682: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            653 GB used, 53140 GB / 53794 GB avail
            20533/135384 objects misplaced (15.166%)
                2593 active+clean
                 108 remapped+peering
                  44 active+remapped+backfill_wait
                  38 active+remapped
                  22 peering
                   9 active+remapped+backfilling
                   2 activating+remapped
recovery io 1933 MB/s, 483 objects/s
  client io 368 kB/s rd, 552 op/s rd, 0 op/s wr

2017-06-07 07:28:07,648 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-07 07:29:07,683 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:29:08,043 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            45 pgs backfill_wait
            4 pgs backfilling
            29 pgs stuck unclean
            recovery 12210/129188 objects misplaced (9.451%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21207: 20 osds: 20 up, 20 in; 47 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79771: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            662 GB used, 55963 GB / 56625 GB avail
            12210/129188 objects misplaced (9.451%)
                2767 active+clean
                  45 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 769 MB/s, 192 objects/s
  client io 389 kB/s rd, 583 op/s rd, 0 op/s wr

2017-06-07 07:29:08,043 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:29:08,044 INFO cluster.py [line:239] usefull PG number is 2767
2017-06-07 07:30:08,104 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 07:30:08,104 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:30:08,445 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            37 pgs backfill_wait
            1 pgs backfilling
            23 pgs stuck unclean
            recovery 9510/127731 objects misplaced (7.445%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21226: 20 osds: 20 up, 20 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79848: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            9510/127731 objects misplaced (7.445%)
                2778 active+clean
                  37 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 267 MB/s, 66 objects/s

2017-06-07 07:30:08,445 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:30:08,445 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-07 07:31:08,494 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 07:31:08,494 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:31:08,871 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            21 pgs stuck unclean
            recovery 7680/126785 objects misplaced (6.057%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21240: 20 osds: 20 up, 20 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79918: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            7680/126785 objects misplaced (6.057%)
                2784 active+clean
                  30 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling

2017-06-07 07:31:08,871 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:31:08,871 INFO cluster.py [line:239] usefull PG number is 2784
2017-06-07 07:32:08,921 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 07:32:08,922 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:32:09,300 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            22 pgs backfill_wait
            1 pgs backfilling
            18 pgs stuck unclean
            recovery 5432/125671 objects misplaced (4.322%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21256: 20 osds: 20 up, 20 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79990: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            5432/125671 objects misplaced (4.322%)
                2793 active+clean
                  22 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 209 MB/s, 52 objects/s

2017-06-07 07:32:09,300 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:32:09,301 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-07 07:33:09,331 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 07:33:09,331 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:33:09,714 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            16 pgs backfill_wait
            1 pgs backfilling
            17 pgs stuck unclean
            recovery 3809/124879 objects misplaced (3.050%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21268: 20 osds: 20 up, 20 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80058: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            3809/124879 objects misplaced (3.050%)
                2799 active+clean
                  16 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s

2017-06-07 07:33:09,714 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:33:09,714 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-07 07:34:09,774 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 07:34:09,775 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:34:10,186 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 2146/124052 objects misplaced (1.730%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21283: 20 osds: 20 up, 20 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80130: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            2146/124052 objects misplaced (1.730%)
                2806 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 07:34:10,186 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:34:10,186 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-07 07:35:10,216 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 07:35:10,216 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:35:10,564 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 430/123177 objects misplaced (0.349%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21296: 20 osds: 20 up, 20 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80201: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
            430/123177 objects misplaced (0.349%)
                2814 active+clean
                   1 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 212 MB/s, 53 objects/s

2017-06-07 07:35:10,565 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:35:10,565 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-07 07:36:10,613 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 07:36:10,613 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:36:11,016 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21300: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80249: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            660 GB used, 55964 GB / 56625 GB avail
                2816 active+clean

2017-06-07 07:36:11,016 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:36:11,016 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:36:11,016 INFO TC52_remove_osd_on_two_node.py [line:32] health status is OK
2017-06-07 07:36:11,016 INFO TC52_remove_osd_on_two_node.py [line:37] 
Step1: Check IO from clients
2017-06-07 07:36:11,566 INFO client.py [line:172] ['enali   10153 10151  0 23:36 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   10155 10153  0 23:36 ?        00:00:00 grep fio', 'root     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 20 Jun05 ?        05:02:31 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'stdin: is not a tty', '']
2017-06-07 07:36:11,567 INFO client.py [line:174] IO is running
2017-06-07 07:36:11,737 INFO node.py [line:159] /var/lib/jenkins/workspace/AutoRun/config/changeCommon.sh
2017-06-07 07:36:11,737 INFO node.py [line:161] /var/lib/jenkins/workspace/AutoRun/config/updateCephConfig.sh
2017-06-07 07:36:12,931 INFO node.py [line:159] /var/lib/jenkins/workspace/AutoRun/config/changeCommon.sh
2017-06-07 07:36:12,931 INFO node.py [line:161] /var/lib/jenkins/workspace/AutoRun/config/updateCephConfig.sh
2017-06-07 07:36:14,004 INFO TC52_remove_osd_on_two_node.py [line:47] 
Step2: kill one osd from two node
2017-06-07 07:36:14,004 INFO TC52_remove_osd_on_two_node.py [line:49] start to delete osd on node ubuntu-A 
2017-06-07 07:36:14,189 INFO node.py [line:185] 0
2017-06-07 07:36:14,189 INFO node.py [line:192] nvme6n1
2017-06-07 07:36:14,189 INFO node.py [line:185] 0
2017-06-07 07:36:14,189 INFO node.py [line:192] nvme6n1
2017-06-07 07:36:14,190 INFO node.py [line:185] 0
2017-06-07 07:36:14,190 INFO node.py [line:192] nvme6n1
2017-06-07 07:36:14,190 INFO node.py [line:185] 1
2017-06-07 07:36:14,190 INFO node.py [line:192] nvme2n1
2017-06-07 07:36:14,190 INFO node.py [line:185] 1
2017-06-07 07:36:14,190 INFO node.py [line:192] nvme2n1
2017-06-07 07:36:14,190 INFO node.py [line:185] 1
2017-06-07 07:36:14,190 INFO node.py [line:192] nvme2n1
2017-06-07 07:36:14,190 INFO node.py [line:185] 2
2017-06-07 07:36:14,191 INFO node.py [line:192] nvme5n1
2017-06-07 07:36:14,191 INFO node.py [line:185] 2
2017-06-07 07:36:14,191 INFO node.py [line:192] nvme5n1
2017-06-07 07:36:14,191 INFO node.py [line:185] 2
2017-06-07 07:36:14,191 INFO node.py [line:192] nvme5n1
2017-06-07 07:36:14,191 INFO node.py [line:185] 3
2017-06-07 07:36:14,191 INFO node.py [line:192] nvme1n1
2017-06-07 07:36:14,191 INFO node.py [line:185] 3
2017-06-07 07:36:14,191 INFO node.py [line:192] nvme1n1
2017-06-07 07:36:14,192 INFO node.py [line:185] 3
2017-06-07 07:36:14,192 INFO node.py [line:192] nvme1n1
2017-06-07 07:36:14,192 INFO node.py [line:185] 4
2017-06-07 07:36:14,192 INFO node.py [line:192] nvme4n1
2017-06-07 07:36:14,192 INFO node.py [line:185] 4
2017-06-07 07:36:14,192 INFO node.py [line:192] nvme4n1
2017-06-07 07:36:14,192 INFO node.py [line:185] 4
2017-06-07 07:36:14,192 INFO node.py [line:192] nvme4n1
2017-06-07 07:36:14,192 INFO node.py [line:185] 5
2017-06-07 07:36:14,193 INFO node.py [line:192] nvme7n1
2017-06-07 07:36:14,193 INFO node.py [line:185] 5
2017-06-07 07:36:14,193 INFO node.py [line:192] nvme7n1
2017-06-07 07:36:14,193 INFO node.py [line:185] 5
2017-06-07 07:36:14,193 INFO node.py [line:192] nvme7n1
2017-06-07 07:36:14,193 INFO node.py [line:185] 6
2017-06-07 07:36:14,193 INFO node.py [line:192] nvme3n1
2017-06-07 07:36:14,193 INFO node.py [line:185] 6
2017-06-07 07:36:14,193 INFO node.py [line:192] nvme3n1
2017-06-07 07:36:14,194 INFO node.py [line:185] 6
2017-06-07 07:36:14,194 INFO node.py [line:192] nvme3n1
2017-06-07 07:36:14,194 INFO node.py [line:185] 
2017-06-07 07:36:14,194 INFO node.py [line:192] nvme3n1
2017-06-07 07:36:14,194 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 07:36:14,194 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 07:36:14,194 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 07:36:14,194 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 07:36:14,194 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 07:36:14,195 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 07:36:14,195 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 07:36:14,195 INFO osd.py [line:40] execute command is sudo -i kill -9  & sleep 3
2017-06-07 07:36:17,368 INFO osd.py [line:89] node is  ubuntu-A
2017-06-07 07:36:17,369 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=0 & sleep 30
2017-06-07 07:36:47,555 ERROR osd.py [line:96] Error when start osdosd.0
2017-06-07 07:36:47,555 ERROR osd.py [line:97] sudo -i start ceph-osd id=0 & sleep 30
2017-06-07 07:36:47,555 ERROR osd.py [line:98] tdin: is not a tty
start: Job is already running: ceph-osd (ceph/0)

2017-06-07 07:36:47,555 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 07:38:40,705 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:38:41,036 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21390: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80444: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
                2816 active+clean

2017-06-07 07:38:41,036 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:38:41,036 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:38:41,037 INFO TC52_remove_osd_on_two_node.py [line:63] osd.0 create succesfully
2017-06-07 07:38:41,037 INFO TC52_remove_osd_on_two_node.py [line:64] osd was delete successfully on node ubuntu-A 
2017-06-07 07:38:42,865 INFO TC52_remove_osd_on_two_node.py [line:67] start to delete osd on node ubuntu-B 
2017-06-07 07:38:43,086 INFO node.py [line:185] 10
2017-06-07 07:38:43,086 INFO node.py [line:192] nvme1n1
2017-06-07 07:38:43,086 INFO node.py [line:185] 10
2017-06-07 07:38:43,086 INFO node.py [line:192] nvme1n1
2017-06-07 07:38:43,086 INFO node.py [line:185] 10
2017-06-07 07:38:43,087 INFO node.py [line:192] nvme1n1
2017-06-07 07:38:43,087 INFO node.py [line:185] 11
2017-06-07 07:38:43,087 INFO node.py [line:192] nvme4n1
2017-06-07 07:38:43,087 INFO node.py [line:185] 11
2017-06-07 07:38:43,087 INFO node.py [line:192] nvme4n1
2017-06-07 07:38:43,087 INFO node.py [line:185] 11
2017-06-07 07:38:43,087 INFO node.py [line:192] nvme4n1
2017-06-07 07:38:43,087 INFO node.py [line:185] 12
2017-06-07 07:38:43,087 INFO node.py [line:192] nvme3n1
2017-06-07 07:38:43,088 INFO node.py [line:185] 12
2017-06-07 07:38:43,088 INFO node.py [line:192] nvme3n1
2017-06-07 07:38:43,088 INFO node.py [line:185] 12
2017-06-07 07:38:43,088 INFO node.py [line:192] nvme3n1
2017-06-07 07:38:43,088 INFO node.py [line:185] 7
2017-06-07 07:38:43,088 INFO node.py [line:192] nvme6n1
2017-06-07 07:38:43,088 INFO node.py [line:185] 7
2017-06-07 07:38:43,088 INFO node.py [line:192] nvme6n1
2017-06-07 07:38:43,088 INFO node.py [line:185] 7
2017-06-07 07:38:43,089 INFO node.py [line:192] nvme6n1
2017-06-07 07:38:43,089 INFO node.py [line:185] 8
2017-06-07 07:38:43,089 INFO node.py [line:192] nvme2n1
2017-06-07 07:38:43,089 INFO node.py [line:185] 8
2017-06-07 07:38:43,089 INFO node.py [line:192] nvme2n1
2017-06-07 07:38:43,089 INFO node.py [line:185] 8
2017-06-07 07:38:43,089 INFO node.py [line:192] nvme2n1
2017-06-07 07:38:43,089 INFO node.py [line:185] 9
2017-06-07 07:38:43,089 INFO node.py [line:192] nvme5n1
2017-06-07 07:38:43,090 INFO node.py [line:185] 9
2017-06-07 07:38:43,090 INFO node.py [line:192] nvme5n1
2017-06-07 07:38:43,090 INFO node.py [line:185] 9
2017-06-07 07:38:43,090 INFO node.py [line:192] nvme5n1
2017-06-07 07:38:43,090 INFO node.py [line:185] 
2017-06-07 07:38:43,090 INFO node.py [line:192] nvme3n1
2017-06-07 07:38:43,090 INFO node.py [line:200] osd.7  ---> disk nvme6n1
2017-06-07 07:38:43,090 INFO node.py [line:200] osd.8  ---> disk nvme2n1
2017-06-07 07:38:43,090 INFO node.py [line:200] osd.9  ---> disk nvme5n1
2017-06-07 07:38:43,091 INFO node.py [line:200] osd.10  ---> disk nvme1n1
2017-06-07 07:38:43,091 INFO node.py [line:200] osd.11  ---> disk nvme4n1
2017-06-07 07:38:43,091 INFO node.py [line:200] osd.12  ---> disk nvme3n1
2017-06-07 07:38:43,091 INFO osd.py [line:40] execute command is sudo -i kill -9  & sleep 3
2017-06-07 07:38:46,307 INFO osd.py [line:89] node is  ubuntu-A
2017-06-07 07:38:46,307 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=7 & sleep 30
2017-06-07 07:39:16,490 ERROR osd.py [line:96] Error when start osdosd.7
2017-06-07 07:39:16,491 ERROR osd.py [line:97] sudo -i start ceph-osd id=7 & sleep 30
2017-06-07 07:39:16,491 ERROR osd.py [line:98] eph-osd (ceph/7) stop/pre-start, process 30117
stdin: is not a tty

2017-06-07 07:39:16,491 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 07:44:04,573 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:44:04,968 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21511: 19 osds: 19 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80839: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
                2816 active+clean

2017-06-07 07:44:04,968 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:44:04,969 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:44:04,969 INFO TC52_remove_osd_on_two_node.py [line:79] osd.7 delete succesfully
2017-06-07 07:44:04,969 INFO TC52_remove_osd_on_two_node.py [line:89] osd was delete successfully on node ubuntu-B 
2017-06-07 07:44:06,961 INFO TC52_remove_osd_on_two_node.py [line:95] start to create osd on ubuntu-A
2017-06-07 07:44:06,961 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 07:44:28,629 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:44:28,630 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:44:28,832 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:44:29,205 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21513: 20 osds: 19 up, 19 in; 478 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v80862: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
                2816 active+clean
  client io 133 kB/s rd, 199 op/s rd, 0 op/s wr

2017-06-07 07:44:29,205 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:44:29,205 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:44:29,206 INFO TC52_remove_osd_on_two_node.py [line:101] osd on ubuntu-A create succesfully
2017-06-07 07:44:32,138 INFO TC52_remove_osd_on_two_node.py [line:104] start to create osd on ubuntu-B
2017-06-07 07:44:32,138 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 07:44:35,784 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:44:35,784 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
WARNING: /dev/nvme6n1 has partitions
ERROR: make gpt label in '/dev/nvme6n1' failed.Error: Partition(s) 2, 3, 4 on /dev/nvme6n1 have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use.  As a result, the old partition(s) will remain in use.  You should reboot now before making further changes.
Reslut:Create osd on ubuntu-B failed.
Detail:make gpt label in '/dev/nvme6n1' failed.Error: Partition(s) 2, 3, 4 on /dev/nvme6n1 have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use.  As a result, the old partition(s) will remain in use.  You should reboot now before making further changes.
stdin: is not a tty

2017-06-07 07:44:35,784 ERROR node.py [line:215] Error when create osd
2017-06-07 07:44:35,784 ERROR node.py [line:216] sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:44:35,784 ERROR node.py [line:217] NFO: osd_num_in_each_disk=1
WARNING: /dev/nvme6n1 has partitions
ERROR: make gpt label in '/dev/nvme6n1' failed.Error: Partition(s) 2, 3, 4 on /dev/nvme6n1 have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use.  As a result, the old partition(s) will remain in use.  You should reboot now before making further changes.
Reslut:Create osd on ubuntu-B failed.
Detail:make gpt label in '/dev/nvme6n1' failed.Error: Partition(s) 2, 3, 4 on /dev/nvme6n1 have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use.  As a result, the old partition(s) will remain in use.  You should reboot now before making further changes.
stdin: is not a tty

