2017-06-06 19:11:55,974 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. remove the osd one by one on the first node
4. check the status
5. create osd on the node

2017-06-06 19:11:56,921 INFO monitors.py [line:126]    "quorum_leader_name": "ubuntu-A",
stdin: is not a tty

2017-06-06 19:11:56,921 INFO monitors.py [line:129]    "quorum_leader_name": "ubuntu-A",
2017-06-06 19:11:58,927 INFO node.py [line:97] init osd on node ubuntu-A
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.0  ---> processId 2589
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.1  ---> processId 2597
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.2  ---> processId 2557
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.3  ---> processId 2581
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.4  ---> processId 2565
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.5  ---> processId 2573
2017-06-06 19:11:59,170 INFO node.py [line:112] osd.6  ---> processId 2605
2017-06-06 19:11:59,170 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:11:59,170 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=0 & sleep 3
2017-06-06 19:12:04,070 INFO osd.py [line:32] osd osd.0 is shutdown successfully
2017-06-06 19:12:09,075 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:12:09,075 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 0 & sleep 30
2017-06-06 19:12:39,261 INFO osd.py [line:107] osd osd.0 is start successfully
2017-06-06 19:12:39,261 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:12:39,261 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=1 & sleep 3
2017-06-06 19:12:43,677 INFO osd.py [line:32] osd osd.1 is shutdown successfully
2017-06-06 19:12:48,682 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:12:48,683 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 1 & sleep 30
2017-06-06 19:13:18,863 INFO osd.py [line:107] osd osd.1 is start successfully
2017-06-06 19:13:18,863 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:13:18,863 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=2 & sleep 3
2017-06-06 19:13:23,747 INFO osd.py [line:32] osd osd.2 is shutdown successfully
2017-06-06 19:13:28,752 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:13:28,753 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 2 & sleep 30
2017-06-06 19:13:58,907 INFO osd.py [line:107] osd osd.2 is start successfully
2017-06-06 19:13:58,907 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:13:58,907 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=3 & sleep 3
2017-06-06 19:14:04,332 INFO osd.py [line:32] osd osd.3 is shutdown successfully
2017-06-06 19:14:09,337 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:14:09,337 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 3 & sleep 30
2017-06-06 19:14:39,522 INFO osd.py [line:107] osd osd.3 is start successfully
2017-06-06 19:14:39,523 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:14:39,523 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=4 & sleep 3
2017-06-06 19:14:45,125 INFO osd.py [line:32] osd osd.4 is shutdown successfully
2017-06-06 19:14:50,130 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:14:50,130 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 4 & sleep 30
2017-06-06 19:15:20,332 INFO osd.py [line:107] osd osd.4 is start successfully
2017-06-06 19:15:20,332 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:15:20,332 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=5 & sleep 3
2017-06-06 19:15:25,673 INFO osd.py [line:32] osd osd.5 is shutdown successfully
2017-06-06 19:15:30,697 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:15:30,697 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 5 & sleep 30
2017-06-06 19:16:00,855 INFO osd.py [line:107] osd osd.5 is start successfully
2017-06-06 19:16:00,855 INFO osd.py [line:28] node is  ubuntu-A
2017-06-06 19:16:00,856 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=6 & sleep 3
2017-06-06 19:16:05,832 INFO osd.py [line:32] osd osd.6 is shutdown successfully
2017-06-06 19:16:10,837 INFO osd.py [line:102] node is  ubuntu-A
2017-06-06 19:16:10,838 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 6 & sleep 30
2017-06-06 19:16:40,991 INFO osd.py [line:107] osd osd.6 is start successfully
2017-06-06 19:16:41,241 INFO node.py [line:133] osd.0  ---> processId 71257
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.1  ---> processId 8477
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.2  ---> processId 17098
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.3  ---> processId 26113
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.4  ---> processId 35349
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.5  ---> processId 44378
2017-06-06 19:16:41,242 INFO node.py [line:133] osd.6  ---> processId 53282
2017-06-06 19:16:41,242 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:16:41,622 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22678: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped

2017-06-06 19:16:41,623 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:16:41,623 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:17:41,664 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-06 19:17:41,665 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:17:45,010 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22715: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped

2017-06-06 19:17:45,010 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:17:45,010 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:18:45,071 INFO cluster.py [line:247] cost 64 seconds, left 5876 seconds when check the ceph status
2017-06-06 19:18:45,071 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:18:48,494 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22753: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped

2017-06-06 19:18:48,494 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:18:48,494 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:19:48,499 INFO cluster.py [line:247] cost 63 seconds, left 5813 seconds when check the ceph status
2017-06-06 19:19:48,499 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:19:48,838 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22788: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped

2017-06-06 19:19:48,839 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:19:48,839 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:20:48,867 INFO cluster.py [line:247] cost 60 seconds, left 5753 seconds when check the ceph status
2017-06-06 19:20:48,868 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:20:49,245 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22823: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped

2017-06-06 19:20:49,246 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:20:49,246 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:21:49,268 INFO cluster.py [line:247] cost 61 seconds, left 5692 seconds when check the ceph status
2017-06-06 19:21:49,269 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:21:49,648 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22859: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 55607 B/s rd, 54 op/s rd, 0 op/s wr

2017-06-06 19:21:49,648 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:21:49,648 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:22:49,695 INFO cluster.py [line:247] cost 60 seconds, left 5632 seconds when check the ceph status
2017-06-06 19:22:49,695 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:22:50,055 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22896: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 16218 B/s rd, 23 op/s rd, 0 op/s wr

2017-06-06 19:22:50,055 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:22:50,055 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:23:50,115 INFO cluster.py [line:247] cost 61 seconds, left 5571 seconds when check the ceph status
2017-06-06 19:23:50,116 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:23:50,488 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22931: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 16183 B/s rd, 23 op/s rd, 0 op/s wr

2017-06-06 19:23:50,488 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:23:50,489 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:24:50,525 INFO cluster.py [line:247] cost 60 seconds, left 5511 seconds when check the ceph status
2017-06-06 19:24:50,526 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:24:54,047 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v22969: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 63766 B/s rd, 71 op/s rd, 0 op/s wr

2017-06-06 19:24:54,048 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:24:54,048 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:25:54,064 INFO cluster.py [line:247] cost 64 seconds, left 5447 seconds when check the ceph status
2017-06-06 19:25:54,064 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:25:57,447 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23008: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 75759 B/s rd, 88 op/s rd, 0 op/s wr

2017-06-06 19:25:57,447 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:25:57,447 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:26:57,507 INFO cluster.py [line:247] cost 63 seconds, left 5384 seconds when check the ceph status
2017-06-06 19:26:57,508 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:26:57,851 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23045: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 48355 B/s rd, 61 op/s rd, 0 op/s wr

2017-06-06 19:26:57,851 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:26:57,852 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:27:57,912 INFO cluster.py [line:247] cost 60 seconds, left 5324 seconds when check the ceph status
2017-06-06 19:27:57,912 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:27:58,282 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23083: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 40421 B/s rd, 44 op/s rd, 0 op/s wr

2017-06-06 19:27:58,283 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:27:58,283 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:28:58,343 INFO cluster.py [line:247] cost 61 seconds, left 5263 seconds when check the ceph status
2017-06-06 19:28:58,343 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:29:01,732 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23120: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 68746 B/s rd, 100 op/s rd, 0 op/s wr

2017-06-06 19:29:01,732 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:29:01,732 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:30:01,789 INFO cluster.py [line:247] cost 63 seconds, left 5200 seconds when check the ceph status
2017-06-06 19:30:01,789 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:30:05,177 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23161: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 30329 B/s rd, 44 op/s rd, 0 op/s wr

2017-06-06 19:30:05,177 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:30:05,177 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:31:05,203 INFO cluster.py [line:247] cost 64 seconds, left 5136 seconds when check the ceph status
2017-06-06 19:31:05,204 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:31:08,626 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            520 pgs degraded
            580 pgs stuck unclean
            520 pgs undersized
            recovery 12193/122934 objects degraded (9.918%)
            recovery 1240/122934 objects misplaced (1.009%)
            1/14 in osds are down
            1 mons down, quorum 0,1 ubuntu-A,ubuntu-B
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 12, quorum 0,1 ubuntu-A,ubuntu-B
     osdmap e1227: 20 osds: 13 up, 14 in; 265 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23202: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            582 GB used, 39055 GB / 39637 GB avail
            12193/122934 objects degraded (9.918%)
            1240/122934 objects misplaced (1.009%)
                2236 active+clean
                 520 active+undersized+degraded
                  50 active
                  10 active+remapped
  client io 95389 B/s rd, 106 op/s rd, 0 op/s wr

2017-06-06 19:31:08,626 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:31:08,626 INFO cluster.py [line:239] usefull PG number is 2236
2017-06-06 19:32:08,687 INFO cluster.py [line:247] cost 63 seconds, left 5073 seconds when check the ceph status
2017-06-06 19:32:08,687 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:32:09,076 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            69 pgs backfill_wait
            5 pgs backfilling
            2 pgs peering
            60 pgs stuck unclean
            recovery 17284/131704 objects misplaced (13.123%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1249: 20 osds: 20 up, 20 in; 72 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23269: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            687 GB used, 55938 GB / 56625 GB avail
            17284/131704 objects misplaced (13.123%)
                2740 active+clean
                  69 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   2 peering
recovery io 1489 MB/s, 372 objects/s

2017-06-06 19:32:09,077 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:32:09,077 INFO cluster.py [line:239] usefull PG number is 2740
2017-06-06 19:33:09,128 INFO cluster.py [line:247] cost 61 seconds, left 5012 seconds when check the ceph status
2017-06-06 19:33:09,128 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:33:09,579 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            39 pgs backfill_wait
            4 pgs backfilling
            33 pgs stuck unclean
            recovery 9800/128010 objects misplaced (7.656%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1287: 20 osds: 20 up, 20 in; 41 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23356: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            672 GB used, 55952 GB / 56625 GB avail
            9800/128010 objects misplaced (7.656%)
                2773 active+clean
                  39 active+remapped+backfill_wait
                   4 active+remapped+backfilling
  client io 325 kB/s rd, 488 op/s rd, 0 op/s wr

2017-06-06 19:33:09,580 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:33:09,580 INFO cluster.py [line:239] usefull PG number is 2773
2017-06-06 19:34:09,640 INFO cluster.py [line:247] cost 60 seconds, left 4952 seconds when check the ceph status
2017-06-06 19:34:09,640 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:34:10,056 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            3 pgs backfilling
            12 pgs stuck unclean
            recovery 4135/125092 objects misplaced (3.306%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1318: 20 osds: 20 up, 20 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23435: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            663 GB used, 55962 GB / 56625 GB avail
            4135/125092 objects misplaced (3.306%)
                2798 active+clean
                  15 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 545 MB/s, 136 objects/s

2017-06-06 19:34:10,056 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:34:10,056 INFO cluster.py [line:239] usefull PG number is 2798
2017-06-06 19:35:10,112 INFO cluster.py [line:247] cost 61 seconds, left 4891 seconds when check the ceph status
2017-06-06 19:35:10,112 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:35:10,523 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 636/123285 objects misplaced (0.516%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1343: 20 osds: 20 up, 20 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23516: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            656 GB used, 55969 GB / 56625 GB avail
            636/123285 objects misplaced (0.516%)
                2813 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 248 MB/s, 62 objects/s
  client io 173 kB/s rd, 260 op/s rd, 0 op/s wr

2017-06-06 19:35:10,523 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:35:10,523 INFO cluster.py [line:239] usefull PG number is 2813
2017-06-06 19:36:10,560 INFO cluster.py [line:247] cost 60 seconds, left 4831 seconds when check the ceph status
2017-06-06 19:36:10,561 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:36:10,969 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1349: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23570: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            654 GB used, 55971 GB / 56625 GB avail
                2816 active+clean
  client io 173 kB/s rd, 260 op/s rd, 0 op/s wr

2017-06-06 19:36:10,970 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:36:10,970 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:36:10,970 INFO cluster.py [line:302] osd on node ubuntu-A were init successfully
2017-06-06 19:36:10,970 INFO node.py [line:97] init osd on node ubuntu-B
2017-06-06 19:36:14,925 INFO node.py [line:112] osd.7  ---> processId 22392
2017-06-06 19:36:14,926 INFO node.py [line:112] osd.8  ---> processId 23806
2017-06-06 19:36:14,926 INFO node.py [line:112] osd.9  ---> processId 25214
2017-06-06 19:36:14,926 INFO node.py [line:112] osd.10  ---> processId 26621
2017-06-06 19:36:14,926 INFO node.py [line:112] osd.11  ---> processId 28028
2017-06-06 19:36:14,926 INFO node.py [line:112] osd.12  ---> processId 29441
2017-06-06 19:36:14,926 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:36:14,926 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=7 & sleep 3
2017-06-06 19:36:19,851 INFO osd.py [line:32] osd osd.7 is shutdown successfully
2017-06-06 19:36:24,856 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:36:24,856 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 7 & sleep 30
2017-06-06 19:36:55,097 INFO osd.py [line:107] osd osd.7 is start successfully
2017-06-06 19:36:55,097 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:36:55,097 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=8 & sleep 3
2017-06-06 19:36:59,694 INFO osd.py [line:32] osd osd.8 is shutdown successfully
2017-06-06 19:37:04,700 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:37:04,700 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 8 & sleep 30
2017-06-06 19:37:34,921 INFO osd.py [line:107] osd osd.8 is start successfully
2017-06-06 19:37:34,921 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:37:34,921 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=9 & sleep 3
2017-06-06 19:37:39,723 INFO osd.py [line:32] osd osd.9 is shutdown successfully
2017-06-06 19:37:44,729 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:37:44,729 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 9 & sleep 30
2017-06-06 19:38:14,993 INFO osd.py [line:107] osd osd.9 is start successfully
2017-06-06 19:38:14,993 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:38:14,994 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=10 & sleep 3
2017-06-06 19:38:19,715 INFO osd.py [line:32] osd osd.10 is shutdown successfully
2017-06-06 19:38:24,720 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:38:24,721 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 10 & sleep 30
2017-06-06 19:38:54,975 INFO osd.py [line:107] osd osd.10 is start successfully
2017-06-06 19:38:54,975 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:38:54,975 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=11 & sleep 3
2017-06-06 19:38:59,761 INFO osd.py [line:32] osd osd.11 is shutdown successfully
2017-06-06 19:39:04,766 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:39:04,767 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 11 & sleep 30
2017-06-06 19:39:35,020 INFO osd.py [line:107] osd osd.11 is start successfully
2017-06-06 19:39:35,020 INFO osd.py [line:28] node is  ubuntu-B
2017-06-06 19:39:35,020 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=12 & sleep 3
2017-06-06 19:39:39,644 INFO osd.py [line:32] osd osd.12 is shutdown successfully
2017-06-06 19:39:44,649 INFO osd.py [line:102] node is  ubuntu-B
2017-06-06 19:39:44,649 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 12 & sleep 30
2017-06-06 19:40:14,903 INFO osd.py [line:107] osd osd.12 is start successfully
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.7  ---> processId 67842
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.8  ---> processId 9092
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.9  ---> processId 22386
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.10  ---> processId 36204
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.11  ---> processId 50297
2017-06-06 19:40:15,200 INFO node.py [line:133] osd.12  ---> processId 63865
2017-06-06 19:40:15,201 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:40:15,601 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1379: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v23773: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            654 GB used, 55971 GB / 56625 GB avail
                2816 active+clean
  client io 282 kB/s rd, 323 op/s rd, 0 op/s wr

2017-06-06 19:40:15,602 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:40:15,602 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:40:15,602 INFO cluster.py [line:302] osd on node ubuntu-B were init successfully
2017-06-06 19:40:15,602 INFO node.py [line:97] init osd on node ubuntu-C
2017-06-06 19:40:15,878 INFO node.py [line:112] osd.13  ---> processId 2556
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.14  ---> processId 2548
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.15  ---> processId 2580
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.16  ---> processId 2588
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.17  ---> processId 2572
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.18  ---> processId 2596
2017-06-06 19:40:15,879 INFO node.py [line:112] osd.19  ---> processId 2564
2017-06-06 19:40:15,879 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:40:15,879 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=13 & sleep 3
2017-06-06 19:40:20,479 INFO osd.py [line:32] osd osd.13 is shutdown successfully
2017-06-06 19:40:25,484 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:40:25,484 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 13 & sleep 30
2017-06-06 19:40:55,703 INFO osd.py [line:107] osd osd.13 is start successfully
2017-06-06 19:40:55,704 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:40:55,704 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=14 & sleep 3
2017-06-06 19:41:00,489 INFO osd.py [line:32] osd osd.14 is shutdown successfully
2017-06-06 19:41:05,494 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:41:05,494 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 14 & sleep 30
2017-06-06 19:41:35,715 INFO osd.py [line:107] osd osd.14 is start successfully
2017-06-06 19:41:35,715 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:41:35,715 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=15 & sleep 3
2017-06-06 19:41:40,061 INFO osd.py [line:32] osd osd.15 is shutdown successfully
2017-06-06 19:41:45,066 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:41:45,066 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 15 & sleep 30
2017-06-06 19:42:15,318 INFO osd.py [line:107] osd osd.15 is start successfully
2017-06-06 19:42:15,318 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:42:15,318 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=16 & sleep 3
2017-06-06 19:42:19,876 INFO osd.py [line:32] osd osd.16 is shutdown successfully
2017-06-06 19:42:24,881 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:42:24,881 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 16 & sleep 30
2017-06-06 19:42:55,214 INFO osd.py [line:107] osd osd.16 is start successfully
2017-06-06 19:42:55,214 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:42:55,214 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=17 & sleep 3
2017-06-06 19:42:59,910 INFO osd.py [line:32] osd osd.17 is shutdown successfully
2017-06-06 19:43:04,915 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:43:04,915 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 17 & sleep 30
2017-06-06 19:43:35,135 INFO osd.py [line:107] osd osd.17 is start successfully
2017-06-06 19:43:35,135 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:43:35,135 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=18 & sleep 3
2017-06-06 19:43:39,392 INFO osd.py [line:32] osd osd.18 is shutdown successfully
2017-06-06 19:43:44,398 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:43:44,398 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 18 & sleep 30
2017-06-06 19:44:14,655 INFO osd.py [line:107] osd osd.18 is start successfully
2017-06-06 19:44:14,655 INFO osd.py [line:28] node is  ubuntu-C
2017-06-06 19:44:14,655 INFO osd.py [line:29] execute command is sudo -i stop ceph-osd id=19 & sleep 3
2017-06-06 19:44:18,207 INFO osd.py [line:32] osd osd.19 is shutdown successfully
2017-06-06 19:44:23,212 INFO osd.py [line:102] node is  ubuntu-C
2017-06-06 19:44:23,213 INFO osd.py [line:103] execute command is sudo -i ceph-osd -i 19 & sleep 30
2017-06-06 19:44:53,432 INFO osd.py [line:107] osd osd.19 is start successfully
2017-06-06 19:44:53,684 INFO node.py [line:133] osd.13  ---> processId 43786
2017-06-06 19:44:53,684 INFO node.py [line:133] osd.14  ---> processId 56867
2017-06-06 19:44:53,684 INFO node.py [line:133] osd.15  ---> processId 70170
2017-06-06 19:44:53,685 INFO node.py [line:133] osd.16  ---> processId 10280
2017-06-06 19:44:53,685 INFO node.py [line:133] osd.17  ---> processId 24620
2017-06-06 19:44:53,685 INFO node.py [line:133] osd.18  ---> processId 38400
2017-06-06 19:44:53,685 INFO node.py [line:133] osd.19  ---> processId 50100
2017-06-06 19:44:53,685 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:44:54,101 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1415: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v24001: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            654 GB used, 55971 GB / 56625 GB avail
                2816 active+clean

2017-06-06 19:44:54,101 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:44:54,101 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:44:54,101 INFO cluster.py [line:302] osd on node ubuntu-C were init successfully
2017-06-06 19:44:54,101 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:30] start to check cluster status before case running
2017-06-06 19:44:56,106 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:44:56,507 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1415: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v24001: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            654 GB used, 55971 GB / 56625 GB avail
                2816 active+clean

2017-06-06 19:44:56,508 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:44:56,508 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:44:56,508 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:33] health status is OK
2017-06-06 19:44:56,508 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:38] 
Step1: Check IO from clients
2017-06-06 19:44:57,028 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 39 Jun05 ?        05:00:42 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   54950 54949  0 11:44 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   54952 54950  0 11:44 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-06 19:44:57,028 INFO client.py [line:174] IO is running
2017-06-06 19:44:57,183 INFO node.py [line:159] /var/lib/jenkins/workspace/AutoRun/config/changeCommon.sh
2017-06-06 19:44:57,183 INFO node.py [line:161] /var/lib/jenkins/workspace/AutoRun/config/updateCephConfig.sh
2017-06-06 19:44:58,143 INFO osd.py [line:40] execute command is sudo -i kill -9 71257 & sleep 3
2017-06-06 19:45:01,328 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:45:01,328 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=0 & sleep 30
2017-06-06 19:45:31,513 ERROR osd.py [line:96] Error when start osdosd.0
2017-06-06 19:45:31,513 ERROR osd.py [line:97] sudo -i start ceph-osd id=0 & sleep 30
2017-06-06 19:45:31,513 ERROR osd.py [line:98] eph-osd (ceph/0) start/running, process 46757
stdin: is not a tty

2017-06-06 19:45:31,513 INFO osd.py [line:40] execute command is sudo -i kill -9 8477 & sleep 3
2017-06-06 19:45:34,699 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:45:34,699 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=1 & sleep 30
2017-06-06 19:46:04,884 ERROR osd.py [line:96] Error when start osdosd.1
2017-06-06 19:46:04,884 ERROR osd.py [line:97] sudo -i start ceph-osd id=1 & sleep 30
2017-06-06 19:46:04,884 ERROR osd.py [line:98] eph-osd (ceph/1) start/running, process 57496
stdin: is not a tty

2017-06-06 19:46:04,885 INFO osd.py [line:40] execute command is sudo -i kill -9 17098 & sleep 3
2017-06-06 19:46:08,101 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:46:08,101 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=2 & sleep 30
2017-06-06 19:46:38,286 ERROR osd.py [line:96] Error when start osdosd.2
2017-06-06 19:46:38,287 ERROR osd.py [line:97] sudo -i start ceph-osd id=2 & sleep 30
2017-06-06 19:46:38,287 ERROR osd.py [line:98] eph-osd (ceph/2) start/running, process 67627
stdin: is not a tty

2017-06-06 19:46:38,287 INFO osd.py [line:40] execute command is sudo -i kill -9 26113 & sleep 3
2017-06-06 19:46:41,471 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:46:41,471 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=3 & sleep 30
2017-06-06 19:47:11,656 ERROR osd.py [line:96] Error when start osdosd.3
2017-06-06 19:47:11,656 ERROR osd.py [line:97] sudo -i start ceph-osd id=3 & sleep 30
2017-06-06 19:47:11,656 ERROR osd.py [line:98] eph-osd (ceph/3) start/running, process 5426
stdin: is not a tty

2017-06-06 19:47:11,656 INFO osd.py [line:40] execute command is sudo -i kill -9 35349 & sleep 3
2017-06-06 19:47:14,872 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:47:14,873 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=4 & sleep 30
2017-06-06 19:47:45,056 ERROR osd.py [line:96] Error when start osdosd.4
2017-06-06 19:47:45,057 ERROR osd.py [line:97] sudo -i start ceph-osd id=4 & sleep 30
2017-06-06 19:47:45,057 ERROR osd.py [line:98] eph-osd (ceph/4) start/running, process 15604
stdin: is not a tty

2017-06-06 19:47:45,057 INFO osd.py [line:40] execute command is sudo -i kill -9 44378 & sleep 3
2017-06-06 19:47:48,242 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:47:48,242 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=5 & sleep 30
2017-06-06 19:48:18,464 ERROR osd.py [line:96] Error when start osdosd.5
2017-06-06 19:48:18,464 ERROR osd.py [line:97] sudo -i start ceph-osd id=5 & sleep 30
2017-06-06 19:48:18,464 ERROR osd.py [line:98] eph-osd (ceph/5) start/running, process 26084
stdin: is not a tty

2017-06-06 19:48:18,464 INFO osd.py [line:40] execute command is sudo -i kill -9 53282 & sleep 3
2017-06-06 19:48:21,649 INFO osd.py [line:89] node is  ubuntu-A
2017-06-06 19:48:21,649 INFO osd.py [line:90] execute command is sudo -i start ceph-osd id=6 & sleep 30
2017-06-06 19:48:51,866 ERROR osd.py [line:96] Error when start osdosd.6
2017-06-06 19:48:51,866 ERROR osd.py [line:97] sudo -i start ceph-osd id=6 & sleep 30
2017-06-06 19:48:51,866 ERROR osd.py [line:98] eph-osd (ceph/6) start/running, process 36182
stdin: is not a tty

2017-06-06 19:49:51,894 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:52] 
Step2: remove osd and create them 10 times
2017-06-06 19:49:52,079 INFO node.py [line:185] 0
2017-06-06 19:49:52,079 INFO node.py [line:192] nvme6n1
2017-06-06 19:49:52,079 INFO node.py [line:185] 0
2017-06-06 19:49:52,079 INFO node.py [line:192] nvme6n1
2017-06-06 19:49:52,079 INFO node.py [line:185] 0
2017-06-06 19:49:52,079 INFO node.py [line:192] nvme6n1
2017-06-06 19:49:52,080 INFO node.py [line:185] 1
2017-06-06 19:49:52,080 INFO node.py [line:192] nvme2n1
2017-06-06 19:49:52,080 INFO node.py [line:185] 1
2017-06-06 19:49:52,080 INFO node.py [line:192] nvme2n1
2017-06-06 19:49:52,080 INFO node.py [line:185] 1
2017-06-06 19:49:52,080 INFO node.py [line:192] nvme2n1
2017-06-06 19:49:52,080 INFO node.py [line:185] 2
2017-06-06 19:49:52,080 INFO node.py [line:192] nvme5n1
2017-06-06 19:49:52,080 INFO node.py [line:185] 2
2017-06-06 19:49:52,081 INFO node.py [line:192] nvme5n1
2017-06-06 19:49:52,081 INFO node.py [line:185] 2
2017-06-06 19:49:52,081 INFO node.py [line:192] nvme5n1
2017-06-06 19:49:52,081 INFO node.py [line:185] 3
2017-06-06 19:49:52,081 INFO node.py [line:192] nvme1n1
2017-06-06 19:49:52,081 INFO node.py [line:185] 3
2017-06-06 19:49:52,081 INFO node.py [line:192] nvme1n1
2017-06-06 19:49:52,081 INFO node.py [line:185] 3
2017-06-06 19:49:52,081 INFO node.py [line:192] nvme1n1
2017-06-06 19:49:52,082 INFO node.py [line:185] 4
2017-06-06 19:49:52,082 INFO node.py [line:192] nvme4n1
2017-06-06 19:49:52,082 INFO node.py [line:185] 4
2017-06-06 19:49:52,082 INFO node.py [line:192] nvme4n1
2017-06-06 19:49:52,082 INFO node.py [line:185] 4
2017-06-06 19:49:52,082 INFO node.py [line:192] nvme4n1
2017-06-06 19:49:52,082 INFO node.py [line:185] 5
2017-06-06 19:49:52,082 INFO node.py [line:192] nvme7n1
2017-06-06 19:49:52,082 INFO node.py [line:185] 5
2017-06-06 19:49:52,083 INFO node.py [line:192] nvme7n1
2017-06-06 19:49:52,083 INFO node.py [line:185] 5
2017-06-06 19:49:52,083 INFO node.py [line:192] nvme7n1
2017-06-06 19:49:52,083 INFO node.py [line:185] 6
2017-06-06 19:49:52,083 INFO node.py [line:192] nvme3n1
2017-06-06 19:49:52,083 INFO node.py [line:185] 6
2017-06-06 19:49:52,083 INFO node.py [line:192] nvme3n1
2017-06-06 19:49:52,083 INFO node.py [line:185] 6
2017-06-06 19:49:52,083 INFO node.py [line:192] nvme3n1
2017-06-06 19:49:52,083 INFO node.py [line:185] 
2017-06-06 19:49:52,084 INFO node.py [line:192] nvme5n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-06 19:49:52,084 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-06 19:49:52,084 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-06 19:49:52,085 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-06 19:54:28,231 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:54:28,610 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1543: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v24615: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            645 GB used, 53148 GB / 53794 GB avail
                2816 active+clean

2017-06-06 19:54:28,611 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:54:28,611 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:54:28,611 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-06 19:54:28,611 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-06 19:57:46,774 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 19:57:47,158 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1649: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v24887: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            636 GB used, 50325 GB / 50962 GB avail
                2816 active+clean
  client io 239 kB/s rd, 239 op/s rd, 0 op/s wr

2017-06-06 19:57:47,158 INFO cluster.py [line:238] PG number is 2816
2017-06-06 19:57:47,158 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 19:57:47,158 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-06 19:57:47,158 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-06 20:02:10,597 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:02:10,950 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1778: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v25242: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            628 GB used, 47503 GB / 48131 GB avail
                2816 active+clean

2017-06-06 20:02:10,950 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:02:10,950 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:02:10,950 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-06 20:02:10,950 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-06 20:08:28,252 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:08:28,627 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e1941: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v25732: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            619 GB used, 44680 GB / 45300 GB avail
                2816 active+clean
  client io 130 kB/s rd, 195 op/s rd, 0 op/s wr

2017-06-06 20:08:28,627 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:08:28,627 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:08:28,628 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-06 20:08:28,628 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-06 20:14:31,033 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:14:31,430 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2114: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v26223: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            610 GB used, 41858 GB / 42468 GB avail
                2816 active+clean

2017-06-06 20:14:31,431 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:14:31,431 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:14:31,431 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-06 20:14:31,431 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-06 20:22:39,687 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:22:40,084 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2319: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v26873: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            602 GB used, 39035 GB / 39637 GB avail
                2816 active+clean

2017-06-06 20:22:40,085 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:22:40,085 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:22:40,085 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-06 20:22:40,085 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-06 20:25:44,266 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:25:44,678 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2442: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27148: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            593 GB used, 36212 GB / 36806 GB avail
                2816 active+clean

2017-06-06 20:25:44,678 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:25:44,679 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:25:44,679 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-06 20:25:46,759 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-06 20:25:46,759 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-06 20:25:46,759 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-06 20:26:08,939 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:26:08,939 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:26:08,940 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:26:09,317 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2444: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27174: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            593 GB used, 36212 GB / 36806 GB avail
                2816 active+clean
  client io 121 kB/s rd, 182 op/s rd, 0 op/s wr

2017-06-06 20:26:09,317 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:26:09,317 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:26:09,317 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 20:26:09,318 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-06 20:26:31,982 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:26:31,982 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:26:31,982 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:26:32,386 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            95 pgs backfill_wait
            1 pgs backfilling
            1 pgs degraded
            1 pgs recovery_wait
            12 pgs stuck unclean
            recovery 2/136383 objects degraded (0.001%)
            recovery 26536/136383 objects misplaced (19.457%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2455: 15 osds: 14 up, 15 in; 740 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27200: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            603 GB used, 39034 GB / 39637 GB avail
            2/136383 objects degraded (0.001%)
            26536/136383 objects misplaced (19.457%)
                2719 active+clean
                  95 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+recovery_wait+degraded
recovery io 260 MB/s, 65 objects/s
  client io 204 kB/s rd, 204 op/s rd, 0 op/s wr

2017-06-06 20:26:32,386 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:26:32,387 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-06 20:27:32,444 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 20:27:32,444 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:27:32,822 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            26 pgs stuck unclean
            recovery 3/145983 objects degraded (0.002%)
            recovery 45917/145983 objects misplaced (31.454%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2477: 15 osds: 15 up, 15 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27274: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            3/145983 objects degraded (0.002%)
            45917/145983 objects misplaced (31.454%)
                2650 active+clean
                 163 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling

2017-06-06 20:27:32,823 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:27:32,823 INFO cluster.py [line:239] usefull PG number is 2650
2017-06-06 20:28:32,873 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 20:28:32,874 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:28:33,282 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            154 pgs backfill_wait
            1 pgs backfilling
            89 pgs stuck unclean
            recovery 42926/144501 objects misplaced (29.706%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2495: 15 osds: 15 up, 15 in; 155 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27351: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            42926/144501 objects misplaced (29.706%)
                2661 active+clean
                 154 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 20:28:33,282 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:28:33,283 INFO cluster.py [line:239] usefull PG number is 2661
2017-06-06 20:29:33,304 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 20:29:33,304 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:29:33,704 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            145 pgs backfill_wait
            1 pgs backfilling
            125 pgs stuck unclean
            recovery 40677/143373 objects misplaced (28.371%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2513: 15 osds: 15 up, 15 in; 146 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27425: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            40677/143373 objects misplaced (28.371%)
                2670 active+clean
                 145 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 365 MB/s, 91 objects/s

2017-06-06 20:29:33,705 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:29:33,705 INFO cluster.py [line:239] usefull PG number is 2670
2017-06-06 20:30:33,740 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 20:30:33,741 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:30:34,117 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            135 pgs backfill_wait
            1 pgs backfilling
            131 pgs stuck unclean
            recovery 37944/141978 objects misplaced (26.725%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2531: 15 osds: 15 up, 15 in; 136 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27501: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            37944/141978 objects misplaced (26.725%)
                2680 active+clean
                 135 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 205 MB/s, 51 objects/s

2017-06-06 20:30:34,117 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:30:34,118 INFO cluster.py [line:239] usefull PG number is 2680
2017-06-06 20:31:34,130 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-06 20:31:34,130 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:31:34,535 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            124 pgs backfill_wait
            1 pgs backfilling
            125 pgs stuck unclean
            recovery 35087/140552 objects misplaced (24.964%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2554: 15 osds: 15 up, 15 in; 124 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27581: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            35087/140552 objects misplaced (24.964%)
                2691 active+clean
                 124 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 350 MB/s, 87 objects/s

2017-06-06 20:31:34,535 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:31:34,535 INFO cluster.py [line:239] usefull PG number is 2691
2017-06-06 20:32:34,564 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-06 20:32:34,564 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:32:34,955 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            2 pgs backfilling
            109 pgs stuck unclean
            recovery 29737/137886 objects misplaced (21.566%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2583: 15 osds: 15 up, 15 in; 109 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27662: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            29737/137886 objects misplaced (21.566%)
                2707 active+clean
                 107 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 751 MB/s, 187 objects/s

2017-06-06 20:32:34,955 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:32:34,955 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-06 20:33:35,012 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-06 20:33:35,012 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:33:35,420 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            91 pgs backfill_wait
            1 pgs backfilling
            93 pgs stuck unclean
            recovery 25228/135675 objects misplaced (18.594%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2613: 15 osds: 15 up, 15 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27747: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            25228/135675 objects misplaced (18.594%)
                2723 active+clean
                  91 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped

2017-06-06 20:33:35,420 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:33:35,420 INFO cluster.py [line:239] usefull PG number is 2723
2017-06-06 20:34:35,425 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-06 20:34:35,425 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:34:35,799 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            72 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            75 pgs stuck unclean
            recovery 20231/133181 objects misplaced (15.191%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2645: 15 osds: 15 up, 15 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27830: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            20231/133181 objects misplaced (15.191%)
                2740 active+clean
                  72 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 174 MB/s, 43 objects/s
  client io 230 kB/s rd, 345 op/s rd, 0 op/s wr

2017-06-06 20:34:35,800 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:34:35,800 INFO cluster.py [line:239] usefull PG number is 2740
2017-06-06 20:35:35,854 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 20:35:35,855 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:35:36,266 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            56 pgs backfill_wait
            2 pgs backfilling
            58 pgs stuck unclean
            recovery 15899/130981 objects misplaced (12.138%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2674: 15 osds: 15 up, 15 in; 57 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27914: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            15899/130981 objects misplaced (12.138%)
                2758 active+clean
                  56 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 150 kB/s rd, 226 op/s rd, 0 op/s wr

2017-06-06 20:35:36,266 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:35:36,267 INFO cluster.py [line:239] usefull PG number is 2758
2017-06-06 20:36:36,291 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-06 20:36:36,292 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:36:36,657 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            45 pgs backfill_wait
            2 pgs backfilling
            47 pgs stuck unclean
            recovery 12686/129334 objects misplaced (9.809%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2693: 15 osds: 15 up, 15 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v27990: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            12686/129334 objects misplaced (9.809%)
                2769 active+clean
                  45 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 97538 kB/s, 23 objects/s

2017-06-06 20:36:36,657 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:36:36,657 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-06 20:37:36,717 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-06 20:37:36,718 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:37:37,143 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            33 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            34 pgs stuck unclean
            recovery 9434/127676 objects misplaced (7.389%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2716: 15 osds: 15 up, 15 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28068: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            9434/127676 objects misplaced (7.389%)
                2781 active+clean
                  33 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 201 MB/s, 50 objects/s
  client io 200 kB/s rd, 200 op/s rd, 0 op/s wr

2017-06-06 20:37:37,144 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:37:37,144 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-06 20:38:37,198 INFO cluster.py [line:247] cost 61 seconds, left 5274 seconds when check the ceph status
2017-06-06 20:38:37,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:38:37,603 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            25 pgs backfill_wait
            1 pgs backfilling
            26 pgs stuck unclean
            recovery 7316/126615 objects misplaced (5.778%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2732: 15 osds: 15 up, 15 in; 26 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28143: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            7316/126615 objects misplaced (5.778%)
                2790 active+clean
                  25 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 229 kB/s rd, 229 op/s rd, 0 op/s wr

2017-06-06 20:38:37,604 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:38:37,604 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-06 20:39:37,633 INFO cluster.py [line:247] cost 60 seconds, left 5214 seconds when check the ceph status
2017-06-06 20:39:37,633 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:39:38,053 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs peering
            18 pgs stuck unclean
            recovery 5044/125583 objects misplaced (4.016%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2751: 15 osds: 15 up, 15 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28219: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            5044/125583 objects misplaced (4.016%)
                2797 active+clean
                  17 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped

2017-06-06 20:39:38,054 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:39:38,054 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-06 20:40:38,065 INFO cluster.py [line:247] cost 61 seconds, left 5153 seconds when check the ceph status
2017-06-06 20:40:38,065 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:40:38,468 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            7 pgs backfill_wait
            1 pgs backfilling
            8 pgs stuck unclean
            recovery 2134/124020 objects misplaced (1.721%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2768: 15 osds: 15 up, 15 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28292: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            2134/124020 objects misplaced (1.721%)
                2808 active+clean
                   7 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 81699 B/s rd, 119 op/s rd, 0 op/s wr

2017-06-06 20:40:38,468 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:40:38,468 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-06 20:41:38,516 INFO cluster.py [line:247] cost 60 seconds, left 5093 seconds when check the ceph status
2017-06-06 20:41:38,516 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:41:38,932 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2784: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28365: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
                2816 active+clean

2017-06-06 20:41:38,932 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:41:38,932 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:41:38,933 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 20:41:38,933 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-06 20:42:00,471 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:42:00,472 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:42:00,472 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:42:00,854 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2786: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28387: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
                2816 active+clean

2017-06-06 20:42:00,855 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:42:00,855 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:42:00,855 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 20:42:00,855 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-06 20:42:22,932 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:42:22,932 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:42:22,932 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:42:23,308 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            4 pgs backfilling
            85 pgs stuck unclean
            recovery 28323/137389 objects misplaced (20.615%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2804: 17 osds: 16 up, 17 in; 701 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28421: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            620 GB used, 44679 GB / 45300 GB avail
            28323/137389 objects misplaced (20.615%)
                2706 active+clean
                 106 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 1236 MB/s, 310 objects/s

2017-06-06 20:42:23,308 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:42:23,308 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-06 20:43:23,354 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 20:43:23,354 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:43:23,702 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            156 pgs backfill_wait
            4 pgs backfilling
            1 pgs degraded
            1 pgs peering
            1 pgs recovery_wait
            132 pgs stuck unclean
            recovery 2/145266 objects degraded (0.001%)
            recovery 44392/145266 objects misplaced (30.559%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2851: 17 osds: 17 up, 17 in; 159 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28515: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            2/145266 objects degraded (0.001%)
            44392/145266 objects misplaced (30.559%)
                2654 active+clean
                 156 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 active+recovery_wait+degraded
                   1 peering
recovery io 210 MB/s, 52 objects/s

2017-06-06 20:43:23,702 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:43:23,702 INFO cluster.py [line:239] usefull PG number is 2654
2017-06-06 20:44:23,746 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 20:44:23,747 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:44:24,131 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            141 pgs backfill_wait
            1 pgs backfilling
            122 pgs stuck unclean
            recovery 39576/142829 objects misplaced (27.709%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2882: 17 osds: 17 up, 17 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28601: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            39576/142829 objects misplaced (27.709%)
                2674 active+clean
                 141 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 503 MB/s, 125 objects/s

2017-06-06 20:44:24,131 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:44:24,131 INFO cluster.py [line:239] usefull PG number is 2674
2017-06-06 20:45:24,186 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 20:45:24,186 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:45:24,559 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            132 pgs backfill_wait
            2 pgs backfilling
            123 pgs stuck unclean
            recovery 37679/141877 objects misplaced (26.558%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2897: 17 osds: 17 up, 17 in; 134 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28673: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            37679/141877 objects misplaced (26.558%)
                2682 active+clean
                 132 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 231 MB/s, 57 objects/s

2017-06-06 20:45:24,559 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:45:24,559 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-06 20:46:24,604 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 20:46:24,604 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:46:24,986 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            120 pgs backfill_wait
            2 pgs backfilling
            117 pgs stuck unclean
            recovery 34025/140129 objects misplaced (24.281%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2916: 17 osds: 17 up, 17 in; 122 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28746: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            34025/140129 objects misplaced (24.281%)
                2693 active+clean
                 120 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped

2017-06-06 20:46:24,987 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:46:24,987 INFO cluster.py [line:239] usefull PG number is 2693
2017-06-06 20:47:25,042 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-06 20:47:25,042 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:47:25,442 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            99 pgs backfill_wait
            3 pgs backfilling
            102 pgs stuck unclean
            recovery 28078/137123 objects misplaced (20.477%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2950: 17 osds: 17 up, 17 in; 102 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28831: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            28078/137123 objects misplaced (20.477%)
                2714 active+clean
                  99 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 323 MB/s, 80 objects/s

2017-06-06 20:47:25,442 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:47:25,442 INFO cluster.py [line:239] usefull PG number is 2714
2017-06-06 20:48:25,470 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-06 20:48:25,470 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:48:25,882 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            84 pgs backfill_wait
            1 pgs backfilling
            85 pgs stuck unclean
            recovery 22852/134408 objects misplaced (17.002%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e2979: 17 osds: 17 up, 17 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28913: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
            22852/134408 objects misplaced (17.002%)
                2731 active+clean
                  84 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 153 kB/s rd, 230 op/s rd, 0 op/s wr

2017-06-06 20:48:25,882 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:48:25,882 INFO cluster.py [line:239] usefull PG number is 2731
2017-06-06 20:49:25,912 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 20:49:25,913 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:49:26,288 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            68 pgs backfill_wait
            4 pgs backfilling
            72 pgs stuck unclean
            recovery 18866/132498 objects misplaced (14.239%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3004: 17 osds: 17 up, 17 in; 70 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v28994: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
            18866/132498 objects misplaced (14.239%)
                2744 active+clean
                  68 active+remapped+backfill_wait
                   4 active+remapped+backfilling

2017-06-06 20:49:26,288 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:49:26,288 INFO cluster.py [line:239] usefull PG number is 2744
2017-06-06 20:50:26,325 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 20:50:26,325 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:50:26,737 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            48 pgs backfill_wait
            3 pgs backfilling
            51 pgs stuck unclean
            recovery 13020/129481 objects misplaced (10.056%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3035: 17 osds: 17 up, 17 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29081: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
            13020/129481 objects misplaced (10.056%)
                2764 active+clean
                  48 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 activating

2017-06-06 20:50:26,738 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:50:26,738 INFO cluster.py [line:239] usefull PG number is 2764
2017-06-06 20:51:26,749 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 20:51:26,749 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:51:27,090 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            28 pgs backfill_wait
            3 pgs backfilling
            31 pgs stuck unclean
            recovery 7621/126864 objects misplaced (6.007%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3072: 17 osds: 17 up, 17 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29174: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
            7621/126864 objects misplaced (6.007%)
                2785 active+clean
                  28 active+remapped+backfill_wait
                   3 active+remapped+backfilling

2017-06-06 20:51:27,090 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:51:27,090 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-06 20:52:27,127 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-06 20:52:27,127 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:52:27,519 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            22 pgs backfill_wait
            1 pgs backfilling
            23 pgs stuck unclean
            recovery 5822/125874 objects misplaced (4.625%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3084: 17 osds: 17 up, 17 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29245: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
            5822/125874 objects misplaced (4.625%)
                2793 active+clean
                  22 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 20:52:27,519 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:52:27,519 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-06 20:53:27,555 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-06 20:53:27,555 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:53:27,917 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            15 pgs stuck unclean
            recovery 3808/124838 objects misplaced (3.050%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3100: 17 osds: 17 up, 17 in; 15 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29318: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            628 GB used, 47502 GB / 48131 GB avail
            3808/124838 objects misplaced (3.050%)
                2801 active+clean
                  15 active+remapped+backfill_wait

2017-06-06 20:53:27,918 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:53:27,918 INFO cluster.py [line:239] usefull PG number is 2801
2017-06-06 20:54:27,974 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-06 20:54:27,974 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:54:28,389 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 1998/123990 objects misplaced (1.611%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3116: 17 osds: 17 up, 17 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29392: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
            1998/123990 objects misplaced (1.611%)
                2809 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 20:54:28,390 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:54:28,390 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-06 20:55:28,450 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-06 20:55:28,451 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:55:28,826 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3128: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29462: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            628 GB used, 47502 GB / 48131 GB avail
                2816 active+clean

2017-06-06 20:55:28,826 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:55:28,826 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:55:28,827 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 20:55:28,827 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-06 20:55:50,280 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:55:50,280 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:55:50,280 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:55:50,669 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3130: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29484: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            628 GB used, 47502 GB / 48131 GB avail
                2816 active+clean
  client io 114 kB/s rd, 172 op/s rd, 0 op/s wr

2017-06-06 20:55:50,669 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:55:50,669 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 20:55:50,669 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 20:55:50,670 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-06 20:56:13,235 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 20:56:13,235 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 20:56:13,235 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:56:13,632 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            93 pgs backfill_wait
            3 pgs backfilling
            75 pgs stuck unclean
            recovery 26349/136197 objects misplaced (19.346%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3147: 19 osds: 18 up, 19 in; 601 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29516: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            638 GB used, 50323 GB / 50962 GB avail
            26349/136197 objects misplaced (19.346%)
                2719 active+clean
                  93 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 activating
recovery io 404 MB/s, 101 objects/s

2017-06-06 20:56:13,632 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:56:13,632 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-06 20:57:13,639 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-06 20:57:13,640 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:57:13,971 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            128 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            89 pgs stuck unclean
            recovery 35947/141028 objects misplaced (25.489%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3187: 19 osds: 19 up, 19 in; 131 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29597: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            35947/141028 objects misplaced (25.489%)
                2684 active+clean
                 128 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 1044 MB/s, 261 objects/s

2017-06-06 20:57:13,972 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:57:13,972 INFO cluster.py [line:239] usefull PG number is 2684
2017-06-06 20:58:13,974 INFO cluster.py [line:247] cost 60 seconds, left 5880 seconds when check the ceph status
2017-06-06 20:58:13,974 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:58:14,391 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            78 pgs stuck unclean
            recovery 29173/137582 objects misplaced (21.204%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3220: 19 osds: 19 up, 19 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29688: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            29173/137582 objects misplaced (21.204%)
                2707 active+clean
                 107 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 635 MB/s, 158 objects/s

2017-06-06 20:58:14,391 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:58:14,391 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-06 20:59:14,452 INFO cluster.py [line:247] cost 61 seconds, left 5819 seconds when check the ceph status
2017-06-06 20:59:14,452 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 20:59:14,834 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            100 pgs backfill_wait
            2 pgs backfilling
            92 pgs stuck unclean
            recovery 27520/136827 objects misplaced (20.113%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3235: 19 osds: 19 up, 19 in; 100 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29761: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            27520/136827 objects misplaced (20.113%)
                2714 active+clean
                 100 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-06 20:59:14,834 INFO cluster.py [line:238] PG number is 2816
2017-06-06 20:59:14,834 INFO cluster.py [line:239] usefull PG number is 2714
2017-06-06 21:00:14,843 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-06 21:00:14,844 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:00:15,220 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            85 pgs backfill_wait
            1 pgs backfilling
            79 pgs stuck unclean
            recovery 23993/135008 objects misplaced (17.772%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3259: 19 osds: 19 up, 19 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29842: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            23993/135008 objects misplaced (17.772%)
                2730 active+clean
                  85 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 164 kB/s rd, 246 op/s rd, 0 op/s wr

2017-06-06 21:00:15,220 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:00:15,221 INFO cluster.py [line:239] usefull PG number is 2730
2017-06-06 21:01:15,259 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-06 21:01:15,259 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:01:15,662 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            72 pgs backfill_wait
            2 pgs backfilling
            74 pgs stuck unclean
            recovery 20613/133330 objects misplaced (15.460%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3277: 19 osds: 19 up, 19 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v29917: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            20613/133330 objects misplaced (15.460%)
                2742 active+clean
                  72 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 1007 MB/s, 251 objects/s

2017-06-06 21:01:15,663 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:01:15,663 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-06 21:02:15,695 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-06 21:02:15,696 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:02:16,107 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            55 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 14995/130456 objects misplaced (11.494%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3305: 19 osds: 19 up, 19 in; 56 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30000: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            14995/130456 objects misplaced (11.494%)
                2760 active+clean
                  55 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 280 MB/s, 70 objects/s
  client io 30672 kB/s rd, 46009 op/s rd, 0 op/s wr

2017-06-06 21:02:16,107 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:02:16,107 INFO cluster.py [line:239] usefull PG number is 2760
2017-06-06 21:03:16,108 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-06 21:03:16,109 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:03:16,486 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            36 pgs backfill_wait
            3 pgs backfilling
            39 pgs stuck unclean
            recovery 10002/128045 objects misplaced (7.811%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3334: 19 osds: 19 up, 19 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30083: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            10002/128045 objects misplaced (7.811%)
                2777 active+clean
                  36 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 435 MB/s, 108 objects/s

2017-06-06 21:03:16,487 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:03:16,487 INFO cluster.py [line:239] usefull PG number is 2777
2017-06-06 21:04:16,547 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-06 21:04:16,547 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:04:16,917 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 4108/125014 objects misplaced (3.286%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3369: 19 osds: 19 up, 19 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30166: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            4108/125014 objects misplaced (3.286%)
                2800 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 643 MB/s, 160 objects/s
  client io 230 kB/s rd, 345 op/s rd, 0 op/s wr

2017-06-06 21:04:16,917 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:04:16,917 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-06 21:05:16,974 INFO cluster.py [line:247] cost 60 seconds, left 5457 seconds when check the ceph status
2017-06-06 21:05:16,974 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:05:17,348 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            8 pgs backfill_wait
            1 pgs backfilling
            9 pgs stuck unclean
            recovery 2264/124072 objects misplaced (1.825%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3383: 19 osds: 19 up, 19 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30238: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            2264/124072 objects misplaced (1.825%)
                2807 active+clean
                   8 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 230 kB/s rd, 345 op/s rd, 0 op/s wr

2017-06-06 21:05:17,348 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:05:17,348 INFO cluster.py [line:239] usefull PG number is 2807
2017-06-06 21:06:17,388 INFO cluster.py [line:247] cost 61 seconds, left 5396 seconds when check the ceph status
2017-06-06 21:06:17,388 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:06:17,761 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 399/123153 objects misplaced (0.324%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3397: 19 osds: 19 up, 19 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30311: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            399/123153 objects misplaced (0.324%)
                2814 active+clean
                   1 active+remapped+backfilling
                   1 active+remapped+backfill_wait
  client io 155 kB/s rd, 232 op/s rd, 0 op/s wr

2017-06-06 21:06:17,762 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:06:17,762 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-06 21:07:17,801 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-06 21:07:17,801 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:07:18,194 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3401: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30375: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            645 GB used, 53148 GB / 53794 GB avail
                2816 active+clean
  client io 214 kB/s rd, 214 op/s rd, 0 op/s wr

2017-06-06 21:07:18,194 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:07:18,194 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:07:18,194 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 21:07:18,194 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-06 21:07:40,031 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 21:07:40,031 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 21:07:40,031 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:07:40,431 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3403: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v30397: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            645 GB used, 53148 GB / 53794 GB avail
                2816 active+clean

2017-06-06 21:07:40,431 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:07:40,431 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:07:40,431 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 21:07:42,628 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-06 21:07:42,942 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 35 Jun05 ?        05:00:54 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   39398 39396  0 13:07 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   39400 39398  0 13:07 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-06 21:07:42,942 INFO client.py [line:174] IO is running
2017-06-06 21:07:43,126 INFO node.py [line:185] 0
2017-06-06 21:07:43,126 INFO node.py [line:192] nvme6n1
2017-06-06 21:07:43,126 INFO node.py [line:185] 0
2017-06-06 21:07:43,126 INFO node.py [line:192] nvme6n1
2017-06-06 21:07:43,126 INFO node.py [line:185] 0
2017-06-06 21:07:43,126 INFO node.py [line:192] nvme6n1
2017-06-06 21:07:43,126 INFO node.py [line:185] 1
2017-06-06 21:07:43,127 INFO node.py [line:192] nvme2n1
2017-06-06 21:07:43,127 INFO node.py [line:185] 1
2017-06-06 21:07:43,127 INFO node.py [line:192] nvme2n1
2017-06-06 21:07:43,127 INFO node.py [line:185] 1
2017-06-06 21:07:43,127 INFO node.py [line:192] nvme2n1
2017-06-06 21:07:43,127 INFO node.py [line:185] 2
2017-06-06 21:07:43,127 INFO node.py [line:192] nvme5n1
2017-06-06 21:07:43,127 INFO node.py [line:185] 2
2017-06-06 21:07:43,127 INFO node.py [line:192] nvme5n1
2017-06-06 21:07:43,128 INFO node.py [line:185] 2
2017-06-06 21:07:43,128 INFO node.py [line:192] nvme5n1
2017-06-06 21:07:43,128 INFO node.py [line:185] 3
2017-06-06 21:07:43,128 INFO node.py [line:192] nvme1n1
2017-06-06 21:07:43,128 INFO node.py [line:185] 3
2017-06-06 21:07:43,128 INFO node.py [line:192] nvme1n1
2017-06-06 21:07:43,128 INFO node.py [line:185] 3
2017-06-06 21:07:43,128 INFO node.py [line:192] nvme1n1
2017-06-06 21:07:43,128 INFO node.py [line:185] 4
2017-06-06 21:07:43,129 INFO node.py [line:192] nvme4n1
2017-06-06 21:07:43,129 INFO node.py [line:185] 4
2017-06-06 21:07:43,129 INFO node.py [line:192] nvme4n1
2017-06-06 21:07:43,129 INFO node.py [line:185] 4
2017-06-06 21:07:43,129 INFO node.py [line:192] nvme4n1
2017-06-06 21:07:43,129 INFO node.py [line:185] 5
2017-06-06 21:07:43,129 INFO node.py [line:192] nvme7n1
2017-06-06 21:07:43,129 INFO node.py [line:185] 5
2017-06-06 21:07:43,129 INFO node.py [line:192] nvme7n1
2017-06-06 21:07:43,129 INFO node.py [line:185] 5
2017-06-06 21:07:43,130 INFO node.py [line:192] nvme7n1
2017-06-06 21:07:43,130 INFO node.py [line:185] 6
2017-06-06 21:07:43,130 INFO node.py [line:192] nvme3n1
2017-06-06 21:07:43,130 INFO node.py [line:185] 6
2017-06-06 21:07:43,130 INFO node.py [line:192] nvme3n1
2017-06-06 21:07:43,130 INFO node.py [line:185] 6
2017-06-06 21:07:43,130 INFO node.py [line:192] nvme3n1
2017-06-06 21:07:43,130 INFO node.py [line:185] 
2017-06-06 21:07:43,130 INFO node.py [line:192] nvme3n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-06 21:07:43,131 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-06 21:07:43,131 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-06 21:07:43,131 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-06 21:15:41,190 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:15:41,576 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3577: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v31012: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            645 GB used, 53148 GB / 53794 GB avail
                2816 active+clean

2017-06-06 21:15:41,576 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:15:41,576 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:15:41,576 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-06 21:15:41,576 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-06 21:17:57,597 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:17:57,980 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3674: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v31220: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            637 GB used, 50325 GB / 50962 GB avail
                2816 active+clean
  client io 263 kB/s rd, 263 op/s rd, 0 op/s wr

2017-06-06 21:17:57,980 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:17:57,980 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:17:57,980 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-06 21:17:57,980 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-06 21:20:28,186 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:20:28,597 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3801: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v31450: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            628 GB used, 47502 GB / 48131 GB avail
                2816 active+clean

2017-06-06 21:20:28,598 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:20:28,598 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:20:28,598 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-06 21:20:28,598 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-06 21:24:19,392 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:24:19,804 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e3965: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v31788: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            620 GB used, 44680 GB / 45300 GB avail
                2816 active+clean

2017-06-06 21:24:19,804 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:24:19,804 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:24:19,804 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-06 21:24:19,804 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-06 21:28:21,501 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:28:21,874 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4121: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32124: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
                2816 active+clean

2017-06-06 21:28:21,874 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:28:21,875 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:28:21,875 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-06 21:28:21,875 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-06 21:34:19,432 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:34:19,807 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4306: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32583: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            602 GB used, 39034 GB / 39637 GB avail
                2816 active+clean
  client io 497 kB/s rd, 745 op/s rd, 0 op/s wr

2017-06-06 21:34:19,808 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:34:19,808 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:34:19,808 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-06 21:34:19,808 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-06 21:36:54,139 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:36:54,513 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4419: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32804: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            594 GB used, 36212 GB / 36806 GB avail
                2816 active+clean
  client io 133 kB/s rd, 200 op/s rd, 0 op/s wr

2017-06-06 21:36:54,513 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:36:54,513 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:36:54,513 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-06 21:36:56,522 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-06 21:36:56,522 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-06 21:36:56,522 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-06 21:37:18,795 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 21:37:18,796 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 21:37:18,796 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:37:19,204 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4421: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32825: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            594 GB used, 36212 GB / 36806 GB avail
                2816 active+clean
  client io 80070 B/s rd, 117 op/s rd, 0 op/s wr

2017-06-06 21:37:19,205 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:37:19,205 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:37:19,205 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 21:37:19,205 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-06 21:37:40,852 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 21:37:40,852 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 21:37:40,852 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:37:41,213 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136629 objects degraded (0.004%)
            recovery 27094/136629 objects misplaced (19.830%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4432: 15 osds: 14 up, 15 in; 739 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32852: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            604 GB used, 39033 GB / 39637 GB avail
            6/136629 objects degraded (0.004%)
            27094/136629 objects misplaced (19.830%)
                2716 active+clean
                  97 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling

2017-06-06 21:37:41,214 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:37:41,214 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-06 21:38:41,234 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 21:38:41,234 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:38:41,639 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            162 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            48 pgs stuck unclean
            recovery 3/145804 objects degraded (0.002%)
            recovery 45481/145804 objects misplaced (31.193%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4455: 15 osds: 15 up, 15 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v32924: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            3/145804 objects degraded (0.002%)
            45481/145804 objects misplaced (31.193%)
                2651 active+clean
                 162 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling

2017-06-06 21:38:41,639 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:38:41,639 INFO cluster.py [line:239] usefull PG number is 2651
2017-06-06 21:39:41,654 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 21:39:41,654 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:39:42,021 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            150 pgs backfill_wait
            2 pgs backfilling
            62 pgs stuck unclean
            recovery 42348/144245 objects misplaced (29.358%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4479: 15 osds: 15 up, 15 in; 151 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33003: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            42348/144245 objects misplaced (29.358%)
                2664 active+clean
                 150 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 227 MB/s, 56 objects/s

2017-06-06 21:39:42,022 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:39:42,022 INFO cluster.py [line:239] usefull PG number is 2664
2017-06-06 21:40:42,082 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 21:40:42,082 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:40:42,481 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            141 pgs backfill_wait
            1 pgs backfilling
            86 pgs stuck unclean
            recovery 39422/142744 objects misplaced (27.617%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4498: 15 osds: 15 up, 15 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33075: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            39422/142744 objects misplaced (27.617%)
                2674 active+clean
                 141 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 21:40:42,482 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:40:42,482 INFO cluster.py [line:239] usefull PG number is 2674
2017-06-06 21:41:42,526 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 21:41:42,526 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:41:42,897 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            128 pgs backfill_wait
            1 pgs backfilling
            92 pgs stuck unclean
            recovery 35916/141002 objects misplaced (25.472%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4522: 15 osds: 15 up, 15 in; 128 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33152: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            35916/141002 objects misplaced (25.472%)
                2687 active+clean
                 128 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 21:41:42,897 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:41:42,897 INFO cluster.py [line:239] usefull PG number is 2687
2017-06-06 21:42:42,952 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-06 21:42:42,952 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:42:43,325 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            112 pgs backfill_wait
            1 pgs backfilling
            113 pgs stuck unclean
            recovery 30890/138500 objects misplaced (22.303%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4545: 15 osds: 15 up, 15 in; 113 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33229: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            30890/138500 objects misplaced (22.303%)
                2703 active+clean
                 112 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 253 MB/s, 63 objects/s

2017-06-06 21:42:43,326 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:42:43,326 INFO cluster.py [line:239] usefull PG number is 2703
2017-06-06 21:43:43,351 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-06 21:43:43,351 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:43:43,770 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            99 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            101 pgs stuck unclean
            recovery 27653/136875 objects misplaced (20.203%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4569: 15 osds: 15 up, 15 in; 101 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33308: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            27653/136875 objects misplaced (20.203%)
                2714 active+clean
                  99 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 449 MB/s, 112 objects/s

2017-06-06 21:43:43,771 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:43:43,771 INFO cluster.py [line:239] usefull PG number is 2714
2017-06-06 21:44:43,831 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 21:44:43,831 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:44:44,203 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            77 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            79 pgs stuck unclean
            recovery 20996/133504 objects misplaced (15.727%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4604: 15 osds: 15 up, 15 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33395: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            20996/133504 objects misplaced (15.727%)
                2736 active+clean
                  77 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 488 MB/s, 122 objects/s
  client io 215 kB/s rd, 215 op/s rd, 0 op/s wr

2017-06-06 21:44:44,203 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:44:44,203 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-06 21:45:44,263 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 21:45:44,264 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:45:44,601 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            60 pgs backfill_wait
            1 pgs backfilling
            62 pgs stuck unclean
            recovery 16383/131246 objects misplaced (12.483%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4632: 15 osds: 15 up, 15 in; 61 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33475: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            16383/131246 objects misplaced (12.483%)
                2754 active+clean
                  60 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
recovery io 1588 MB/s, 397 objects/s
  client io 407 kB/s rd, 611 op/s rd, 0 op/s wr

2017-06-06 21:45:44,601 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:45:44,601 INFO cluster.py [line:239] usefull PG number is 2754
2017-06-06 21:46:44,639 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 21:46:44,639 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:46:45,047 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            49 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 13318/129638 objects misplaced (10.273%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4653: 15 osds: 15 up, 15 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33548: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41856 GB / 42468 GB avail
            13318/129638 objects misplaced (10.273%)
                2766 active+clean
                  49 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 256 MB/s, 65 objects/s
  client io 268 kB/s rd, 403 op/s rd, 0 op/s wr

2017-06-06 21:46:45,047 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:46:45,047 INFO cluster.py [line:239] usefull PG number is 2766
2017-06-06 21:47:45,082 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-06 21:47:45,082 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:47:45,461 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            38 pgs backfill_wait
            1 pgs backfilling
            40 pgs stuck unclean
            recovery 10682/128371 objects misplaced (8.321%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4673: 15 osds: 15 up, 15 in; 39 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33622: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            10682/128371 objects misplaced (8.321%)
                2776 active+clean
                  38 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 346 MB/s, 86 objects/s
  client io 331 kB/s rd, 497 op/s rd, 0 op/s wr

2017-06-06 21:47:45,462 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:47:45,462 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-06 21:48:45,468 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-06 21:48:45,468 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:48:45,877 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            31 pgs backfill_wait
            1 pgs backfilling
            32 pgs stuck unclean
            recovery 8897/127422 objects misplaced (6.982%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4688: 15 osds: 15 up, 15 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33694: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41856 GB / 42468 GB avail
            8897/127422 objects misplaced (6.982%)
                2784 active+clean
                  31 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 21:48:45,877 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:48:45,877 INFO cluster.py [line:239] usefull PG number is 2784
2017-06-06 21:49:45,881 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-06 21:49:45,882 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:49:46,228 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 7035/126520 objects misplaced (5.560%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4703: 15 osds: 15 up, 15 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33766: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            7035/126520 objects misplaced (5.560%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 260 MB/s, 65 objects/s
  client io 236 kB/s rd, 354 op/s rd, 0 op/s wr

2017-06-06 21:49:46,228 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:49:46,229 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-06 21:50:46,257 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-06 21:50:46,257 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:50:46,636 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 4721/125344 objects misplaced (3.766%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4719: 15 osds: 15 up, 15 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33839: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
            4721/125344 objects misplaced (3.766%)
                2800 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 260 MB/s, 65 objects/s
  client io 202 kB/s rd, 303 op/s rd, 0 op/s wr

2017-06-06 21:50:46,636 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:50:46,636 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-06 21:51:46,696 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-06 21:51:46,697 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:51:47,086 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 1931/123928 objects misplaced (1.558%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4737: 15 osds: 15 up, 15 in; 7 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33914: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            1931/123928 objects misplaced (1.558%)
                2809 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 21:51:47,087 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:51:47,087 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-06 21:52:47,147 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-06 21:52:47,147 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:52:47,543 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4751: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v33984: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
                2816 active+clean

2017-06-06 21:52:47,544 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:52:47,544 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:52:47,544 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 21:52:47,544 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-06 21:53:09,527 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 21:53:09,528 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 21:53:09,528 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:53:09,908 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4753: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34008: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            611 GB used, 41857 GB / 42468 GB avail
                2816 active+clean
  client io 141 kB/s rd, 212 op/s rd, 0 op/s wr

2017-06-06 21:53:09,909 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:53:09,909 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 21:53:09,909 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 21:53:09,909 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-06 21:53:31,921 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 21:53:31,921 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 21:53:31,921 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:53:32,334 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            43 pgs stuck unclean
            recovery 28490/137370 objects misplaced (20.740%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4770: 17 osds: 16 up, 17 in; 701 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34039: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44677 GB / 45300 GB avail
            28490/137370 objects misplaced (20.740%)
                2706 active+clean
                 107 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 315 MB/s, 78 objects/s

2017-06-06 21:53:32,334 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:53:32,334 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-06 21:54:32,386 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 21:54:32,386 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:54:32,731 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            5 pgs backfilling
            108 pgs stuck unclean
            recovery 45972/146245 objects misplaced (31.435%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4803: 17 osds: 17 up, 17 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34118: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            45972/146245 objects misplaced (31.435%)
                2648 active+clean
                 163 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 397 MB/s, 99 objects/s

2017-06-06 21:54:32,732 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:54:32,732 INFO cluster.py [line:239] usefull PG number is 2648
2017-06-06 21:55:32,746 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 21:55:32,746 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:55:33,124 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            140 pgs backfill_wait
            2 pgs backfilling
            123 pgs stuck unclean
            recovery 38976/142531 objects misplaced (27.346%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4836: 17 osds: 17 up, 17 in; 142 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34204: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            38976/142531 objects misplaced (27.346%)
                2674 active+clean
                 140 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s

2017-06-06 21:55:33,124 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:55:33,124 INFO cluster.py [line:239] usefull PG number is 2674
2017-06-06 21:56:33,139 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 21:56:33,139 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:56:33,516 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            130 pgs backfill_wait
            123 pgs stuck unclean
            recovery 35817/140919 objects misplaced (25.417%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4856: 17 osds: 17 up, 17 in; 130 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34278: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            35817/140919 objects misplaced (25.417%)
                2685 active+clean
                 130 active+remapped+backfill_wait
                   1 active+remapped

2017-06-06 21:56:33,517 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:56:33,517 INFO cluster.py [line:239] usefull PG number is 2685
2017-06-06 21:57:33,518 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 21:57:33,518 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:57:33,898 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            117 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            116 pgs stuck unclean
            recovery 33024/139535 objects misplaced (23.667%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4879: 17 osds: 17 up, 17 in; 118 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34356: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            33024/139535 objects misplaced (23.667%)
                2696 active+clean
                 117 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering

2017-06-06 21:57:33,899 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:57:33,899 INFO cluster.py [line:239] usefull PG number is 2696
2017-06-06 21:58:33,946 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-06 21:58:33,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:58:34,331 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            104 pgs stuck unclean
            recovery 28727/137375 objects misplaced (20.911%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4906: 17 osds: 17 up, 17 in; 103 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34435: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            28727/137375 objects misplaced (20.911%)
                2711 active+clean
                 102 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 249 MB/s, 62 objects/s
  client io 157 kB/s rd, 157 op/s rd, 0 op/s wr

2017-06-06 21:58:34,332 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:58:34,332 INFO cluster.py [line:239] usefull PG number is 2711
2017-06-06 21:59:34,390 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-06 21:59:34,391 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 21:59:34,777 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            78 pgs backfill_wait
            2 pgs backfilling
            80 pgs stuck unclean
            recovery 21339/133722 objects misplaced (15.958%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4943: 17 osds: 17 up, 17 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34523: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            21339/133722 objects misplaced (15.958%)
                2736 active+clean
                  78 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 1238 MB/s, 309 objects/s
  client io 29530 kB/s rd, 44296 op/s rd, 0 op/s wr

2017-06-06 21:59:34,778 INFO cluster.py [line:238] PG number is 2816
2017-06-06 21:59:34,778 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-06 22:00:34,797 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 22:00:34,798 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:00:35,173 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            53 pgs backfill_wait
            2 pgs backfilling
            55 pgs stuck unclean
            recovery 14318/130120 objects misplaced (11.004%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e4981: 17 osds: 17 up, 17 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34611: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            14318/130120 objects misplaced (11.004%)
                2761 active+clean
                  53 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 896 MB/s, 224 objects/s
  client io 91433 B/s rd, 133 op/s rd, 0 op/s wr

2017-06-06 22:00:35,174 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:00:35,174 INFO cluster.py [line:239] usefull PG number is 2761
2017-06-06 22:01:35,212 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 22:01:35,213 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:01:35,578 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            34 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            36 pgs stuck unclean
            recovery 9315/127642 objects misplaced (7.298%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5015: 17 osds: 17 up, 17 in; 36 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34697: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            9315/127642 objects misplaced (7.298%)
                2779 active+clean
                  34 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
  client io 174 kB/s rd, 261 op/s rd, 0 op/s wr

2017-06-06 22:01:35,578 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:01:35,578 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-06 22:02:35,638 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 22:02:35,638 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:02:36,009 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            24 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            25 pgs stuck unclean
            recovery 6511/126203 objects misplaced (5.159%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5037: 17 osds: 17 up, 17 in; 25 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34776: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
            6511/126203 objects misplaced (5.159%)
                2790 active+clean
                  24 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 111 MB/s, 27 objects/s
  client io 91583 B/s rd, 134 op/s rd, 0 op/s wr

2017-06-06 22:02:36,009 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:02:36,009 INFO cluster.py [line:239] usefull PG number is 2790
2017-06-06 22:03:36,070 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-06 22:03:36,070 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:03:36,447 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            16 pgs backfill_wait
            1 pgs backfilling
            17 pgs stuck unclean
            recovery 4178/125046 objects misplaced (3.341%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5053: 17 osds: 17 up, 17 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34848: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
            4178/125046 objects misplaced (3.341%)
                2799 active+clean
                  16 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 22:03:36,447 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:03:36,447 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-06 22:04:36,492 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-06 22:04:36,492 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:04:36,898 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 2399/124182 objects misplaced (1.932%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5067: 17 osds: 17 up, 17 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34917: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
            2399/124182 objects misplaced (1.932%)
                2806 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 176 MB/s, 44 objects/s
  client io 58743 B/s rd, 86 op/s rd, 0 op/s wr

2017-06-06 22:04:36,899 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:04:36,899 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-06 22:05:36,946 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-06 22:05:36,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:05:37,295 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5085: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v34989: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
                2816 active+clean

2017-06-06 22:05:37,296 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:05:37,296 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:05:37,296 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 22:05:37,296 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-06 22:05:58,429 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 22:05:58,429 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 22:05:58,429 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:05:58,839 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5087: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35010: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
                2816 active+clean

2017-06-06 22:05:58,839 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:05:58,839 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:05:58,840 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 22:05:58,840 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-06 22:06:19,919 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 22:06:19,919 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty
/sbin/ldconfig.real: Changing access rights of /etc/ld.so.cache~ to 0644 failed: No such file or directory

2017-06-06 22:06:19,920 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:06:20,314 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            66 pgs stuck unclean
            recovery 26349/136224 objects misplaced (19.342%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5107: 19 osds: 18 up, 19 in; 601 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35042: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            639 GB used, 50323 GB / 50962 GB avail
            26349/136224 objects misplaced (19.342%)
                2720 active+clean
                  92 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 481 MB/s, 120 objects/s

2017-06-06 22:06:20,314 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:06:20,315 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-06 22:07:20,343 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 22:07:20,343 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:07:20,716 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            129 pgs backfill_wait
            5 pgs backfilling
            102 pgs stuck unclean
            recovery 36378/141294 objects misplaced (25.746%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5152: 19 osds: 19 up, 19 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35125: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            36378/141294 objects misplaced (25.746%)
                2682 active+clean
                 129 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 836 MB/s, 209 objects/s

2017-06-06 22:07:20,716 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:07:20,716 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-06 22:08:20,754 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 22:08:20,755 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:08:21,171 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            112 pgs backfill_wait
            2 pgs backfilling
            88 pgs stuck unclean
            recovery 30218/138149 objects misplaced (21.873%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5182: 19 osds: 19 up, 19 in; 113 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35208: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            30218/138149 objects misplaced (21.873%)
                2702 active+clean
                 112 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-06 22:08:21,171 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:08:21,171 INFO cluster.py [line:239] usefull PG number is 2702
2017-06-06 22:09:21,201 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 22:09:21,201 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:09:21,610 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            2 pgs backfilling
            85 pgs stuck unclean
            recovery 26227/136151 objects misplaced (19.263%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5207: 19 osds: 19 up, 19 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35282: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            26227/136151 objects misplaced (19.263%)
                2717 active+clean
                  97 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-06 22:09:21,611 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:09:21,611 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-06 22:10:21,671 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 22:10:21,671 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:10:22,047 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            85 pgs backfill_wait
            2 pgs backfilling
            76 pgs stuck unclean
            recovery 23165/134627 objects misplaced (17.207%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5226: 19 osds: 19 up, 19 in; 87 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35356: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            23165/134627 objects misplaced (17.207%)
                2729 active+clean
                  85 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 267 MB/s, 66 objects/s

2017-06-06 22:10:22,047 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:10:22,047 INFO cluster.py [line:239] usefull PG number is 2729
2017-06-06 22:11:22,076 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-06 22:11:22,076 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:11:22,442 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            75 pgs backfill_wait
            75 pgs stuck unclean
            recovery 20476/133197 objects misplaced (15.373%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5249: 19 osds: 19 up, 19 in; 75 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35437: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            20476/133197 objects misplaced (15.373%)
                2741 active+clean
                  75 active+remapped+backfill_wait
recovery io 103 MB/s, 25 objects/s

2017-06-06 22:11:22,442 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:11:22,442 INFO cluster.py [line:239] usefull PG number is 2741
2017-06-06 22:12:22,467 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-06 22:12:22,467 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:12:22,859 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            58 pgs backfill_wait
            2 pgs backfilling
            60 pgs stuck unclean
            recovery 15775/130902 objects misplaced (12.051%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5275: 19 osds: 19 up, 19 in; 60 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35516: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            15775/130902 objects misplaced (12.051%)
                2756 active+clean
                  58 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 515 MB/s, 128 objects/s
  client io 414 kB/s rd, 522 op/s rd, 0 op/s wr

2017-06-06 22:12:22,860 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:12:22,860 INFO cluster.py [line:239] usefull PG number is 2756
2017-06-06 22:13:22,920 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 22:13:22,920 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:13:23,290 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            32 pgs backfill_wait
            3 pgs backfilling
            35 pgs stuck unclean
            recovery 9031/127582 objects misplaced (7.079%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5314: 19 osds: 19 up, 19 in; 34 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35604: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            9031/127582 objects misplaced (7.079%)
                2781 active+clean
                  32 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 765 MB/s, 191 objects/s
  client io 420 kB/s rd, 420 op/s rd, 0 op/s wr

2017-06-06 22:13:23,290 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:13:23,290 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-06 22:14:23,334 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 22:14:23,334 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:14:23,720 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 4122/125022 objects misplaced (3.297%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5340: 19 osds: 19 up, 19 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35680: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            4122/125022 objects misplaced (3.297%)
                2800 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 412 kB/s rd, 518 op/s rd, 0 op/s wr

2017-06-06 22:14:23,720 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:14:23,720 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-06 22:15:23,729 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 22:15:23,730 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:15:24,105 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            7 pgs backfill_wait
            1 pgs backfilling
            8 pgs stuck unclean
            recovery 2049/124001 objects misplaced (1.652%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5356: 19 osds: 19 up, 19 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35753: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
            2049/124001 objects misplaced (1.652%)
                2808 active+clean
                   7 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 442 MB/s, 111 objects/s
  client io 189 kB/s rd, 284 op/s rd, 0 op/s wr

2017-06-06 22:15:24,106 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:15:24,106 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-06 22:16:24,158 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-06 22:16:24,159 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:16:24,567 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5372: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35828: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
                2816 active+clean
recovery io 93091 kB/s, 22 objects/s

2017-06-06 22:16:24,568 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:16:24,568 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:16:24,568 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 22:16:24,568 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-06 22:16:46,528 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 22:16:46,528 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 22:16:46,529 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:16:46,905 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5374: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v35852: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
                2816 active+clean

2017-06-06 22:16:46,905 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:16:46,905 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:16:46,905 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 22:16:49,055 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-06 22:16:49,339 INFO client.py [line:172] ['enali   17243 17242  0 14:16 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   17245 17243  0 14:16 ?        00:00:00 grep fio', 'root     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 33 Jun05 ?        05:01:04 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'stdin: is not a tty', '']
2017-06-06 22:16:49,339 INFO client.py [line:174] IO is running
2017-06-06 22:16:49,577 INFO node.py [line:185] 0
2017-06-06 22:16:49,578 INFO node.py [line:192] nvme6n1
2017-06-06 22:16:49,578 INFO node.py [line:185] 0
2017-06-06 22:16:49,578 INFO node.py [line:192] nvme6n1
2017-06-06 22:16:49,578 INFO node.py [line:185] 0
2017-06-06 22:16:49,578 INFO node.py [line:192] nvme6n1
2017-06-06 22:16:49,578 INFO node.py [line:185] 1
2017-06-06 22:16:49,578 INFO node.py [line:192] nvme2n1
2017-06-06 22:16:49,579 INFO node.py [line:185] 1
2017-06-06 22:16:49,579 INFO node.py [line:192] nvme2n1
2017-06-06 22:16:49,579 INFO node.py [line:185] 1
2017-06-06 22:16:49,579 INFO node.py [line:192] nvme2n1
2017-06-06 22:16:49,579 INFO node.py [line:185] 2
2017-06-06 22:16:49,579 INFO node.py [line:192] nvme5n1
2017-06-06 22:16:49,579 INFO node.py [line:185] 2
2017-06-06 22:16:49,579 INFO node.py [line:192] nvme5n1
2017-06-06 22:16:49,579 INFO node.py [line:185] 2
2017-06-06 22:16:49,580 INFO node.py [line:192] nvme5n1
2017-06-06 22:16:49,580 INFO node.py [line:185] 3
2017-06-06 22:16:49,580 INFO node.py [line:192] nvme1n1
2017-06-06 22:16:49,580 INFO node.py [line:185] 3
2017-06-06 22:16:49,580 INFO node.py [line:192] nvme1n1
2017-06-06 22:16:49,580 INFO node.py [line:185] 3
2017-06-06 22:16:49,580 INFO node.py [line:192] nvme1n1
2017-06-06 22:16:49,580 INFO node.py [line:185] 4
2017-06-06 22:16:49,580 INFO node.py [line:192] nvme4n1
2017-06-06 22:16:49,581 INFO node.py [line:185] 4
2017-06-06 22:16:49,581 INFO node.py [line:192] nvme4n1
2017-06-06 22:16:49,581 INFO node.py [line:185] 4
2017-06-06 22:16:49,581 INFO node.py [line:192] nvme4n1
2017-06-06 22:16:49,581 INFO node.py [line:185] 5
2017-06-06 22:16:49,581 INFO node.py [line:192] nvme7n1
2017-06-06 22:16:49,581 INFO node.py [line:185] 5
2017-06-06 22:16:49,581 INFO node.py [line:192] nvme7n1
2017-06-06 22:16:49,581 INFO node.py [line:185] 5
2017-06-06 22:16:49,582 INFO node.py [line:192] nvme7n1
2017-06-06 22:16:49,582 INFO node.py [line:185] 6
2017-06-06 22:16:49,582 INFO node.py [line:192] nvme3n1
2017-06-06 22:16:49,582 INFO node.py [line:185] 6
2017-06-06 22:16:49,582 INFO node.py [line:192] nvme3n1
2017-06-06 22:16:49,582 INFO node.py [line:185] 6
2017-06-06 22:16:49,582 INFO node.py [line:192] nvme3n1
2017-06-06 22:16:49,582 INFO node.py [line:185] 
2017-06-06 22:16:49,582 INFO node.py [line:192] nvme3n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-06 22:16:49,583 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-06 22:16:49,583 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-06 22:16:49,583 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-06 22:24:26,432 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:24:26,844 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5551: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36451: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            646 GB used, 53147 GB / 53794 GB avail
                2816 active+clean

2017-06-06 22:24:26,845 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:24:26,845 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:24:26,845 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-06 22:24:26,845 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-06 22:27:00,070 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:27:00,566 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5654: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36668: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            638 GB used, 50324 GB / 50962 GB avail
                2816 active+clean

2017-06-06 22:27:00,566 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:27:00,566 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:27:00,566 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-06 22:27:00,566 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-06 22:29:18,104 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:29:18,441 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5762: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v36867: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47502 GB / 48131 GB avail
                2816 active+clean

2017-06-06 22:29:18,441 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:29:18,441 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:29:18,442 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-06 22:29:18,442 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-06 22:32:48,189 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:32:48,566 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e5905: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37172: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            620 GB used, 44679 GB / 45300 GB avail
                2816 active+clean
  client io 350 kB/s rd, 350 op/s rd, 0 op/s wr

2017-06-06 22:32:48,566 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:32:48,566 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:32:48,567 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-06 22:32:48,567 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-06 22:36:58,960 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:36:59,326 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6073: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v37533: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
                2816 active+clean

2017-06-06 22:36:59,326 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:36:59,326 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:36:59,326 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-06 22:36:59,326 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-06 22:43:10,318 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:43:10,720 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6257: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38012: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            603 GB used, 39034 GB / 39637 GB avail
                2816 active+clean
  client io 328 kB/s rd, 492 op/s rd, 0 op/s wr

2017-06-06 22:43:10,720 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:43:10,720 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:43:10,721 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-06 22:43:10,721 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-06 22:45:19,925 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:45:20,310 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6363: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38206: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            594 GB used, 36211 GB / 36806 GB avail
                2816 active+clean
  client io 146 kB/s rd, 219 op/s rd, 0 op/s wr

2017-06-06 22:45:20,311 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:45:20,311 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:45:20,311 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-06 22:45:22,176 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-06 22:45:22,176 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-06 22:45:22,176 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-06 22:45:43,266 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 22:45:43,266 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 22:45:43,267 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:45:43,679 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6365: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38231: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            594 GB used, 36211 GB / 36806 GB avail
                2816 active+clean

2017-06-06 22:45:43,679 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:45:43,679 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 22:45:43,679 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 22:45:43,679 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-06 22:46:05,519 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 22:46:05,520 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 22:46:05,520 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:46:05,940 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            1 pgs peering
            2 pgs recovery_wait
            13 pgs stuck unclean
            recovery 3/135549 objects degraded (0.002%)
            recovery 24909/135549 objects misplaced (18.376%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6384: 15 osds: 14 up, 15 in; 741 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38262: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            607 GB used, 39030 GB / 39637 GB avail
            3/135549 objects degraded (0.002%)
            24909/135549 objects misplaced (18.376%)
                2716 active+clean
                  96 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 peering
                   1 active+remapped+backfilling
  client io 460 kB/s rd, 690 op/s rd, 0 op/s wr

2017-06-06 22:46:05,941 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:46:05,941 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-06 22:47:05,961 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-06 22:47:05,961 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:47:06,353 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            54 pgs stuck unclean
            recovery 44473/145299 objects misplaced (30.608%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6408: 15 osds: 15 up, 15 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38337: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            44473/145299 objects misplaced (30.608%)
                2653 active+clean
                 163 active+remapped+backfill_wait
recovery io 926 MB/s, 235 objects/s
  client io 306 kB/s rd, 459 op/s rd, 0 op/s wr

2017-06-06 22:47:06,353 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:47:06,353 INFO cluster.py [line:239] usefull PG number is 2653
2017-06-06 22:48:06,409 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-06 22:48:06,409 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:48:06,789 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            153 pgs backfill_wait
            1 pgs backfilling
            55 pgs stuck unclean
            recovery 41510/143795 objects misplaced (28.867%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6426: 15 osds: 15 up, 15 in; 154 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38411: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            41510/143795 objects misplaced (28.867%)
                2662 active+clean
                 153 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 22:48:06,790 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:48:06,790 INFO cluster.py [line:239] usefull PG number is 2662
2017-06-06 22:49:06,850 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-06 22:49:06,850 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:49:07,246 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            142 pgs backfill_wait
            1 pgs backfilling
            83 pgs stuck unclean
            recovery 38167/142078 objects misplaced (26.863%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6445: 15 osds: 15 up, 15 in; 143 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38479: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            38167/142078 objects misplaced (26.863%)
                2673 active+clean
                 142 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 165 MB/s, 41 objects/s

2017-06-06 22:49:07,246 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:49:07,246 INFO cluster.py [line:239] usefull PG number is 2673
2017-06-06 22:50:07,306 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-06 22:50:07,307 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:50:07,709 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            131 pgs backfill_wait
            1 pgs backfilling
            97 pgs stuck unclean
            recovery 35566/140727 objects misplaced (25.273%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6467: 15 osds: 15 up, 15 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38557: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            35566/140727 objects misplaced (25.273%)
                2684 active+clean
                 131 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 22:50:07,709 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:50:07,709 INFO cluster.py [line:239] usefull PG number is 2684
2017-06-06 22:51:07,740 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-06 22:51:07,740 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:51:08,106 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            115 pgs backfill_wait
            1 pgs peering
            115 pgs stuck unclean
            recovery 30222/138045 objects misplaced (21.893%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6498: 15 osds: 15 up, 15 in; 115 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38640: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            30222/138045 objects misplaced (21.893%)
                2700 active+clean
                 115 active+remapped+backfill_wait
                   1 peering

2017-06-06 22:51:08,107 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:51:08,107 INFO cluster.py [line:239] usefull PG number is 2700
2017-06-06 22:52:08,167 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-06 22:52:08,167 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:52:08,540 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            1 pgs backfilling
            108 pgs stuck unclean
            recovery 28551/137216 objects misplaced (20.807%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6511: 15 osds: 15 up, 15 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38707: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            28551/137216 objects misplaced (20.807%)
                2708 active+clean
                 107 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 22:52:08,541 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:52:08,541 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-06 22:53:08,597 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 22:53:08,598 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:53:09,018 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            89 pgs backfill_wait
            2 pgs backfilling
            91 pgs stuck unclean
            recovery 23393/134710 objects misplaced (17.365%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6544: 15 osds: 15 up, 15 in; 91 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38793: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            23393/134710 objects misplaced (17.365%)
                2725 active+clean
                  89 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 491 MB/s, 122 objects/s
  client io 228 kB/s rd, 228 op/s rd, 0 op/s wr

2017-06-06 22:53:09,018 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:53:09,018 INFO cluster.py [line:239] usefull PG number is 2725
2017-06-06 22:54:09,070 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 22:54:09,070 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:54:09,435 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            68 pgs backfill_wait
            1 pgs backfilling
            70 pgs stuck unclean
            recovery 17733/131942 objects misplaced (13.440%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6574: 15 osds: 15 up, 15 in; 69 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38869: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            17733/131942 objects misplaced (13.440%)
                2746 active+clean
                  68 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 1724 MB/s, 433 objects/s
  client io 165 kB/s rd, 247 op/s rd, 0 op/s wr

2017-06-06 22:54:09,435 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:54:09,435 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-06 22:55:09,491 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 22:55:09,491 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:55:09,856 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            51 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            52 pgs stuck unclean
            recovery 13534/129715 objects misplaced (10.434%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6600: 15 osds: 15 up, 15 in; 52 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v38948: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            13534/129715 objects misplaced (10.434%)
                2763 active+clean
                  51 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 226 MB/s, 56 objects/s
  client io 170 kB/s rd, 255 op/s rd, 0 op/s wr

2017-06-06 22:55:09,856 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:55:09,856 INFO cluster.py [line:239] usefull PG number is 2763
2017-06-06 22:56:09,886 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-06 22:56:09,886 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:56:10,290 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            44 pgs stuck unclean
            recovery 11881/128890 objects misplaced (9.218%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6614: 15 osds: 15 up, 15 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39019: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            11881/128890 objects misplaced (9.218%)
                2772 active+clean
                  43 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 314 kB/s rd, 471 op/s rd, 0 op/s wr

2017-06-06 22:56:10,290 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:56:10,290 INFO cluster.py [line:239] usefull PG number is 2772
2017-06-06 22:57:10,295 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-06 22:57:10,295 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:57:10,714 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            35 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            36 pgs stuck unclean
            recovery 9631/127753 objects misplaced (7.539%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6630: 15 osds: 15 up, 15 in; 36 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39089: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            9631/127753 objects misplaced (7.539%)
                2779 active+clean
                  35 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 12141 kB/s, 2 objects/s
  client io 274 kB/s rd, 412 op/s rd, 0 op/s wr

2017-06-06 22:57:10,714 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:57:10,714 INFO cluster.py [line:239] usefull PG number is 2779
2017-06-06 22:58:10,755 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-06 22:58:10,755 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:58:11,090 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            2 pgs peering
            27 pgs stuck unclean
            recovery 7088/126485 objects misplaced (5.604%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6648: 15 osds: 15 up, 15 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39162: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            7088/126485 objects misplaced (5.604%)
                2787 active+clean
                  26 active+remapped+backfill_wait
                   2 peering
                   1 active+remapped+backfilling
recovery io 468 MB/s, 117 objects/s
  client io 329 kB/s rd, 494 op/s rd, 0 op/s wr

2017-06-06 22:58:11,091 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:58:11,091 INFO cluster.py [line:239] usefull PG number is 2787
2017-06-06 22:59:11,127 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-06 22:59:11,127 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 22:59:11,505 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 4912/125457 objects misplaced (3.915%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6666: 15 osds: 15 up, 15 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39232: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            4912/125457 objects misplaced (3.915%)
                2797 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 22:59:11,505 INFO cluster.py [line:238] PG number is 2816
2017-06-06 22:59:11,505 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-06 23:00:11,566 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-06 23:00:11,566 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:00:11,949 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            10 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            11 pgs stuck unclean
            recovery 2860/124445 objects misplaced (2.298%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6682: 15 osds: 15 up, 15 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39305: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            2860/124445 objects misplaced (2.298%)
                2804 active+clean
                  10 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering

2017-06-06 23:00:11,949 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:00:11,950 INFO cluster.py [line:239] usefull PG number is 2804
2017-06-06 23:01:12,002 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-06 23:01:12,002 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:01:12,379 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            2 pgs backfilling
            2 pgs stuck unclean
            recovery 370/123165 objects misplaced (0.300%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6700: 15 osds: 15 up, 15 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39380: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
            370/123165 objects misplaced (0.300%)
                2814 active+clean
                   2 active+remapped+backfilling

2017-06-06 23:01:12,379 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:01:12,379 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-06 23:02:12,396 INFO cluster.py [line:247] cost 60 seconds, left 5033 seconds when check the ceph status
2017-06-06 23:02:12,396 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:02:12,781 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6702: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39432: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
                2816 active+clean

2017-06-06 23:02:12,781 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:02:12,781 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:02:12,781 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:02:12,781 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-06 23:02:34,026 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:02:34,026 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:02:34,027 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:02:34,410 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6704: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39454: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
                2816 active+clean

2017-06-06 23:02:34,410 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:02:34,410 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:02:34,411 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:02:34,411 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-06 23:02:56,682 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:02:56,682 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:02:56,682 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:02:57,055 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            105 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            44 pgs stuck unclean
            recovery 27232/136651 objects misplaced (19.928%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6724: 17 osds: 16 up, 17 in; 702 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39488: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44677 GB / 45300 GB avail
            27232/136651 objects misplaced (19.928%)
                2708 active+clean
                 105 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
                   1 activating
recovery io 984 MB/s, 246 objects/s

2017-06-06 23:02:57,056 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:02:57,056 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-06 23:03:57,102 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 23:03:57,102 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:03:57,476 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            159 pgs backfill_wait
            2 pgs backfilling
            128 pgs stuck unclean
            recovery 44098/145115 objects misplaced (30.388%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6766: 17 osds: 17 up, 17 in; 160 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39571: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            44098/145115 objects misplaced (30.388%)
                2655 active+clean
                 159 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-06 23:03:57,476 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:03:57,476 INFO cluster.py [line:239] usefull PG number is 2655
2017-06-06 23:04:57,537 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 23:04:57,537 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:04:57,893 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            137 pgs backfill_wait
            3 pgs backfilling
            121 pgs stuck unclean
            recovery 38058/142090 objects misplaced (26.784%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6802: 17 osds: 17 up, 17 in; 139 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39659: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            38058/142090 objects misplaced (26.784%)
                2676 active+clean
                 137 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 869 MB/s, 217 objects/s

2017-06-06 23:04:57,894 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:04:57,894 INFO cluster.py [line:239] usefull PG number is 2676
2017-06-06 23:05:57,934 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-06 23:05:57,934 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:05:58,290 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            126 pgs backfill_wait
            2 pgs backfilling
            118 pgs stuck unclean
            recovery 35225/140647 objects misplaced (25.045%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6822: 17 osds: 17 up, 17 in; 127 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39736: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            35225/140647 objects misplaced (25.045%)
                2688 active+clean
                 126 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 288 MB/s, 72 objects/s

2017-06-06 23:05:58,290 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:05:58,290 INFO cluster.py [line:239] usefull PG number is 2688
2017-06-06 23:06:58,350 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-06 23:06:58,351 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:06:58,744 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            111 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            105 pgs stuck unclean
            recovery 30859/138434 objects misplaced (22.291%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6851: 17 osds: 17 up, 17 in; 111 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39821: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            30859/138434 objects misplaced (22.291%)
                2702 active+clean
                 111 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 8009 kB/s, 1 objects/s

2017-06-06 23:06:58,744 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:06:58,744 INFO cluster.py [line:239] usefull PG number is 2702
2017-06-06 23:07:58,781 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-06 23:07:58,781 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:07:59,152 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            93 pgs stuck unclean
            recovery 25115/135520 objects misplaced (18.532%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6881: 17 osds: 17 up, 17 in; 93 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39906: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            25115/135520 objects misplaced (18.532%)
                2722 active+clean
                  92 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 40492 kB/s, 9 objects/s

2017-06-06 23:07:59,153 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:07:59,153 INFO cluster.py [line:239] usefull PG number is 2722
2017-06-06 23:08:59,198 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-06 23:08:59,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:08:59,588 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            66 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            69 pgs stuck unclean
            recovery 17595/131902 objects misplaced (13.339%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6917: 17 osds: 17 up, 17 in; 67 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v39994: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            17595/131902 objects misplaced (13.339%)
                2746 active+clean
                  66 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 1177 MB/s, 294 objects/s
  client io 75258 B/s rd, 110 op/s rd, 0 op/s wr

2017-06-06 23:08:59,589 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:08:59,589 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-06 23:09:59,646 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-06 23:09:59,646 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:10:00,018 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            44 pgs backfill_wait
            2 pgs backfilling
            46 pgs stuck unclean
            recovery 11524/128803 objects misplaced (8.947%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6956: 17 osds: 17 up, 17 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40081: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            11524/128803 objects misplaced (8.947%)
                2770 active+clean
                  44 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 714 MB/s, 178 objects/s
  client io 101 kB/s rd, 152 op/s rd, 0 op/s wr

2017-06-06 23:10:00,018 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:10:00,019 INFO cluster.py [line:239] usefull PG number is 2770
2017-06-06 23:11:00,078 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-06 23:11:00,078 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:11:00,447 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            28 pgs backfill_wait
            1 pgs peering
            28 pgs stuck unclean
            recovery 6888/126378 objects misplaced (5.450%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e6986: 17 osds: 17 up, 17 in; 28 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40163: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            6888/126378 objects misplaced (5.450%)
                2787 active+clean
                  28 active+remapped+backfill_wait
                   1 peering
recovery io 1178 MB/s, 294 objects/s
  client io 281 kB/s rd, 422 op/s rd, 0 op/s wr

2017-06-06 23:11:00,448 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:11:00,448 INFO cluster.py [line:239] usefull PG number is 2787
2017-06-06 23:12:00,479 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-06 23:12:00,480 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:12:00,838 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 4246/125108 objects misplaced (3.394%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7004: 17 osds: 17 up, 17 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40238: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            4246/125108 objects misplaced (3.394%)
                2797 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 263 MB/s, 65 objects/s
  client io 315 kB/s rd, 472 op/s rd, 0 op/s wr

2017-06-06 23:12:00,838 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:12:00,839 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-06 23:13:00,899 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-06 23:13:00,899 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:13:01,274 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            10 pgs backfill_wait
            11 pgs stuck unclean
            recovery 2543/124275 objects misplaced (2.046%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7019: 17 osds: 17 up, 17 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40309: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            2543/124275 objects misplaced (2.046%)
                2805 active+clean
                  10 active+remapped+backfill_wait
                   1 active+remapped

2017-06-06 23:13:01,274 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:13:01,274 INFO cluster.py [line:239] usefull PG number is 2805
2017-06-06 23:14:01,335 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-06 23:14:01,335 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:14:01,705 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 400/123168 objects misplaced (0.325%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7035: 17 osds: 17 up, 17 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40380: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
            400/123168 objects misplaced (0.325%)
                2814 active+clean
                   1 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 260 MB/s, 65 objects/s
  client io 429 kB/s rd, 537 op/s rd, 0 op/s wr

2017-06-06 23:14:01,706 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:14:01,706 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-06 23:15:01,722 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-06 23:15:01,723 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:15:02,062 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7039: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40443: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
                2816 active+clean
  client io 109 kB/s rd, 163 op/s rd, 0 op/s wr

2017-06-06 23:15:02,062 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:15:02,062 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:15:02,062 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:15:02,062 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-06 23:15:23,434 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:15:23,434 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:15:23,435 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:15:23,798 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7041: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40462: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            629 GB used, 47501 GB / 48131 GB avail
                2816 active+clean

2017-06-06 23:15:23,798 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:15:23,798 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:15:23,799 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:15:23,799 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-06 23:15:45,996 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:15:45,997 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:15:45,997 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:15:46,411 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            91 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            70 pgs stuck unclean
            recovery 26047/136106 objects misplaced (19.137%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7061: 19 osds: 18 up, 19 in; 600 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40494: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            640 GB used, 50321 GB / 50962 GB avail
            26047/136106 objects misplaced (19.137%)
                2720 active+clean
                  91 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 492 MB/s, 123 objects/s

2017-06-06 23:15:46,411 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:15:46,411 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-06 23:16:46,455 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-06 23:16:46,456 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:16:46,869 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            125 pgs backfill_wait
            5 pgs backfilling
            90 pgs stuck unclean
            recovery 35208/140770 objects misplaced (25.011%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7096: 19 osds: 19 up, 19 in; 128 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40570: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            35208/140770 objects misplaced (25.011%)
                2686 active+clean
                 125 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 31554 kB/s, 7 objects/s

2017-06-06 23:16:46,869 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:16:46,869 INFO cluster.py [line:239] usefull PG number is 2686
2017-06-06 23:17:46,902 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-06 23:17:46,902 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:17:47,272 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            2 pgs backfilling
            79 pgs stuck unclean
            recovery 28826/137364 objects misplaced (20.985%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7121: 19 osds: 19 up, 19 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40649: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            28826/137364 objects misplaced (20.985%)
                2708 active+clean
                 106 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 118 MB/s, 29 objects/s

2017-06-06 23:17:47,273 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:17:47,273 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-06 23:18:47,333 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-06 23:18:47,333 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:18:47,685 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            1 pgs backfilling
            75 pgs stuck unclean
            recovery 26510/136197 objects misplaced (19.464%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7139: 19 osds: 19 up, 19 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40724: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            26510/136197 objects misplaced (19.464%)
                2718 active+clean
                  97 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 23:18:47,685 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:18:47,686 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-06 23:19:47,725 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-06 23:19:47,726 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:19:48,109 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            82 pgs backfill_wait
            3 pgs backfilling
            67 pgs stuck unclean
            recovery 22891/134471 objects misplaced (17.023%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7165: 19 osds: 19 up, 19 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40807: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53145 GB / 53794 GB avail
            22891/134471 objects misplaced (17.023%)
                2731 active+clean
                  82 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 350 MB/s, 87 objects/s

2017-06-06 23:19:48,109 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:19:48,109 INFO cluster.py [line:239] usefull PG number is 2731
2017-06-06 23:20:48,169 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-06 23:20:48,170 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:20:48,577 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            72 pgs backfill_wait
            2 pgs backfilling
            74 pgs stuck unclean
            recovery 19825/132912 objects misplaced (14.916%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7185: 19 osds: 19 up, 19 in; 73 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40884: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            19825/132912 objects misplaced (14.916%)
                2742 active+clean
                  72 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 466 MB/s, 116 objects/s

2017-06-06 23:20:48,578 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:20:48,578 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-06 23:21:48,624 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-06 23:21:48,625 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:21:49,019 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            55 pgs backfill_wait
            2 pgs backfilling
            59 pgs stuck unclean
            recovery 15104/130652 objects misplaced (11.560%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7212: 19 osds: 19 up, 19 in; 57 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v40967: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            15104/130652 objects misplaced (11.560%)
                2757 active+clean
                  55 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   2 active+remapped
recovery io 1021 MB/s, 255 objects/s
  client io 119 kB/s rd, 179 op/s rd, 0 op/s wr

2017-06-06 23:21:49,019 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:21:49,019 INFO cluster.py [line:239] usefull PG number is 2757
2017-06-06 23:22:49,079 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-06 23:22:49,080 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:22:49,488 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            29 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            32 pgs stuck unclean
            recovery 8162/127206 objects misplaced (6.416%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7247: 19 osds: 19 up, 19 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41057: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            8162/127206 objects misplaced (6.416%)
                2783 active+clean
                  29 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 1948 MB/s, 487 objects/s
  client io 162 kB/s rd, 243 op/s rd, 0 op/s wr

2017-06-06 23:22:49,488 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:22:49,488 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-06 23:23:49,549 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-06 23:23:49,549 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:23:49,952 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs peering
            13 pgs stuck unclean
            recovery 3424/124646 objects misplaced (2.747%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7276: 19 osds: 19 up, 19 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41141: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            3424/124646 objects misplaced (2.747%)
                2802 active+clean
                  13 active+remapped+backfill_wait
                   1 peering

2017-06-06 23:23:49,953 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:23:49,953 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-06 23:24:50,010 INFO cluster.py [line:247] cost 61 seconds, left 5455 seconds when check the ceph status
2017-06-06 23:24:50,010 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:24:50,397 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            4 pgs backfill_wait
            5 pgs stuck unclean
            recovery 1086/123594 objects misplaced (0.879%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7293: 19 osds: 19 up, 19 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41216: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
            1086/123594 objects misplaced (0.879%)
                2811 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped
recovery io 719 MB/s, 179 objects/s

2017-06-06 23:24:50,398 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:24:50,398 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-06 23:25:50,458 INFO cluster.py [line:247] cost 60 seconds, left 5395 seconds when check the ceph status
2017-06-06 23:25:50,458 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:25:50,854 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7302: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41281: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean
  client io 86770 B/s rd, 127 op/s rd, 0 op/s wr

2017-06-06 23:25:50,855 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:25:50,855 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:25:50,855 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:25:50,855 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-06 23:26:12,736 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:26:12,736 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:26:12,736 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:26:13,112 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7304: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41301: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean

2017-06-06 23:26:13,113 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:26:13,113 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:26:13,113 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:26:15,349 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-06 23:26:15,629 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 30 Jun05 ?        05:01:14 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   50934 50932  0 15:26 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   50936 50934  0 15:26 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-06 23:26:15,629 INFO client.py [line:174] IO is running
2017-06-06 23:26:15,834 INFO node.py [line:185] 0
2017-06-06 23:26:15,834 INFO node.py [line:192] nvme6n1
2017-06-06 23:26:15,834 INFO node.py [line:185] 0
2017-06-06 23:26:15,834 INFO node.py [line:192] nvme6n1
2017-06-06 23:26:15,835 INFO node.py [line:185] 0
2017-06-06 23:26:15,835 INFO node.py [line:192] nvme6n1
2017-06-06 23:26:15,835 INFO node.py [line:185] 1
2017-06-06 23:26:15,835 INFO node.py [line:192] nvme2n1
2017-06-06 23:26:15,835 INFO node.py [line:185] 1
2017-06-06 23:26:15,835 INFO node.py [line:192] nvme2n1
2017-06-06 23:26:15,835 INFO node.py [line:185] 1
2017-06-06 23:26:15,835 INFO node.py [line:192] nvme2n1
2017-06-06 23:26:15,835 INFO node.py [line:185] 2
2017-06-06 23:26:15,835 INFO node.py [line:192] nvme5n1
2017-06-06 23:26:15,836 INFO node.py [line:185] 2
2017-06-06 23:26:15,836 INFO node.py [line:192] nvme5n1
2017-06-06 23:26:15,836 INFO node.py [line:185] 2
2017-06-06 23:26:15,836 INFO node.py [line:192] nvme5n1
2017-06-06 23:26:15,836 INFO node.py [line:185] 3
2017-06-06 23:26:15,836 INFO node.py [line:192] nvme1n1
2017-06-06 23:26:15,836 INFO node.py [line:185] 3
2017-06-06 23:26:15,836 INFO node.py [line:192] nvme1n1
2017-06-06 23:26:15,836 INFO node.py [line:185] 3
2017-06-06 23:26:15,837 INFO node.py [line:192] nvme1n1
2017-06-06 23:26:15,837 INFO node.py [line:185] 4
2017-06-06 23:26:15,837 INFO node.py [line:192] nvme4n1
2017-06-06 23:26:15,837 INFO node.py [line:185] 4
2017-06-06 23:26:15,837 INFO node.py [line:192] nvme4n1
2017-06-06 23:26:15,837 INFO node.py [line:185] 4
2017-06-06 23:26:15,837 INFO node.py [line:192] nvme4n1
2017-06-06 23:26:15,837 INFO node.py [line:185] 5
2017-06-06 23:26:15,837 INFO node.py [line:192] nvme7n1
2017-06-06 23:26:15,838 INFO node.py [line:185] 5
2017-06-06 23:26:15,838 INFO node.py [line:192] nvme7n1
2017-06-06 23:26:15,838 INFO node.py [line:185] 5
2017-06-06 23:26:15,838 INFO node.py [line:192] nvme7n1
2017-06-06 23:26:15,838 INFO node.py [line:185] 6
2017-06-06 23:26:15,838 INFO node.py [line:192] nvme3n1
2017-06-06 23:26:15,838 INFO node.py [line:185] 6
2017-06-06 23:26:15,838 INFO node.py [line:192] nvme3n1
2017-06-06 23:26:15,838 INFO node.py [line:185] 6
2017-06-06 23:26:15,839 INFO node.py [line:192] nvme3n1
2017-06-06 23:26:15,839 INFO node.py [line:185] 
2017-06-06 23:26:15,839 INFO node.py [line:192] nvme3n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-06 23:26:15,839 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-06 23:26:15,840 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-06 23:26:15,840 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-06 23:33:49,116 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:33:49,529 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7473: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v41886: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean
  client io 374 kB/s rd, 562 op/s rd, 0 op/s wr

2017-06-06 23:33:49,529 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:33:49,529 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:33:49,529 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-06 23:33:49,529 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-06 23:36:25,387 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:36:25,795 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7573: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42108: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            638 GB used, 50324 GB / 50962 GB avail
                2816 active+clean

2017-06-06 23:36:25,795 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:36:25,795 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:36:25,795 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-06 23:36:25,795 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-06 23:39:03,526 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:39:03,892 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7703: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42350: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
                2816 active+clean

2017-06-06 23:39:03,892 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:39:03,893 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:39:03,893 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-06 23:39:03,893 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-06 23:42:48,810 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:42:49,203 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e7865: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v42694: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            621 GB used, 44678 GB / 45300 GB avail
                2816 active+clean
  client io 352 kB/s rd, 352 op/s rd, 0 op/s wr

2017-06-06 23:42:49,203 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:42:49,203 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:42:49,203 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-06 23:42:49,203 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-06 23:46:49,520 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:46:49,912 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8016: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43050: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            612 GB used, 41856 GB / 42468 GB avail
                2816 active+clean

2017-06-06 23:46:49,912 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:46:49,912 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:46:49,912 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-06 23:46:49,912 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-06 23:52:50,351 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:52:50,758 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8202: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43537: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            604 GB used, 39033 GB / 39637 GB avail
                2816 active+clean

2017-06-06 23:52:50,758 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:52:50,758 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:52:50,758 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-06 23:52:50,759 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-06 23:55:11,184 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:55:11,590 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8310: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43747: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            595 GB used, 36210 GB / 36806 GB avail
                2816 active+clean

2017-06-06 23:55:11,591 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:55:11,591 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:55:11,591 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-06 23:55:13,398 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-06 23:55:13,398 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-06 23:55:13,399 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-06 23:55:35,810 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:55:35,810 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:55:35,811 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:55:36,195 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8312: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43770: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            595 GB used, 36210 GB / 36806 GB avail
                2816 active+clean

2017-06-06 23:55:36,195 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:55:36,195 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-06 23:55:36,196 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-06 23:55:36,196 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-06 23:55:57,173 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-06 23:55:57,173 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-06 23:55:57,173 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:55:57,582 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            95 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136372 objects degraded (0.004%)
            recovery 26623/136372 objects misplaced (19.522%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8325: 15 osds: 14 up, 15 in; 740 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43799: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39032 GB / 39637 GB avail
            6/136372 objects degraded (0.004%)
            26623/136372 objects misplaced (19.522%)
                2718 active+clean
                  95 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling

2017-06-06 23:55:57,582 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:55:57,582 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-06 23:56:57,586 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-06 23:56:57,586 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:56:57,930 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            161 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 45379/145702 objects misplaced (31.145%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8353: 15 osds: 15 up, 15 in; 162 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43880: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            45379/145702 objects misplaced (31.145%)
                2654 active+clean
                 161 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 23:56:57,930 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:56:57,930 INFO cluster.py [line:239] usefull PG number is 2654
2017-06-06 23:57:57,946 INFO cluster.py [line:247] cost 60 seconds, left 5880 seconds when check the ceph status
2017-06-06 23:57:57,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:57:58,324 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            152 pgs backfill_wait
            1 pgs backfilling
            56 pgs stuck unclean
            recovery 42745/144394 objects misplaced (29.603%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8371: 15 osds: 15 up, 15 in; 152 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v43951: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            42745/144394 objects misplaced (29.603%)
                2663 active+clean
                 152 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 23:57:58,325 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:57:58,325 INFO cluster.py [line:239] usefull PG number is 2663
2017-06-06 23:58:58,365 INFO cluster.py [line:247] cost 61 seconds, left 5819 seconds when check the ceph status
2017-06-06 23:58:58,365 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:58:58,735 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            142 pgs backfill_wait
            1 pgs backfilling
            92 pgs stuck unclean
            recovery 40013/143018 objects misplaced (27.978%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8390: 15 osds: 15 up, 15 in; 143 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44023: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            40013/143018 objects misplaced (27.978%)
                2673 active+clean
                 142 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 23:58:58,735 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:58:58,735 INFO cluster.py [line:239] usefull PG number is 2673
2017-06-06 23:59:58,795 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-06 23:59:58,796 INFO cluster.py [line:211] execute command is ceph -s
2017-06-06 23:59:59,168 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            132 pgs backfill_wait
            1 pgs backfilling
            101 pgs stuck unclean
            recovery 36931/141492 objects misplaced (26.101%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8411: 15 osds: 15 up, 15 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44099: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            36931/141492 objects misplaced (26.101%)
                2683 active+clean
                 132 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-06 23:59:59,169 INFO cluster.py [line:238] PG number is 2816
2017-06-06 23:59:59,169 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 00:00:59,198 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 00:00:59,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:00:59,587 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            114 pgs backfill_wait
            3 pgs backfilling
            117 pgs stuck unclean
            recovery 31999/139052 objects misplaced (23.012%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8441: 15 osds: 15 up, 15 in; 116 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44178: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            31999/139052 objects misplaced (23.012%)
                2699 active+clean
                 114 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 591 MB/s, 147 objects/s

2017-06-07 00:00:59,588 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:00:59,588 INFO cluster.py [line:239] usefull PG number is 2699
2017-06-07 00:01:59,602 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 00:01:59,602 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:01:59,988 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            95 pgs backfill_wait
            1 pgs backfilling
            96 pgs stuck unclean
            recovery 26887/136417 objects misplaced (19.709%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8470: 15 osds: 15 up, 15 in; 96 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44261: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            26887/136417 objects misplaced (19.709%)
                2720 active+clean
                  95 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 341 MB/s, 85 objects/s

2017-06-07 00:01:59,989 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:01:59,989 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-07 00:03:00,046 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 00:03:00,046 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:03:00,461 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            82 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            83 pgs stuck unclean
            recovery 23308/134633 objects misplaced (17.312%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8493: 15 osds: 15 up, 15 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44340: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            23308/134633 objects misplaced (17.312%)
                2732 active+clean
                  82 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 391 MB/s, 97 objects/s

2017-06-07 00:03:00,461 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:03:00,461 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-07 00:04:00,513 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 00:04:00,514 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:04:00,928 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            61 pgs backfill_wait
            2 pgs backfilling
            63 pgs stuck unclean
            recovery 16847/131449 objects misplaced (12.816%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8528: 15 osds: 15 up, 15 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44422: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            16847/131449 objects misplaced (12.816%)
                2753 active+clean
                  61 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s
  client io 304 kB/s rd, 457 op/s rd, 0 op/s wr

2017-06-07 00:04:00,928 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:04:00,928 INFO cluster.py [line:239] usefull PG number is 2753
2017-06-07 00:05:00,956 INFO cluster.py [line:247] cost 60 seconds, left 5457 seconds when check the ceph status
2017-06-07 00:05:00,956 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:05:01,324 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            48 pgs backfill_wait
            1 pgs backfilling
            49 pgs stuck unclean
            recovery 13110/129524 objects misplaced (10.122%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8554: 15 osds: 15 up, 15 in; 49 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44505: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            13110/129524 objects misplaced (10.122%)
                2767 active+clean
                  48 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 302 kB/s rd, 454 op/s rd, 0 op/s wr

2017-06-07 00:05:01,325 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:05:01,325 INFO cluster.py [line:239] usefull PG number is 2767
2017-06-07 00:06:01,385 INFO cluster.py [line:247] cost 61 seconds, left 5396 seconds when check the ceph status
2017-06-07 00:06:01,386 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:06:01,763 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            37 pgs backfill_wait
            1 pgs backfilling
            38 pgs stuck unclean
            recovery 9737/127868 objects misplaced (7.615%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8576: 15 osds: 15 up, 15 in; 38 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44584: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            9737/127868 objects misplaced (7.615%)
                2778 active+clean
                  37 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 248 MB/s, 62 objects/s
  client io 270 kB/s rd, 406 op/s rd, 0 op/s wr

2017-06-07 00:06:01,763 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:06:01,764 INFO cluster.py [line:239] usefull PG number is 2778
2017-06-07 00:07:01,824 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-07 00:07:01,824 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:07:02,207 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            28 pgs backfill_wait
            2 pgs backfilling
            30 pgs stuck unclean
            recovery 7880/126960 objects misplaced (6.207%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8594: 15 osds: 15 up, 15 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44651: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            7880/126960 objects misplaced (6.207%)
                2786 active+clean
                  28 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 250 MB/s, 62 objects/s

2017-06-07 00:07:02,207 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:07:02,207 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-07 00:08:02,243 INFO cluster.py [line:247] cost 61 seconds, left 5275 seconds when check the ceph status
2017-06-07 00:08:02,243 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:08:02,630 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            21 pgs backfill_wait
            1 pgs backfilling
            22 pgs stuck unclean
            recovery 6273/126145 objects misplaced (4.973%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8607: 15 osds: 15 up, 15 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44721: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            6273/126145 objects misplaced (4.973%)
                2794 active+clean
                  21 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:08:02,630 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:08:02,631 INFO cluster.py [line:239] usefull PG number is 2794
2017-06-07 00:09:02,671 INFO cluster.py [line:247] cost 60 seconds, left 5215 seconds when check the ceph status
2017-06-07 00:09:02,671 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:09:03,049 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            2 pgs backfilling
            14 pgs stuck unclean
            recovery 3798/124940 objects misplaced (3.040%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8624: 15 osds: 15 up, 15 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44796: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            3798/124940 objects misplaced (3.040%)
                2802 active+clean
                  12 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 414 MB/s, 103 objects/s

2017-06-07 00:09:03,049 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:09:03,049 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 00:10:03,069 INFO cluster.py [line:247] cost 61 seconds, left 5154 seconds when check the ceph status
2017-06-07 00:10:03,069 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:10:03,417 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            5 pgs backfill_wait
            1 pgs backfilling
            6 pgs stuck unclean
            recovery 1806/123910 objects misplaced (1.458%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8639: 15 osds: 15 up, 15 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44868: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            1806/123910 objects misplaced (1.458%)
                2810 active+clean
                   5 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:10:03,417 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:10:03,418 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 00:11:03,478 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-07 00:11:03,478 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:11:03,851 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8650: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44934: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
                2816 active+clean

2017-06-07 00:11:03,852 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:11:03,852 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:11:03,852 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:11:03,852 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 00:11:24,820 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 00:11:24,820 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 00:11:24,821 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:11:25,187 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8652: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44956: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
                2816 active+clean
  client io 103 kB/s rd, 154 op/s rd, 0 op/s wr

2017-06-07 00:11:25,187 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:11:25,187 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:11:25,187 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:11:25,187 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 00:11:47,534 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 00:11:47,534 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 00:11:47,534 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:11:47,906 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            104 pgs backfill_wait
            4 pgs backfilling
            45 pgs stuck unclean
            recovery 27985/137143 objects misplaced (20.406%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8671: 17 osds: 16 up, 17 in; 702 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v44988: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
            27985/137143 objects misplaced (20.406%)
                2708 active+clean
                 104 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 147 MB/s, 36 objects/s

2017-06-07 00:11:47,906 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:11:47,906 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-07 00:12:47,966 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 00:12:47,967 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:12:48,326 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            159 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            104 pgs stuck unclean
            recovery 44400/145348 objects misplaced (30.547%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8710: 17 osds: 17 up, 17 in; 160 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45072: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            44400/145348 objects misplaced (30.547%)
                2653 active+clean
                 159 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 1426 MB/s, 356 objects/s

2017-06-07 00:12:48,327 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:12:48,327 INFO cluster.py [line:239] usefull PG number is 2653
2017-06-07 00:13:48,366 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 00:13:48,366 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:13:48,744 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            136 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            117 pgs stuck unclean
            recovery 38272/142205 objects misplaced (26.913%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8739: 17 osds: 17 up, 17 in; 138 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45152: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            38272/142205 objects misplaced (26.913%)
                2677 active+clean
                 136 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 205 MB/s, 51 objects/s

2017-06-07 00:13:48,745 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:13:48,745 INFO cluster.py [line:239] usefull PG number is 2677
2017-06-07 00:14:48,777 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 00:14:48,777 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:14:49,181 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_ERR
            1 pgs are stuck inactive for more than 300 seconds
            121 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            1 pgs stuck inactive
            116 pgs stuck unclean
            recovery 33428/139728 objects misplaced (23.924%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8765: 17 osds: 17 up, 17 in; 122 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45230: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            33428/139728 objects misplaced (23.924%)
                2693 active+clean
                 121 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 232 MB/s, 58 objects/s

2017-06-07 00:14:49,181 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-07 00:15:49,234 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:15:49,620 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            108 pgs backfill_wait
            1 pgs backfilling
            106 pgs stuck unclean
            recovery 29873/137949 objects misplaced (21.655%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8790: 17 osds: 17 up, 17 in; 107 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45310: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            29873/137949 objects misplaced (21.655%)
                2707 active+clean
                 108 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:15:49,620 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:15:49,620 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 00:16:49,628 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 00:16:49,629 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:16:49,979 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_ERR
            1 pgs are stuck inactive for more than 300 seconds
            91 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            1 pgs stuck inactive
            92 pgs stuck unclean
            recovery 24383/135248 objects misplaced (18.028%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8820: 17 osds: 17 up, 17 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45395: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            24383/135248 objects misplaced (18.028%)
                2723 active+clean
                  91 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 399 MB/s, 99 objects/s

2017-06-07 00:16:49,979 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-07 00:17:50,024 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:17:50,427 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            65 pgs backfill_wait
            5 pgs backfilling
            1 pgs peering
            71 pgs stuck unclean
            recovery 18262/132293 objects misplaced (13.804%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8851: 17 osds: 17 up, 17 in; 68 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45478: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
            18262/132293 objects misplaced (13.804%)
                2744 active+clean
                  65 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 active+remapped
                   1 peering
recovery io 1459 MB/s, 364 objects/s
  client io 169 kB/s rd, 253 op/s rd, 0 op/s wr

2017-06-07 00:17:50,428 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:17:50,428 INFO cluster.py [line:239] usefull PG number is 2744
2017-06-07 00:18:50,464 INFO cluster.py [line:247] cost 60 seconds, left 5699 seconds when check the ceph status
2017-06-07 00:18:50,464 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:18:50,840 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            44 pgs backfill_wait
            3 pgs backfilling
            47 pgs stuck unclean
            recovery 11980/129032 objects misplaced (9.285%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8887: 17 osds: 17 up, 17 in; 46 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45567: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            11980/129032 objects misplaced (9.285%)
                2769 active+clean
                  44 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 268 MB/s, 67 objects/s
  client io 363 kB/s rd, 545 op/s rd, 0 op/s wr

2017-06-07 00:18:50,841 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:18:50,841 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-07 00:19:50,901 INFO cluster.py [line:247] cost 60 seconds, left 5639 seconds when check the ceph status
2017-06-07 00:19:50,901 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:19:51,278 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            28 pgs backfill_wait
            2 pgs backfilling
            30 pgs stuck unclean
            recovery 7439/126725 objects misplaced (5.870%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8916: 17 osds: 17 up, 17 in; 30 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45647: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            7439/126725 objects misplaced (5.870%)
                2786 active+clean
                  28 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 212 MB/s, 53 objects/s
  client io 298 kB/s rd, 447 op/s rd, 0 op/s wr

2017-06-07 00:19:51,278 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:19:51,278 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-07 00:20:51,279 INFO cluster.py [line:247] cost 61 seconds, left 5578 seconds when check the ceph status
2017-06-07 00:20:51,280 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:20:51,659 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            20 pgs backfill_wait
            1 pgs backfilling
            21 pgs stuck unclean
            recovery 4976/125454 objects misplaced (3.966%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8934: 17 osds: 17 up, 17 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45721: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            4976/125454 objects misplaced (3.966%)
                2795 active+clean
                  20 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 312 kB/s rd, 469 op/s rd, 0 op/s wr

2017-06-07 00:20:51,660 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:20:51,660 INFO cluster.py [line:239] usefull PG number is 2795
2017-06-07 00:21:51,720 INFO cluster.py [line:247] cost 60 seconds, left 5518 seconds when check the ceph status
2017-06-07 00:21:51,720 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:21:52,051 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 3035/124498 objects misplaced (2.438%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8950: 17 osds: 17 up, 17 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45794: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
            3035/124498 objects misplaced (2.438%)
                2803 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s
  client io 317 kB/s rd, 475 op/s rd, 0 op/s wr

2017-06-07 00:21:52,051 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:21:52,051 INFO cluster.py [line:239] usefull PG number is 2803
2017-06-07 00:22:52,099 INFO cluster.py [line:247] cost 61 seconds, left 5457 seconds when check the ceph status
2017-06-07 00:22:52,099 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:22:52,472 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 536/123276 objects misplaced (0.435%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8972: 17 osds: 17 up, 17 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45867: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            536/123276 objects misplaced (0.435%)
                2814 active+clean
                   1 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:22:52,473 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:22:52,473 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-07 00:23:52,513 INFO cluster.py [line:247] cost 60 seconds, left 5397 seconds when check the ceph status
2017-06-07 00:23:52,514 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:23:52,864 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8974: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45919: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
                2816 active+clean
  client io 281 kB/s rd, 422 op/s rd, 0 op/s wr

2017-06-07 00:23:52,864 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:23:52,865 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:23:52,865 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:23:52,865 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 00:24:14,049 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 00:24:14,049 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 00:24:14,050 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:24:14,468 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8976: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45940: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47501 GB / 48131 GB avail
                2816 active+clean
  client io 174 kB/s rd, 174 op/s rd, 0 op/s wr

2017-06-07 00:24:14,468 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:24:14,468 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:24:14,468 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:24:14,468 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 00:24:35,604 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 00:24:35,605 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 00:24:35,605 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:24:35,981 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            89 pgs backfill_wait
            5 pgs backfilling
            1 pgs peering
            63 pgs stuck unclean
            recovery 25464/135960 objects misplaced (18.729%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e8996: 19 osds: 18 up, 19 in; 600 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v45971: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            640 GB used, 50322 GB / 50962 GB avail
            25464/135960 objects misplaced (18.729%)
                2720 active+clean
                  89 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 peering
                   1 active+remapped
recovery io 1289 MB/s, 322 objects/s

2017-06-07 00:24:35,981 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:24:35,982 INFO cluster.py [line:239] usefull PG number is 2720
2017-06-07 00:25:35,983 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 00:25:35,983 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:25:36,344 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            128 pgs backfill_wait
            5 pgs backfilling
            85 pgs stuck unclean
            recovery 36054/141202 objects misplaced (25.534%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9037: 19 osds: 19 up, 19 in; 130 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46054: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            36054/141202 objects misplaced (25.534%)
                2683 active+clean
                 128 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 577 MB/s, 144 objects/s

2017-06-07 00:25:36,344 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:25:36,344 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 00:26:36,391 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 00:26:36,391 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:26:36,797 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            109 pgs backfill_wait
            1 pgs backfilling
            74 pgs stuck unclean
            recovery 29546/137775 objects misplaced (21.445%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9069: 19 osds: 19 up, 19 in; 109 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46138: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            29546/137775 objects misplaced (21.445%)
                2706 active+clean
                 109 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:26:36,798 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:26:36,798 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-07 00:27:36,800 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 00:27:36,800 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:27:37,182 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            93 pgs backfill_wait
            2 pgs backfilling
            70 pgs stuck unclean
            recovery 25621/135879 objects misplaced (18.856%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9100: 19 osds: 19 up, 19 in; 94 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46224: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            25621/135879 objects misplaced (18.856%)
                2721 active+clean
                  93 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 00:27:37,183 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:27:37,183 INFO cluster.py [line:239] usefull PG number is 2721
2017-06-07 00:28:37,217 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 00:28:37,217 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:28:37,586 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            81 pgs backfill_wait
            1 pgs backfilling
            62 pgs stuck unclean
            recovery 22156/134084 objects misplaced (16.524%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9121: 19 osds: 19 up, 19 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46301: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            22156/134084 objects misplaced (16.524%)
                2734 active+clean
                  81 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 469 MB/s, 117 objects/s

2017-06-07 00:28:37,586 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:28:37,586 INFO cluster.py [line:239] usefull PG number is 2734
2017-06-07 00:29:37,622 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 00:29:37,622 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:29:38,042 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            71 pgs backfill_wait
            2 pgs backfilling
            73 pgs stuck unclean
            recovery 19397/132703 objects misplaced (14.617%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9134: 19 osds: 19 up, 19 in; 73 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46370: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            19397/132703 objects misplaced (14.617%)
                2743 active+clean
                  71 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 00:29:38,043 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:29:38,043 INFO cluster.py [line:239] usefull PG number is 2743
2017-06-07 00:30:38,095 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 00:30:38,095 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:30:38,503 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            53 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            55 pgs stuck unclean
            recovery 15187/130588 objects misplaced (11.630%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9165: 19 osds: 19 up, 19 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46452: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            15187/130588 objects misplaced (11.630%)
                2760 active+clean
                  53 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 302 MB/s, 75 objects/s
  client io 215 kB/s rd, 323 op/s rd, 0 op/s wr

2017-06-07 00:30:38,503 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:30:38,503 INFO cluster.py [line:239] usefull PG number is 2760
2017-06-07 00:31:38,547 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 00:31:38,548 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:31:38,909 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            29 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            33 pgs stuck unclean
            recovery 8425/127347 objects misplaced (6.616%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9195: 19 osds: 19 up, 19 in; 33 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46533: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            8425/127347 objects misplaced (6.616%)
                2782 active+clean
                  29 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 967 MB/s, 241 objects/s

2017-06-07 00:31:38,909 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:31:38,909 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-07 00:32:38,970 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 00:32:38,970 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:32:39,340 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            14 pgs backfill_wait
            1 pgs backfilling
            15 pgs stuck unclean
            recovery 3890/124913 objects misplaced (3.114%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9221: 19 osds: 19 up, 19 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46613: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            3890/124913 objects misplaced (3.114%)
                2801 active+clean
                  14 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 00:32:39,341 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:32:39,341 INFO cluster.py [line:239] usefull PG number is 2801
2017-06-07 00:33:39,368 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 00:33:39,368 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:33:39,759 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            6 pgs stuck unclean
            recovery 1596/123732 objects misplaced (1.290%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9238: 19 osds: 19 up, 19 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46686: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            1596/123732 objects misplaced (1.290%)
                2810 active+clean
                   6 active+remapped+backfill_wait
recovery io 273 MB/s, 68 objects/s

2017-06-07 00:33:39,759 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:33:39,760 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 00:34:39,793 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 00:34:39,793 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:34:40,145 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9250: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46755: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean
  client io 289 kB/s rd, 331 op/s rd, 0 op/s wr

2017-06-07 00:34:40,145 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:34:40,145 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:34:40,145 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:34:40,145 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 00:35:01,602 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 00:35:01,602 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 00:35:01,602 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:35:02,016 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9252: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v46776: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean

2017-06-07 00:35:02,016 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:35:02,016 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:35:02,016 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 00:35:04,164 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 00:35:04,445 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 28 Jun05 ?        05:01:25 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   28644 28642  0 16:35 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   28646 28644  0 16:35 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-07 00:35:04,445 INFO client.py [line:174] IO is running
2017-06-07 00:35:04,648 INFO node.py [line:185] 0
2017-06-07 00:35:04,649 INFO node.py [line:192] nvme6n1
2017-06-07 00:35:04,649 INFO node.py [line:185] 0
2017-06-07 00:35:04,649 INFO node.py [line:192] nvme6n1
2017-06-07 00:35:04,649 INFO node.py [line:185] 0
2017-06-07 00:35:04,649 INFO node.py [line:192] nvme6n1
2017-06-07 00:35:04,649 INFO node.py [line:185] 1
2017-06-07 00:35:04,649 INFO node.py [line:192] nvme2n1
2017-06-07 00:35:04,650 INFO node.py [line:185] 1
2017-06-07 00:35:04,650 INFO node.py [line:192] nvme2n1
2017-06-07 00:35:04,650 INFO node.py [line:185] 1
2017-06-07 00:35:04,650 INFO node.py [line:192] nvme2n1
2017-06-07 00:35:04,650 INFO node.py [line:185] 2
2017-06-07 00:35:04,650 INFO node.py [line:192] nvme5n1
2017-06-07 00:35:04,650 INFO node.py [line:185] 2
2017-06-07 00:35:04,650 INFO node.py [line:192] nvme5n1
2017-06-07 00:35:04,650 INFO node.py [line:185] 2
2017-06-07 00:35:04,650 INFO node.py [line:192] nvme5n1
2017-06-07 00:35:04,651 INFO node.py [line:185] 3
2017-06-07 00:35:04,651 INFO node.py [line:192] nvme1n1
2017-06-07 00:35:04,651 INFO node.py [line:185] 3
2017-06-07 00:35:04,651 INFO node.py [line:192] nvme1n1
2017-06-07 00:35:04,651 INFO node.py [line:185] 3
2017-06-07 00:35:04,651 INFO node.py [line:192] nvme1n1
2017-06-07 00:35:04,651 INFO node.py [line:185] 4
2017-06-07 00:35:04,651 INFO node.py [line:192] nvme4n1
2017-06-07 00:35:04,651 INFO node.py [line:185] 4
2017-06-07 00:35:04,652 INFO node.py [line:192] nvme4n1
2017-06-07 00:35:04,652 INFO node.py [line:185] 4
2017-06-07 00:35:04,652 INFO node.py [line:192] nvme4n1
2017-06-07 00:35:04,652 INFO node.py [line:185] 5
2017-06-07 00:35:04,652 INFO node.py [line:192] nvme7n1
2017-06-07 00:35:04,652 INFO node.py [line:185] 5
2017-06-07 00:35:04,652 INFO node.py [line:192] nvme7n1
2017-06-07 00:35:04,652 INFO node.py [line:185] 5
2017-06-07 00:35:04,652 INFO node.py [line:192] nvme7n1
2017-06-07 00:35:04,653 INFO node.py [line:185] 6
2017-06-07 00:35:04,653 INFO node.py [line:192] nvme3n1
2017-06-07 00:35:04,653 INFO node.py [line:185] 6
2017-06-07 00:35:04,653 INFO node.py [line:192] nvme3n1
2017-06-07 00:35:04,653 INFO node.py [line:185] 6
2017-06-07 00:35:04,653 INFO node.py [line:192] nvme3n1
2017-06-07 00:35:04,653 INFO node.py [line:185] 
2017-06-07 00:35:04,653 INFO node.py [line:192] nvme3n1
2017-06-07 00:35:04,653 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 00:35:04,654 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 00:35:04,654 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 00:35:04,654 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 00:42:46,442 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:42:46,848 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9420: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47369: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            647 GB used, 53146 GB / 53794 GB avail
                2816 active+clean

2017-06-07 00:42:46,849 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:42:46,849 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:42:46,849 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 00:42:46,849 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 00:45:08,272 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:45:08,681 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9520: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47576: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            639 GB used, 50323 GB / 50962 GB avail
                2816 active+clean
  client io 405 kB/s rd, 607 op/s rd, 0 op/s wr

2017-06-07 00:45:08,681 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:45:08,681 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:45:08,681 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 00:45:08,681 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 00:47:41,242 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:47:41,602 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9632: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v47799: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
                2816 active+clean

2017-06-07 00:47:41,603 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:47:41,603 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:47:41,603 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 00:47:41,603 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 00:51:31,779 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:51:32,179 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9791: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48147: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44678 GB / 45300 GB avail
                2816 active+clean

2017-06-07 00:51:32,180 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:51:32,180 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:51:32,180 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 00:51:32,180 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 00:55:38,945 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 00:55:39,354 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e9956: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48508: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
                2816 active+clean

2017-06-07 00:55:39,354 INFO cluster.py [line:238] PG number is 2816
2017-06-07 00:55:39,354 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 00:55:39,354 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 00:55:39,354 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 01:01:30,788 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:01:31,199 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10139: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v48988: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            604 GB used, 39032 GB / 39637 GB avail
                2816 active+clean
  client io 361 kB/s rd, 542 op/s rd, 0 op/s wr

2017-06-07 01:01:31,200 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:01:31,200 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:01:31,200 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 01:01:31,200 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 01:03:51,570 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:03:51,949 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10254: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49211: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            596 GB used, 36210 GB / 36806 GB avail
                2816 active+clean
  client io 137 kB/s rd, 206 op/s rd, 0 op/s wr

2017-06-07 01:03:51,950 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:03:51,950 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:03:51,950 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 01:03:54,037 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 01:03:54,037 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 01:03:54,037 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 01:04:16,965 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:04:16,965 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:04:16,965 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:04:17,331 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10256: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49235: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            596 GB used, 36210 GB / 36806 GB avail
                2816 active+clean
  client io 81828 B/s rd, 119 op/s rd, 0 op/s wr

2017-06-07 01:04:17,332 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:04:17,332 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:04:17,332 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:04:17,332 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 01:04:39,351 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:04:39,352 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:04:39,352 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:04:39,722 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136260 objects degraded (0.004%)
            recovery 26340/136260 objects misplaced (19.331%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10269: 15 osds: 14 up, 15 in; 741 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49265: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39030 GB / 39637 GB avail
            6/136260 objects degraded (0.004%)
            26340/136260 objects misplaced (19.331%)
                2717 active+clean
                  96 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
  client io 459 kB/s rd, 459 op/s rd, 0 op/s wr

2017-06-07 01:04:39,722 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:04:39,722 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-07 01:05:39,742 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 01:05:39,742 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:05:40,111 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            162 pgs backfill_wait
            1 pgs backfilling
            61 pgs stuck unclean
            recovery 45757/145917 objects misplaced (31.358%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10297: 15 osds: 15 up, 15 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49345: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            45757/145917 objects misplaced (31.358%)
                2653 active+clean
                 162 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s

2017-06-07 01:05:40,112 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:05:40,112 INFO cluster.py [line:239] usefull PG number is 2653
2017-06-07 01:06:40,172 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 01:06:40,172 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:06:40,506 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            151 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            63 pgs stuck unclean
            recovery 42284/144143 objects misplaced (29.335%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10318: 15 osds: 15 up, 15 in; 152 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49421: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            42284/144143 objects misplaced (29.335%)
                2663 active+clean
                 151 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 343 MB/s, 85 objects/s

2017-06-07 01:06:40,506 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:06:40,506 INFO cluster.py [line:239] usefull PG number is 2663
2017-06-07 01:07:40,524 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 01:07:40,524 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:07:40,923 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            144 pgs backfill_wait
            1 pgs backfilling
            100 pgs stuck unclean
            recovery 40417/143237 objects misplaced (28.217%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10332: 15 osds: 15 up, 15 in; 145 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49493: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            40417/143237 objects misplaced (28.217%)
                2671 active+clean
                 144 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:07:40,923 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:07:40,923 INFO cluster.py [line:239] usefull PG number is 2671
2017-06-07 01:08:40,976 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 01:08:40,976 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:08:41,355 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            133 pgs backfill_wait
            1 pgs backfilling
            109 pgs stuck unclean
            recovery 36838/141427 objects misplaced (26.047%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10354: 15 osds: 15 up, 15 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49573: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            36838/141427 objects misplaced (26.047%)
                2682 active+clean
                 133 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:08:41,355 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:08:41,355 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-07 01:09:41,370 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 01:09:41,371 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:09:41,787 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            122 pgs backfill_wait
            1 pgs backfilling
            123 pgs stuck unclean
            recovery 33946/139958 objects misplaced (24.254%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10373: 15 osds: 15 up, 15 in; 123 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49648: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            33946/139958 objects misplaced (24.254%)
                2693 active+clean
                 122 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:09:41,788 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:09:41,788 INFO cluster.py [line:239] usefull PG number is 2693
2017-06-07 01:10:41,848 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 01:10:41,848 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:10:42,228 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            2 pgs backfilling
            104 pgs stuck unclean
            recovery 28491/137261 objects misplaced (20.757%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10411: 15 osds: 15 up, 15 in; 102 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49734: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            28491/137261 objects misplaced (20.757%)
                2712 active+clean
                 102 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 01:10:42,228 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:10:42,228 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-07 01:11:42,264 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 01:11:42,264 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:11:42,592 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            85 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            87 pgs stuck unclean
            recovery 23221/134642 objects misplaced (17.246%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10440: 15 osds: 15 up, 15 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49821: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            23221/134642 objects misplaced (17.246%)
                2728 active+clean
                  85 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering

2017-06-07 01:11:42,593 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:11:42,593 INFO cluster.py [line:239] usefull PG number is 2728
2017-06-07 01:12:42,604 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 01:12:42,604 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:12:42,976 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            64 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            66 pgs stuck unclean
            recovery 17117/131610 objects misplaced (13.006%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10480: 15 osds: 15 up, 15 in; 64 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49916: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            17117/131610 objects misplaced (13.006%)
                2749 active+clean
                  64 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 498 MB/s, 124 objects/s
  client io 175 kB/s rd, 262 op/s rd, 0 op/s wr

2017-06-07 01:12:42,976 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:12:42,977 INFO cluster.py [line:239] usefull PG number is 2749
2017-06-07 01:13:43,015 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 01:13:43,015 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:13:43,533 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            50 pgs backfill_wait
            1 pgs backfilling
            51 pgs stuck unclean
            recovery 13663/129805 objects misplaced (10.526%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10502: 15 osds: 15 up, 15 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v49992: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            13663/129805 objects misplaced (10.526%)
                2765 active+clean
                  50 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 102 MB/s, 25 objects/s
  client io 86832 B/s rd, 127 op/s rd, 0 op/s wr

2017-06-07 01:13:43,534 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:13:43,534 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-07 01:14:43,577 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 01:14:43,577 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:14:43,943 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            44 pgs backfill_wait
            1 pgs peering
            44 pgs stuck unclean
            recovery 12077/128996 objects misplaced (9.362%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10518: 15 osds: 15 up, 15 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50064: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            12077/128996 objects misplaced (9.362%)
                2771 active+clean
                  44 active+remapped+backfill_wait
                   1 peering

2017-06-07 01:14:43,943 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:14:43,944 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-07 01:15:43,972 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-07 01:15:43,972 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:15:44,321 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            30 pgs backfill_wait
            1 pgs backfilling
            31 pgs stuck unclean
            recovery 8298/127097 objects misplaced (6.529%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10540: 15 osds: 15 up, 15 in; 31 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50144: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            8298/127097 objects misplaced (6.529%)
                2785 active+clean
                  30 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 189 kB/s rd, 189 op/s rd, 0 op/s wr

2017-06-07 01:15:44,321 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:15:44,321 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-07 01:16:44,382 INFO cluster.py [line:247] cost 61 seconds, left 5275 seconds when check the ceph status
2017-06-07 01:16:44,382 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:16:44,768 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 6499/126240 objects misplaced (5.148%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10555: 15 osds: 15 up, 15 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50215: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            6499/126240 objects misplaced (5.148%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 424 kB/s rd, 424 op/s rd, 0 op/s wr

2017-06-07 01:16:44,769 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:16:44,769 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-07 01:17:44,826 INFO cluster.py [line:247] cost 60 seconds, left 5215 seconds when check the ceph status
2017-06-07 01:17:44,826 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:17:45,196 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            2 pgs backfilling
            17 pgs stuck unclean
            recovery 4913/125434 objects misplaced (3.917%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10570: 15 osds: 15 up, 15 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50289: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            4913/125434 objects misplaced (3.917%)
                2799 active+clean
                  15 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 109 MB/s, 27 objects/s

2017-06-07 01:17:45,197 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:17:45,197 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-07 01:18:45,246 INFO cluster.py [line:247] cost 61 seconds, left 5154 seconds when check the ceph status
2017-06-07 01:18:45,246 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:18:45,612 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            5 pgs backfill_wait
            1 pgs backfilling
            6 pgs stuck unclean
            recovery 1520/123759 objects misplaced (1.228%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10593: 15 osds: 15 up, 15 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50369: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
            1520/123759 objects misplaced (1.228%)
                2810 active+clean
                   5 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:18:45,612 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:18:45,612 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 01:19:45,673 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-07 01:19:45,673 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:19:46,045 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10602: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50434: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
                2816 active+clean

2017-06-07 01:19:46,046 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:19:46,046 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:19:46,046 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:19:46,046 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 01:20:06,632 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:20:06,633 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:20:06,633 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:20:07,044 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10604: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50454: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41855 GB / 42468 GB avail
                2816 active+clean

2017-06-07 01:20:07,045 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:20:07,045 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:20:07,045 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:20:07,045 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 01:20:29,283 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:20:29,283 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:20:29,283 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:20:29,696 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            3 pgs backfilling
            45 pgs stuck unclean
            recovery 28696/137518 objects misplaced (20.867%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10622: 17 osds: 16 up, 17 in; 701 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50486: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44675 GB / 45300 GB avail
            28696/137518 objects misplaced (20.867%)
                2706 active+clean
                 106 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 active+remapped
recovery io 401 MB/s, 100 objects/s

2017-06-07 01:20:29,697 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:20:29,697 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-07 01:21:29,728 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 01:21:29,728 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:21:30,123 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            155 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            99 pgs stuck unclean
            recovery 43508/144875 objects misplaced (30.031%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10669: 17 osds: 17 up, 17 in; 157 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50578: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            43508/144875 objects misplaced (30.031%)
                2657 active+clean
                 155 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 3243 MB/s, 810 objects/s

2017-06-07 01:21:30,123 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:21:30,123 INFO cluster.py [line:239] usefull PG number is 2657
2017-06-07 01:22:30,144 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 01:22:30,144 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:22:30,502 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            130 pgs backfill_wait
            4 pgs backfilling
            112 pgs stuck unclean
            recovery 36459/141431 objects misplaced (25.779%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10706: 17 osds: 17 up, 17 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50667: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            36459/141431 objects misplaced (25.779%)
                2682 active+clean
                 130 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 721 MB/s, 180 objects/s

2017-06-07 01:22:30,502 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:22:30,502 INFO cluster.py [line:239] usefull PG number is 2682
2017-06-07 01:23:30,556 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 01:23:30,556 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:23:30,914 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            115 pgs backfill_wait
            1 pgs backfilling
            105 pgs stuck unclean
            recovery 31329/138627 objects misplaced (22.599%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10735: 17 osds: 17 up, 17 in; 116 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50752: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            31329/138627 objects misplaced (22.599%)
                2700 active+clean
                 115 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 244 kB/s rd, 244 op/s rd, 0 op/s wr

2017-06-07 01:23:30,914 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:23:30,914 INFO cluster.py [line:239] usefull PG number is 2700
2017-06-07 01:24:30,966 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 01:24:30,966 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:24:31,350 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            101 pgs backfill_wait
            2 pgs backfilling
            99 pgs stuck unclean
            recovery 28194/137123 objects misplaced (20.561%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10761: 17 osds: 17 up, 17 in; 103 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50832: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
            28194/137123 objects misplaced (20.561%)
                2712 active+clean
                 101 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
  client io 207 kB/s rd, 207 op/s rd, 0 op/s wr

2017-06-07 01:24:31,350 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:24:31,350 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-07 01:25:31,410 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 01:25:31,411 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:25:31,794 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            80 pgs backfill_wait
            2 pgs backfilling
            82 pgs stuck unclean
            recovery 21880/133940 objects misplaced (16.336%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10794: 17 osds: 17 up, 17 in; 81 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v50919: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            21880/133940 objects misplaced (16.336%)
                2734 active+clean
                  80 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 507 MB/s, 126 objects/s
  client io 102 kB/s rd, 153 op/s rd, 0 op/s wr

2017-06-07 01:25:31,794 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:25:31,795 INFO cluster.py [line:239] usefull PG number is 2734
2017-06-07 01:26:31,834 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 01:26:31,834 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:26:32,205 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            54 pgs backfill_wait
            3 pgs backfilling
            57 pgs stuck unclean
            recovery 14533/130329 objects misplaced (11.151%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10833: 17 osds: 17 up, 17 in; 56 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51003: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
            14533/130329 objects misplaced (11.151%)
                2759 active+clean
                  54 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 350 MB/s, 87 objects/s
  client io 349 kB/s rd, 524 op/s rd, 0 op/s wr

2017-06-07 01:26:32,206 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:26:32,206 INFO cluster.py [line:239] usefull PG number is 2759
2017-06-07 01:27:32,266 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 01:27:32,267 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:27:32,612 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            30 pgs backfill_wait
            2 pgs backfilling
            32 pgs stuck unclean
            recovery 8053/127026 objects misplaced (6.340%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10867: 17 osds: 17 up, 17 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51092: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
            8053/127026 objects misplaced (6.340%)
                2784 active+clean
                  30 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 256 MB/s, 64 objects/s
  client io 337 kB/s rd, 506 op/s rd, 0 op/s wr

2017-06-07 01:27:32,613 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:27:32,613 INFO cluster.py [line:239] usefull PG number is 2784
2017-06-07 01:28:32,650 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 01:28:32,650 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:28:33,032 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 4782/125333 objects misplaced (3.815%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10889: 17 osds: 17 up, 17 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51169: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            4782/125333 objects misplaced (3.815%)
                2797 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 214 MB/s, 53 objects/s
  client io 338 kB/s rd, 508 op/s rd, 0 op/s wr

2017-06-07 01:28:33,033 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:28:33,033 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-07 01:29:33,068 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 01:29:33,068 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:29:33,481 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 2349/124152 objects misplaced (1.892%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10908: 17 osds: 17 up, 17 in; 9 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51243: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            2349/124152 objects misplaced (1.892%)
                2806 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:29:33,481 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:29:33,482 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-07 01:30:33,542 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 01:30:33,542 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:30:33,916 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfill_wait
            1 pgs backfilling
            2 pgs stuck unclean
            recovery 180/123055 objects misplaced (0.146%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10923: 17 osds: 17 up, 17 in; 2 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51314: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
            180/123055 objects misplaced (0.146%)
                2814 active+clean
                   1 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 01:30:33,916 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:30:33,916 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-07 01:31:33,947 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-07 01:31:33,947 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:31:34,332 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10925: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51365: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
                2816 active+clean
  client io 231 kB/s rd, 347 op/s rd, 0 op/s wr

2017-06-07 01:31:34,332 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:31:34,332 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:31:34,333 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:31:34,333 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 01:31:55,263 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:31:55,263 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:31:55,264 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:31:55,624 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10927: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51385: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            630 GB used, 47500 GB / 48131 GB avail
                2816 active+clean

2017-06-07 01:31:55,625 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:31:55,625 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:31:55,625 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:31:55,625 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 01:32:17,690 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:32:17,690 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:32:17,691 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:32:18,067 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            5 pgs backfilling
            50 pgs stuck unclean
            recovery 26277/136324 objects misplaced (19.275%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10946: 19 osds: 18 up, 19 in; 601 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51418: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50320 GB / 50962 GB avail
            26277/136324 objects misplaced (19.275%)
                2719 active+clean
                  92 active+remapped+backfill_wait
                   5 active+remapped+backfilling

2017-06-07 01:32:18,067 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:32:18,068 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-07 01:33:18,105 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 01:33:18,106 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:33:18,486 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            127 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            104 pgs stuck unclean
            recovery 35526/141063 objects misplaced (25.184%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e10989: 19 osds: 19 up, 19 in; 129 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51508: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            35526/141063 objects misplaced (25.184%)
                2683 active+clean
                 127 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   2 active+remapped
                   1 peering
recovery io 381 MB/s, 95 objects/s

2017-06-07 01:33:18,486 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:33:18,486 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 01:34:18,490 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 01:34:18,490 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:34:18,875 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_ERR
            1 pgs are stuck inactive for more than 300 seconds
            108 pgs backfill_wait
            1 pgs backfilling
            2 pgs peering
            1 pgs stuck inactive
            93 pgs stuck unclean
            recovery 29039/137531 objects misplaced (21.115%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11019: 19 osds: 19 up, 19 in; 109 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51590: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            29039/137531 objects misplaced (21.115%)
                2705 active+clean
                 108 active+remapped+backfill_wait
                   2 peering
                   1 active+remapped+backfilling
recovery io 522 MB/s, 130 objects/s

2017-06-07 01:34:18,875 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-07 01:35:18,911 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:35:19,287 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            94 pgs backfill_wait
            1 pgs backfilling
            90 pgs stuck unclean
            recovery 25664/135869 objects misplaced (18.889%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11047: 19 osds: 19 up, 19 in; 95 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51675: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            25664/135869 objects misplaced (18.889%)
                2721 active+clean
                  94 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 234 MB/s, 58 objects/s

2017-06-07 01:35:19,287 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:35:19,287 INFO cluster.py [line:239] usefull PG number is 2721
2017-06-07 01:36:19,347 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-07 01:36:19,348 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:36:19,684 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            81 pgs backfill_wait
            2 pgs backfilling
            80 pgs stuck unclean
            recovery 22845/134526 objects misplaced (16.982%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11070: 19 osds: 19 up, 19 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51755: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
            22845/134526 objects misplaced (16.982%)
                2732 active+clean
                  81 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 511 MB/s, 127 objects/s

2017-06-07 01:36:19,685 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:36:19,685 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-07 01:37:19,731 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-07 01:37:19,732 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:37:20,139 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            71 pgs backfill_wait
            3 pgs backfilling
            74 pgs stuck unclean
            recovery 19719/132971 objects misplaced (14.830%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11091: 19 osds: 19 up, 19 in; 72 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51833: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
            19719/132971 objects misplaced (14.830%)
                2742 active+clean
                  71 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 438 kB/s rd, 438 op/s rd, 0 op/s wr

2017-06-07 01:37:20,139 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:37:20,139 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-07 01:38:20,156 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-07 01:38:20,156 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:38:20,569 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            52 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            55 pgs stuck unclean
            recovery 14829/130484 objects misplaced (11.365%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11121: 19 osds: 19 up, 19 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v51916: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            14829/130484 objects misplaced (11.365%)
                2760 active+clean
                  52 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 543 MB/s, 135 objects/s
  client io 461 kB/s rd, 580 op/s rd, 0 op/s wr

2017-06-07 01:38:20,569 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:38:20,569 INFO cluster.py [line:239] usefull PG number is 2760
2017-06-07 01:39:20,629 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-07 01:39:20,629 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:39:21,000 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            27 pgs backfill_wait
            3 pgs backfilling
            31 pgs stuck unclean
            recovery 7925/127124 objects misplaced (6.234%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11159: 19 osds: 19 up, 19 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52005: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            7925/127124 objects misplaced (6.234%)
                2785 active+clean
                  27 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 active+remapped
recovery io 531 MB/s, 132 objects/s

2017-06-07 01:39:21,001 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:39:21,001 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-07 01:40:21,012 INFO cluster.py [line:247] cost 61 seconds, left 5576 seconds when check the ceph status
2017-06-07 01:40:21,012 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:40:21,423 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            13 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 3590/124813 objects misplaced (2.876%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11182: 19 osds: 19 up, 19 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52081: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
            3590/124813 objects misplaced (2.876%)
                2802 active+clean
                  13 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 657 MB/s, 164 objects/s

2017-06-07 01:40:21,423 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:40:21,423 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 01:41:21,483 INFO cluster.py [line:247] cost 60 seconds, left 5516 seconds when check the ceph status
2017-06-07 01:41:21,484 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:41:21,881 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            5 pgs backfill_wait
            1 pgs backfilling
            6 pgs stuck unclean
            recovery 1547/123750 objects misplaced (1.250%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11197: 19 osds: 19 up, 19 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52153: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
            1547/123750 objects misplaced (1.250%)
                2810 active+clean
                   5 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 276 MB/s, 69 objects/s
  client io 211 kB/s rd, 316 op/s rd, 0 op/s wr

2017-06-07 01:41:21,881 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:41:21,882 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 01:42:21,927 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 01:42:21,928 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:42:22,287 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11209: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52223: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
                2816 active+clean
  client io 95078 B/s rd, 139 op/s rd, 0 op/s wr

2017-06-07 01:42:22,287 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:42:22,287 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:42:22,287 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:42:22,287 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 01:42:43,568 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 01:42:43,568 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 01:42:43,568 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:42:43,967 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11211: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52240: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
                2816 active+clean
  client io 64126 B/s rd, 93 op/s rd, 0 op/s wr

2017-06-07 01:42:43,967 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:42:43,967 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:42:43,967 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 01:42:46,008 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 01:42:46,292 INFO client.py [line:172] ['enali    5737  5735  0 17:42 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali    5739  5737  0 17:42 ?        00:00:00 grep fio', 'root     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 27 Jun05 ?        05:01:35 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'stdin: is not a tty', '']
2017-06-07 01:42:46,292 INFO client.py [line:174] IO is running
2017-06-07 01:42:46,477 INFO node.py [line:185] 0
2017-06-07 01:42:46,477 INFO node.py [line:192] nvme6n1
2017-06-07 01:42:46,477 INFO node.py [line:185] 0
2017-06-07 01:42:46,477 INFO node.py [line:192] nvme6n1
2017-06-07 01:42:46,477 INFO node.py [line:185] 0
2017-06-07 01:42:46,478 INFO node.py [line:192] nvme6n1
2017-06-07 01:42:46,478 INFO node.py [line:185] 1
2017-06-07 01:42:46,478 INFO node.py [line:192] nvme2n1
2017-06-07 01:42:46,478 INFO node.py [line:185] 1
2017-06-07 01:42:46,478 INFO node.py [line:192] nvme2n1
2017-06-07 01:42:46,478 INFO node.py [line:185] 1
2017-06-07 01:42:46,478 INFO node.py [line:192] nvme2n1
2017-06-07 01:42:46,478 INFO node.py [line:185] 2
2017-06-07 01:42:46,478 INFO node.py [line:192] nvme5n1
2017-06-07 01:42:46,479 INFO node.py [line:185] 2
2017-06-07 01:42:46,479 INFO node.py [line:192] nvme5n1
2017-06-07 01:42:46,479 INFO node.py [line:185] 2
2017-06-07 01:42:46,479 INFO node.py [line:192] nvme5n1
2017-06-07 01:42:46,479 INFO node.py [line:185] 3
2017-06-07 01:42:46,479 INFO node.py [line:192] nvme1n1
2017-06-07 01:42:46,479 INFO node.py [line:185] 3
2017-06-07 01:42:46,479 INFO node.py [line:192] nvme1n1
2017-06-07 01:42:46,479 INFO node.py [line:185] 3
2017-06-07 01:42:46,480 INFO node.py [line:192] nvme1n1
2017-06-07 01:42:46,480 INFO node.py [line:185] 4
2017-06-07 01:42:46,480 INFO node.py [line:192] nvme4n1
2017-06-07 01:42:46,480 INFO node.py [line:185] 4
2017-06-07 01:42:46,480 INFO node.py [line:192] nvme4n1
2017-06-07 01:42:46,480 INFO node.py [line:185] 4
2017-06-07 01:42:46,480 INFO node.py [line:192] nvme4n1
2017-06-07 01:42:46,480 INFO node.py [line:185] 5
2017-06-07 01:42:46,480 INFO node.py [line:192] nvme7n1
2017-06-07 01:42:46,480 INFO node.py [line:185] 5
2017-06-07 01:42:46,481 INFO node.py [line:192] nvme7n1
2017-06-07 01:42:46,481 INFO node.py [line:185] 5
2017-06-07 01:42:46,481 INFO node.py [line:192] nvme7n1
2017-06-07 01:42:46,481 INFO node.py [line:185] 6
2017-06-07 01:42:46,481 INFO node.py [line:192] nvme3n1
2017-06-07 01:42:46,481 INFO node.py [line:185] 6
2017-06-07 01:42:46,481 INFO node.py [line:192] nvme3n1
2017-06-07 01:42:46,481 INFO node.py [line:185] 6
2017-06-07 01:42:46,481 INFO node.py [line:192] nvme3n1
2017-06-07 01:42:46,482 INFO node.py [line:185] 
2017-06-07 01:42:46,482 INFO node.py [line:192] nvme3n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 01:42:46,482 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 01:42:46,483 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 01:42:46,483 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 01:50:17,164 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:50:17,568 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11381: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v52814: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            648 GB used, 53145 GB / 53794 GB avail
                2816 active+clean

2017-06-07 01:50:17,569 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:50:17,569 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:50:17,569 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 01:50:17,569 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 01:52:37,174 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:52:37,536 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11486: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v53025: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            639 GB used, 50322 GB / 50962 GB avail
                2816 active+clean
  client io 131 kB/s rd, 196 op/s rd, 0 op/s wr

2017-06-07 01:52:37,537 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:52:37,537 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:52:37,537 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 01:52:37,537 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 01:54:58,691 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:54:59,067 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11603: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v53232: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47500 GB / 48131 GB avail
                2816 active+clean

2017-06-07 01:54:59,067 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:54:59,067 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:54:59,067 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 01:54:59,067 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 01:59:03,673 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 01:59:04,023 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11764: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v53583: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44677 GB / 45300 GB avail
                2816 active+clean

2017-06-07 01:59:04,023 INFO cluster.py [line:238] PG number is 2816
2017-06-07 01:59:04,023 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 01:59:04,023 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 01:59:04,023 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 02:02:56,226 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:02:56,615 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e11928: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v53919: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            613 GB used, 41854 GB / 42468 GB avail
                2816 active+clean

2017-06-07 02:02:56,616 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:02:56,616 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:02:56,616 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 02:02:56,616 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 02:09:01,298 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:09:01,658 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12108: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54397: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39032 GB / 39637 GB avail
                2816 active+clean

2017-06-07 02:09:01,659 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:09:01,659 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:09:01,659 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 02:09:01,659 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 02:11:21,896 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:11:22,279 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12218: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54610: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            596 GB used, 36209 GB / 36806 GB avail
                2816 active+clean

2017-06-07 02:11:22,279 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:11:22,279 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:11:22,279 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 02:11:24,280 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 02:11:24,281 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 02:11:24,281 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 02:11:46,586 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:11:46,586 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:11:46,586 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:11:46,975 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            39 pgs peering
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12221: 14 osds: 13 up, 14 in; 523 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54635: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            596 GB used, 36209 GB / 36806 GB avail
                2777 active+clean
                  39 remapped+peering

2017-06-07 02:11:46,975 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:11:46,975 INFO cluster.py [line:239] usefull PG number is 2777
2017-06-07 02:12:46,998 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 02:12:46,999 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:12:47,408 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            86 pgs backfill_wait
            1 pgs backfilling
            11 pgs stuck unclean
            recovery 23757/134959 objects misplaced (17.603%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12252: 14 osds: 14 up, 14 in; 87 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54715: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
            23757/134959 objects misplaced (17.603%)
                2729 active+clean
                  86 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 252 MB/s, 63 objects/s
  client io 96812 B/s rd, 141 op/s rd, 0 op/s wr

2017-06-07 02:12:47,408 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:12:47,408 INFO cluster.py [line:239] usefull PG number is 2729
2017-06-07 02:13:47,466 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 02:13:47,466 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:13:47,831 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            73 pgs backfill_wait
            2 pgs backfilling
            9 pgs stuck unclean
            recovery 20496/133301 objects misplaced (15.376%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12278: 14 osds: 14 up, 14 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54797: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
            20496/133301 objects misplaced (15.376%)
                2741 active+clean
                  73 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 96031 kB/s, 23 objects/s
  client io 181 kB/s rd, 272 op/s rd, 0 op/s wr

2017-06-07 02:13:47,832 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:13:47,832 INFO cluster.py [line:239] usefull PG number is 2741
2017-06-07 02:14:47,861 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 02:14:47,862 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:14:48,256 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            62 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            35 pgs stuck unclean
            recovery 17013/131534 objects misplaced (12.934%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12298: 14 osds: 14 up, 14 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54874: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
            17013/131534 objects misplaced (12.934%)
                2752 active+clean
                  62 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 81222 kB/s, 19 objects/s
  client io 87314 B/s rd, 127 op/s rd, 0 op/s wr

2017-06-07 02:14:48,256 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:14:48,256 INFO cluster.py [line:239] usefull PG number is 2752
2017-06-07 02:15:48,317 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 02:15:48,317 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:15:48,689 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            49 pgs backfill_wait
            2 pgs backfilling
            47 pgs stuck unclean
            recovery 13298/129710 objects misplaced (10.252%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12324: 14 osds: 14 up, 14 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v54953: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39031 GB / 39637 GB avail
            13298/129710 objects misplaced (10.252%)
                2765 active+clean
                  49 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 268 MB/s, 67 objects/s
  client io 101 kB/s rd, 152 op/s rd, 0 op/s wr

2017-06-07 02:15:48,689 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:15:48,689 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-07 02:16:48,739 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 02:16:48,739 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:16:49,077 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            41 pgs backfill_wait
            1 pgs backfilling
            42 pgs stuck unclean
            recovery 11027/128541 objects misplaced (8.579%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12342: 14 osds: 14 up, 14 in; 41 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55029: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39031 GB / 39637 GB avail
            11027/128541 objects misplaced (8.579%)
                2774 active+clean
                  41 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 02:16:49,078 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:16:49,078 INFO cluster.py [line:239] usefull PG number is 2774
2017-06-07 02:17:49,108 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 02:17:49,108 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:17:49,500 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            32 pgs backfill_wait
            1 pgs backfilling
            33 pgs stuck unclean
            recovery 8529/127249 objects misplaced (6.703%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12358: 14 osds: 14 up, 14 in; 33 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55102: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
            8529/127249 objects misplaced (6.703%)
                2783 active+clean
                  32 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 02:17:49,500 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:17:49,500 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-07 02:18:49,552 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 02:18:49,553 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:18:49,921 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs peering
            23 pgs stuck unclean
            recovery 6258/126103 objects misplaced (4.963%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12376: 14 osds: 14 up, 14 in; 23 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55177: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
            6258/126103 objects misplaced (4.963%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 peering
recovery io 390 MB/s, 97 objects/s

2017-06-07 02:18:49,921 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:18:49,921 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-07 02:19:49,946 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 02:19:49,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:19:50,345 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            13 pgs stuck unclean
            recovery 3682/124802 objects misplaced (2.950%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12396: 14 osds: 14 up, 14 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55256: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39031 GB / 39637 GB avail
            3682/124802 objects misplaced (2.950%)
                2802 active+clean
                  12 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
  client io 469 kB/s rd, 469 op/s rd, 0 op/s wr

2017-06-07 02:19:50,345 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:19:50,346 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 02:20:50,406 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 02:20:50,406 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:20:50,808 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            4 pgs backfill_wait
            1 pgs backfilling
            5 pgs stuck unclean
            recovery 1302/123605 objects misplaced (1.053%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12412: 14 osds: 14 up, 14 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55331: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39031 GB / 39637 GB avail
            1302/123605 objects misplaced (1.053%)
                2811 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 258 MB/s, 64 objects/s
  client io 244 kB/s rd, 244 op/s rd, 0 op/s wr

2017-06-07 02:20:50,808 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:20:50,809 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-07 02:21:50,838 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 02:21:50,838 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:21:51,223 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12422: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55395: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39032 GB / 39637 GB avail
                2816 active+clean
  client io 232 kB/s rd, 232 op/s rd, 0 op/s wr

2017-06-07 02:21:51,223 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:21:51,223 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:21:51,224 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:21:51,224 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 02:22:13,350 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:22:13,350 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:22:13,350 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:22:13,727 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12424: 15 osds: 14 up, 15 in; 699 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55418: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            605 GB used, 39032 GB / 39637 GB avail
                2816 active+clean

2017-06-07 02:22:13,727 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:22:13,728 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:22:13,728 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:22:13,728 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 02:22:35,768 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:22:35,769 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:22:35,769 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:22:36,139 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            120 pgs backfill_wait
            2 pgs backfilling
            1 pgs degraded
            1 pgs recovery_wait
            46 pgs stuck unclean
            recovery 4/138734 objects degraded (0.003%)
            recovery 31297/138734 objects misplaced (22.559%)
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12444: 16 osds: 15 up, 16 in; 746 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55449: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            4/138734 objects degraded (0.003%)
            31297/138734 objects misplaced (22.559%)
                2693 active+clean
                 120 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+recovery_wait+degraded
recovery io 1394 MB/s, 348 objects/s

2017-06-07 02:22:36,140 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:22:36,140 INFO cluster.py [line:239] usefull PG number is 2693
2017-06-07 02:23:36,200 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 02:23:36,200 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:23:36,592 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            172 pgs backfill_wait
            3 pgs backfilling
            104 pgs stuck unclean
            recovery 46638/146431 objects misplaced (31.850%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12472: 16 osds: 16 up, 16 in; 174 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55524: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
            46638/146431 objects misplaced (31.850%)
                2641 active+clean
                 172 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 534 MB/s, 133 objects/s

2017-06-07 02:23:36,592 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:23:36,592 INFO cluster.py [line:239] usefull PG number is 2641
2017-06-07 02:24:36,653 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 02:24:36,653 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:24:37,043 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            156 pgs backfill_wait
            3 pgs backfilling
            100 pgs stuck unclean
            recovery 42437/144323 objects misplaced (29.404%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12505: 16 osds: 16 up, 16 in; 157 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55603: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
            42437/144323 objects misplaced (29.404%)
                2657 active+clean
                 156 active+remapped+backfill_wait
                   3 active+remapped+backfilling

2017-06-07 02:24:37,043 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:24:37,044 INFO cluster.py [line:239] usefull PG number is 2657
2017-06-07 02:25:37,104 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-07 02:25:37,104 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:25:37,513 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            139 pgs backfill_wait
            2 pgs backfilling
            119 pgs stuck unclean
            recovery 38072/142095 objects misplaced (26.793%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12537: 16 osds: 16 up, 16 in; 140 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55684: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
            38072/142095 objects misplaced (26.793%)
                2675 active+clean
                 139 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 02:25:37,514 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:25:37,514 INFO cluster.py [line:239] usefull PG number is 2675
2017-06-07 02:26:37,547 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-07 02:26:37,547 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:26:37,944 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            118 pgs backfill_wait
            2 pgs backfilling
            112 pgs stuck unclean
            recovery 32188/139129 objects misplaced (23.135%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12571: 16 osds: 16 up, 16 in; 119 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55770: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44677 GB / 45300 GB avail
            32188/139129 objects misplaced (23.135%)
                2696 active+clean
                 118 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 02:26:37,945 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:26:37,945 INFO cluster.py [line:239] usefull PG number is 2696
2017-06-07 02:27:38,005 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-07 02:27:38,006 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:27:38,380 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            98 pgs backfill_wait
            2 pgs backfilling
            100 pgs stuck unclean
            recovery 26756/136396 objects misplaced (19.616%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12603: 16 osds: 16 up, 16 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55853: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44675 GB / 45300 GB avail
            26756/136396 objects misplaced (19.616%)
                2716 active+clean
                  98 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 960 MB/s, 240 objects/s

2017-06-07 02:27:38,380 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:27:38,381 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-07 02:28:38,429 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-07 02:28:38,430 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:28:38,817 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            79 pgs backfill_wait
            2 pgs backfilling
            81 pgs stuck unclean
            recovery 20529/133394 objects misplaced (15.390%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12637: 16 osds: 16 up, 16 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v55942: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44676 GB / 45300 GB avail
            20529/133394 objects misplaced (15.390%)
                2735 active+clean
                  79 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 02:28:38,817 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:28:38,817 INFO cluster.py [line:239] usefull PG number is 2735
2017-06-07 02:29:38,828 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 02:29:38,828 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:29:39,209 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            63 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            65 pgs stuck unclean
            recovery 16904/131455 objects misplaced (12.859%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12658: 16 osds: 16 up, 16 in; 65 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56017: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44675 GB / 45300 GB avail
            16904/131455 objects misplaced (12.859%)
                2750 active+clean
                  63 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 162 MB/s, 40 objects/s
  client io 306 kB/s rd, 459 op/s rd, 0 op/s wr

2017-06-07 02:29:39,210 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:29:39,210 INFO cluster.py [line:239] usefull PG number is 2750
2017-06-07 02:30:39,235 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 02:30:39,235 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:30:39,606 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            42 pgs backfill_wait
            2 pgs backfilling
            44 pgs stuck unclean
            recovery 11714/128841 objects misplaced (9.092%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12687: 16 osds: 16 up, 16 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56101: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44677 GB / 45300 GB avail
            11714/128841 objects misplaced (9.092%)
                2772 active+clean
                  42 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 02:30:39,606 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:30:39,606 INFO cluster.py [line:239] usefull PG number is 2772
2017-06-07 02:31:39,642 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 02:31:39,642 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:31:40,020 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 5911/125928 objects misplaced (4.694%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12719: 16 osds: 16 up, 16 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56183: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44677 GB / 45300 GB avail
            5911/125928 objects misplaced (4.694%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 02:31:40,021 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:31:40,021 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-07 02:32:40,050 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-07 02:32:40,050 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:32:40,425 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            16 pgs backfill_wait
            1 pgs backfilling
            17 pgs stuck unclean
            recovery 4100/125027 objects misplaced (3.279%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12734: 16 osds: 16 up, 16 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56257: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44677 GB / 45300 GB avail
            4100/125027 objects misplaced (3.279%)
                2799 active+clean
                  16 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 439 kB/s rd, 439 op/s rd, 0 op/s wr

2017-06-07 02:32:40,425 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:32:40,426 INFO cluster.py [line:239] usefull PG number is 2799
2017-06-07 02:33:40,460 INFO cluster.py [line:247] cost 60 seconds, left 5335 seconds when check the ceph status
2017-06-07 02:33:40,460 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:33:40,843 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 1840/123875 objects misplaced (1.485%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12752: 16 osds: 16 up, 16 in; 7 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56331: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
            1840/123875 objects misplaced (1.485%)
                2809 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 197 kB/s rd, 197 op/s rd, 0 op/s wr

2017-06-07 02:33:40,844 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:33:40,844 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-07 02:34:40,867 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 02:34:40,867 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:34:41,251 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12766: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56401: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44677 GB / 45300 GB avail
                2816 active+clean
  client io 202 kB/s rd, 202 op/s rd, 0 op/s wr

2017-06-07 02:34:41,252 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:34:41,252 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:34:41,252 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:34:41,252 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 02:35:02,428 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:35:02,428 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:35:02,428 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:35:02,816 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12768: 17 osds: 16 up, 17 in; 641 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56422: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            622 GB used, 44677 GB / 45300 GB avail
                2816 active+clean

2017-06-07 02:35:02,817 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:35:02,817 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:35:02,817 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:35:02,817 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 02:35:24,220 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:35:24,220 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:35:24,220 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:35:24,617 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            6 pgs backfilling
            1 pgs degraded
            1 pgs peering
            1 pgs recovery_wait
            81 pgs stuck unclean
            recovery 4/137838 objects degraded (0.003%)
            recovery 29295/137838 objects misplaced (21.253%)
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12790: 18 osds: 17 up, 18 in; 658 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56455: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            4/137838 objects degraded (0.003%)
            29295/137838 objects misplaced (21.253%)
                2701 active+clean
                 107 active+remapped+backfill_wait
                   6 active+remapped+backfilling
                   1 peering
                   1 active+recovery_wait+degraded
recovery io 669 MB/s, 167 objects/s

2017-06-07 02:35:24,617 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:35:24,617 INFO cluster.py [line:239] usefull PG number is 2701
2017-06-07 02:36:24,677 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 02:36:24,678 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:36:25,060 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            155 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            112 pgs stuck unclean
            recovery 42999/144552 objects misplaced (29.746%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12838: 18 osds: 18 up, 18 in; 158 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56548: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
            42999/144552 objects misplaced (29.746%)
                2656 active+clean
                 155 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 143 MB/s, 35 objects/s

2017-06-07 02:36:25,060 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:36:25,061 INFO cluster.py [line:239] usefull PG number is 2656
2017-06-07 02:37:25,066 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 02:37:25,066 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:37:25,426 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            136 pgs backfill_wait
            2 pgs backfilling
            98 pgs stuck unclean
            recovery 37170/141602 objects misplaced (26.250%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12872: 18 osds: 18 up, 18 in; 138 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56633: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
            37170/141602 objects misplaced (26.250%)
                2678 active+clean
                 136 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 752 MB/s, 188 objects/s

2017-06-07 02:37:25,426 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:37:25,426 INFO cluster.py [line:239] usefull PG number is 2678
2017-06-07 02:38:25,485 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 02:38:25,485 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:38:25,839 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            117 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            89 pgs stuck unclean
            recovery 31459/138695 objects misplaced (22.682%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12905: 18 osds: 18 up, 18 in; 118 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56716: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
            31459/138695 objects misplaced (22.682%)
                2697 active+clean
                 117 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 412 MB/s, 103 objects/s

2017-06-07 02:38:25,839 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:38:25,839 INFO cluster.py [line:239] usefull PG number is 2697
2017-06-07 02:39:25,843 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 02:39:25,843 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:39:26,220 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            2 pgs backfilling
            81 pgs stuck unclean
            recovery 27661/136849 objects misplaced (20.213%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12928: 18 osds: 18 up, 18 in; 103 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56794: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50320 GB / 50962 GB avail
            27661/136849 objects misplaced (20.213%)
                2712 active+clean
                 102 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 02:39:26,221 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:39:26,221 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-07 02:40:26,270 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 02:40:26,270 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:40:26,639 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            91 pgs backfill_wait
            3 pgs backfilling
            94 pgs stuck unclean
            recovery 24954/135554 objects misplaced (18.409%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12947: 18 osds: 18 up, 18 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56868: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50319 GB / 50962 GB avail
            24954/135554 objects misplaced (18.409%)
                2722 active+clean
                  91 active+remapped+backfill_wait
                   3 active+remapped+backfilling

2017-06-07 02:40:26,640 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:40:26,640 INFO cluster.py [line:239] usefull PG number is 2722
2017-06-07 02:41:26,659 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 02:41:26,660 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:41:27,047 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            78 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            79 pgs stuck unclean
            recovery 21229/133553 objects misplaced (15.896%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12969: 18 osds: 18 up, 18 in; 79 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v56946: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
            21229/133553 objects misplaced (15.896%)
                2736 active+clean
                  78 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling

2017-06-07 02:41:27,047 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:41:27,047 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-07 02:42:27,063 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 02:42:27,063 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:42:27,440 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            59 pgs backfill_wait
            4 pgs backfilling
            63 pgs stuck unclean
            recovery 16809/131520 objects misplaced (12.781%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e12997: 18 osds: 18 up, 18 in; 61 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57028: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50319 GB / 50962 GB avail
            16809/131520 objects misplaced (12.781%)
                2753 active+clean
                  59 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 508 MB/s, 127 objects/s

2017-06-07 02:42:27,440 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:42:27,441 INFO cluster.py [line:239] usefull PG number is 2753
2017-06-07 02:43:27,466 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 02:43:27,466 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:43:27,802 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            42 pgs backfill_wait
            1 pgs backfilling
            43 pgs stuck unclean
            recovery 10980/128465 objects misplaced (8.547%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13029: 18 osds: 18 up, 18 in; 42 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57112: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
            10980/128465 objects misplaced (8.547%)
                2772 active+clean
                  42 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 activating

2017-06-07 02:43:27,802 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:43:27,803 INFO cluster.py [line:239] usefull PG number is 2772
2017-06-07 02:44:27,863 INFO cluster.py [line:247] cost 60 seconds, left 5457 seconds when check the ceph status
2017-06-07 02:44:27,863 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:44:28,240 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            29 pgs backfill_wait
            2 pgs peering
            29 pgs stuck unclean
            recovery 7392/126630 objects misplaced (5.837%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13051: 18 osds: 18 up, 18 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57189: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
            7392/126630 objects misplaced (5.837%)
                2785 active+clean
                  29 active+remapped+backfill_wait
                   2 peering

2017-06-07 02:44:28,240 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:44:28,240 INFO cluster.py [line:239] usefull PG number is 2785
2017-06-07 02:45:28,269 INFO cluster.py [line:247] cost 61 seconds, left 5396 seconds when check the ceph status
2017-06-07 02:45:28,269 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:45:28,644 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            19 pgs backfill_wait
            1 pgs backfilling
            20 pgs stuck unclean
            recovery 5002/125438 objects misplaced (3.988%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13069: 18 osds: 18 up, 18 in; 20 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57265: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
            5002/125438 objects misplaced (3.988%)
                2796 active+clean
                  19 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 02:45:28,644 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:45:28,644 INFO cluster.py [line:239] usefull PG number is 2796
2017-06-07 02:46:28,646 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-07 02:46:28,646 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:46:29,033 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            13 pgs backfill_wait
            14 pgs stuck unclean
            recovery 3425/124710 objects misplaced (2.746%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13083: 18 osds: 18 up, 18 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57333: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
            3425/124710 objects misplaced (2.746%)
                2802 active+clean
                  13 active+remapped+backfill_wait
                   1 active+remapped

2017-06-07 02:46:29,033 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:46:29,033 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 02:47:29,093 INFO cluster.py [line:247] cost 61 seconds, left 5275 seconds when check the ceph status
2017-06-07 02:47:29,094 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:47:29,480 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 1820/123869 objects misplaced (1.469%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13095: 18 osds: 18 up, 18 in; 7 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57403: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50320 GB / 50962 GB avail
            1820/123869 objects misplaced (1.469%)
                2809 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 02:47:29,480 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:47:29,481 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-07 02:48:29,540 INFO cluster.py [line:247] cost 60 seconds, left 5215 seconds when check the ceph status
2017-06-07 02:48:29,541 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:48:29,908 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13109: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57476: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
                2816 active+clean

2017-06-07 02:48:29,908 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:48:29,909 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:48:29,909 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:48:29,909 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 02:48:50,705 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:48:50,705 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:48:50,705 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:48:51,137 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13111: 19 osds: 18 up, 19 in; 524 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57496: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            640 GB used, 50322 GB / 50962 GB avail
                2816 active+clean
  client io 385 kB/s rd, 385 op/s rd, 0 op/s wr

2017-06-07 02:48:51,137 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:48:51,137 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:48:51,137 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:48:51,138 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 02:49:13,351 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 02:49:13,352 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 02:49:13,352 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:49:13,713 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            72 pgs backfill_wait
            3 pgs backfilling
            2 pgs peering
            60 pgs stuck unclean
            recovery 19820/133104 objects misplaced (14.891%)
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13131: 20 osds: 19 up, 20 in; 547 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57529: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            19820/133104 objects misplaced (14.891%)
                2738 active+clean
                  72 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   2 peering
                   1 active+remapped
recovery io 378 MB/s, 94 objects/s

2017-06-07 02:49:13,713 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:49:13,713 INFO cluster.py [line:239] usefull PG number is 2738
2017-06-07 02:50:13,751 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 02:50:13,751 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:50:14,105 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            112 pgs backfill_wait
            4 pgs backfilling
            91 pgs stuck unclean
            recovery 31525/138843 objects misplaced (22.706%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13176: 20 osds: 20 up, 20 in; 114 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57613: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            659 GB used, 55965 GB / 56625 GB avail
            31525/138843 objects misplaced (22.706%)
                2700 active+clean
                 112 active+remapped+backfill_wait
                   4 active+remapped+backfilling

2017-06-07 02:50:14,105 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:50:14,105 INFO cluster.py [line:239] usefull PG number is 2700
2017-06-07 02:51:14,165 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 02:51:14,166 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:51:14,563 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            88 pgs backfill_wait
            3 pgs backfilling
            78 pgs stuck unclean
            recovery 25255/135612 objects misplaced (18.623%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13214: 20 osds: 20 up, 20 in; 90 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57703: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            658 GB used, 55966 GB / 56625 GB avail
            25255/135612 objects misplaced (18.623%)
                2725 active+clean
                  88 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 296 MB/s, 74 objects/s

2017-06-07 02:51:14,563 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:51:14,564 INFO cluster.py [line:239] usefull PG number is 2725
2017-06-07 02:52:14,614 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 02:52:14,614 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:52:14,999 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            69 pgs backfill_wait
            2 pgs backfilling
            63 pgs stuck unclean
            recovery 20332/133199 objects misplaced (15.264%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13244: 20 osds: 20 up, 20 in; 71 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57788: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            658 GB used, 55967 GB / 56625 GB avail
            20332/133199 objects misplaced (15.264%)
                2744 active+clean
                  69 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 608 MB/s, 152 objects/s
  client io 171 kB/s rd, 257 op/s rd, 0 op/s wr

2017-06-07 02:52:14,999 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:52:14,999 INFO cluster.py [line:239] usefull PG number is 2744
2017-06-07 02:53:15,047 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 02:53:15,048 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:53:15,429 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            45 pgs backfill_wait
            2 pgs backfilling
            42 pgs stuck unclean
            recovery 12526/129307 objects misplaced (9.687%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13280: 20 osds: 20 up, 20 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57876: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            658 GB used, 55967 GB / 56625 GB avail
            12526/129307 objects misplaced (9.687%)
                2769 active+clean
                  45 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 585 MB/s, 146 objects/s
  client io 187 kB/s rd, 281 op/s rd, 0 op/s wr

2017-06-07 02:53:15,429 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:53:15,429 INFO cluster.py [line:239] usefull PG number is 2769
2017-06-07 02:54:15,472 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 02:54:15,472 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:54:15,866 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            24 pgs backfill_wait
            4 pgs backfilling
            28 pgs stuck unclean
            recovery 7109/126618 objects misplaced (5.615%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13312: 20 osds: 20 up, 20 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v57962: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            658 GB used, 55966 GB / 56625 GB avail
            7109/126618 objects misplaced (5.615%)
                2788 active+clean
                  24 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 778 MB/s, 194 objects/s
  client io 91543 B/s rd, 134 op/s rd, 0 op/s wr

2017-06-07 02:54:15,866 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:54:15,866 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-07 02:55:15,927 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 02:55:15,927 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:55:16,278 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 3277/124588 objects misplaced (2.630%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13336: 20 osds: 20 up, 20 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58036: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            658 GB used, 55967 GB / 56625 GB avail
            3277/124588 objects misplaced (2.630%)
                2803 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 204 MB/s, 51 objects/s
  client io 87465 B/s rd, 128 op/s rd, 0 op/s wr

2017-06-07 02:55:16,278 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:55:16,278 INFO cluster.py [line:239] usefull PG number is 2803
2017-06-07 02:56:16,339 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 02:56:16,339 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:56:16,704 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            3 pgs backfill_wait
            1 pgs backfilling
            4 pgs stuck unclean
            recovery 928/123418 objects misplaced (0.752%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13352: 20 osds: 20 up, 20 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58107: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            657 GB used, 55967 GB / 56625 GB avail
            928/123418 objects misplaced (0.752%)
                2812 active+clean
                   3 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 295 MB/s, 73 objects/s

2017-06-07 02:56:16,704 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:56:16,704 INFO cluster.py [line:239] usefull PG number is 2812
2017-06-07 02:57:16,717 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 02:57:16,717 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:57:17,131 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13360: 20 osds: 20 up, 20 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58174: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            657 GB used, 55967 GB / 56625 GB avail
                2816 active+clean
  client io 94665 B/s rd, 138 op/s rd, 0 op/s wr

2017-06-07 02:57:17,131 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:57:17,131 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:57:17,131 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 02:57:19,255 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 02:57:19,537 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 25 Jun05 ?        05:01:47 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   41935 41933  0 18:57 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   41937 41935  0 18:57 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-07 02:57:19,537 INFO client.py [line:174] IO is running
2017-06-07 02:57:19,722 INFO node.py [line:185] 0
2017-06-07 02:57:19,722 INFO node.py [line:192] nvme6n1
2017-06-07 02:57:19,722 INFO node.py [line:185] 0
2017-06-07 02:57:19,722 INFO node.py [line:192] nvme6n1
2017-06-07 02:57:19,723 INFO node.py [line:185] 0
2017-06-07 02:57:19,723 INFO node.py [line:192] nvme6n1
2017-06-07 02:57:19,723 INFO node.py [line:185] 1
2017-06-07 02:57:19,723 INFO node.py [line:192] nvme2n1
2017-06-07 02:57:19,723 INFO node.py [line:185] 1
2017-06-07 02:57:19,723 INFO node.py [line:192] nvme2n1
2017-06-07 02:57:19,723 INFO node.py [line:185] 1
2017-06-07 02:57:19,723 INFO node.py [line:192] nvme2n1
2017-06-07 02:57:19,724 INFO node.py [line:185] 2
2017-06-07 02:57:19,724 INFO node.py [line:192] nvme5n1
2017-06-07 02:57:19,724 INFO node.py [line:185] 2
2017-06-07 02:57:19,724 INFO node.py [line:192] nvme5n1
2017-06-07 02:57:19,724 INFO node.py [line:185] 2
2017-06-07 02:57:19,724 INFO node.py [line:192] nvme5n1
2017-06-07 02:57:19,724 INFO node.py [line:185] 3
2017-06-07 02:57:19,724 INFO node.py [line:192] nvme1n1
2017-06-07 02:57:19,724 INFO node.py [line:185] 3
2017-06-07 02:57:19,724 INFO node.py [line:192] nvme1n1
2017-06-07 02:57:19,725 INFO node.py [line:185] 3
2017-06-07 02:57:19,725 INFO node.py [line:192] nvme1n1
2017-06-07 02:57:19,725 INFO node.py [line:185] 4
2017-06-07 02:57:19,725 INFO node.py [line:192] nvme4n1
2017-06-07 02:57:19,725 INFO node.py [line:185] 4
2017-06-07 02:57:19,725 INFO node.py [line:192] nvme4n1
2017-06-07 02:57:19,725 INFO node.py [line:185] 4
2017-06-07 02:57:19,725 INFO node.py [line:192] nvme4n1
2017-06-07 02:57:19,725 INFO node.py [line:185] 5
2017-06-07 02:57:19,726 INFO node.py [line:192] nvme7n1
2017-06-07 02:57:19,726 INFO node.py [line:185] 5
2017-06-07 02:57:19,726 INFO node.py [line:192] nvme7n1
2017-06-07 02:57:19,726 INFO node.py [line:185] 5
2017-06-07 02:57:19,726 INFO node.py [line:192] nvme7n1
2017-06-07 02:57:19,726 INFO node.py [line:185] 6
2017-06-07 02:57:19,726 INFO node.py [line:192] nvme3n1
2017-06-07 02:57:19,726 INFO node.py [line:185] 6
2017-06-07 02:57:19,726 INFO node.py [line:192] nvme3n1
2017-06-07 02:57:19,727 INFO node.py [line:185] 6
2017-06-07 02:57:19,727 INFO node.py [line:192] nvme3n1
2017-06-07 02:57:19,727 INFO node.py [line:185] 
2017-06-07 02:57:19,727 INFO node.py [line:192] nvme3n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 02:57:19,727 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 02:57:19,728 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 02:57:19,728 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 02:57:19,728 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 02:59:23,098 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 02:59:23,473 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13457: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58367: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
                2816 active+clean

2017-06-07 02:59:23,474 INFO cluster.py [line:238] PG number is 2816
2017-06-07 02:59:23,474 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 02:59:23,474 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 02:59:23,474 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 03:01:44,298 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:01:44,660 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13559: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58568: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            640 GB used, 50322 GB / 50962 GB avail
                2816 active+clean

2017-06-07 03:01:44,660 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:01:44,660 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:01:44,660 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 03:01:44,661 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 03:04:31,063 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:04:31,423 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13695: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v58838: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            631 GB used, 47499 GB / 48131 GB avail
                2816 active+clean

2017-06-07 03:04:31,423 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:04:31,423 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:04:31,423 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 03:04:31,423 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 03:08:13,252 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:08:13,637 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e13857: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v59178: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
                2816 active+clean

2017-06-07 03:08:13,637 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:08:13,637 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:08:13,637 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 03:08:13,637 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 03:12:34,650 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:12:35,047 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14023: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v59548: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
                2816 active+clean

2017-06-07 03:12:35,047 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:12:35,047 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:12:35,047 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 03:12:35,047 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 03:18:53,409 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:18:53,783 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14219: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60053: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
                2816 active+clean
  client io 109 kB/s rd, 163 op/s rd, 0 op/s wr

2017-06-07 03:18:53,783 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:18:53,784 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:18:53,784 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 03:18:53,784 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 03:21:20,195 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:21:20,541 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14335: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60284: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            597 GB used, 36209 GB / 36806 GB avail
                2816 active+clean

2017-06-07 03:21:20,541 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:21:20,541 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:21:20,541 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 03:21:22,533 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 03:21:22,533 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 03:21:22,534 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 03:21:44,290 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:21:44,290 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:21:44,291 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:21:44,633 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14337: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60306: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            597 GB used, 36209 GB / 36806 GB avail
                2816 active+clean

2017-06-07 03:21:44,633 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:21:44,633 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:21:44,633 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:21:44,633 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 03:22:06,676 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:22:06,677 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:22:06,677 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:22:07,046 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136494 objects degraded (0.004%)
            recovery 26845/136494 objects misplaced (19.668%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14348: 15 osds: 14 up, 15 in; 740 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60336: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            607 GB used, 39030 GB / 39637 GB avail
            6/136494 objects degraded (0.004%)
            26845/136494 objects misplaced (19.668%)
                2716 active+clean
                  97 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling

2017-06-07 03:22:07,046 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:22:07,046 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-07 03:23:07,084 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 03:23:07,084 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:23:07,416 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            43 pgs stuck unclean
            recovery 3/146252 objects degraded (0.002%)
            recovery 46454/146252 objects misplaced (31.763%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14371: 15 osds: 15 up, 15 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60411: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            3/146252 objects degraded (0.002%)
            46454/146252 objects misplaced (31.763%)
                2650 active+clean
                 163 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 256 MB/s, 64 objects/s

2017-06-07 03:23:07,417 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:23:07,417 INFO cluster.py [line:239] usefull PG number is 2650
2017-06-07 03:24:07,466 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 03:24:07,466 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:24:07,836 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            153 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            50 pgs stuck unclean
            recovery 43049/144533 objects misplaced (29.785%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14390: 15 osds: 15 up, 15 in; 154 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60487: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            43049/144533 objects misplaced (29.785%)
                2661 active+clean
                 153 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 639 MB/s, 159 objects/s

2017-06-07 03:24:07,836 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:24:07,836 INFO cluster.py [line:239] usefull PG number is 2661
2017-06-07 03:25:07,867 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 03:25:07,867 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:25:08,217 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            140 pgs backfill_wait
            2 pgs backfilling
            82 pgs stuck unclean
            recovery 39185/142595 objects misplaced (27.480%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14416: 15 osds: 15 up, 15 in; 141 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60565: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            39185/142595 objects misplaced (27.480%)
                2674 active+clean
                 140 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 298 MB/s, 74 objects/s

2017-06-07 03:25:08,218 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:25:08,218 INFO cluster.py [line:239] usefull PG number is 2674
2017-06-07 03:26:08,278 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 03:26:08,278 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:26:08,634 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            132 pgs backfill_wait
            1 pgs backfilling
            89 pgs stuck unclean
            recovery 36840/141432 objects misplaced (26.048%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14432: 15 osds: 15 up, 15 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60639: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            36840/141432 objects misplaced (26.048%)
                2683 active+clean
                 132 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 03:26:08,635 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:26:08,635 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 03:27:08,695 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 03:27:08,695 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:27:09,071 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            119 pgs backfill_wait
            2 pgs backfilling
            121 pgs stuck unclean
            recovery 33404/139711 objects misplaced (23.909%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14454: 15 osds: 15 up, 15 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60718: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            33404/139711 objects misplaced (23.909%)
                2695 active+clean
                 119 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 03:27:09,071 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:27:09,072 INFO cluster.py [line:239] usefull PG number is 2695
2017-06-07 03:28:09,132 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 03:28:09,132 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:28:09,509 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            2 pgs backfilling
            104 pgs stuck unclean
            recovery 28383/137257 objects misplaced (20.679%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14483: 15 osds: 15 up, 15 in; 102 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60802: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            28383/137257 objects misplaced (20.679%)
                2712 active+clean
                 102 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 03:28:09,510 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:28:09,510 INFO cluster.py [line:239] usefull PG number is 2712
2017-06-07 03:29:09,559 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 03:29:09,560 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:29:09,939 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            82 pgs backfill_wait
            2 pgs backfilling
            84 pgs stuck unclean
            recovery 22828/134441 objects misplaced (16.980%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14516: 15 osds: 15 up, 15 in; 84 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60887: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41851 GB / 42468 GB avail
            22828/134441 objects misplaced (16.980%)
                2732 active+clean
                  82 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 03:29:09,940 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:29:09,940 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-07 03:30:09,974 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 03:30:09,974 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:30:10,354 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            61 pgs backfill_wait
            2 pgs backfilling
            63 pgs stuck unclean
            recovery 16745/131429 objects misplaced (12.741%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14551: 15 osds: 15 up, 15 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v60975: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            16745/131429 objects misplaced (12.741%)
                2753 active+clean
                  61 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 1128 MB/s, 282 objects/s
  client io 175 kB/s rd, 175 op/s rd, 0 op/s wr

2017-06-07 03:30:10,354 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:30:10,355 INFO cluster.py [line:239] usefull PG number is 2753
2017-06-07 03:31:10,381 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 03:31:10,381 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:31:10,738 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            47 pgs backfill_wait
            1 pgs backfilling
            48 pgs stuck unclean
            recovery 12983/129512 objects misplaced (10.025%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14580: 15 osds: 15 up, 15 in; 47 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61059: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41852 GB / 42468 GB avail
            12983/129512 objects misplaced (10.025%)
                2768 active+clean
                  47 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 439 kB/s rd, 439 op/s rd, 0 op/s wr

2017-06-07 03:31:10,738 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:31:10,738 INFO cluster.py [line:239] usefull PG number is 2768
2017-06-07 03:32:10,789 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 03:32:10,790 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:32:11,160 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            38 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            39 pgs stuck unclean
            recovery 10554/128250 objects misplaced (8.229%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14597: 15 osds: 15 up, 15 in; 39 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61132: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41853 GB / 42468 GB avail
            10554/128250 objects misplaced (8.229%)
                2776 active+clean
                  38 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
  client io 205 kB/s rd, 205 op/s rd, 0 op/s wr

2017-06-07 03:32:11,160 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:32:11,161 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-07 03:33:11,196 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 03:33:11,196 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:33:11,573 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            28 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            29 pgs stuck unclean
            recovery 7650/126795 objects misplaced (6.033%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14617: 15 osds: 15 up, 15 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61210: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
            7650/126795 objects misplaced (6.033%)
                2786 active+clean
                  28 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
  client io 244 kB/s rd, 244 op/s rd, 0 op/s wr

2017-06-07 03:33:11,573 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:33:11,573 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-07 03:34:11,627 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 03:34:11,627 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:34:12,009 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            20 pgs backfill_wait
            1 pgs backfilling
            21 pgs stuck unclean
            recovery 5230/125566 objects misplaced (4.165%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14633: 15 osds: 15 up, 15 in; 21 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61285: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            5230/125566 objects misplaced (4.165%)
                2795 active+clean
                  20 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 216 kB/s rd, 216 op/s rd, 0 op/s wr

2017-06-07 03:34:12,009 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:34:12,010 INFO cluster.py [line:239] usefull PG number is 2795
2017-06-07 03:35:12,069 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-07 03:35:12,070 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:35:12,425 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            14 pgs backfill_wait
            1 pgs backfilling
            15 pgs stuck unclean
            recovery 3681/124818 objects misplaced (2.949%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14647: 15 osds: 15 up, 15 in; 14 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61356: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            3681/124818 objects misplaced (2.949%)
                2801 active+clean
                  14 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 03:35:12,425 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:35:12,425 INFO cluster.py [line:239] usefull PG number is 2801
2017-06-07 03:36:12,471 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-07 03:36:12,471 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:36:12,837 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            6 pgs stuck unclean
            recovery 1412/123640 objects misplaced (1.142%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14663: 15 osds: 15 up, 15 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61430: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            1412/123640 objects misplaced (1.142%)
                2810 active+clean
                   6 active+remapped+backfill_wait
recovery io 158 MB/s, 39 objects/s
  client io 348 kB/s rd, 523 op/s rd, 0 op/s wr

2017-06-07 03:36:12,837 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:36:12,838 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 03:37:12,898 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-07 03:37:12,898 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:37:13,243 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14675: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61500: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
                2816 active+clean

2017-06-07 03:37:13,244 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:37:13,244 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:37:13,244 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:37:13,244 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 03:37:35,329 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:37:35,329 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:37:35,329 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:37:35,677 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14677: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61521: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            614 GB used, 41854 GB / 42468 GB avail
                2816 active+clean

2017-06-07 03:37:35,677 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:37:35,677 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:37:35,677 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:37:35,677 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 03:37:57,696 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:37:57,697 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:37:57,697 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:37:58,100 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            105 pgs backfill_wait
            3 pgs backfilling
            43 pgs stuck unclean
            recovery 28236/137247 objects misplaced (20.573%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14697: 17 osds: 16 up, 17 in; 504 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61555: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44675 GB / 45300 GB avail
            28236/137247 objects misplaced (20.573%)
                2708 active+clean
                 105 active+remapped+backfill_wait
                   3 active+remapped+backfilling

2017-06-07 03:37:58,100 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:37:58,100 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-07 03:38:58,149 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 03:38:58,150 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:38:58,530 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            162 pgs backfill_wait
            1 pgs backfilling
            115 pgs stuck unclean
            recovery 44700/145463 objects misplaced (30.729%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14739: 17 osds: 17 up, 17 in; 161 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61643: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
            44700/145463 objects misplaced (30.729%)
                2653 active+clean
                 162 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 03:38:58,530 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:38:58,530 INFO cluster.py [line:239] usefull PG number is 2653
2017-06-07 03:39:58,558 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 03:39:58,559 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:39:58,919 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            137 pgs backfill_wait
            3 pgs backfilling
            116 pgs stuck unclean
            recovery 38427/142285 objects misplaced (27.007%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14770: 17 osds: 17 up, 17 in; 140 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61724: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
            38427/142285 objects misplaced (27.007%)
                2676 active+clean
                 137 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 131 MB/s, 32 objects/s

2017-06-07 03:39:58,919 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:39:58,919 INFO cluster.py [line:239] usefull PG number is 2676
2017-06-07 03:40:58,977 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 03:40:58,977 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:40:59,351 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            123 pgs backfill_wait
            2 pgs backfilling
            111 pgs stuck unclean
            recovery 34390/140217 objects misplaced (24.526%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14798: 17 osds: 17 up, 17 in; 125 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61805: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            34390/140217 objects misplaced (24.526%)
                2691 active+clean
                 123 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 251 MB/s, 62 objects/s

2017-06-07 03:40:59,352 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:40:59,352 INFO cluster.py [line:239] usefull PG number is 2691
2017-06-07 03:41:59,412 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 03:41:59,413 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:41:59,787 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            105 pgs backfill_wait
            1 pgs backfilling
            104 pgs stuck unclean
            recovery 29581/137844 objects misplaced (21.460%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14831: 17 osds: 17 up, 17 in; 105 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61893: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            29581/137844 objects misplaced (21.460%)
                2709 active+clean
                 105 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped

2017-06-07 03:41:59,788 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:41:59,788 INFO cluster.py [line:239] usefull PG number is 2709
2017-06-07 03:42:59,840 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 03:42:59,841 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:43:00,221 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            78 pgs backfill_wait
            2 pgs backfilling
            82 pgs stuck unclean
            recovery 21948/134086 objects misplaced (16.369%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14872: 17 osds: 17 up, 17 in; 80 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v61985: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            21948/134086 objects misplaced (16.369%)
                2734 active+clean
                  78 active+remapped+backfill_wait
                   2 active+remapped
                   2 active+remapped+backfilling

2017-06-07 03:43:00,221 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:43:00,221 INFO cluster.py [line:239] usefull PG number is 2734
2017-06-07 03:44:00,282 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 03:44:00,282 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:44:00,640 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            55 pgs backfill_wait
            2 pgs backfilling
            57 pgs stuck unclean
            recovery 14411/130235 objects misplaced (11.065%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14909: 17 osds: 17 up, 17 in; 55 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62075: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            14411/130235 objects misplaced (11.065%)
                2759 active+clean
                  55 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 515 MB/s, 128 objects/s
  client io 613 kB/s rd, 696 op/s rd, 0 op/s wr

2017-06-07 03:44:00,641 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:44:00,641 INFO cluster.py [line:239] usefull PG number is 2759
2017-06-07 03:45:00,701 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 03:45:00,701 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:45:01,083 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            32 pgs backfill_wait
            3 pgs backfilling
            35 pgs stuck unclean
            recovery 8733/127389 objects misplaced (6.855%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14947: 17 osds: 17 up, 17 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62160: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            8733/127389 objects misplaced (6.855%)
                2781 active+clean
                  32 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 507 kB/s rd, 574 op/s rd, 0 op/s wr

2017-06-07 03:45:01,083 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:45:01,083 INFO cluster.py [line:239] usefull PG number is 2781
2017-06-07 03:46:01,100 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 03:46:01,101 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:46:01,474 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            21 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            22 pgs stuck unclean
            recovery 5689/125812 objects misplaced (4.522%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14966: 17 osds: 17 up, 17 in; 22 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62236: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
            5689/125812 objects misplaced (4.522%)
                2793 active+clean
                  21 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 237 MB/s, 59 objects/s
  client io 91326 B/s rd, 133 op/s rd, 0 op/s wr

2017-06-07 03:46:01,474 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:46:01,474 INFO cluster.py [line:239] usefull PG number is 2793
2017-06-07 03:47:01,508 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 03:47:01,508 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:47:01,870 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 3409/124656 objects misplaced (2.735%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e14984: 17 osds: 17 up, 17 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62310: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            3409/124656 objects misplaced (2.735%)
                2803 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 03:47:01,870 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:47:01,870 INFO cluster.py [line:239] usefull PG number is 2803
2017-06-07 03:48:01,906 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 03:48:01,907 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:48:02,252 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            3 pgs backfill_wait
            1 pgs backfilling
            4 pgs stuck unclean
            recovery 892/123416 objects misplaced (0.723%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15000: 17 osds: 17 up, 17 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62382: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
            892/123416 objects misplaced (0.723%)
                2812 active+clean
                   3 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 254 MB/s, 63 objects/s
  client io 244 kB/s rd, 366 op/s rd, 0 op/s wr

2017-06-07 03:48:02,252 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:48:02,252 INFO cluster.py [line:239] usefull PG number is 2812
2017-06-07 03:49:02,313 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 03:49:02,313 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:49:02,689 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15008: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62446: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
                2816 active+clean
  client io 205 kB/s rd, 307 op/s rd, 0 op/s wr

2017-06-07 03:49:02,690 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:49:02,690 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:49:02,690 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:49:02,690 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 03:49:24,364 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:49:24,364 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:49:24,365 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:49:24,740 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15010: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62465: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
                2816 active+clean
  client io 190 kB/s rd, 285 op/s rd, 0 op/s wr

2017-06-07 03:49:24,740 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:49:24,740 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:49:24,740 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:49:24,740 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 03:49:47,710 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 03:49:47,710 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 03:49:47,711 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:49:48,090 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            89 pgs backfill_wait
            5 pgs backfilling
            67 pgs stuck unclean
            recovery 26134/136231 objects misplaced (19.184%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15028: 19 osds: 18 up, 19 in; 602 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62499: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50319 GB / 50962 GB avail
            26134/136231 objects misplaced (19.184%)
                2721 active+clean
                  89 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 active+remapped
recovery io 645 MB/s, 161 objects/s

2017-06-07 03:49:48,091 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:49:48,091 INFO cluster.py [line:239] usefull PG number is 2721
2017-06-07 03:50:48,108 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 03:50:48,108 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:50:48,486 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            129 pgs backfill_wait
            3 pgs backfilling
            97 pgs stuck unclean
            recovery 35877/141002 objects misplaced (25.444%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15072: 19 osds: 19 up, 19 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62587: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            35877/141002 objects misplaced (25.444%)
                2684 active+clean
                 129 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 508 MB/s, 127 objects/s

2017-06-07 03:50:48,486 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:50:48,486 INFO cluster.py [line:239] usefull PG number is 2684
2017-06-07 03:51:48,546 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 03:51:48,547 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:51:48,913 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            2 pgs backfilling
            85 pgs stuck unclean
            recovery 29049/137600 objects misplaced (21.111%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15106: 19 osds: 19 up, 19 in; 107 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62671: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            29049/137600 objects misplaced (21.111%)
                2707 active+clean
                 107 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 03:51:48,914 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:51:48,914 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 03:52:48,946 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 03:52:48,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:52:49,320 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            91 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            73 pgs stuck unclean
            recovery 24968/135470 objects misplaced (18.431%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15130: 19 osds: 19 up, 19 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62745: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            24968/135470 objects misplaced (18.431%)
                2723 active+clean
                  91 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 peering
recovery io 515 MB/s, 128 objects/s

2017-06-07 03:52:49,321 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:52:49,321 INFO cluster.py [line:239] usefull PG number is 2723
2017-06-07 03:53:49,323 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 03:53:49,324 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:53:49,737 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            82 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            72 pgs stuck unclean
            recovery 22911/134442 objects misplaced (17.042%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15146: 19 osds: 19 up, 19 in; 83 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62820: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            22911/134442 objects misplaced (17.042%)
                2732 active+clean
                  82 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 522 MB/s, 130 objects/s

2017-06-07 03:53:49,737 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:53:49,737 INFO cluster.py [line:239] usefull PG number is 2732
2017-06-07 03:54:49,754 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 03:54:49,754 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:54:50,168 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            68 pgs backfill_wait
            2 pgs backfilling
            70 pgs stuck unclean
            recovery 19238/132674 objects misplaced (14.500%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15168: 19 osds: 19 up, 19 in; 69 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62896: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            19238/132674 objects misplaced (14.500%)
                2746 active+clean
                  68 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 932 MB/s, 234 objects/s
  client io 92613 B/s rd, 135 op/s rd, 0 op/s wr

2017-06-07 03:54:50,168 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:54:50,168 INFO cluster.py [line:239] usefull PG number is 2746
2017-06-07 03:55:50,219 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 03:55:50,219 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:55:50,589 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            48 pgs backfill_wait
            5 pgs backfilling
            53 pgs stuck unclean
            recovery 14162/130124 objects misplaced (10.883%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15198: 19 osds: 19 up, 19 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v62975: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            14162/130124 objects misplaced (10.883%)
                2763 active+clean
                  48 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 47835 kB/s, 11 objects/s
  client io 632 kB/s rd, 948 op/s rd, 0 op/s wr

2017-06-07 03:55:50,589 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:55:50,589 INFO cluster.py [line:239] usefull PG number is 2763
2017-06-07 03:56:50,648 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 03:56:50,648 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:56:51,005 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            25 pgs backfill_wait
            3 pgs backfilling
            28 pgs stuck unclean
            recovery 6931/126488 objects misplaced (5.480%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15236: 19 osds: 19 up, 19 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63064: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            6931/126488 objects misplaced (5.480%)
                2788 active+clean
                  25 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 501 MB/s, 125 objects/s
  client io 648 kB/s rd, 741 op/s rd, 0 op/s wr

2017-06-07 03:56:51,005 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:56:51,005 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-07 03:57:51,063 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 03:57:51,063 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:57:51,459 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            2 pgs backfilling
            14 pgs stuck unclean
            recovery 3590/124800 objects misplaced (2.877%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15261: 19 osds: 19 up, 19 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63144: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            3590/124800 objects misplaced (2.877%)
                2802 active+clean
                  12 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 170 MB/s, 42 objects/s
  client io 346 kB/s rd, 520 op/s rd, 0 op/s wr

2017-06-07 03:57:51,459 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:57:51,459 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 03:58:51,519 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 03:58:51,519 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:58:51,901 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            4 pgs backfill_wait
            4 pgs stuck unclean
            recovery 1118/123493 objects misplaced (0.905%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15279: 19 osds: 19 up, 19 in; 4 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63218: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
            1118/123493 objects misplaced (0.905%)
                2812 active+clean
                   4 active+remapped+backfill_wait
recovery io 312 MB/s, 78 objects/s

2017-06-07 03:58:51,901 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:58:51,901 INFO cluster.py [line:239] usefull PG number is 2812
2017-06-07 03:59:51,954 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 03:59:51,955 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 03:59:52,296 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15287: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63280: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
                2816 active+clean

2017-06-07 03:59:52,297 INFO cluster.py [line:238] PG number is 2816
2017-06-07 03:59:52,297 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 03:59:52,297 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 03:59:52,297 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 04:00:13,680 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:00:13,680 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:00:13,680 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:00:14,089 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15289: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63298: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
                2816 active+clean

2017-06-07 04:00:14,090 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:00:14,090 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:00:14,090 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:00:16,262 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 04:00:16,514 INFO client.py [line:172] ['enali   16807 16806  0 20:00 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   16809 16807  0 20:00 ?        00:00:00 grep fio', 'root     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 24 Jun05 ?        05:01:56 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'stdin: is not a tty', '']
2017-06-07 04:00:16,514 INFO client.py [line:174] IO is running
2017-06-07 04:00:16,699 INFO node.py [line:185] 0
2017-06-07 04:00:16,700 INFO node.py [line:192] nvme6n1
2017-06-07 04:00:16,700 INFO node.py [line:185] 0
2017-06-07 04:00:16,700 INFO node.py [line:192] nvme6n1
2017-06-07 04:00:16,700 INFO node.py [line:185] 0
2017-06-07 04:00:16,700 INFO node.py [line:192] nvme6n1
2017-06-07 04:00:16,700 INFO node.py [line:185] 1
2017-06-07 04:00:16,700 INFO node.py [line:192] nvme2n1
2017-06-07 04:00:16,701 INFO node.py [line:185] 1
2017-06-07 04:00:16,701 INFO node.py [line:192] nvme2n1
2017-06-07 04:00:16,701 INFO node.py [line:185] 1
2017-06-07 04:00:16,701 INFO node.py [line:192] nvme2n1
2017-06-07 04:00:16,701 INFO node.py [line:185] 2
2017-06-07 04:00:16,701 INFO node.py [line:192] nvme5n1
2017-06-07 04:00:16,701 INFO node.py [line:185] 2
2017-06-07 04:00:16,701 INFO node.py [line:192] nvme5n1
2017-06-07 04:00:16,701 INFO node.py [line:185] 2
2017-06-07 04:00:16,702 INFO node.py [line:192] nvme5n1
2017-06-07 04:00:16,702 INFO node.py [line:185] 3
2017-06-07 04:00:16,702 INFO node.py [line:192] nvme1n1
2017-06-07 04:00:16,702 INFO node.py [line:185] 3
2017-06-07 04:00:16,702 INFO node.py [line:192] nvme1n1
2017-06-07 04:00:16,702 INFO node.py [line:185] 3
2017-06-07 04:00:16,702 INFO node.py [line:192] nvme1n1
2017-06-07 04:00:16,702 INFO node.py [line:185] 4
2017-06-07 04:00:16,702 INFO node.py [line:192] nvme4n1
2017-06-07 04:00:16,703 INFO node.py [line:185] 4
2017-06-07 04:00:16,703 INFO node.py [line:192] nvme4n1
2017-06-07 04:00:16,703 INFO node.py [line:185] 4
2017-06-07 04:00:16,703 INFO node.py [line:192] nvme4n1
2017-06-07 04:00:16,703 INFO node.py [line:185] 5
2017-06-07 04:00:16,703 INFO node.py [line:192] nvme7n1
2017-06-07 04:00:16,703 INFO node.py [line:185] 5
2017-06-07 04:00:16,703 INFO node.py [line:192] nvme7n1
2017-06-07 04:00:16,704 INFO node.py [line:185] 5
2017-06-07 04:00:16,704 INFO node.py [line:192] nvme7n1
2017-06-07 04:00:16,704 INFO node.py [line:185] 6
2017-06-07 04:00:16,704 INFO node.py [line:192] nvme3n1
2017-06-07 04:00:16,704 INFO node.py [line:185] 6
2017-06-07 04:00:16,704 INFO node.py [line:192] nvme3n1
2017-06-07 04:00:16,704 INFO node.py [line:185] 6
2017-06-07 04:00:16,704 INFO node.py [line:192] nvme3n1
2017-06-07 04:00:16,704 INFO node.py [line:185] 
2017-06-07 04:00:16,705 INFO node.py [line:192] nvme3n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 04:00:16,705 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 04:00:16,705 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 04:00:16,705 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 04:07:51,546 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:07:51,952 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15460: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v63885: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            649 GB used, 53144 GB / 53794 GB avail
                2816 active+clean

2017-06-07 04:07:51,952 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:07:51,952 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:07:51,952 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 04:07:51,952 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 04:10:10,688 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:10:11,056 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15562: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v64088: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50321 GB / 50962 GB avail
                2816 active+clean
  client io 880 kB/s rd, 1119 op/s rd, 0 op/s wr

2017-06-07 04:10:11,056 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:10:11,056 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:10:11,056 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 04:10:11,056 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 04:12:56,258 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:12:56,651 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15692: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v64334: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47499 GB / 48131 GB avail
                2816 active+clean

2017-06-07 04:12:56,651 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:12:56,651 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:12:56,651 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 04:12:56,651 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 04:16:56,978 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:16:57,347 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e15858: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v64692: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            623 GB used, 44676 GB / 45300 GB avail
                2816 active+clean

2017-06-07 04:16:57,347 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:16:57,347 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:16:57,348 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 04:16:57,348 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 04:21:42,020 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:21:42,404 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16012: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65075: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
                2816 active+clean

2017-06-07 04:21:42,404 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:21:42,404 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:21:42,404 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 04:21:42,404 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 04:27:41,866 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:27:42,222 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16191: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65544: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            606 GB used, 39031 GB / 39637 GB avail
                2816 active+clean

2017-06-07 04:27:42,222 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:27:42,222 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:27:42,222 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 04:27:42,223 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 04:30:32,225 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:30:32,628 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16313: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65780: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            598 GB used, 36208 GB / 36806 GB avail
                2816 active+clean

2017-06-07 04:30:32,628 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:30:32,628 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:30:32,628 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 04:30:34,863 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 04:30:34,863 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 04:30:34,864 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 04:30:57,506 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:30:57,506 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:30:57,507 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:30:57,920 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16315: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65804: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            598 GB used, 36208 GB / 36806 GB avail
                2816 active+clean

2017-06-07 04:30:57,921 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:30:57,921 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:30:57,921 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:30:57,921 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 04:31:20,176 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:31:20,176 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:31:20,177 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:31:20,542 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136266 objects degraded (0.004%)
            recovery 26497/136266 objects misplaced (19.445%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16328: 15 osds: 14 up, 15 in; 739 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65832: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            608 GB used, 39029 GB / 39637 GB avail
            6/136266 objects degraded (0.004%)
            26497/136266 objects misplaced (19.445%)
                2717 active+clean
                  96 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 911 MB/s, 227 objects/s

2017-06-07 04:31:20,542 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:31:20,543 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-07 04:32:20,573 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 04:32:20,573 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:32:20,941 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            160 pgs backfill_wait
            1 pgs backfilling
            1 pgs degraded
            1 pgs recovery_wait
            35 pgs stuck unclean
            recovery 2/145812 objects degraded (0.001%)
            recovery 45459/145812 objects misplaced (31.176%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16355: 15 osds: 15 up, 15 in; 161 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65912: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            2/145812 objects degraded (0.001%)
            45459/145812 objects misplaced (31.176%)
                2653 active+clean
                 160 active+remapped+backfill_wait
                   1 active+recovery_wait+degraded
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 127 MB/s, 31 objects/s

2017-06-07 04:32:20,941 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:32:20,942 INFO cluster.py [line:239] usefull PG number is 2653
2017-06-07 04:33:21,002 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 04:33:21,002 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:33:21,369 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            152 pgs backfill_wait
            1 pgs peering
            55 pgs stuck unclean
            recovery 42284/144216 objects misplaced (29.320%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16373: 15 osds: 15 up, 15 in; 152 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v65982: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            42284/144216 objects misplaced (29.320%)
                2662 active+clean
                 152 active+remapped+backfill_wait
                   1 active+remapped
                   1 peering
recovery io 523 MB/s, 130 objects/s

2017-06-07 04:33:21,369 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:33:21,370 INFO cluster.py [line:239] usefull PG number is 2662
2017-06-07 04:34:21,430 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 04:34:21,430 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:34:21,823 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            141 pgs backfill_wait
            1 pgs backfilling
            79 pgs stuck unclean
            recovery 39740/142873 objects misplaced (27.815%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16391: 15 osds: 15 up, 15 in; 142 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66057: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            39740/142873 objects misplaced (27.815%)
                2674 active+clean
                 141 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 182 MB/s, 45 objects/s

2017-06-07 04:34:21,823 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:34:21,823 INFO cluster.py [line:239] usefull PG number is 2674
2017-06-07 04:35:21,863 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 04:35:21,863 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:35:22,219 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            132 pgs backfill_wait
            1 pgs backfilling
            91 pgs stuck unclean
            recovery 37125/141583 objects misplaced (26.221%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16409: 15 osds: 15 up, 15 in; 133 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66130: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            37125/141583 objects misplaced (26.221%)
                2683 active+clean
                 132 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 281 MB/s, 70 objects/s

2017-06-07 04:35:22,219 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:35:22,219 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 04:36:22,262 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 04:36:22,263 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:36:22,646 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            121 pgs backfill_wait
            122 pgs stuck unclean
            recovery 33623/139853 objects misplaced (24.042%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16433: 15 osds: 15 up, 15 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66210: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            33623/139853 objects misplaced (24.042%)
                2694 active+clean
                 121 active+remapped+backfill_wait
                   1 active+remapped

2017-06-07 04:36:22,646 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:36:22,646 INFO cluster.py [line:239] usefull PG number is 2694
2017-06-07 04:37:22,657 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 04:37:22,657 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:37:23,040 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            104 pgs stuck unclean
            recovery 28326/137206 objects misplaced (20.645%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16464: 15 osds: 15 up, 15 in; 103 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66287: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            617 GB used, 41851 GB / 42468 GB avail
            28326/137206 objects misplaced (20.645%)
                2711 active+clean
                 102 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
                   1 peering
recovery io 1857 MB/s, 464 objects/s

2017-06-07 04:37:23,040 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:37:23,040 INFO cluster.py [line:239] usefull PG number is 2711
2017-06-07 04:38:23,083 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 04:38:23,084 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:38:23,479 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            84 pgs backfill_wait
            2 pgs backfilling
            86 pgs stuck unclean
            recovery 23068/134569 objects misplaced (17.142%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16491: 15 osds: 15 up, 15 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66366: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            23068/134569 objects misplaced (17.142%)
                2730 active+clean
                  84 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 524 MB/s, 131 objects/s

2017-06-07 04:38:23,479 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:38:23,479 INFO cluster.py [line:239] usefull PG number is 2730
2017-06-07 04:39:23,520 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 04:39:23,520 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:39:23,892 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            64 pgs backfill_wait
            2 pgs backfilling
            66 pgs stuck unclean
            recovery 16966/131512 objects misplaced (12.901%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16526: 15 osds: 15 up, 15 in; 64 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66452: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            16966/131512 objects misplaced (12.901%)
                2750 active+clean
                  64 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 110 MB/s, 27 objects/s
  client io 476 kB/s rd, 714 op/s rd, 0 op/s wr

2017-06-07 04:39:23,892 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:39:23,892 INFO cluster.py [line:239] usefull PG number is 2750
2017-06-07 04:40:23,904 INFO cluster.py [line:247] cost 60 seconds, left 5457 seconds when check the ceph status
2017-06-07 04:40:23,905 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:40:24,281 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            51 pgs backfill_wait
            1 pgs backfilling
            52 pgs stuck unclean
            recovery 13353/129652 objects misplaced (10.299%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16548: 15 osds: 15 up, 15 in; 52 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66530: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            13353/129652 objects misplaced (10.299%)
                2764 active+clean
                  51 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 81285 kB/s, 19 objects/s
  client io 349 kB/s rd, 523 op/s rd, 0 op/s wr

2017-06-07 04:40:24,281 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:40:24,282 INFO cluster.py [line:239] usefull PG number is 2764
2017-06-07 04:41:24,339 INFO cluster.py [line:247] cost 61 seconds, left 5396 seconds when check the ceph status
2017-06-07 04:41:24,339 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:41:24,724 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            44 pgs stuck unclean
            recovery 11336/128647 objects misplaced (8.812%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16564: 15 osds: 15 up, 15 in; 44 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66599: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            11336/128647 objects misplaced (8.812%)
                2771 active+clean
                  43 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
recovery io 141 MB/s, 35 objects/s
  client io 325 kB/s rd, 487 op/s rd, 0 op/s wr

2017-06-07 04:41:24,725 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:41:24,725 INFO cluster.py [line:239] usefull PG number is 2771
2017-06-07 04:42:24,785 INFO cluster.py [line:247] cost 60 seconds, left 5336 seconds when check the ceph status
2017-06-07 04:42:24,785 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:42:25,144 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            35 pgs backfill_wait
            1 pgs backfilling
            36 pgs stuck unclean
            recovery 9606/127814 objects misplaced (7.516%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16580: 15 osds: 15 up, 15 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66670: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            9606/127814 objects misplaced (7.516%)
                2780 active+clean
                  35 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 04:42:25,144 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:42:25,144 INFO cluster.py [line:239] usefull PG number is 2780
2017-06-07 04:43:25,198 INFO cluster.py [line:247] cost 61 seconds, left 5275 seconds when check the ceph status
2017-06-07 04:43:25,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:43:25,532 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            27 pgs stuck unclean
            recovery 7292/126663 objects misplaced (5.757%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16598: 15 osds: 15 up, 15 in; 26 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66743: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            7292/126663 objects misplaced (5.757%)
                2789 active+clean
                  26 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 100563 B/s rd, 147 op/s rd, 0 op/s wr

2017-06-07 04:43:25,532 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:43:25,532 INFO cluster.py [line:239] usefull PG number is 2789
2017-06-07 04:44:25,584 INFO cluster.py [line:247] cost 60 seconds, left 5215 seconds when check the ceph status
2017-06-07 04:44:25,584 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:44:25,995 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs peering
            17 pgs stuck unclean
            recovery 4561/125242 objects misplaced (3.642%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16616: 15 osds: 15 up, 15 in; 17 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66819: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            4561/125242 objects misplaced (3.642%)
                2798 active+clean
                  17 active+remapped+backfill_wait
                   1 peering
recovery io 461 MB/s, 115 objects/s
  client io 451 kB/s rd, 451 op/s rd, 0 op/s wr

2017-06-07 04:44:25,996 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:44:25,996 INFO cluster.py [line:239] usefull PG number is 2798
2017-06-07 04:45:26,013 INFO cluster.py [line:247] cost 61 seconds, left 5154 seconds when check the ceph status
2017-06-07 04:45:26,014 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:45:26,452 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 2950/124463 objects misplaced (2.370%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16630: 15 osds: 15 up, 15 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66890: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
            2950/124463 objects misplaced (2.370%)
                2806 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 236 kB/s rd, 236 op/s rd, 0 op/s wr

2017-06-07 04:45:26,452 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:45:26,452 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-07 04:46:26,502 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-07 04:46:26,502 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:46:26,917 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16649: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66966: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
                2816 active+clean

2017-06-07 04:46:26,917 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:46:26,917 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:46:26,918 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:46:26,918 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 04:46:48,087 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:46:48,088 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:46:48,088 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:46:48,484 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16651: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v66987: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
                2816 active+clean
  client io 284 kB/s rd, 426 op/s rd, 0 op/s wr

2017-06-07 04:46:48,484 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:46:48,485 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:46:48,485 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:46:48,485 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 04:47:10,473 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:47:10,473 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:47:10,473 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:47:10,878 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            1 pgs backfilling
            46 pgs stuck unclean
            recovery 28608/137418 objects misplaced (20.818%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16670: 17 osds: 16 up, 17 in; 704 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67015: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            626 GB used, 44673 GB / 45300 GB avail
            28608/137418 objects misplaced (20.818%)
                2707 active+clean
                 107 active+remapped+backfill_wait
                   1 active+remapped+backfilling
                   1 active+remapped
recovery io 56305 kB/s, 13 objects/s

2017-06-07 04:47:10,878 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:47:10,878 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 04:48:10,932 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 04:48:10,932 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:48:11,276 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            167 pgs backfill_wait
            3 pgs backfilling
            113 pgs stuck unclean
            recovery 46678/146515 objects misplaced (31.859%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16710: 17 osds: 17 up, 17 in; 168 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67098: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47495 GB / 48131 GB avail
            46678/146515 objects misplaced (31.859%)
                2646 active+clean
                 167 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 550 MB/s, 137 objects/s

2017-06-07 04:48:11,277 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:48:11,277 INFO cluster.py [line:239] usefull PG number is 2646
2017-06-07 04:49:11,322 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 04:49:11,322 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:49:11,731 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            143 pgs backfill_wait
            2 pgs backfilling
            104 pgs stuck unclean
            recovery 40082/143110 objects misplaced (28.008%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16744: 17 osds: 17 up, 17 in; 144 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67180: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47495 GB / 48131 GB avail
            40082/143110 objects misplaced (28.008%)
                2671 active+clean
                 143 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 148 MB/s, 37 objects/s

2017-06-07 04:49:11,731 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:49:11,731 INFO cluster.py [line:239] usefull PG number is 2671
2017-06-07 04:50:11,777 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 04:50:11,777 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:50:12,189 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            133 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            99 pgs stuck unclean
            recovery 37194/141657 objects misplaced (26.256%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16763: 17 osds: 17 up, 17 in; 134 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67247: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47496 GB / 48131 GB avail
            37194/141657 objects misplaced (26.256%)
                2680 active+clean
                 133 active+remapped+backfill_wait
                   1 peering
                   1 activating
                   1 active+remapped+backfilling
recovery io 484 MB/s, 121 objects/s

2017-06-07 04:50:12,189 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:50:12,189 INFO cluster.py [line:239] usefull PG number is 2680
2017-06-07 04:51:12,198 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 04:51:12,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:51:12,605 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            120 pgs backfill_wait
            2 pgs backfilling
            100 pgs stuck unclean
            recovery 33450/139810 objects misplaced (23.925%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16785: 17 osds: 17 up, 17 in; 122 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67322: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
            33450/139810 objects misplaced (23.925%)
                2694 active+clean
                 120 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 519 MB/s, 129 objects/s
  client io 236 kB/s rd, 236 op/s rd, 0 op/s wr

2017-06-07 04:51:12,605 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:51:12,606 INFO cluster.py [line:239] usefull PG number is 2694
2017-06-07 04:52:12,658 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 04:52:12,658 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:52:13,060 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            2 pgs backfilling
            99 pgs stuck unclean
            recovery 27260/136636 objects misplaced (19.951%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16819: 17 osds: 17 up, 17 in; 99 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67409: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            27260/136636 objects misplaced (19.951%)
                2717 active+clean
                  97 active+remapped+backfill_wait
                   2 active+remapped+backfilling
  client io 221 kB/s rd, 221 op/s rd, 0 op/s wr

2017-06-07 04:52:13,061 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:52:13,061 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-07 04:53:13,121 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 04:53:13,121 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:53:13,481 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            76 pgs backfill_wait
            2 pgs backfilling
            78 pgs stuck unclean
            recovery 20739/133399 objects misplaced (15.547%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16856: 17 osds: 17 up, 17 in; 78 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67498: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            20739/133399 objects misplaced (15.547%)
                2738 active+clean
                  76 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 623 MB/s, 155 objects/s
  client io 303 kB/s rd, 454 op/s rd, 0 op/s wr

2017-06-07 04:53:13,481 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:53:13,481 INFO cluster.py [line:239] usefull PG number is 2738
2017-06-07 04:54:13,537 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 04:54:13,537 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:54:13,914 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            49 pgs backfill_wait
            2 pgs backfilling
            51 pgs stuck unclean
            recovery 13014/129545 objects misplaced (10.046%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16900: 17 osds: 17 up, 17 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67584: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            13014/129545 objects misplaced (10.046%)
                2765 active+clean
                  49 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 664 MB/s, 166 objects/s
  client io 594 kB/s rd, 891 op/s rd, 0 op/s wr

2017-06-07 04:54:13,914 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:54:13,914 INFO cluster.py [line:239] usefull PG number is 2765
2017-06-07 04:55:13,970 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 04:55:13,970 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:55:14,376 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            31 pgs backfill_wait
            2 pgs backfilling
            34 pgs stuck unclean
            recovery 8284/127210 objects misplaced (6.512%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16933: 17 osds: 17 up, 17 in; 33 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67669: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
            8284/127210 objects misplaced (6.512%)
                2782 active+clean
                  31 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 257 MB/s, 64 objects/s
  client io 267 kB/s rd, 401 op/s rd, 0 op/s wr

2017-06-07 04:55:14,377 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:55:14,377 INFO cluster.py [line:239] usefull PG number is 2782
2017-06-07 04:56:14,379 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 04:56:14,380 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:56:14,755 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            25 pgs stuck unclean
            recovery 6216/126145 objects misplaced (4.928%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16951: 17 osds: 17 up, 17 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67746: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            6216/126145 objects misplaced (4.928%)
                2791 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 146 MB/s, 36 objects/s

2017-06-07 04:56:14,755 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:56:14,755 INFO cluster.py [line:239] usefull PG number is 2791
2017-06-07 04:57:14,793 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 04:57:14,793 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:57:15,201 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            13 pgs stuck unclean
            recovery 3602/124760 objects misplaced (2.887%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16971: 17 osds: 17 up, 17 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67821: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            3602/124760 objects misplaced (2.887%)
                2803 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 04:57:15,201 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:57:15,201 INFO cluster.py [line:239] usefull PG number is 2803
2017-06-07 04:58:15,253 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 04:58:15,253 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:58:15,643 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            5 pgs backfill_wait
            1 pgs backfilling
            6 pgs stuck unclean
            recovery 1786/123862 objects misplaced (1.442%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16985: 17 osds: 17 up, 17 in; 6 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67892: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            1786/123862 objects misplaced (1.442%)
                2810 active+clean
                   5 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 04:58:15,644 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:58:15,644 INFO cluster.py [line:239] usefull PG number is 2810
2017-06-07 04:59:15,682 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 04:59:15,682 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:59:16,056 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16997: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67956: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
                2816 active+clean

2017-06-07 04:59:16,056 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:59:16,056 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:59:16,057 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:59:16,057 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 04:59:39,087 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 04:59:39,087 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 04:59:39,087 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 04:59:39,500 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e16999: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v67976: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            632 GB used, 47498 GB / 48131 GB avail
                2816 active+clean

2017-06-07 04:59:39,500 INFO cluster.py [line:238] PG number is 2816
2017-06-07 04:59:39,500 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 04:59:39,500 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 04:59:39,500 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 05:00:02,043 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:00:02,043 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:00:02,043 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:00:02,457 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            5 pgs backfilling
            74 pgs stuck unclean
            recovery 26323/136451 objects misplaced (19.291%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17016: 19 osds: 18 up, 19 in; 602 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68008: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            643 GB used, 50319 GB / 50962 GB avail
            26323/136451 objects misplaced (19.291%)
                2718 active+clean
                  92 active+remapped+backfill_wait
                   5 active+remapped+backfilling
                   1 active+remapped
recovery io 1300 MB/s, 325 objects/s

2017-06-07 05:00:02,457 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:00:02,457 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-07 05:01:02,518 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 05:01:02,518 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:01:02,935 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            126 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            84 pgs stuck unclean
            recovery 35027/140636 objects misplaced (24.906%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17063: 19 osds: 19 up, 19 in; 128 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68099: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            35027/140636 objects misplaced (24.906%)
                2685 active+clean
                 126 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
                   1 active+remapped
recovery io 504 MB/s, 126 objects/s

2017-06-07 05:01:02,936 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:01:02,936 INFO cluster.py [line:239] usefull PG number is 2685
2017-06-07 05:02:02,967 INFO cluster.py [line:247] cost 60 seconds, left 5880 seconds when check the ceph status
2017-06-07 05:02:02,967 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:02:03,334 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            73 pgs stuck unclean
            recovery 29096/137527 objects misplaced (21.157%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17092: 19 osds: 19 up, 19 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68176: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            29096/137527 objects misplaced (21.157%)
                2707 active+clean
                 106 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 134 MB/s, 33 objects/s

2017-06-07 05:02:03,334 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:02:03,334 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 05:03:03,395 INFO cluster.py [line:247] cost 61 seconds, left 5819 seconds when check the ceph status
2017-06-07 05:03:03,395 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:03:03,808 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            96 pgs backfill_wait
            1 pgs backfilling
            70 pgs stuck unclean
            recovery 26019/136050 objects misplaced (19.125%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17110: 19 osds: 19 up, 19 in; 97 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68251: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            26019/136050 objects misplaced (19.125%)
                2719 active+clean
                  96 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 423 MB/s, 105 objects/s

2017-06-07 05:03:03,808 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:03:03,808 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-07 05:04:03,869 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 05:04:03,869 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:04:04,276 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            84 pgs backfill_wait
            3 pgs backfilling
            78 pgs stuck unclean
            recovery 23166/134603 objects misplaced (17.211%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17131: 19 osds: 19 up, 19 in; 86 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68328: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            23166/134603 objects misplaced (17.211%)
                2729 active+clean
                  84 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 7998 kB/s, 1 objects/s

2017-06-07 05:04:04,276 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:04:04,276 INFO cluster.py [line:239] usefull PG number is 2729
2017-06-07 05:05:04,303 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 05:05:04,303 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:05:04,663 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            69 pgs backfill_wait
            3 pgs backfilling
            72 pgs stuck unclean
            recovery 19284/132666 objects misplaced (14.536%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17153: 19 osds: 19 up, 19 in; 72 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68407: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            19284/132666 objects misplaced (14.536%)
                2744 active+clean
                  69 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 94807 B/s rd, 138 op/s rd, 0 op/s wr

2017-06-07 05:05:04,663 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:05:04,663 INFO cluster.py [line:239] usefull PG number is 2744
2017-06-07 05:06:04,724 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 05:06:04,724 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:06:05,071 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            52 pgs backfill_wait
            3 pgs backfilling
            55 pgs stuck unclean
            recovery 14513/130337 objects misplaced (11.135%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17182: 19 osds: 19 up, 19 in; 53 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68490: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            14513/130337 objects misplaced (11.135%)
                2761 active+clean
                  52 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 449 kB/s rd, 673 op/s rd, 0 op/s wr

2017-06-07 05:06:05,071 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:06:05,072 INFO cluster.py [line:239] usefull PG number is 2761
2017-06-07 05:07:05,130 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 05:07:05,131 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:07:05,471 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            27 pgs backfill_wait
            3 pgs backfilling
            30 pgs stuck unclean
            recovery 7476/126740 objects misplaced (5.899%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17223: 19 osds: 19 up, 19 in; 28 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68580: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            7476/126740 objects misplaced (5.899%)
                2786 active+clean
                  27 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 171 MB/s, 42 objects/s

2017-06-07 05:07:05,471 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:07:05,471 INFO cluster.py [line:239] usefull PG number is 2786
2017-06-07 05:08:05,522 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 05:08:05,522 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:08:05,902 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs backfilling
            14 pgs stuck unclean
            recovery 3377/124686 objects misplaced (2.708%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17243: 19 osds: 19 up, 19 in; 13 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68657: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            3377/124686 objects misplaced (2.708%)
                2802 active+clean
                  12 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
  client io 249 kB/s rd, 374 op/s rd, 0 op/s wr

2017-06-07 05:08:05,902 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:08:05,903 INFO cluster.py [line:239] usefull PG number is 2802
2017-06-07 05:09:05,953 INFO cluster.py [line:247] cost 60 seconds, left 5457 seconds when check the ceph status
2017-06-07 05:09:05,953 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:09:06,323 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            4 pgs backfill_wait
            1 pgs backfilling
            5 pgs stuck unclean
            recovery 1165/123521 objects misplaced (0.943%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17259: 19 osds: 19 up, 19 in; 5 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68729: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
            1165/123521 objects misplaced (0.943%)
                2811 active+clean
                   4 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 261 kB/s rd, 391 op/s rd, 0 op/s wr

2017-06-07 05:09:06,323 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:09:06,323 INFO cluster.py [line:239] usefull PG number is 2811
2017-06-07 05:10:06,358 INFO cluster.py [line:247] cost 61 seconds, left 5396 seconds when check the ceph status
2017-06-07 05:10:06,358 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:10:06,761 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17269: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68797: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean

2017-06-07 05:10:06,761 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:10:06,761 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:10:06,761 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 05:10:06,761 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 05:10:29,225 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:10:29,225 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:10:29,226 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:10:29,614 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17271: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v68820: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean
  client io 340 kB/s rd, 510 op/s rd, 0 op/s wr

2017-06-07 05:10:29,614 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:10:29,614 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:10:29,614 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 05:10:31,753 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 05:10:32,039 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 22 Jun05 ?        05:02:07 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   50874 50873  0 21:10 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   50876 50874  0 21:10 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-07 05:10:32,040 INFO client.py [line:174] IO is running
2017-06-07 05:10:32,225 INFO node.py [line:185] 0
2017-06-07 05:10:32,225 INFO node.py [line:192] nvme6n1
2017-06-07 05:10:32,225 INFO node.py [line:185] 0
2017-06-07 05:10:32,225 INFO node.py [line:192] nvme6n1
2017-06-07 05:10:32,225 INFO node.py [line:185] 0
2017-06-07 05:10:32,225 INFO node.py [line:192] nvme6n1
2017-06-07 05:10:32,225 INFO node.py [line:185] 1
2017-06-07 05:10:32,225 INFO node.py [line:192] nvme2n1
2017-06-07 05:10:32,226 INFO node.py [line:185] 1
2017-06-07 05:10:32,226 INFO node.py [line:192] nvme2n1
2017-06-07 05:10:32,226 INFO node.py [line:185] 1
2017-06-07 05:10:32,226 INFO node.py [line:192] nvme2n1
2017-06-07 05:10:32,226 INFO node.py [line:185] 2
2017-06-07 05:10:32,226 INFO node.py [line:192] nvme5n1
2017-06-07 05:10:32,226 INFO node.py [line:185] 2
2017-06-07 05:10:32,226 INFO node.py [line:192] nvme5n1
2017-06-07 05:10:32,226 INFO node.py [line:185] 2
2017-06-07 05:10:32,227 INFO node.py [line:192] nvme5n1
2017-06-07 05:10:32,227 INFO node.py [line:185] 3
2017-06-07 05:10:32,227 INFO node.py [line:192] nvme1n1
2017-06-07 05:10:32,227 INFO node.py [line:185] 3
2017-06-07 05:10:32,227 INFO node.py [line:192] nvme1n1
2017-06-07 05:10:32,227 INFO node.py [line:185] 3
2017-06-07 05:10:32,227 INFO node.py [line:192] nvme1n1
2017-06-07 05:10:32,227 INFO node.py [line:185] 4
2017-06-07 05:10:32,227 INFO node.py [line:192] nvme4n1
2017-06-07 05:10:32,228 INFO node.py [line:185] 4
2017-06-07 05:10:32,228 INFO node.py [line:192] nvme4n1
2017-06-07 05:10:32,228 INFO node.py [line:185] 4
2017-06-07 05:10:32,228 INFO node.py [line:192] nvme4n1
2017-06-07 05:10:32,228 INFO node.py [line:185] 5
2017-06-07 05:10:32,228 INFO node.py [line:192] nvme7n1
2017-06-07 05:10:32,228 INFO node.py [line:185] 5
2017-06-07 05:10:32,228 INFO node.py [line:192] nvme7n1
2017-06-07 05:10:32,228 INFO node.py [line:185] 5
2017-06-07 05:10:32,228 INFO node.py [line:192] nvme7n1
2017-06-07 05:10:32,229 INFO node.py [line:185] 6
2017-06-07 05:10:32,229 INFO node.py [line:192] nvme3n1
2017-06-07 05:10:32,229 INFO node.py [line:185] 6
2017-06-07 05:10:32,229 INFO node.py [line:192] nvme3n1
2017-06-07 05:10:32,229 INFO node.py [line:185] 6
2017-06-07 05:10:32,229 INFO node.py [line:192] nvme3n1
2017-06-07 05:10:32,229 INFO node.py [line:185] 
2017-06-07 05:10:32,229 INFO node.py [line:192] nvme3n1
2017-06-07 05:10:32,229 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 05:10:32,230 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 05:10:32,230 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 05:10:32,230 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 05:18:04,820 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:18:05,222 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17445: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v69400: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean

2017-06-07 05:18:05,222 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:18:05,222 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:18:05,222 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 05:18:05,222 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 05:20:28,180 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:20:28,546 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17551: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v69616: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            641 GB used, 50320 GB / 50962 GB avail
                2816 active+clean
  client io 143 kB/s rd, 214 op/s rd, 0 op/s wr

2017-06-07 05:20:28,547 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:20:28,547 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:20:28,547 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 05:20:28,547 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 05:23:06,711 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:23:07,122 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17670: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v69854: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
                2816 active+clean

2017-06-07 05:23:07,122 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:23:07,122 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:23:07,122 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 05:23:07,123 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 05:26:47,098 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:26:47,453 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17832: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v70187: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            624 GB used, 44675 GB / 45300 GB avail
                2816 active+clean
  client io 403 kB/s rd, 403 op/s rd, 0 op/s wr

2017-06-07 05:26:47,453 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:26:47,453 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:26:47,453 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 05:26:47,454 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 05:31:05,256 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:31:05,624 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e17997: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v70552: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            615 GB used, 41853 GB / 42468 GB avail
                2816 active+clean

2017-06-07 05:31:05,625 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:31:05,625 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:31:05,625 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 05:31:05,625 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 05:37:16,939 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:37:17,309 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18172: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71037: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            607 GB used, 39030 GB / 39637 GB avail
                2816 active+clean
  client io 318 kB/s rd, 318 op/s rd, 0 op/s wr

2017-06-07 05:37:17,309 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:37:17,309 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:37:17,309 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 05:37:17,310 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 05:39:42,623 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:39:43,005 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18281: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71240: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            598 GB used, 36207 GB / 36806 GB avail
                2816 active+clean

2017-06-07 05:39:43,005 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:39:43,005 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:39:43,005 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 05:39:45,049 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 05:39:45,049 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 05:39:45,049 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 05:40:07,136 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:40:07,136 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:40:07,136 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:40:07,515 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18283: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71264: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            598 GB used, 36207 GB / 36806 GB avail
                2816 active+clean

2017-06-07 05:40:07,515 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:40:07,515 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:40:07,515 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 05:40:07,515 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 05:40:29,583 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:40:29,583 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:40:29,583 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:40:29,959 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136488 objects degraded (0.004%)
            recovery 26796/136488 objects misplaced (19.632%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18294: 15 osds: 14 up, 15 in; 741 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71291: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            608 GB used, 39029 GB / 39637 GB avail
            6/136488 objects degraded (0.004%)
            26796/136488 objects misplaced (19.632%)
                2716 active+clean
                  97 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 381 MB/s, 95 objects/s
  client io 143 kB/s rd, 215 op/s rd, 0 op/s wr

2017-06-07 05:40:29,959 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:40:29,959 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-07 05:41:30,001 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 05:41:30,001 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:41:30,384 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            45 pgs stuck unclean
            recovery 3/146065 objects degraded (0.002%)
            recovery 46143/146065 objects misplaced (31.591%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18318: 15 osds: 15 up, 15 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71369: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            3/146065 objects degraded (0.002%)
            46143/146065 objects misplaced (31.591%)
                2650 active+clean
                 163 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 681 MB/s, 170 objects/s

2017-06-07 05:41:30,384 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:41:30,384 INFO cluster.py [line:239] usefull PG number is 2650
2017-06-07 05:42:30,445 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 05:42:30,445 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:42:30,839 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            151 pgs backfill_wait
            1 pgs peering
            49 pgs stuck unclean
            recovery 42447/144177 objects misplaced (29.441%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18341: 15 osds: 15 up, 15 in; 151 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71445: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            42447/144177 objects misplaced (29.441%)
                2664 active+clean
                 151 active+remapped+backfill_wait
                   1 peering
recovery io 1116 MB/s, 279 objects/s

2017-06-07 05:42:30,839 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:42:30,840 INFO cluster.py [line:239] usefull PG number is 2664
2017-06-07 05:43:30,900 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 05:43:30,900 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:43:31,280 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            142 pgs backfill_wait
            1 pgs backfilling
            80 pgs stuck unclean
            recovery 40030/142975 objects misplaced (27.998%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18358: 15 osds: 15 up, 15 in; 142 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71513: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            40030/142975 objects misplaced (27.998%)
                2673 active+clean
                 142 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 280 MB/s, 70 objects/s

2017-06-07 05:43:31,280 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:43:31,280 INFO cluster.py [line:239] usefull PG number is 2673
2017-06-07 05:44:31,340 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 05:44:31,341 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:44:31,752 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            132 pgs backfill_wait
            1 pgs backfilling
            92 pgs stuck unclean
            recovery 37270/141628 objects misplaced (26.315%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18379: 15 osds: 15 up, 15 in; 132 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71587: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            37270/141628 objects misplaced (26.315%)
                2683 active+clean
                 132 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 05:44:31,752 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:44:31,753 INFO cluster.py [line:239] usefull PG number is 2683
2017-06-07 05:45:31,781 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 05:45:31,782 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:45:32,147 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            121 pgs backfill_wait
            1 pgs backfilling
            122 pgs stuck unclean
            recovery 33401/139703 objects misplaced (23.909%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18400: 15 osds: 15 up, 15 in; 121 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71665: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            33401/139703 objects misplaced (23.909%)
                2694 active+clean
                 121 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 05:45:32,147 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:45:32,147 INFO cluster.py [line:239] usefull PG number is 2694
2017-06-07 05:46:32,198 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 05:46:32,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:46:32,595 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            102 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            104 pgs stuck unclean
            recovery 28854/137406 objects misplaced (20.999%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18432: 15 osds: 15 up, 15 in; 104 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71752: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            617 GB used, 41851 GB / 42468 GB avail
            28854/137406 objects misplaced (20.999%)
                2711 active+clean
                 102 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 575 MB/s, 143 objects/s

2017-06-07 05:46:32,595 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:46:32,595 INFO cluster.py [line:239] usefull PG number is 2711
2017-06-07 05:47:32,655 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 05:47:32,656 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:47:33,028 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            82 pgs backfill_wait
            2 pgs backfilling
            85 pgs stuck unclean
            recovery 22676/134370 objects misplaced (16.876%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18468: 15 osds: 15 up, 15 in; 84 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71841: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            617 GB used, 41851 GB / 42468 GB avail
            22676/134370 objects misplaced (16.876%)
                2731 active+clean
                  82 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 active+remapped
recovery io 87636 kB/s, 21 objects/s
  client io 490 kB/s rd, 735 op/s rd, 0 op/s wr

2017-06-07 05:47:33,028 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:47:33,028 INFO cluster.py [line:239] usefull PG number is 2731
2017-06-07 05:48:33,089 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 05:48:33,089 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:48:33,480 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            64 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            67 pgs stuck unclean
            recovery 17716/131859 objects misplaced (13.436%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18499: 15 osds: 15 up, 15 in; 66 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v71926: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            17716/131859 objects misplaced (13.436%)
                2748 active+clean
                  64 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 94652 kB/s, 23 objects/s
  client io 462 kB/s rd, 693 op/s rd, 0 op/s wr

2017-06-07 05:48:33,481 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:48:33,481 INFO cluster.py [line:239] usefull PG number is 2748
2017-06-07 05:49:33,526 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 05:49:33,526 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:49:33,908 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            49 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 13154/129542 objects misplaced (10.154%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18528: 15 osds: 15 up, 15 in; 50 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72006: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            13154/129542 objects misplaced (10.154%)
                2766 active+clean
                  49 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 478 kB/s rd, 599 op/s rd, 0 op/s wr

2017-06-07 05:49:33,909 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:49:33,909 INFO cluster.py [line:239] usefull PG number is 2766
2017-06-07 05:50:33,969 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 05:50:33,969 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:50:34,314 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            39 pgs backfill_wait
            1 pgs backfilling
            40 pgs stuck unclean
            recovery 10397/128154 objects misplaced (8.113%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18548: 15 osds: 15 up, 15 in; 40 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72082: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            10397/128154 objects misplaced (8.113%)
                2776 active+clean
                  39 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 340 kB/s rd, 510 op/s rd, 0 op/s wr

2017-06-07 05:50:34,314 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:50:34,314 INFO cluster.py [line:239] usefull PG number is 2776
2017-06-07 05:51:34,343 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 05:51:34,344 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:51:34,741 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            32 pgs backfill_wait
            1 pgs backfilling
            33 pgs stuck unclean
            recovery 8424/127194 objects misplaced (6.623%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18563: 15 osds: 15 up, 15 in; 32 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72154: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            8424/127194 objects misplaced (6.623%)
                2783 active+clean
                  32 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 89569 B/s rd, 131 op/s rd, 0 op/s wr

2017-06-07 05:51:34,741 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:51:34,741 INFO cluster.py [line:239] usefull PG number is 2783
2017-06-07 05:52:34,793 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 05:52:34,793 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:52:35,166 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 6382/126146 objects misplaced (5.059%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18580: 15 osds: 15 up, 15 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72225: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            6382/126146 objects misplaced (5.059%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 194 MB/s, 48 objects/s
  client io 310 kB/s rd, 465 op/s rd, 0 op/s wr

2017-06-07 05:52:35,167 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:52:35,167 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-07 05:53:35,198 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-07 05:53:35,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:53:35,571 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 4464/125181 objects misplaced (3.566%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18596: 15 osds: 15 up, 15 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72295: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            4464/125181 objects misplaced (3.566%)
                2800 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 193 MB/s, 48 objects/s
  client io 311 kB/s rd, 467 op/s rd, 0 op/s wr

2017-06-07 05:53:35,572 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:53:35,572 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-07 05:54:35,615 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-07 05:54:35,615 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:54:36,013 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            7 pgs backfill_wait
            1 pgs backfilling
            8 pgs stuck unclean
            recovery 2150/124048 objects misplaced (1.733%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18612: 15 osds: 15 up, 15 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72365: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            2150/124048 objects misplaced (1.733%)
                2808 active+clean
                   7 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 05:54:36,014 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:54:36,014 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-07 05:55:36,064 INFO cluster.py [line:247] cost 61 seconds, left 5093 seconds when check the ceph status
2017-06-07 05:55:36,064 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:55:36,444 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18628: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72438: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
                2816 active+clean

2017-06-07 05:55:36,445 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:55:36,445 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:55:36,445 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 05:55:36,445 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 05:55:58,075 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:55:58,076 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:55:58,076 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:55:58,473 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18630: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72459: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
                2816 active+clean

2017-06-07 05:55:58,473 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:55:58,473 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 05:55:58,473 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 05:55:58,473 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 05:56:20,534 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 05:56:20,535 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 05:56:20,535 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:56:20,894 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            3 pgs backfilling
            44 pgs stuck unclean
            recovery 28547/137404 objects misplaced (20.776%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18647: 17 osds: 16 up, 17 in; 703 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72490: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            626 GB used, 44673 GB / 45300 GB avail
            28547/137404 objects misplaced (20.776%)
                2706 active+clean
                 106 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 active+remapped

2017-06-07 05:56:20,894 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:56:20,894 INFO cluster.py [line:239] usefull PG number is 2706
2017-06-07 05:57:20,946 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 05:57:20,946 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:57:21,310 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            160 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            114 pgs stuck unclean
            recovery 44666/145330 objects misplaced (30.734%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18681: 17 osds: 17 up, 17 in; 163 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72569: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47495 GB / 48131 GB avail
            44666/145330 objects misplaced (30.734%)
                2652 active+clean
                 160 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 536 MB/s, 134 objects/s

2017-06-07 05:57:21,310 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:57:21,310 INFO cluster.py [line:239] usefull PG number is 2652
2017-06-07 05:58:21,358 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 05:58:21,358 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:58:21,728 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            138 pgs backfill_wait
            2 pgs backfilling
            115 pgs stuck unclean
            recovery 38107/142101 objects misplaced (26.817%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18716: 17 osds: 17 up, 17 in; 139 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72651: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            38107/142101 objects misplaced (26.817%)
                2676 active+clean
                 138 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 05:58:21,728 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:58:21,728 INFO cluster.py [line:239] usefull PG number is 2676
2017-06-07 05:59:21,766 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 05:59:21,767 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 05:59:22,095 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            126 pgs backfill_wait
            1 pgs backfilling
            112 pgs stuck unclean
            recovery 34770/140330 objects misplaced (24.777%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18738: 17 osds: 17 up, 17 in; 127 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72728: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            34770/140330 objects misplaced (24.777%)
                2689 active+clean
                 126 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 111 MB/s, 27 objects/s

2017-06-07 05:59:22,095 INFO cluster.py [line:238] PG number is 2816
2017-06-07 05:59:22,095 INFO cluster.py [line:239] usefull PG number is 2689
2017-06-07 06:00:22,120 INFO cluster.py [line:247] cost 61 seconds, left 5758 seconds when check the ceph status
2017-06-07 06:00:22,120 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:00:22,511 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            1 pgs peering
            101 pgs stuck unclean
            recovery 29538/137762 objects misplaced (21.441%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18772: 17 osds: 17 up, 17 in; 106 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72815: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            29538/137762 objects misplaced (21.441%)
                2708 active+clean
                 106 active+remapped+backfill_wait
                   1 active+remapped
                   1 peering
recovery io 210 MB/s, 52 objects/s
  client io 239 kB/s rd, 239 op/s rd, 0 op/s wr

2017-06-07 06:00:22,511 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:00:22,511 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-07 06:01:22,570 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 06:01:22,570 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:01:22,959 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            85 pgs backfill_wait
            4 pgs backfilling
            89 pgs stuck unclean
            recovery 24137/135116 objects misplaced (17.864%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18806: 17 osds: 17 up, 17 in; 88 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72902: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
            24137/135116 objects misplaced (17.864%)
                2727 active+clean
                  85 active+remapped+backfill_wait
                   4 active+remapped+backfilling
  client io 481 kB/s rd, 481 op/s rd, 0 op/s wr

2017-06-07 06:01:22,959 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:01:22,959 INFO cluster.py [line:239] usefull PG number is 2727
2017-06-07 06:02:23,019 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 06:02:23,020 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:02:23,394 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            61 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            65 pgs stuck unclean
            recovery 16536/131410 objects misplaced (12.584%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18842: 17 osds: 17 up, 17 in; 63 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v72990: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47496 GB / 48131 GB avail
            16536/131410 objects misplaced (12.584%)
                2750 active+clean
                  61 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
  client io 590 kB/s rd, 885 op/s rd, 0 op/s wr

2017-06-07 06:02:23,395 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:02:23,395 INFO cluster.py [line:239] usefull PG number is 2750
2017-06-07 06:03:23,421 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 06:03:23,421 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:03:23,803 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_ERR
            1 pgs are stuck inactive for more than 300 seconds
            42 pgs backfill_wait
            4 pgs backfilling
            1 pgs peering
            1 pgs stuck inactive
            46 pgs stuck unclean
            recovery 11170/128614 objects misplaced (8.685%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18868: 17 osds: 17 up, 17 in; 45 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73072: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            11170/128614 objects misplaced (8.685%)
                2769 active+clean
                  42 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 peering
recovery io 187 MB/s, 46 objects/s
  client io 644 kB/s rd, 967 op/s rd, 0 op/s wr

2017-06-07 06:03:23,803 INFO cluster.py [line:215] Now status is HEALTH_ERR, sleep 60s and try again 
2017-06-07 06:04:23,831 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:04:24,234 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            23 pgs backfill_wait
            1 pgs backfilling
            24 pgs stuck unclean
            recovery 5751/125849 objects misplaced (4.570%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18902: 17 osds: 17 up, 17 in; 24 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73159: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            5751/125849 objects misplaced (4.570%)
                2792 active+clean
                  23 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 241 MB/s, 3 keys/s, 61 objects/s
  client io 339 kB/s rd, 508 op/s rd, 0 op/s wr

2017-06-07 06:04:24,234 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:04:24,234 INFO cluster.py [line:239] usefull PG number is 2792
2017-06-07 06:05:24,294 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 06:05:24,294 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:05:24,650 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            15 pgs backfill_wait
            1 pgs backfilling
            16 pgs stuck unclean
            recovery 3810/124875 objects misplaced (3.051%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18918: 17 osds: 17 up, 17 in; 16 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73232: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
            3810/124875 objects misplaced (3.051%)
                2800 active+clean
                  15 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 342 MB/s, 85 objects/s
  client io 334 kB/s rd, 502 op/s rd, 0 op/s wr

2017-06-07 06:05:24,650 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:05:24,651 INFO cluster.py [line:239] usefull PG number is 2800
2017-06-07 06:06:24,711 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 06:06:24,711 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:06:25,106 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            6 pgs backfill_wait
            1 pgs backfilling
            7 pgs stuck unclean
            recovery 1523/123707 objects misplaced (1.231%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18936: 17 osds: 17 up, 17 in; 7 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73304: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
            1523/123707 objects misplaced (1.231%)
                2809 active+clean
                   6 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 80932 kB/s, 19 objects/s
  client io 303 kB/s rd, 454 op/s rd, 0 op/s wr

2017-06-07 06:06:25,106 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:06:25,106 INFO cluster.py [line:239] usefull PG number is 2809
2017-06-07 06:07:25,149 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-07 06:07:25,149 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:07:25,561 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18948: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73375: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
                2816 active+clean
  client io 339 kB/s rd, 509 op/s rd, 0 op/s wr

2017-06-07 06:07:25,561 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:07:25,561 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:07:25,561 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 06:07:25,561 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 06:07:47,925 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 06:07:47,925 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 06:07:47,926 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:07:48,302 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18950: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73399: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47498 GB / 48131 GB avail
                2816 active+clean
  client io 135 kB/s rd, 203 op/s rd, 0 op/s wr

2017-06-07 06:07:48,303 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:07:48,303 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:07:48,303 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 06:07:48,303 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 06:08:09,910 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 06:08:09,910 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 06:08:09,910 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:08:10,324 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            4 pgs backfilling
            1 pgs degraded
            1 pgs peering
            1 pgs recovery_wait
            66 pgs stuck unclean
            recovery 26675/136435 objects misplaced (19.551%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e18966: 19 osds: 18 up, 19 in; 600 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73429: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            643 GB used, 50319 GB / 50962 GB avail
            26675/136435 objects misplaced (19.551%)
                2718 active+clean
                  92 active+remapped+backfill_wait
                   4 active+remapped+backfilling
                   1 active+recovery_wait+degraded+remapped
                   1 peering

2017-06-07 06:08:10,325 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:08:10,325 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-07 06:09:10,385 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 06:09:10,385 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:09:10,834 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            128 pgs backfill_wait
            4 pgs backfilling
            106 pgs stuck unclean
            recovery 36009/141140 objects misplaced (25.513%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19008: 19 osds: 19 up, 19 in; 130 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73517: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            36009/141140 objects misplaced (25.513%)
                2684 active+clean
                 128 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 558 MB/s, 139 objects/s

2017-06-07 06:09:10,834 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:09:10,834 INFO cluster.py [line:239] usefull PG number is 2684
2017-06-07 06:10:10,872 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 06:10:10,872 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:10:11,259 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            2 pgs backfilling
            93 pgs stuck unclean
            recovery 29572/137775 objects misplaced (21.464%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19036: 19 osds: 19 up, 19 in; 109 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73596: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            29572/137775 objects misplaced (21.464%)
                2707 active+clean
                 107 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 253 MB/s, 63 objects/s

2017-06-07 06:10:11,259 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:10:11,259 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 06:11:11,263 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-07 06:11:11,263 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:11:11,633 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            98 pgs backfill_wait
            1 pgs backfilling
            93 pgs stuck unclean
            recovery 26721/136341 objects misplaced (19.599%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19056: 19 osds: 19 up, 19 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73669: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            26721/136341 objects misplaced (19.599%)
                2717 active+clean
                  98 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 454 kB/s rd, 454 op/s rd, 0 op/s wr

2017-06-07 06:11:11,634 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:11:11,634 INFO cluster.py [line:239] usefull PG number is 2717
2017-06-07 06:12:11,666 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-07 06:12:11,666 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:12:12,025 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            88 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            87 pgs stuck unclean
            recovery 24015/134969 objects misplaced (17.793%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19070: 19 osds: 19 up, 19 in; 90 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73739: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            24015/134969 objects misplaced (17.793%)
                2725 active+clean
                  88 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 251 MB/s, 62 objects/s
  client io 212 kB/s rd, 212 op/s rd, 0 op/s wr

2017-06-07 06:12:12,026 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:12:12,026 INFO cluster.py [line:239] usefull PG number is 2725
2017-06-07 06:13:12,049 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-07 06:13:12,049 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:13:12,422 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            70 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            72 pgs stuck unclean
            recovery 19752/132848 objects misplaced (14.868%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19092: 19 osds: 19 up, 19 in; 72 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73815: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            19752/132848 objects misplaced (14.868%)
                2743 active+clean
                  70 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 1351 MB/s, 337 objects/s
  client io 483 kB/s rd, 483 op/s rd, 0 op/s wr

2017-06-07 06:13:12,423 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:13:12,423 INFO cluster.py [line:239] usefull PG number is 2743
2017-06-07 06:14:12,483 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-07 06:14:12,483 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:14:12,870 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            49 pgs backfill_wait
            3 pgs backfilling
            52 pgs stuck unclean
            recovery 14028/130044 objects misplaced (10.787%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19122: 19 osds: 19 up, 19 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73900: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            14028/130044 objects misplaced (10.787%)
                2764 active+clean
                  49 active+remapped+backfill_wait
                   3 active+remapped+backfilling
  client io 181 kB/s rd, 272 op/s rd, 0 op/s wr

2017-06-07 06:14:12,871 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:14:12,871 INFO cluster.py [line:239] usefull PG number is 2764
2017-06-07 06:15:12,931 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 06:15:12,931 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:15:13,322 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            27 pgs backfill_wait
            5 pgs backfilling
            32 pgs stuck unclean
            recovery 8500/127323 objects misplaced (6.676%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19158: 19 osds: 19 up, 19 in; 29 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v73987: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            8500/127323 objects misplaced (6.676%)
                2784 active+clean
                  27 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 55984 kB/s, 13 objects/s
  client io 699 kB/s rd, 1048 op/s rd, 0 op/s wr

2017-06-07 06:15:13,322 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:15:13,322 INFO cluster.py [line:239] usefull PG number is 2784
2017-06-07 06:16:13,326 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 06:16:13,326 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:16:13,706 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            12 pgs backfill_wait
            1 pgs peering
            12 pgs stuck unclean
            recovery 3218/124543 objects misplaced (2.584%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19184: 19 osds: 19 up, 19 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74067: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            3218/124543 objects misplaced (2.584%)
                2803 active+clean
                  12 active+remapped+backfill_wait
                   1 peering
  client io 177 kB/s rd, 266 op/s rd, 0 op/s wr

2017-06-07 06:16:13,707 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:16:13,707 INFO cluster.py [line:239] usefull PG number is 2803
2017-06-07 06:17:13,734 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 06:17:13,734 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:17:14,087 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            2 pgs backfill_wait
            1 pgs backfilling
            3 pgs stuck unclean
            recovery 651/123282 objects misplaced (0.528%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19202: 19 osds: 19 up, 19 in; 3 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74143: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            651/123282 objects misplaced (0.528%)
                2813 active+clean
                   2 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 94795 B/s rd, 138 op/s rd, 0 op/s wr

2017-06-07 06:17:14,087 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:17:14,087 INFO cluster.py [line:239] usefull PG number is 2813
2017-06-07 06:18:14,130 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-07 06:18:14,130 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:18:14,544 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19208: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74203: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean
  client io 345 kB/s rd, 517 op/s rd, 0 op/s wr

2017-06-07 06:18:14,545 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:18:14,545 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:18:14,545 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 06:18:14,545 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 06:18:36,223 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 06:18:36,223 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 06:18:36,224 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:18:36,633 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19210: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74224: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean

2017-06-07 06:18:36,633 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:18:36,633 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:18:36,634 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 06:18:38,624 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 06:18:38,905 INFO client.py [line:172] ['oot     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 21 Jun05 ?        05:02:18 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'denali   28240 28238  0 22:18 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali   28242 28240  0 22:18 ?        00:00:00 grep fio', 'stdin: is not a tty', '']
2017-06-07 06:18:38,905 INFO client.py [line:174] IO is running
2017-06-07 06:18:39,092 INFO node.py [line:185] 0
2017-06-07 06:18:39,092 INFO node.py [line:192] nvme6n1
2017-06-07 06:18:39,092 INFO node.py [line:185] 0
2017-06-07 06:18:39,093 INFO node.py [line:192] nvme6n1
2017-06-07 06:18:39,093 INFO node.py [line:185] 0
2017-06-07 06:18:39,093 INFO node.py [line:192] nvme6n1
2017-06-07 06:18:39,093 INFO node.py [line:185] 1
2017-06-07 06:18:39,093 INFO node.py [line:192] nvme2n1
2017-06-07 06:18:39,093 INFO node.py [line:185] 1
2017-06-07 06:18:39,093 INFO node.py [line:192] nvme2n1
2017-06-07 06:18:39,093 INFO node.py [line:185] 1
2017-06-07 06:18:39,094 INFO node.py [line:192] nvme2n1
2017-06-07 06:18:39,094 INFO node.py [line:185] 2
2017-06-07 06:18:39,094 INFO node.py [line:192] nvme5n1
2017-06-07 06:18:39,094 INFO node.py [line:185] 2
2017-06-07 06:18:39,094 INFO node.py [line:192] nvme5n1
2017-06-07 06:18:39,094 INFO node.py [line:185] 2
2017-06-07 06:18:39,094 INFO node.py [line:192] nvme5n1
2017-06-07 06:18:39,094 INFO node.py [line:185] 3
2017-06-07 06:18:39,094 INFO node.py [line:192] nvme1n1
2017-06-07 06:18:39,095 INFO node.py [line:185] 3
2017-06-07 06:18:39,095 INFO node.py [line:192] nvme1n1
2017-06-07 06:18:39,095 INFO node.py [line:185] 3
2017-06-07 06:18:39,095 INFO node.py [line:192] nvme1n1
2017-06-07 06:18:39,095 INFO node.py [line:185] 4
2017-06-07 06:18:39,095 INFO node.py [line:192] nvme4n1
2017-06-07 06:18:39,095 INFO node.py [line:185] 4
2017-06-07 06:18:39,095 INFO node.py [line:192] nvme4n1
2017-06-07 06:18:39,095 INFO node.py [line:185] 4
2017-06-07 06:18:39,096 INFO node.py [line:192] nvme4n1
2017-06-07 06:18:39,096 INFO node.py [line:185] 5
2017-06-07 06:18:39,096 INFO node.py [line:192] nvme7n1
2017-06-07 06:18:39,096 INFO node.py [line:185] 5
2017-06-07 06:18:39,096 INFO node.py [line:192] nvme7n1
2017-06-07 06:18:39,096 INFO node.py [line:185] 5
2017-06-07 06:18:39,096 INFO node.py [line:192] nvme7n1
2017-06-07 06:18:39,096 INFO node.py [line:185] 6
2017-06-07 06:18:39,096 INFO node.py [line:192] nvme3n1
2017-06-07 06:18:39,097 INFO node.py [line:185] 6
2017-06-07 06:18:39,097 INFO node.py [line:192] nvme3n1
2017-06-07 06:18:39,097 INFO node.py [line:185] 6
2017-06-07 06:18:39,097 INFO node.py [line:192] nvme3n1
2017-06-07 06:18:39,097 INFO node.py [line:185] 
2017-06-07 06:18:39,097 INFO node.py [line:192] nvme3n1
2017-06-07 06:18:39,097 INFO node.py [line:200] osd.0  ---> disk nvme6n1
2017-06-07 06:18:39,097 INFO node.py [line:200] osd.1  ---> disk nvme2n1
2017-06-07 06:18:39,097 INFO node.py [line:200] osd.2  ---> disk nvme5n1
2017-06-07 06:18:39,098 INFO node.py [line:200] osd.3  ---> disk nvme1n1
2017-06-07 06:18:39,098 INFO node.py [line:200] osd.4  ---> disk nvme4n1
2017-06-07 06:18:39,098 INFO node.py [line:200] osd.5  ---> disk nvme7n1
2017-06-07 06:18:39,098 INFO node.py [line:200] osd.6  ---> disk nvme3n1
2017-06-07 06:18:39,098 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:56] start to delete osd on node ubuntu-A 
2017-06-07 06:18:39,098 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme6n1
2017-06-07 06:26:18,538 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:26:18,943 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19377: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v74808: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            650 GB used, 53143 GB / 53794 GB avail
                2816 active+clean

2017-06-07 06:26:18,943 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:26:18,943 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:26:18,943 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.0 delete succesfully
2017-06-07 06:26:18,944 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme2n1
2017-06-07 06:28:43,434 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:28:43,813 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19480: 18 osds: 18 up, 18 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75024: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            642 GB used, 50320 GB / 50962 GB avail
                2816 active+clean
  client io 147 kB/s rd, 221 op/s rd, 0 op/s wr

2017-06-07 06:28:43,813 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:28:43,813 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:28:43,813 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.1 delete succesfully
2017-06-07 06:28:43,814 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme5n1
2017-06-07 06:31:08,985 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:31:09,338 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19597: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75245: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            633 GB used, 47497 GB / 48131 GB avail
                2816 active+clean

2017-06-07 06:31:09,339 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:31:09,339 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:31:09,339 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.2 delete succesfully
2017-06-07 06:31:09,339 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme1n1
2017-06-07 06:34:45,633 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:34:46,037 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19748: 16 osds: 16 up, 16 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75565: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            625 GB used, 44675 GB / 45300 GB avail
                2816 active+clean

2017-06-07 06:34:46,037 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:34:46,037 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:34:46,037 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.3 delete succesfully
2017-06-07 06:34:46,037 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme4n1
2017-06-07 06:38:44,098 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:38:44,507 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e19910: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v75916: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
                2816 active+clean
  client io 133 kB/s rd, 200 op/s rd, 0 op/s wr

2017-06-07 06:38:44,508 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:38:44,508 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:38:44,508 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.4 delete succesfully
2017-06-07 06:38:44,508 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme7n1
2017-06-07 06:44:44,385 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:44:44,782 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20095: 14 osds: 14 up, 14 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76400: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            607 GB used, 39029 GB / 39637 GB avail
                2816 active+clean
  client io 143 kB/s rd, 215 op/s rd, 0 op/s wr

2017-06-07 06:44:44,782 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:44:44,782 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:44:44,783 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.5 delete succesfully
2017-06-07 06:44:44,783 INFO osd.py [line:156] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/delete_osds_local.sh -n -d /dev/nvme3n1
2017-06-07 06:47:07,101 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:47:07,470 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20203: 13 osds: 13 up, 13 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76603: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            599 GB used, 36207 GB / 36806 GB avail
                2816 active+clean

2017-06-07 06:47:07,470 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:47:07,470 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:47:07,470 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:63] osd.6 delete succesfully
2017-06-07 06:47:09,502 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:76] all osds on node ubuntu-A delete succesfully
2017-06-07 06:47:09,502 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:78] start to create osd on node ubuntu-A 
2017-06-07 06:47:09,503 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme6n1
2017-06-07 06:47:31,762 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 06:47:31,762 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.0==============
INFO: --- Create osd.0 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 06:47:31,762 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:47:32,166 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/14 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20205: 14 osds: 13 up, 14 in; 538 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76627: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            599 GB used, 36207 GB / 36806 GB avail
                2816 active+clean

2017-06-07 06:47:32,166 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:47:32,166 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 06:47:32,166 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 06:47:32,166 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme2n1
2017-06-07 06:47:53,739 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 06:47:53,739 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.1==============
INFO: --- Create osd.1 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 06:47:53,739 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:47:54,146 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            95 pgs backfill_wait
            1 pgs backfilling
            2 pgs degraded
            2 pgs recovery_wait
            12 pgs stuck unclean
            recovery 6/136245 objects degraded (0.004%)
            recovery 26266/136245 objects misplaced (19.279%)
            1/15 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20219: 15 osds: 14 up, 15 in; 739 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76654: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            610 GB used, 39027 GB / 39637 GB avail
            6/136245 objects degraded (0.004%)
            26266/136245 objects misplaced (19.279%)
                2718 active+clean
                  95 active+remapped+backfill_wait
                   2 active+recovery_wait+degraded
                   1 active+remapped+backfilling
recovery io 473 MB/s, 118 objects/s
  client io 248 kB/s rd, 372 op/s rd, 0 op/s wr

2017-06-07 06:47:54,147 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:47:54,147 INFO cluster.py [line:239] usefull PG number is 2718
2017-06-07 06:48:54,198 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 06:48:54,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:48:54,595 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 46119/146137 objects misplaced (31.559%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20243: 15 osds: 15 up, 15 in; 164 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76728: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            619 GB used, 41849 GB / 42468 GB avail
            46119/146137 objects misplaced (31.559%)
                2652 active+clean
                 163 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 263 MB/s, 65 objects/s

2017-06-07 06:48:54,595 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:48:54,595 INFO cluster.py [line:239] usefull PG number is 2652
2017-06-07 06:49:54,655 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 06:49:54,656 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:49:55,028 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            154 pgs backfill_wait
            1 pgs backfilling
            50 pgs stuck unclean
            recovery 43544/144820 objects misplaced (30.068%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20261: 15 osds: 15 up, 15 in; 155 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76805: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            43544/144820 objects misplaced (30.068%)
                2661 active+clean
                 154 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 06:49:55,029 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:49:55,029 INFO cluster.py [line:239] usefull PG number is 2661
2017-06-07 06:50:55,075 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-07 06:50:55,075 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:50:55,447 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            145 pgs backfill_wait
            85 pgs stuck unclean
            recovery 40297/143148 objects misplaced (28.151%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20281: 15 osds: 15 up, 15 in; 145 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76880: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            40297/143148 objects misplaced (28.151%)
                2671 active+clean
                 145 active+remapped+backfill_wait
recovery io 190 MB/s, 47 objects/s

2017-06-07 06:50:55,447 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:50:55,447 INFO cluster.py [line:239] usefull PG number is 2671
2017-06-07 06:51:55,453 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-07 06:51:55,453 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:51:55,804 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            134 pgs backfill_wait
            1 pgs backfilling
            95 pgs stuck unclean
            recovery 37164/141623 objects misplaced (26.242%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20303: 15 osds: 15 up, 15 in; 134 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v76960: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            37164/141623 objects misplaced (26.242%)
                2681 active+clean
                 134 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 06:51:55,804 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:51:55,804 INFO cluster.py [line:239] usefull PG number is 2681
2017-06-07 06:52:55,823 INFO cluster.py [line:247] cost 60 seconds, left 5698 seconds when check the ceph status
2017-06-07 06:52:55,823 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:52:56,190 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            123 pgs backfill_wait
            2 pgs backfilling
            125 pgs stuck unclean
            recovery 34366/140214 objects misplaced (24.510%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20323: 15 osds: 15 up, 15 in; 124 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77034: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            34366/140214 objects misplaced (24.510%)
                2691 active+clean
                 123 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 06:52:56,191 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:52:56,191 INFO cluster.py [line:239] usefull PG number is 2691
2017-06-07 06:53:56,198 INFO cluster.py [line:247] cost 61 seconds, left 5637 seconds when check the ceph status
2017-06-07 06:53:56,198 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:53:56,570 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            103 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            105 pgs stuck unclean
            recovery 28963/137498 objects misplaced (21.064%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20356: 15 osds: 15 up, 15 in; 104 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77122: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            619 GB used, 41848 GB / 42468 GB avail
            28963/137498 objects misplaced (21.064%)
                2710 active+clean
                 103 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 409 MB/s, 102 objects/s

2017-06-07 06:53:56,570 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:53:56,570 INFO cluster.py [line:239] usefull PG number is 2710
2017-06-07 06:54:56,611 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 06:54:56,611 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:54:56,963 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            83 pgs backfill_wait
            2 pgs backfilling
            85 pgs stuck unclean
            recovery 22480/134240 objects misplaced (16.746%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20390: 15 osds: 15 up, 15 in; 85 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77207: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            619 GB used, 41849 GB / 42468 GB avail
            22480/134240 objects misplaced (16.746%)
                2731 active+clean
                  83 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 968 MB/s, 242 objects/s
  client io 220 kB/s rd, 252 op/s rd, 0 op/s wr

2017-06-07 06:54:56,963 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:54:56,963 INFO cluster.py [line:239] usefull PG number is 2731
2017-06-07 06:55:57,011 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 06:55:57,012 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:55:57,414 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            64 pgs backfill_wait
            3 pgs backfilling
            67 pgs stuck unclean
            recovery 17501/131759 objects misplaced (13.283%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20422: 15 osds: 15 up, 15 in; 65 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77288: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            619 GB used, 41849 GB / 42468 GB avail
            17501/131759 objects misplaced (13.283%)
                2749 active+clean
                  64 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 390 MB/s, 97 objects/s

2017-06-07 06:55:57,414 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:55:57,414 INFO cluster.py [line:239] usefull PG number is 2749
2017-06-07 06:56:57,454 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 06:56:57,454 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:56:57,811 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            50 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            51 pgs stuck unclean
            recovery 13434/129692 objects misplaced (10.358%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20446: 15 osds: 15 up, 15 in; 51 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77365: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            13434/129692 objects misplaced (10.358%)
                2764 active+clean
                  50 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
  client io 222 kB/s rd, 222 op/s rd, 0 op/s wr

2017-06-07 06:56:57,811 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:56:57,811 INFO cluster.py [line:239] usefull PG number is 2764
2017-06-07 06:57:57,813 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 06:57:57,813 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:57:58,174 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            43 pgs backfill_wait
            1 pgs backfilling
            44 pgs stuck unclean
            recovery 11633/128839 objects misplaced (9.029%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20461: 15 osds: 15 up, 15 in; 43 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77437: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            11633/128839 objects misplaced (9.029%)
                2772 active+clean
                  43 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 519 MB/s, 129 objects/s
  client io 445 kB/s rd, 445 op/s rd, 0 op/s wr

2017-06-07 06:57:58,174 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:57:58,174 INFO cluster.py [line:239] usefull PG number is 2772
2017-06-07 06:58:58,222 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 06:58:58,223 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:58:58,611 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            34 pgs backfill_wait
            1 pgs backfilling
            1 pgs peering
            35 pgs stuck unclean
            recovery 9396/127682 objects misplaced (7.359%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20478: 15 osds: 15 up, 15 in; 35 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77511: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            9396/127682 objects misplaced (7.359%)
                2780 active+clean
                  34 active+remapped+backfill_wait
                   1 peering
                   1 active+remapped+backfilling
  client io 231 kB/s rd, 231 op/s rd, 0 op/s wr

2017-06-07 06:58:58,611 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:58:58,611 INFO cluster.py [line:239] usefull PG number is 2780
2017-06-07 06:59:58,635 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 06:59:58,635 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 06:59:59,026 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            26 pgs backfill_wait
            2 pgs backfilling
            28 pgs stuck unclean
            recovery 7564/126826 objects misplaced (5.964%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20493: 15 osds: 15 up, 15 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77584: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            618 GB used, 41850 GB / 42468 GB avail
            7564/126826 objects misplaced (5.964%)
                2788 active+clean
                  26 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 398 MB/s, 99 objects/s
  client io 474 kB/s rd, 712 op/s rd, 0 op/s wr

2017-06-07 06:59:59,026 INFO cluster.py [line:238] PG number is 2816
2017-06-07 06:59:59,026 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-07 07:00:59,087 INFO cluster.py [line:247] cost 61 seconds, left 5214 seconds when check the ceph status
2017-06-07 07:00:59,087 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:00:59,455 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            18 pgs backfill_wait
            1 pgs backfilling
            19 pgs stuck unclean
            recovery 4724/125344 objects misplaced (3.769%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20510: 15 osds: 15 up, 15 in; 19 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77657: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            4724/125344 objects misplaced (3.769%)
                2797 active+clean
                  18 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 264 MB/s, 66 objects/s
  client io 245 kB/s rd, 367 op/s rd, 0 op/s wr

2017-06-07 07:00:59,456 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:00:59,456 INFO cluster.py [line:239] usefull PG number is 2797
2017-06-07 07:01:59,486 INFO cluster.py [line:247] cost 60 seconds, left 5154 seconds when check the ceph status
2017-06-07 07:01:59,486 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:01:59,884 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            8 pgs backfill_wait
            8 pgs stuck unclean
            recovery 2118/123993 objects misplaced (1.708%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20532: 15 osds: 15 up, 15 in; 8 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77736: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            617 GB used, 41851 GB / 42468 GB avail
            2118/123993 objects misplaced (1.708%)
                2808 active+clean
                   8 active+remapped+backfill_wait

2017-06-07 07:01:59,884 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:01:59,884 INFO cluster.py [line:239] usefull PG number is 2808
2017-06-07 07:02:59,914 INFO cluster.py [line:247] cost 60 seconds, left 5094 seconds when check the ceph status
2017-06-07 07:02:59,914 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:03:00,286 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 174/123069 objects misplaced (0.141%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20546: 15 osds: 15 up, 15 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77806: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
            174/123069 objects misplaced (0.141%)
                2815 active+clean
                   1 active+remapped+backfilling
recovery io 266 MB/s, 66 objects/s

2017-06-07 07:03:00,286 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:03:00,286 INFO cluster.py [line:239] usefull PG number is 2815
2017-06-07 07:04:00,338 INFO cluster.py [line:247] cost 61 seconds, left 5033 seconds when check the ceph status
2017-06-07 07:04:00,339 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:04:00,741 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20548: 15 osds: 15 up, 15 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77857: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
                2816 active+clean

2017-06-07 07:04:00,741 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:04:00,741 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:04:00,741 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:04:00,741 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme5n1
2017-06-07 07:04:22,860 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:04:22,860 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.2==============
INFO: --- Create osd.2 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:04:22,860 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:04:23,269 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/16 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20550: 16 osds: 15 up, 16 in; 670 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77877: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            616 GB used, 41852 GB / 42468 GB avail
                2816 active+clean

2017-06-07 07:04:23,269 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:04:23,269 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:04:23,269 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:04:23,269 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme1n1
2017-06-07 07:04:45,238 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:04:45,238 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.3==============
INFO: --- Create osd.3 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:04:45,238 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:04:45,626 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            106 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            43 pgs stuck unclean
            recovery 28093/137170 objects misplaced (20.480%)
            1/17 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20569: 17 osds: 16 up, 17 in; 505 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77909: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            626 GB used, 44673 GB / 45300 GB avail
            28093/137170 objects misplaced (20.480%)
                2707 active+clean
                 106 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering

2017-06-07 07:04:45,626 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:04:45,626 INFO cluster.py [line:239] usefull PG number is 2707
2017-06-07 07:05:45,686 INFO cluster.py [line:247] cost 60 seconds, left 5940 seconds when check the ceph status
2017-06-07 07:05:45,687 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:05:46,064 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            163 pgs backfill_wait
            3 pgs backfilling
            126 pgs stuck unclean
            recovery 45367/145737 objects misplaced (31.129%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20603: 17 osds: 17 up, 17 in; 166 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v77990: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47495 GB / 48131 GB avail
            45367/145737 objects misplaced (31.129%)
                2650 active+clean
                 163 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 683 MB/s, 170 objects/s

2017-06-07 07:05:46,064 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:05:46,065 INFO cluster.py [line:239] usefull PG number is 2650
2017-06-07 07:06:46,075 INFO cluster.py [line:247] cost 61 seconds, left 5879 seconds when check the ceph status
2017-06-07 07:06:46,076 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:06:46,448 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            146 pgs backfill_wait
            2 pgs backfilling
            126 pgs stuck unclean
            recovery 40839/143460 objects misplaced (28.467%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20631: 17 osds: 17 up, 17 in; 148 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78071: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47496 GB / 48131 GB avail
            40839/143460 objects misplaced (28.467%)
                2668 active+clean
                 146 active+remapped+backfill_wait
                   2 active+remapped+backfilling

2017-06-07 07:06:46,448 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:06:46,448 INFO cluster.py [line:239] usefull PG number is 2668
2017-06-07 07:07:46,478 INFO cluster.py [line:247] cost 60 seconds, left 5819 seconds when check the ceph status
2017-06-07 07:07:46,478 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:07:46,873 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            129 pgs backfill_wait
            2 pgs backfilling
            1 pgs peering
            120 pgs stuck unclean
            recovery 36206/141075 objects misplaced (25.664%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20659: 17 osds: 17 up, 17 in; 131 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78150: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            36206/141075 objects misplaced (25.664%)
                2684 active+clean
                 129 active+remapped+backfill_wait
                   2 active+remapped+backfilling
                   1 peering
recovery io 292 MB/s, 73 objects/s

2017-06-07 07:07:46,873 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:07:46,873 INFO cluster.py [line:239] usefull PG number is 2684
2017-06-07 07:08:46,934 INFO cluster.py [line:247] cost 60 seconds, left 5759 seconds when check the ceph status
2017-06-07 07:08:46,934 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:08:47,345 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            112 pgs backfill_wait
            2 pgs backfilling
            104 pgs stuck unclean
            recovery 31277/138650 objects misplaced (22.558%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20687: 17 osds: 17 up, 17 in; 113 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78233: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            635 GB used, 47496 GB / 48131 GB avail
            31277/138650 objects misplaced (22.558%)
                2702 active+clean
                 112 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 405 MB/s, 101 objects/s
  client io 362 kB/s rd, 362 op/s rd, 0 op/s wr

2017-06-07 07:08:47,346 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:08:47,346 INFO cluster.py [line:239] usefull PG number is 2702
2017-06-07 07:09:47,404 INFO cluster.py [line:247] cost 61 seconds, left 5698 seconds when check the ceph status
2017-06-07 07:09:47,404 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:09:47,784 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            97 pgs backfill_wait
            3 pgs backfilling
            100 pgs stuck unclean
            recovery 27004/136679 objects misplaced (19.757%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20715: 17 osds: 17 up, 17 in; 98 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78317: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            27004/136679 objects misplaced (19.757%)
                2716 active+clean
                  97 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 1525 MB/s, 381 objects/s
  client io 440 kB/s rd, 440 op/s rd, 0 op/s wr

2017-06-07 07:09:47,785 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:09:47,785 INFO cluster.py [line:239] usefull PG number is 2716
2017-06-07 07:10:47,845 INFO cluster.py [line:247] cost 60 seconds, left 5638 seconds when check the ceph status
2017-06-07 07:10:47,845 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:10:48,230 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            71 pgs backfill_wait
            3 pgs backfilling
            74 pgs stuck unclean
            recovery 18928/132447 objects misplaced (14.291%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20754: 17 osds: 17 up, 17 in; 74 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78407: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            18928/132447 objects misplaced (14.291%)
                2742 active+clean
                  71 active+remapped+backfill_wait
                   3 active+remapped+backfilling
recovery io 468 MB/s, 117 objects/s
  client io 284 kB/s rd, 322 op/s rd, 0 op/s wr

2017-06-07 07:10:48,230 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:10:48,230 INFO cluster.py [line:239] usefull PG number is 2742
2017-06-07 07:11:48,278 INFO cluster.py [line:247] cost 61 seconds, left 5577 seconds when check the ceph status
2017-06-07 07:11:48,279 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:11:48,686 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            46 pgs backfill_wait
            3 pgs backfilling
            1 pgs peering
            49 pgs stuck unclean
            recovery 12099/129061 objects misplaced (9.375%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20791: 17 osds: 17 up, 17 in; 49 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78494: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            636 GB used, 47495 GB / 48131 GB avail
            12099/129061 objects misplaced (9.375%)
                2766 active+clean
                  46 active+remapped+backfill_wait
                   3 active+remapped+backfilling
                   1 peering
recovery io 267 MB/s, 66 objects/s
  client io 577 kB/s rd, 745 op/s rd, 0 op/s wr

2017-06-07 07:11:48,687 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:11:48,687 INFO cluster.py [line:239] usefull PG number is 2766
2017-06-07 07:12:48,745 INFO cluster.py [line:247] cost 60 seconds, left 5517 seconds when check the ceph status
2017-06-07 07:12:48,745 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:12:49,122 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            26 pgs backfill_wait
            1 pgs backfilling
            28 pgs stuck unclean
            recovery 6609/126400 objects misplaced (5.229%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20828: 17 osds: 17 up, 17 in; 27 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78579: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            6609/126400 objects misplaced (5.229%)
                2788 active+clean
                  26 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 468 MB/s, 117 objects/s
  client io 460 kB/s rd, 690 op/s rd, 0 op/s wr

2017-06-07 07:12:49,122 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:12:49,123 INFO cluster.py [line:239] usefull PG number is 2788
2017-06-07 07:13:49,151 INFO cluster.py [line:247] cost 61 seconds, left 5456 seconds when check the ceph status
2017-06-07 07:13:49,151 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:13:49,529 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            17 pgs backfill_wait
            1 pgs backfilling
            18 pgs stuck unclean
            recovery 4259/125082 objects misplaced (3.405%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20846: 17 osds: 17 up, 17 in; 18 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78654: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            4259/125082 objects misplaced (3.405%)
                2798 active+clean
                  17 active+remapped+backfill_wait
                   1 active+remapped+backfilling
  client io 327 kB/s rd, 490 op/s rd, 0 op/s wr

2017-06-07 07:13:49,530 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:13:49,530 INFO cluster.py [line:239] usefull PG number is 2798
2017-06-07 07:14:49,590 INFO cluster.py [line:247] cost 60 seconds, left 5396 seconds when check the ceph status
2017-06-07 07:14:49,590 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:14:49,966 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            9 pgs backfill_wait
            1 pgs backfilling
            10 pgs stuck unclean
            recovery 2324/124123 objects misplaced (1.872%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20862: 17 osds: 17 up, 17 in; 10 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78725: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            2324/124123 objects misplaced (1.872%)
                2806 active+clean
                   9 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 217 MB/s, 54 objects/s
  client io 341 kB/s rd, 512 op/s rd, 0 op/s wr

2017-06-07 07:14:49,966 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:14:49,966 INFO cluster.py [line:239] usefull PG number is 2806
2017-06-07 07:15:50,013 INFO cluster.py [line:247] cost 61 seconds, left 5335 seconds when check the ceph status
2017-06-07 07:15:50,014 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:15:50,389 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 238/123073 objects misplaced (0.193%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20878: 17 osds: 17 up, 17 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78799: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47496 GB / 48131 GB avail
            238/123073 objects misplaced (0.193%)
                2815 active+clean
                   1 active+remapped+backfilling
  client io 236 kB/s rd, 354 op/s rd, 0 op/s wr

2017-06-07 07:15:50,389 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:15:50,389 INFO cluster.py [line:239] usefull PG number is 2815
2017-06-07 07:16:50,394 INFO cluster.py [line:247] cost 60 seconds, left 5275 seconds when check the ceph status
2017-06-07 07:16:50,394 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:16:50,788 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20880: 17 osds: 17 up, 17 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78850: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
                2816 active+clean
  client io 238 kB/s rd, 357 op/s rd, 0 op/s wr

2017-06-07 07:16:50,789 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:16:50,789 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:16:50,789 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:16:50,789 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme4n1
2017-06-07 07:17:12,428 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:17:12,428 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.4==============
INFO: --- Create osd.4 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:17:12,428 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:17:12,803 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/18 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20882: 18 osds: 17 up, 18 in; 576 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78871: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            634 GB used, 47497 GB / 48131 GB avail
                2816 active+clean

2017-06-07 07:17:12,804 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:17:12,804 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:17:12,804 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:17:12,804 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme7n1
2017-06-07 07:17:34,992 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:17:34,992 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.5==============
INFO: --- Create osd.5 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:17:34,992 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:17:35,379 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            88 pgs backfill_wait
            5 pgs backfilling
            66 pgs stuck unclean
            recovery 25343/135810 objects misplaced (18.661%)
            1/19 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20904: 19 osds: 18 up, 19 in; 597 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78907: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            644 GB used, 50318 GB / 50962 GB avail
            25343/135810 objects misplaced (18.661%)
                2723 active+clean
                  88 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 736 MB/s, 184 objects/s

2017-06-07 07:17:35,379 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:17:35,379 INFO cluster.py [line:239] usefull PG number is 2723
2017-06-07 07:18:35,420 INFO cluster.py [line:247] cost 61 seconds, left 5939 seconds when check the ceph status
2017-06-07 07:18:35,420 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:18:35,810 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            123 pgs backfill_wait
            5 pgs backfilling
            90 pgs stuck unclean
            recovery 34644/140443 objects misplaced (24.668%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20950: 19 osds: 19 up, 19 in; 126 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v78995: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            653 GB used, 53140 GB / 53794 GB avail
            34644/140443 objects misplaced (24.668%)
                2688 active+clean
                 123 active+remapped+backfill_wait
                   5 active+remapped+backfilling

2017-06-07 07:18:35,811 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:18:35,811 INFO cluster.py [line:239] usefull PG number is 2688
2017-06-07 07:19:35,853 INFO cluster.py [line:247] cost 60 seconds, left 5879 seconds when check the ceph status
2017-06-07 07:19:35,853 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:19:36,230 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            107 pgs backfill_wait
            1 pgs backfilling
            84 pgs stuck unclean
            recovery 28922/137448 objects misplaced (21.042%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e20978: 19 osds: 19 up, 19 in; 108 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79072: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            28922/137448 objects misplaced (21.042%)
                2708 active+clean
                 107 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 07:19:36,230 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:19:36,230 INFO cluster.py [line:239] usefull PG number is 2708
2017-06-07 07:20:36,270 INFO cluster.py [line:247] cost 61 seconds, left 5818 seconds when check the ceph status
2017-06-07 07:20:36,270 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:20:36,620 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            92 pgs backfill_wait
            5 pgs backfilling
            79 pgs stuck unclean
            recovery 25619/135881 objects misplaced (18.854%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21001: 19 osds: 19 up, 19 in; 95 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79154: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            653 GB used, 53140 GB / 53794 GB avail
            25619/135881 objects misplaced (18.854%)
                2719 active+clean
                  92 active+remapped+backfill_wait
                   5 active+remapped+backfilling
recovery io 532 MB/s, 133 objects/s

2017-06-07 07:20:36,621 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:20:36,621 INFO cluster.py [line:239] usefull PG number is 2719
2017-06-07 07:21:36,651 INFO cluster.py [line:247] cost 60 seconds, left 5758 seconds when check the ceph status
2017-06-07 07:21:36,652 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:21:37,068 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            79 pgs backfill_wait
            1 pgs backfilling
            65 pgs stuck unclean
            recovery 21759/133857 objects misplaced (16.255%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21025: 19 osds: 19 up, 19 in; 80 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79235: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            21759/133857 objects misplaced (16.255%)
                2736 active+clean
                  79 active+remapped+backfill_wait
                   1 active+remapped+backfilling

2017-06-07 07:21:37,068 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:21:37,068 INFO cluster.py [line:239] usefull PG number is 2736
2017-06-07 07:22:37,114 INFO cluster.py [line:247] cost 61 seconds, left 5697 seconds when check the ceph status
2017-06-07 07:22:37,114 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:22:37,471 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            69 pgs backfill_wait
            1 pgs backfilling
            71 pgs stuck unclean
            recovery 18917/132492 objects misplaced (14.278%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21041: 19 osds: 19 up, 19 in; 70 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79303: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            653 GB used, 53140 GB / 53794 GB avail
            18917/132492 objects misplaced (14.278%)
                2745 active+clean
                  69 active+remapped+backfill_wait
                   1 active+remapped
                   1 active+remapped+backfilling
recovery io 262 MB/s, 65 objects/s

2017-06-07 07:22:37,472 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:22:37,472 INFO cluster.py [line:239] usefull PG number is 2745
2017-06-07 07:23:37,490 INFO cluster.py [line:247] cost 60 seconds, left 5637 seconds when check the ceph status
2017-06-07 07:23:37,490 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:23:37,853 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            50 pgs backfill_wait
            4 pgs backfilling
            54 pgs stuck unclean
            recovery 14525/130291 objects misplaced (11.148%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21070: 19 osds: 19 up, 19 in; 53 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79384: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            14525/130291 objects misplaced (11.148%)
                2762 active+clean
                  50 active+remapped+backfill_wait
                   4 active+remapped+backfilling
recovery io 316 MB/s, 79 objects/s
  client io 1135 kB/s rd, 1470 op/s rd, 0 op/s wr

2017-06-07 07:23:37,853 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:23:37,854 INFO cluster.py [line:239] usefull PG number is 2762
2017-06-07 07:24:37,899 INFO cluster.py [line:247] cost 60 seconds, left 5577 seconds when check the ceph status
2017-06-07 07:24:37,899 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:24:38,267 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            27 pgs backfill_wait
            2 pgs backfilling
            29 pgs stuck unclean
            recovery 7850/126965 objects misplaced (6.183%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21105: 19 osds: 19 up, 19 in; 28 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79462: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            652 GB used, 53141 GB / 53794 GB avail
            7850/126965 objects misplaced (6.183%)
                2787 active+clean
                  27 active+remapped+backfill_wait
                   2 active+remapped+backfilling
recovery io 482 MB/s, 120 objects/s
  client io 1056 kB/s rd, 1369 op/s rd, 0 op/s wr

2017-06-07 07:24:38,289 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:24:38,289 INFO cluster.py [line:239] usefull PG number is 2787
2017-06-07 07:25:38,309 INFO cluster.py [line:247] cost 61 seconds, left 5516 seconds when check the ceph status
2017-06-07 07:25:38,309 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:25:38,727 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            11 pgs backfill_wait
            1 pgs backfilling
            12 pgs stuck unclean
            recovery 3189/124574 objects misplaced (2.560%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21131: 19 osds: 19 up, 19 in; 12 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79539: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            3189/124574 objects misplaced (2.560%)
                2804 active+clean
                  11 active+remapped+backfill_wait
                   1 active+remapped+backfilling
recovery io 251 MB/s, 62 objects/s
  client io 341 kB/s rd, 511 op/s rd, 0 op/s wr

2017-06-07 07:25:38,727 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:25:38,727 INFO cluster.py [line:239] usefull PG number is 2804
2017-06-07 07:26:38,787 INFO cluster.py [line:247] cost 60 seconds, left 5456 seconds when check the ceph status
2017-06-07 07:26:38,787 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:26:39,226 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1 pgs backfilling
            1 pgs stuck unclean
            recovery 229/123057 objects misplaced (0.186%)
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21153: 19 osds: 19 up, 19 in; 1 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79614: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
            229/123057 objects misplaced (0.186%)
                2814 active+clean
                   1 active+remapped+backfilling
                   1 activating
recovery io 184 MB/s, 46 objects/s
  client io 270 kB/s rd, 406 op/s rd, 0 op/s wr

2017-06-07 07:26:39,226 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:26:39,226 INFO cluster.py [line:239] usefull PG number is 2814
2017-06-07 07:27:39,242 INFO cluster.py [line:247] cost 61 seconds, left 5395 seconds when check the ceph status
2017-06-07 07:27:39,242 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:27:39,647 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_OK
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21155: 19 osds: 19 up, 19 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79658: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
                2816 active+clean

2017-06-07 07:27:39,647 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:27:39,647 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:27:39,648 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:27:39,648 INFO node.py [line:205] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/changeCommon.sh nvme3n1
2017-06-07 07:28:01,524 INFO node.py [line:212] execute command is sudo -i /usr/local/bin/scripts/create_cluster_scripts/bluestore/create_osds_local.sh -f 
2017-06-07 07:28:01,525 INFO node.py [line:213] NFO: osd_num_in_each_disk=1
INFO: ============osd.6==============
INFO: --- Create osd.6 OK ---
Reslut:Create osd on ubuntu-A successfully.
Detail:
stdin: is not a tty

2017-06-07 07:28:01,525 INFO cluster.py [line:211] execute command is ceph -s
2017-06-07 07:28:01,903 INFO cluster.py [line:213]    cluster 5fa3b8d7-2669-4a31-8093-71436230038b
     health HEALTH_WARN
            1/20 in osds are down
     monmap e3: 3 mons at {ubuntu-A=192.168.40.170:6789/0,ubuntu-B=192.168.40.171:6789/0,ubuntu-C=192.168.40.172:6789/0}
            election epoch 14, quorum 0,1,2 ubuntu-A,ubuntu-B,ubuntu-C
     osdmap e21157: 20 osds: 19 up, 20 in; 489 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v79675: 2816 pgs, 10 pools, 240 GB data, 61467 objects
            651 GB used, 53142 GB / 53794 GB avail
                2816 active+clean

2017-06-07 07:28:01,903 INFO cluster.py [line:238] PG number is 2816
2017-06-07 07:28:01,904 INFO cluster.py [line:239] usefull PG number is 2816
2017-06-07 07:28:01,904 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:83] osd.6 create succesfully
2017-06-07 07:28:04,014 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:96] all osd need to create on node ubuntu-A create succesfully
2017-06-07 07:28:04,296 INFO client.py [line:172] ['enali    6179  6177  0 23:28 ?        00:00:00 bash -c sudo -i ps -ef | grep fio ', 'denali    6181  6179  0 23:28 ?        00:00:00 grep fio', 'root     22289     1  0 Jun05 ?        00:00:00 sudo -i fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'root     22291 22289 20 Jun05 ?        05:02:29 fio -direct=1 -iodepth_batch_complete=1 -ioengine=rbd -clientname=client112 -pool=reliablityTestPool -rbdname=client112rbdImg4 -rw=randwrite -bs=8K -size=500G -norandommap=1 -randrepeat=0 -verify=md5 -verify_fatal=1 -verify_dump=1 -do_verify=1 -overwrite=1 -iodepth=256 -name=client112rbdImg4', 'stdin: is not a tty', '']
2017-06-07 07:28:04,296 INFO client.py [line:174] IO is running
2017-06-07 07:28:04,562 INFO TC47_48_49_50_51_remove_osds_on_single_node.py [line:102] case runs complete
