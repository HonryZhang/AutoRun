2017-05-24 12:12:40,969 INFO TC39_shutdown_osd_on_single_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. stop all osds in sequence
4. start all osds in sequence
5. check the cluster status
6. repeat step 2-5 on the other node

2017-05-24 12:12:40,970 INFO TC39_shutdown_osd_on_single_node.py [line:25] the timeout is 6000
2017-05-24 12:12:43,605 INFO monitors.py [line:123]    "quorum_leader_name": "denali01",

2017-05-24 12:12:43,609 INFO monitors.py [line:126]    "quorum_leader_name": "denali01",
2017-05-24 12:12:43,615 INFO TC39_shutdown_osd_on_single_node.py [line:31] start to check cluster status before case running
2017-05-24 12:12:43,727 INFO cluster.py [line:203] execute command is ceph -s
2017-05-24 12:12:44,457 INFO cluster.py [line:205]    cluster 012dd832-3b17-4cb0-b763-c71908a82dda
     health HEALTH_ERR
            69 pgs are stuck inactive for more than 300 seconds
            33 pgs backfill_wait
            3 pgs backfilling
            36 pgs degraded
            69 pgs down
            69 pgs peering
            69 pgs stuck inactive
            36 pgs stuck unclean
            36 pgs undersized
            recovery 6287/173415 objects degraded (3.625%)
            recovery 9872/173415 objects misplaced (5.693%)
     monmap e3: 3 mons at {denali01=192.168.28.26:6789/0,denali02=192.168.28.33:6789/0,denali03=192.168.28.34:6789/0}
            election epoch 18, quorum 0,1,2 denali01,denali02,denali03
     osdmap e2008: 9 osds: 8 up, 8 in; 92 remapped pgs
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v104965: 3016 pgs, 13 pools, 322 GB data, 85570 objects
            63734 MB used, 238 GB / 301 GB avail
            6287/173415 objects degraded (3.625%)
            9872/173415 objects misplaced (5.693%)
                2911 active+clean
                  52 down+remapped+peering
                  33 active+undersized+degraded+remapped+backfill_wait
                  17 down+peering
                   3 active+undersized+degraded+remapped+backfilling
recovery io 16027 kB/s, 10 objects/s

2017-05-24 12:12:44,482 INFO cluster.py [line:207] Now status is HEALTH_ERR, sleep 60s and try again 
