2017-05-24 14:09:33,096 INFO TC39_shutdown_osd_on_single_node.py [line:24] 
This test case will do the following steps:
1. start IO on 10 images with randwrite and verify
2. login the first node 
3. stop all osds in sequence
4. start all osds in sequence
5. check the cluster status
6. repeat step 2-5 on the other node

2017-05-24 14:09:33,096 INFO TC39_shutdown_osd_on_single_node.py [line:25] the timeout is 6000
2017-05-24 14:09:34,994 INFO monitors.py [line:123]    "quorum_leader_name": "denali01",

2017-05-24 14:09:34,994 INFO monitors.py [line:126]    "quorum_leader_name": "denali01",
2017-05-24 14:09:34,994 INFO TC39_shutdown_osd_on_single_node.py [line:31] start to check cluster status before case running
2017-05-24 14:09:35,056 INFO cluster.py [line:203] execute command is ceph -s
2017-05-24 14:09:35,976 INFO cluster.py [line:205]    cluster 06eb5bdc-13bc-4ee0-bcb3-b3881e7eef0a
     health HEALTH_OK
     monmap e3: 3 mons at {denali01=192.168.28.26:6789/0,denali02=192.168.28.33:6789/0,denali03=192.168.28.34:6789/0}
            election epoch 6, quorum 0,1,2 denali01,denali02,denali03
     osdmap e67: 9 osds: 9 up, 9 in
            flags sortbitwise,require_jewel_osds,require_kraken_osds
      pgmap v363: 2504 pgs, 12 pools, 2032 bytes data, 205 objects
            13633 MB used, 325 GB / 338 GB avail
                2504 active+clean

2017-05-24 14:09:35,976 INFO cluster.py [line:230] PG number is 2504
2017-05-24 14:09:35,976 INFO cluster.py [line:231] usefull PG number is 2504
2017-05-24 14:09:35,993 INFO TC39_shutdown_osd_on_single_node.py [line:34] health status is OK
2017-05-24 14:09:35,993 INFO TC39_shutdown_osd_on_single_node.py [line:39] 
Step 1: start IO from clients
2017-05-24 14:09:35,993 INFO base.py [line:35] 
Now start IO on  clientrbdImg0
